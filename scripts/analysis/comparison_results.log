[I 2025-09-17 13:15:04,446] A new study created in memory with name: no-name-e73be507-6ed0-45f1-be2a-f8e202094416
[I 2025-09-17 13:15:04,456] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.25186293256435743, 'feature_fraction': 0.8916523378732706, 'bagging_fraction': 0.9457420070054112, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:04,464] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 244, 'learning_rate': 0.21627774630565344, 'feature_fraction': 0.5862399546851145, 'bagging_fraction': 0.44062947050302004, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:04,470] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 224, 'learning_rate': 0.1379254167733372, 'feature_fraction': 0.6507611818655825, 'bagging_fraction': 0.7767997799749121, 'bagging_freq': 1, 'min_child_samples': 71}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:04,475] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 34, 'learning_rate': 0.20400919317688124, 'feature_fraction': 0.5026356419339651, 'bagging_fraction': 0.8269316334110186, 'bagging_freq': 1, 'min_child_samples': 74}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:04,483] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.04404391673366328, 'feature_fraction': 0.5156507230137557, 'bagging_fraction': 0.6515741934233423, 'bagging_freq': 7, 'min_child_samples': 69}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:04,491] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 66, 'learning_rate': 0.2734310181651018, 'feature_fraction': 0.926931831143869, 'bagging_fraction': 0.4448268262882478, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:04,499] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 292, 'learning_rate': 0.18343732479208638, 'feature_fraction': 0.797568326998568, 'bagging_fraction': 0.7752984117969364, 'bagging_freq': 6, 'min_child_samples': 68}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:04,507] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 31, 'learning_rate': 0.0486940042679635, 'feature_fraction': 0.6821663607601679, 'bagging_fraction': 0.427830770198796, 'bagging_freq': 1, 'min_child_samples': 92}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:04,540] Trial 8 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 169, 'learning_rate': 0.27716691045777425, 'feature_fraction': 0.6760098923999948, 'bagging_fraction': 0.7637157329900603, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 8 with value: 0.8253968253968254.
[I 2025-09-17 13:15:04,555] Trial 9 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 217, 'learning_rate': 0.28809896051443235, 'feature_fraction': 0.4602925820459145, 'bagging_fraction': 0.8616213267942485, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 8 with value: 0.8253968253968254.
[I 2025-09-17 13:15:04,627] Trial 10 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 115, 'learning_rate': 0.10525497716516519, 'feature_fraction': 0.7876368042898073, 'bagging_fraction': 0.6197911781506766, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 8 with value: 0.8253968253968254.
[I 2025-09-17 13:15:04,666] Trial 11 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 179, 'learning_rate': 0.29277472407483174, 'feature_fraction': 0.407195116878188, 'bagging_fraction': 0.9962323054330512, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 8 with value: 0.8253968253968254.
[I 2025-09-17 13:15:04,693] Trial 12 finished with value: 0.761904761904762 and parameters: {'num_leaves': 200, 'learning_rate': 0.2445623441587807, 'feature_fraction': 0.41948941950935503, 'bagging_fraction': 0.8772289128944148, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 8 with value: 0.8253968253968254.
[I 2025-09-17 13:15:04,740] Trial 13 finished with value: 0.873015873015873 and parameters: {'num_leaves': 119, 'learning_rate': 0.2841637370775032, 'feature_fraction': 0.7707146038197046, 'bagging_fraction': 0.7213169547707043, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:04,815] Trial 14 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 115, 'learning_rate': 0.2330799775856644, 'feature_fraction': 0.7770624357539987, 'bagging_fraction': 0.5952648728439996, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:04,881] Trial 15 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 116, 'learning_rate': 0.1592231085933771, 'feature_fraction': 0.787974447404149, 'bagging_fraction': 0.5630763080785397, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:04,905] Trial 16 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 113, 'learning_rate': 0.23245442084469137, 'feature_fraction': 0.8722183240492234, 'bagging_fraction': 0.5427673752049479, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:04,932] Trial 17 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 82, 'learning_rate': 0.18751446051997733, 'feature_fraction': 0.9998884682861928, 'bagging_fraction': 0.6990792760536008, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:04,962] Trial 18 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 136, 'learning_rate': 0.10112387616180948, 'feature_fraction': 0.7281534328996346, 'bagging_fraction': 0.5213972903376872, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:04,984] Trial 19 finished with value: 0.7896825396825398 and parameters: {'num_leaves': 79, 'learning_rate': 0.262810981209931, 'feature_fraction': 0.835596017715142, 'bagging_fraction': 0.624245780502725, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,030] Trial 20 finished with value: 0.7321428571428571 and parameters: {'num_leaves': 142, 'learning_rate': 0.22843969602357558, 'feature_fraction': 0.5949899755229551, 'bagging_fraction': 0.6621968758250718, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,065] Trial 21 finished with value: 0.8531746031746031 and parameters: {'num_leaves': 138, 'learning_rate': 0.10068249470787999, 'feature_fraction': 0.7324258810015292, 'bagging_fraction': 0.5220292604826582, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,094] Trial 22 finished with value: 0.8174603174603176 and parameters: {'num_leaves': 95, 'learning_rate': 0.08460496786712611, 'feature_fraction': 0.7350109333541025, 'bagging_fraction': 0.49594668669800934, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,108] Trial 23 finished with value: 0.5992063492063493 and parameters: {'num_leaves': 57, 'learning_rate': 0.1353221906027472, 'feature_fraction': 0.7251757101095414, 'bagging_fraction': 0.5751167876209518, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,173] Trial 24 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 143, 'learning_rate': 0.015139046492501834, 'feature_fraction': 0.6128259541465771, 'bagging_fraction': 0.7183107732316305, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,245] Trial 25 finished with value: 0.75 and parameters: {'num_leaves': 194, 'learning_rate': 0.15975709815908418, 'feature_fraction': 0.7662514572297526, 'bagging_fraction': 0.48050460663788014, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,266] Trial 26 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 105, 'learning_rate': 0.2975477729887549, 'feature_fraction': 0.8425118652895978, 'bagging_fraction': 0.575201207687276, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,287] Trial 27 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 10, 'learning_rate': 0.08270616493577362, 'feature_fraction': 0.943326479011211, 'bagging_fraction': 0.7187799930615792, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,302] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 133, 'learning_rate': 0.12667039801881724, 'feature_fraction': 0.831184275921033, 'bagging_fraction': 0.6269408769610143, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,334] Trial 29 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 170, 'learning_rate': 0.25516366182636496, 'feature_fraction': 0.6295704553928549, 'bagging_fraction': 0.4057460370350277, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,346] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 153, 'learning_rate': 0.18360022757430916, 'feature_fraction': 0.9020417362992947, 'bagging_fraction': 0.5993286750791255, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,374] Trial 31 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 131, 'learning_rate': 0.10174729578517554, 'feature_fraction': 0.731758408606809, 'bagging_fraction': 0.516893256499684, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,399] Trial 32 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 124, 'learning_rate': 0.06326252796787546, 'feature_fraction': 0.7619255563132894, 'bagging_fraction': 0.49371881473523815, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,437] Trial 33 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 91, 'learning_rate': 0.11358439990138765, 'feature_fraction': 0.7083572891645025, 'bagging_fraction': 0.5262322200058519, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,455] Trial 34 finished with value: 0.7678571428571429 and parameters: {'num_leaves': 155, 'learning_rate': 0.21171636331294286, 'feature_fraction': 0.6627920151379806, 'bagging_fraction': 0.4643591463188972, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,473] Trial 35 finished with value: 0.5496031746031746 and parameters: {'num_leaves': 61, 'learning_rate': 0.07966365605917669, 'feature_fraction': 0.5675139639959607, 'bagging_fraction': 0.6663483144633773, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,509] Trial 36 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 97, 'learning_rate': 0.12387711241096303, 'feature_fraction': 0.7574735850234467, 'bagging_fraction': 0.5462672988196994, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,520] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 186, 'learning_rate': 0.14615614146414851, 'feature_fraction': 0.8198220524815012, 'bagging_fraction': 0.695642334206307, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,563] Trial 38 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 129, 'learning_rate': 0.030369603026480563, 'feature_fraction': 0.6448862454683945, 'bagging_fraction': 0.6039766440789833, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,576] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 153, 'learning_rate': 0.060919790656990304, 'feature_fraction': 0.6998286480066104, 'bagging_fraction': 0.7540311131842561, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,589] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 256, 'learning_rate': 0.1969958565815753, 'feature_fraction': 0.8694345486183186, 'bagging_fraction': 0.4369495347335592, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,618] Trial 41 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 140, 'learning_rate': 0.104143250723946, 'feature_fraction': 0.7363996723231376, 'bagging_fraction': 0.5191158719724062, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,639] Trial 42 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 125, 'learning_rate': 0.10189745173104015, 'feature_fraction': 0.7066247122082266, 'bagging_fraction': 0.5146321865558773, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,703] Trial 43 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 167, 'learning_rate': 0.1666679670452403, 'feature_fraction': 0.7980945917016051, 'bagging_fraction': 0.8038693721189523, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,722] Trial 44 finished with value: 0.7261904761904763 and parameters: {'num_leaves': 106, 'learning_rate': 0.2756536530403407, 'feature_fraction': 0.6783990520796973, 'bagging_fraction': 0.45202023319969936, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,774] Trial 45 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 76, 'learning_rate': 0.09202351036936546, 'feature_fraction': 0.5576353465580809, 'bagging_fraction': 0.5858967942892301, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,797] Trial 46 finished with value: 0.75 and parameters: {'num_leaves': 216, 'learning_rate': 0.06884756387247373, 'feature_fraction': 0.7611759416279862, 'bagging_fraction': 0.5490309260069447, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,827] Trial 47 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 48, 'learning_rate': 0.048440212365788986, 'feature_fraction': 0.8111420182244707, 'bagging_fraction': 0.6415402221746328, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,857] Trial 48 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 111, 'learning_rate': 0.11972059676698696, 'feature_fraction': 0.7382768851639171, 'bagging_fraction': 0.47721247699292685, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:05,901] Trial 49 finished with value: 0.7083333333333334 and parameters: {'num_leaves': 178, 'learning_rate': 0.22932649965244656, 'feature_fraction': 0.6898799943990702, 'bagging_fraction': 0.6771666157249555, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 13 with value: 0.873015873015873.
[I 2025-09-17 13:15:06,110] A new study created in memory with name: no-name-bc14ff52-25d1-4bc5-9563-eec2433c10ac
[I 2025-09-17 13:15:06,128] Trial 0 finished with value: 0.5515873015873016 and parameters: {'num_leaves': 21, 'learning_rate': 0.26260115401731216, 'feature_fraction': 0.49803860425791885, 'bagging_fraction': 0.559168950861505, 'bagging_freq': 2, 'min_child_samples': 37}. Best is trial 0 with value: 0.5515873015873016.
[I 2025-09-17 13:15:06,140] Trial 1 finished with value: 0.7956349206349207 and parameters: {'num_leaves': 123, 'learning_rate': 0.0819907136483774, 'feature_fraction': 0.4421760059980548, 'bagging_fraction': 0.7159913997487293, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 1 with value: 0.7956349206349207.
[I 2025-09-17 13:15:06,145] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.06049678289496645, 'feature_fraction': 0.5608047357538446, 'bagging_fraction': 0.6199399444102603, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 1 with value: 0.7956349206349207.
[I 2025-09-17 13:15:06,154] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 253, 'learning_rate': 0.24067643301614836, 'feature_fraction': 0.7191920494270405, 'bagging_fraction': 0.5408084264495712, 'bagging_freq': 7, 'min_child_samples': 53}. Best is trial 1 with value: 0.7956349206349207.
[I 2025-09-17 13:15:06,168] Trial 4 finished with value: 0.7757936507936508 and parameters: {'num_leaves': 64, 'learning_rate': 0.14980499082964005, 'feature_fraction': 0.8102938452910591, 'bagging_fraction': 0.9337972067709401, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 1 with value: 0.7956349206349207.
[I 2025-09-17 13:15:06,186] Trial 5 finished with value: 0.7797619047619048 and parameters: {'num_leaves': 201, 'learning_rate': 0.1933232366784828, 'feature_fraction': 0.6733853518812626, 'bagging_fraction': 0.7279831911802288, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 1 with value: 0.7956349206349207.
[I 2025-09-17 13:15:06,215] Trial 6 finished with value: 0.8234126984126984 and parameters: {'num_leaves': 141, 'learning_rate': 0.23391726391899734, 'feature_fraction': 0.47981701617827527, 'bagging_fraction': 0.5456721030870648, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 6 with value: 0.8234126984126984.
[I 2025-09-17 13:15:06,226] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 12, 'learning_rate': 0.2165039126080814, 'feature_fraction': 0.48588705639702917, 'bagging_fraction': 0.8992813070771966, 'bagging_freq': 7, 'min_child_samples': 70}. Best is trial 6 with value: 0.8234126984126984.
=== COMPARING DATASETS WITH DIFFERENT NORMALIZATION ===

1. Training models on full 216-feature dataset (user-wise normalized)...
Training model for P024... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.525096
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.550598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.57682
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.558704
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.580776
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.478823
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.485133
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.56152
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.604195
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.575639
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.56024
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.594076
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.599942
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.551028
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.539505
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.635757
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.606543
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.585884
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.56841
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.568979
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.567297
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.560469
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.594261
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.574115
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.595289
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.674533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.55048
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.610312
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.575624
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.594842
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.608807
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.609886
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.556451
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.605298
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.589602
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.5754
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.625731
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.613334
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.622449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.628927
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.576254
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.529948
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:06,234] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 293, 'learning_rate': 0.2967892774867587, 'feature_fraction': 0.49796077829616275, 'bagging_fraction': 0.8692916960356409, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 6 with value: 0.8234126984126984.
[I 2025-09-17 13:15:06,252] Trial 9 finished with value: 0.8273809523809524 and parameters: {'num_leaves': 286, 'learning_rate': 0.07936626426667957, 'feature_fraction': 0.8493057848187171, 'bagging_fraction': 0.6550193309667367, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 9 with value: 0.8273809523809524.
[I 2025-09-17 13:15:06,301] Trial 10 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 300, 'learning_rate': 0.012706658284345404, 'feature_fraction': 0.9894397091323847, 'bagging_fraction': 0.4330275512888717, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 9 with value: 0.8273809523809524.
[I 2025-09-17 13:15:06,344] Trial 11 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 130, 'learning_rate': 0.14432785681177657, 'feature_fraction': 0.9161410993609025, 'bagging_fraction': 0.4246735393628591, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 9 with value: 0.8273809523809524.
[I 2025-09-17 13:15:06,366] Trial 12 finished with value: 0.8412698412698412 and parameters: {'num_leaves': 184, 'learning_rate': 0.10184444814285275, 'feature_fraction': 0.8459181840071037, 'bagging_fraction': 0.6376275400982, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 12 with value: 0.8412698412698412.
[I 2025-09-17 13:15:06,390] Trial 13 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 222, 'learning_rate': 0.09766883990112157, 'feature_fraction': 0.8402259830644726, 'bagging_fraction': 0.7979932246733834, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,412] Trial 14 finished with value: 0.7956349206349206 and parameters: {'num_leaves': 191, 'learning_rate': 0.11438910569376297, 'feature_fraction': 0.7930756555812161, 'bagging_fraction': 0.7961253167603544, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,467] Trial 15 finished with value: 0.75 and parameters: {'num_leaves': 240, 'learning_rate': 0.02977242078739213, 'feature_fraction': 0.7121838328611527, 'bagging_fraction': 0.8026196090556602, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,487] Trial 16 finished with value: 0.7480158730158731 and parameters: {'num_leaves': 232, 'learning_rate': 0.11417261587817112, 'feature_fraction': 0.9237499717239573, 'bagging_fraction': 0.9951449470663316, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,516] Trial 17 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 101, 'learning_rate': 0.11268948266237391, 'feature_fraction': 0.6343200785345823, 'bagging_fraction': 0.7794001522548736, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,528] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 170, 'learning_rate': 0.17368152160508238, 'feature_fraction': 0.8694346925414116, 'bagging_fraction': 0.622957989956826, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,551] Trial 19 finished with value: 0.8313492063492063 and parameters: {'num_leaves': 174, 'learning_rate': 0.044348070509424235, 'feature_fraction': 0.7654861352582739, 'bagging_fraction': 0.8460679323869733, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,563] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 222, 'learning_rate': 0.0841439181716507, 'feature_fraction': 0.9843408575870112, 'bagging_fraction': 0.6857001824160884, 'bagging_freq': 2, 'min_child_samples': 91}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,585] Trial 21 finished with value: 0.7996031746031746 and parameters: {'num_leaves': 167, 'learning_rate': 0.02315462606386449, 'feature_fraction': 0.7804478679114881, 'bagging_fraction': 0.8248892210723925, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,608] Trial 22 finished with value: 0.8095238095238094 and parameters: {'num_leaves': 174, 'learning_rate': 0.05787762471306458, 'feature_fraction': 0.7593577231656237, 'bagging_fraction': 0.7459328572726379, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,662] Trial 23 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 261, 'learning_rate': 0.05046253240470393, 'feature_fraction': 0.8611106345389388, 'bagging_fraction': 0.8448164798589686, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,692] Trial 24 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 209, 'learning_rate': 0.12419478261426144, 'feature_fraction': 0.6156144155815652, 'bagging_fraction': 0.9464941123760163, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,712] Trial 25 finished with value: 0.5873015873015873 and parameters: {'num_leaves': 159, 'learning_rate': 0.08503795386845946, 'feature_fraction': 0.9179641183426256, 'bagging_fraction': 0.7652466665250335, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,740] Trial 26 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 92, 'learning_rate': 0.04143350669845966, 'feature_fraction': 0.7508956510659575, 'bagging_fraction': 0.8680990323831659, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,756] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.09709295728691088, 'feature_fraction': 0.8286214917444327, 'bagging_fraction': 0.6849451678985969, 'bagging_freq': 5, 'min_child_samples': 61}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,787] Trial 28 finished with value: 0.6468253968253967 and parameters: {'num_leaves': 265, 'learning_rate': 0.13545913954085406, 'feature_fraction': 0.8922348239623898, 'bagging_fraction': 0.49534581271381495, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,803] Trial 29 finished with value: 0.6150793650793651 and parameters: {'num_leaves': 220, 'learning_rate': 0.17896346120489512, 'feature_fraction': 0.95297404807335, 'bagging_fraction': 0.5961826682033207, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,831] Trial 30 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 40, 'learning_rate': 0.061320221837572304, 'feature_fraction': 0.6759978452793911, 'bagging_fraction': 0.9069507808585433, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,858] Trial 31 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 280, 'learning_rate': 0.07353897021329714, 'feature_fraction': 0.8437071916862428, 'bagging_fraction': 0.6588225858101859, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,877] Trial 32 finished with value: 0.8214285714285715 and parameters: {'num_leaves': 244, 'learning_rate': 0.09937768672763621, 'feature_fraction': 0.8214386634018626, 'bagging_fraction': 0.647923588329882, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,915] Trial 33 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 152, 'learning_rate': 0.037006122842017326, 'feature_fraction': 0.7465634069688913, 'bagging_fraction': 0.7074908238226495, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,929] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 275, 'learning_rate': 0.06611951849181937, 'feature_fraction': 0.8911870318029689, 'bagging_fraction': 0.5871242599800337, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,950] Trial 35 finished with value: 0.49007936507936506 and parameters: {'num_leaves': 115, 'learning_rate': 0.09362084055913282, 'feature_fraction': 0.7993835487543065, 'bagging_fraction': 0.51784248877722, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:06,974] Trial 36 finished with value: 0.8174603174603176 and parameters: {'num_leaves': 215, 'learning_rate': 0.0764285922108791, 'feature_fraction': 0.8648125340480582, 'bagging_fraction': 0.7339367443845681, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:07,010] Trial 37 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 182, 'learning_rate': 0.16318332862344048, 'feature_fraction': 0.7366317680645967, 'bagging_fraction': 0.6542235993470893, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:07,177] Trial 38 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 141, 'learning_rate': 0.13198267884572132, 'feature_fraction': 0.5570498352203626, 'bagging_fraction': 0.7602397341322384, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 13 with value: 0.8452380952380952.
[I 2025-09-17 13:15:07,297] Trial 39 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 77, 'learning_rate': 0.14138722369286452, 'feature_fraction': 0.4134612456406627, 'bagging_fraction': 0.8251212705548376, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 39 with value: 0.8492063492063492.
[I 2025-09-17 13:15:07,339] Trial 40 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 38, 'learning_rate': 0.1990019440064562, 'feature_fraction': 0.5360596419306928, 'bagging_fraction': 0.8337289160936874, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 39 with value: 0.8492063492063492.
[I 2025-09-17 13:15:07,417] Trial 41 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 79, 'learning_rate': 0.13286027756955504, 'feature_fraction': 0.5829218402074888, 'bagging_fraction': 0.7707134235643551, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 39 with value: 0.8492063492063492.
[I 2025-09-17 13:15:07,542] Trial 42 finished with value: 0.8690476190476191 and parameters: {'num_leaves': 142, 'learning_rate': 0.15765378144947373, 'feature_fraction': 0.4347451219098158, 'bagging_fraction': 0.8733940093516194, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 42 with value: 0.8690476190476191.
[I 2025-09-17 13:15:07,606] Trial 43 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 62, 'learning_rate': 0.1453896086515971, 'feature_fraction': 0.4219587209659719, 'bagging_fraction': 0.8886072346814772, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 42 with value: 0.8690476190476191.
[I 2025-09-17 13:15:07,663] Trial 44 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 68, 'learning_rate': 0.154249344929822, 'feature_fraction': 0.4307463791536884, 'bagging_fraction': 0.9423668239753841, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 42 with value: 0.8690476190476191.
[I 2025-09-17 13:15:07,730] Trial 45 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 63, 'learning_rate': 0.1520022623219467, 'feature_fraction': 0.4008244578680882, 'bagging_fraction': 0.9303795800374544, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 42 with value: 0.8690476190476191.
[I 2025-09-17 13:15:07,801] Trial 46 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 61, 'learning_rate': 0.19714154574366263, 'feature_fraction': 0.44342643814687666, 'bagging_fraction': 0.9667828485521481, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 42 with value: 0.8690476190476191.
[I 2025-09-17 13:15:07,863] Trial 47 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 35, 'learning_rate': 0.1578374271204569, 'feature_fraction': 0.4018191294135463, 'bagging_fraction': 0.8991064132012146, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 42 with value: 0.8690476190476191.
[I 2025-09-17 13:15:07,990] Trial 48 finished with value: 0.8968253968253969 and parameters: {'num_leaves': 75, 'learning_rate': 0.18182032600971956, 'feature_fraction': 0.4477220637658868, 'bagging_fraction': 0.8812010697038335, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 48 with value: 0.8968253968253969.
[I 2025-09-17 13:15:08,108] Trial 49 finished with value: 0.9087301587301588 and parameters: {'num_leaves': 111, 'learning_rate': 0.21337961108610787, 'feature_fraction': 0.45441427538189627, 'bagging_fraction': 0.8807036453840641, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 49 with value: 0.9087301587301588.
[I 2025-09-17 13:15:08,571] A new study created in memory with name: no-name-ab3ad174-518b-42fa-8809-5aacf76290c8
[I 2025-09-17 13:15:08,580] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 282, 'learning_rate': 0.2615033560837052, 'feature_fraction': 0.6136994073293782, 'bagging_fraction': 0.7233543531902209, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:08,592] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 222, 'learning_rate': 0.2273007754404039, 'feature_fraction': 0.7354626598108542, 'bagging_fraction': 0.7313040235639785, 'bagging_freq': 7, 'min_child_samples': 51}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:08,601] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 130, 'learning_rate': 0.2361716558761102, 'feature_fraction': 0.900433568416778, 'bagging_fraction': 0.8751641389646851, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:08,650] Trial 3 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 43, 'learning_rate': 0.01221768176616489, 'feature_fraction': 0.8550452557346253, 'bagging_fraction': 0.6180438888741071, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 3 with value: 0.7619047619047619.
[I 2025-09-17 13:15:08,680] Trial 4 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 273, 'learning_rate': 0.04797445671806762, 'feature_fraction': 0.8359431550328047, 'bagging_fraction': 0.6809660466139731, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 4 with value: 0.8015873015873016.
[I 2025-09-17 13:15:08,686] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 288, 'learning_rate': 0.21786727293191466, 'feature_fraction': 0.5095135114730134, 'bagging_fraction': 0.8631685601795089, 'bagging_freq': 1, 'min_child_samples': 64}. Best is trial 4 with value: 0.8015873015873016.
[I 2025-09-17 13:15:08,712] Trial 6 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 282, 'learning_rate': 0.1616698391490549, 'feature_fraction': 0.817502750118045, 'bagging_fraction': 0.6213762352165548, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 4 with value: 0.8015873015873016.
[I 2025-09-17 13:15:08,720] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 294, 'learning_rate': 0.2276066577728554, 'feature_fraction': 0.6673012419064368, 'bagging_fraction': 0.7368744461630006, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 4 with value: 0.8015873015873016.
[I 2025-09-17 13:15:08,739] Trial 8 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 75, 'learning_rate': 0.13287835737743275, 'feature_fraction': 0.7830991746802807, 'bagging_fraction': 0.8088988919251208, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 4 with value: 0.8015873015873016.
[I 2025-09-17 13:15:08,760] Trial 9 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 267, 'learning_rate': 0.1357555667224539, 'feature_fraction': 0.6425579738480991, 'bagging_fraction': 0.9226843607466201, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 4 with value: 0.8015873015873016.
[I 2025-09-17 13:15:08,834] Trial 10 finished with value: 0.8452380952380953 and parameters: {'num_leaves': 189, 'learning_rate': 0.01004133073440501, 'feature_fraction': 0.9898520642158186, 'bagging_fraction': 0.4172200446983807, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:08,910] Trial 11 finished with value: 0.7857142857142856 and parameters: {'num_leaves': 190, 'learning_rate': 0.010112729164656914, 'feature_fraction': 0.9816808406124764, 'bagging_fraction': 0.457435869901073, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:08,934] Trial 12 finished with value: 0.7380952380952381 and parameters: {'num_leaves': 143, 'learning_rate': 0.06332224351049659, 'feature_fraction': 0.9550473615043858, 'bagging_fraction': 0.4059276591329485, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,015] Trial 13 finished with value: 0.761904761904762 and parameters: {'num_leaves': 218, 'learning_rate': 0.07033239837269115, 'feature_fraction': 0.888506533948648, 'bagging_fraction': 0.546307214115091, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,044] Trial 14 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 179, 'learning_rate': 0.0651235119080416, 'feature_fraction': 0.9929466222236375, 'bagging_fraction': 0.9957983628889651, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,074] Trial 15 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 231, 'learning_rate': 0.08988756182694091, 'feature_fraction': 0.9109030424304392, 'bagging_fraction': 0.525995824223222, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,087] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 111, 'learning_rate': 0.040149196343888305, 'feature_fraction': 0.41222964025477116, 'bagging_fraction': 0.6184340682874008, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 10 with value: 0.8452380952380953.
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.579514
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.616951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.588292
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.583909
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.577807
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.601368
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.605107
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.630263
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.600227
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.60965
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.632288
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.5986
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.596515
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.597134
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.653961
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.593305
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.635336
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.652093
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.602088
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.589917
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.595693
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.626583
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.685402
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.589221
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.572412
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.553733
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.525861
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.537933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.593834
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.481421
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.519504
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.517768
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.521811
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.585054
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.528283
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.454063
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.438856
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.591986
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.527357
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.548423
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.530544
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.526143
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.546819
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.567626
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.586446
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.554846
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.546643
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.571632
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:09,102] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.1002872254640839, 'feature_fraction': 0.8160473501907038, 'bagging_fraction': 0.5038772005554224, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,129] Trial 18 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 185, 'learning_rate': 0.18531870116225851, 'feature_fraction': 0.7338023920257039, 'bagging_fraction': 0.6581160707813566, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,164] Trial 19 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 179, 'learning_rate': 0.1787722032702208, 'feature_fraction': 0.5761654399477002, 'bagging_fraction': 0.4017773599381756, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,183] Trial 20 finished with value: 0.6805555555555556 and parameters: {'num_leaves': 107, 'learning_rate': 0.2979499845104808, 'feature_fraction': 0.7272679324857811, 'bagging_fraction': 0.579013350014988, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,216] Trial 21 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 209, 'learning_rate': 0.18876416036909394, 'feature_fraction': 0.7666208113730132, 'bagging_fraction': 0.6725150074320423, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 10 with value: 0.8452380952380953.
[I 2025-09-17 13:15:09,262] Trial 22 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 183, 'learning_rate': 0.1968652024891133, 'feature_fraction': 0.7704162764275917, 'bagging_fraction': 0.7734319318218035, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,313] Trial 23 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 156, 'learning_rate': 0.19728310981767894, 'feature_fraction': 0.775287833854422, 'bagging_fraction': 0.7969117523084036, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,353] Trial 24 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 203, 'learning_rate': 0.13650700053963963, 'feature_fraction': 0.5522642584997483, 'bagging_fraction': 0.7755740694953454, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,408] Trial 25 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 164, 'learning_rate': 0.26406056813040557, 'feature_fraction': 0.9368297064889045, 'bagging_fraction': 0.46986170763171686, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,434] Trial 26 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 243, 'learning_rate': 0.16267708186078877, 'feature_fraction': 0.6725096194598151, 'bagging_fraction': 0.8831913111216413, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,444] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.11085270210919457, 'feature_fraction': 0.7749184956171447, 'bagging_fraction': 0.9755397682744988, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,479] Trial 28 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 127, 'learning_rate': 0.20333975153690978, 'feature_fraction': 0.865924042881648, 'bagging_fraction': 0.8250202320406401, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,528] Trial 29 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 259, 'learning_rate': 0.2587982032625298, 'feature_fraction': 0.4496483087682341, 'bagging_fraction': 0.7446068766830779, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,551] Trial 30 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 200, 'learning_rate': 0.2568986509909479, 'feature_fraction': 0.612592289507225, 'bagging_fraction': 0.6929654896646552, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,574] Trial 31 finished with value: 0.8253968253968255 and parameters: {'num_leaves': 170, 'learning_rate': 0.18619189814583859, 'feature_fraction': 0.7298620013535613, 'bagging_fraction': 0.6538891184924812, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,595] Trial 32 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 220, 'learning_rate': 0.18474552540443384, 'feature_fraction': 0.7047530487344962, 'bagging_fraction': 0.6674326298602562, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,607] Trial 33 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.20570848004157688, 'feature_fraction': 0.7599903600456618, 'bagging_fraction': 0.7660103881853467, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,651] Trial 34 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 151, 'learning_rate': 0.15615960017265934, 'feature_fraction': 0.7071103312868507, 'bagging_fraction': 0.5861704576946369, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,695] Trial 35 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 144, 'learning_rate': 0.14916711894099077, 'feature_fraction': 0.6849567232595787, 'bagging_fraction': 0.7141171080609271, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,733] Trial 36 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 25, 'learning_rate': 0.11823789580013518, 'feature_fraction': 0.6285016336463615, 'bagging_fraction': 0.551947998747119, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,776] Trial 37 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 93, 'learning_rate': 0.17121671927037077, 'feature_fraction': 0.815934244968594, 'bagging_fraction': 0.578043494788174, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,803] Trial 38 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 142, 'learning_rate': 0.23891429476934084, 'feature_fraction': 0.8673252970483801, 'bagging_fraction': 0.49758707044857764, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,839] Trial 39 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 237, 'learning_rate': 0.15958123367059845, 'feature_fraction': 0.49468931231990243, 'bagging_fraction': 0.5922813609389022, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,875] Trial 40 finished with value: 0.8373015873015873 and parameters: {'num_leaves': 73, 'learning_rate': 0.14640765684439389, 'feature_fraction': 0.5871665080753126, 'bagging_fraction': 0.4384189019491566, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,897] Trial 41 finished with value: 0.8253968253968255 and parameters: {'num_leaves': 160, 'learning_rate': 0.2115992645486709, 'feature_fraction': 0.7494990417810362, 'bagging_fraction': 0.6379910606632915, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,945] Trial 42 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 196, 'learning_rate': 0.22460159349906, 'feature_fraction': 0.7014790805627766, 'bagging_fraction': 0.6891464663656294, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:09,958] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 208, 'learning_rate': 0.19034695669310742, 'feature_fraction': 0.7941994852833151, 'bagging_fraction': 0.7136715407146258, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:10,044] Trial 44 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 173, 'learning_rate': 0.17124947202188168, 'feature_fraction': 0.656624555208956, 'bagging_fraction': 0.657288427767332, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:10,065] Trial 45 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 125, 'learning_rate': 0.23683666297071504, 'feature_fraction': 0.8346938103182987, 'bagging_fraction': 0.8547152103055571, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 22 with value: 0.8650793650793651.
[I 2025-09-17 13:15:10,093] Trial 46 finished with value: 0.8730158730158729 and parameters: {'num_leaves': 186, 'learning_rate': 0.17240037329635444, 'feature_fraction': 0.7108802016364775, 'bagging_fraction': 0.75865980813896, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 46 with value: 0.8730158730158729.
[I 2025-09-17 13:15:10,131] Trial 47 finished with value: 0.8174603174603176 and parameters: {'num_leaves': 218, 'learning_rate': 0.13337165367050885, 'feature_fraction': 0.7035545426736817, 'bagging_fraction': 0.7379135582307743, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 46 with value: 0.8730158730158729.
[I 2025-09-17 13:15:10,161] Trial 48 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 150, 'learning_rate': 0.11935630626481387, 'feature_fraction': 0.9221781547499005, 'bagging_fraction': 0.8413249488258379, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 46 with value: 0.8730158730158729.
[I 2025-09-17 13:15:10,184] Trial 49 finished with value: 0.7936507936507935 and parameters: {'num_leaves': 228, 'learning_rate': 0.024261932642916637, 'feature_fraction': 0.9597143656216461, 'bagging_fraction': 0.7780991261077894, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 46 with value: 0.8730158730158729.
[I 2025-09-17 13:15:10,461] A new study created in memory with name: no-name-494f0000-56a0-469a-9fae-7f2cc18646dc
[I 2025-09-17 13:15:10,469] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 81, 'learning_rate': 0.2869942987969083, 'feature_fraction': 0.6039445616988873, 'bagging_fraction': 0.9015947570245079, 'bagging_freq': 7, 'min_child_samples': 69}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:10,475] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 147, 'learning_rate': 0.18888586059070236, 'feature_fraction': 0.7505918556186828, 'bagging_fraction': 0.91327234534355, 'bagging_freq': 1, 'min_child_samples': 77}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:10,509] Trial 2 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 45, 'learning_rate': 0.18518319319042065, 'feature_fraction': 0.6717874433530668, 'bagging_fraction': 0.9745155934859039, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,540] Trial 3 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 18, 'learning_rate': 0.12889434182859333, 'feature_fraction': 0.9741482946352013, 'bagging_fraction': 0.6267076336373308, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,562] Trial 4 finished with value: 0.7658730158730159 and parameters: {'num_leaves': 259, 'learning_rate': 0.01216675860852138, 'feature_fraction': 0.6830136600673271, 'bagging_fraction': 0.4744872742704674, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,594] Trial 5 finished with value: 0.8293650793650794 and parameters: {'num_leaves': 288, 'learning_rate': 0.11434408473285086, 'feature_fraction': 0.7882941334362732, 'bagging_fraction': 0.9185480052240501, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,618] Trial 6 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 232, 'learning_rate': 0.2696551888693861, 'feature_fraction': 0.9678974529854811, 'bagging_fraction': 0.614847267165399, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,640] Trial 7 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 80, 'learning_rate': 0.14522727920619352, 'feature_fraction': 0.8806966756064463, 'bagging_fraction': 0.4280475330770197, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,649] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 84, 'learning_rate': 0.10092227021253566, 'feature_fraction': 0.9503560643459683, 'bagging_fraction': 0.7949065556529044, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,658] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 205, 'learning_rate': 0.27477302067150383, 'feature_fraction': 0.7172451903853466, 'bagging_fraction': 0.9492468714784705, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,683] Trial 10 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 13, 'learning_rate': 0.20568320312135036, 'feature_fraction': 0.5060548292059661, 'bagging_fraction': 0.7895078694969023, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,710] Trial 11 finished with value: 0.8373015873015873 and parameters: {'num_leaves': 22, 'learning_rate': 0.20727803043382498, 'feature_fraction': 0.41700256132700303, 'bagging_fraction': 0.7858122242602811, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,807] Trial 12 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 10, 'learning_rate': 0.21363504286627133, 'feature_fraction': 0.4885783087886117, 'bagging_fraction': 0.7866237781920689, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 2 with value: 0.8571428571428572.
[I 2025-09-17 13:15:10,831] Trial 13 finished with value: 0.9047619047619049 and parameters: {'num_leaves': 137, 'learning_rate': 0.2313464552662569, 'feature_fraction': 0.5826060498470208, 'bagging_fraction': 0.9861419780834063, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 13 with value: 0.9047619047619049.
[I 2025-09-17 13:15:10,853] Trial 14 finished with value: 0.7896825396825398 and parameters: {'num_leaves': 152, 'learning_rate': 0.24147993521643157, 'feature_fraction': 0.6190024016793148, 'bagging_fraction': 0.9974632787156108, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 13 with value: 0.9047619047619049.
[I 2025-09-17 13:15:10,882] Trial 15 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 109, 'learning_rate': 0.07304857664327735, 'feature_fraction': 0.5844262170939076, 'bagging_fraction': 0.9970871301369688, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:10,911] Trial 16 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 126, 'learning_rate': 0.07187040166197417, 'feature_fraction': 0.5515512552027234, 'bagging_fraction': 0.8648950134745712, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:10,927] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.031165163060344565, 'feature_fraction': 0.4026221851667354, 'bagging_fraction': 0.6806492378864983, 'bagging_freq': 3, 'min_child_samples': 52}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:10,947] Trial 18 finished with value: 0.7083333333333334 and parameters: {'num_leaves': 106, 'learning_rate': 0.06112884232857842, 'feature_fraction': 0.5923881770227287, 'bagging_fraction': 0.8655696000777442, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:10,976] Trial 19 finished with value: 0.8531746031746033 and parameters: {'num_leaves': 183, 'learning_rate': 0.1596662957950781, 'feature_fraction': 0.48552840602332303, 'bagging_fraction': 0.9969808182354435, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,054] Trial 20 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 114, 'learning_rate': 0.08296071526563835, 'feature_fraction': 0.8250827907467613, 'bagging_fraction': 0.7195655853897198, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,091] Trial 21 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 53, 'learning_rate': 0.17018761789545972, 'feature_fraction': 0.6787157181517236, 'bagging_fraction': 0.9995971430909674, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,141] Trial 22 finished with value: 0.8611111111111112 and parameters: {'num_leaves': 59, 'learning_rate': 0.22976368739155098, 'feature_fraction': 0.6306594838223402, 'bagging_fraction': 0.9485821526943659, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,164] Trial 23 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 132, 'learning_rate': 0.24035806546948232, 'feature_fraction': 0.5534623215606195, 'bagging_fraction': 0.8548806017428264, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,218] Trial 24 finished with value: 0.8412698412698414 and parameters: {'num_leaves': 58, 'learning_rate': 0.2444931398913244, 'feature_fraction': 0.634279244944712, 'bagging_fraction': 0.9428854823348044, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 15 with value: 0.9285714285714286.
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.487969
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.578082
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.623184
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.49236
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.504748
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.530088
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.544079
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.575401
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.5252
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.524858
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.553369
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.539346
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.495592
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.635369
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.491862
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.533226
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.511839
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.533005
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.509738
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.539178
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.513776
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.496162
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.540931
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.551575
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.535298
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.470447
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.528587
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.498137
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.56518
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.503345
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.540247
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.622512
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.538192
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.537736
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.550673
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.512818
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.522905
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.608127
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.479394
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.536556
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.474966
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.522497
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.638893
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.489222
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.474339
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.523862
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.456274
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.523474
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.488313
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:11,247] Trial 25 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 107, 'learning_rate': 0.22544702774091904, 'feature_fraction': 0.5470619347327703, 'bagging_fraction': 0.8481538460454017, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,273] Trial 26 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 174, 'learning_rate': 0.04341053355239992, 'feature_fraction': 0.638789346929063, 'bagging_fraction': 0.9477498717476409, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,285] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 90, 'learning_rate': 0.258338781354171, 'feature_fraction': 0.4490990271940045, 'bagging_fraction': 0.5352461798191611, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,320] Trial 28 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 44, 'learning_rate': 0.29948091588589965, 'feature_fraction': 0.7387013718322778, 'bagging_fraction': 0.8967916210771918, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,430] Trial 29 finished with value: 0.748015873015873 and parameters: {'num_leaves': 69, 'learning_rate': 0.18405625696765826, 'feature_fraction': 0.5890398175042616, 'bagging_fraction': 0.895585493733741, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,446] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 130, 'learning_rate': 0.1480577921888268, 'feature_fraction': 0.5263319898432117, 'bagging_fraction': 0.7383563637217412, 'bagging_freq': 7, 'min_child_samples': 79}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,510] Trial 31 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 93, 'learning_rate': 0.1822240938034254, 'feature_fraction': 0.6615621097414748, 'bagging_fraction': 0.9668245621051014, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,565] Trial 32 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 98, 'learning_rate': 0.22119574220380123, 'feature_fraction': 0.5903889447332741, 'bagging_fraction': 0.9598956914117306, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,610] Trial 33 finished with value: 0.8611111111111112 and parameters: {'num_leaves': 71, 'learning_rate': 0.19382658344076914, 'feature_fraction': 0.6494155170150712, 'bagging_fraction': 0.9273547991692621, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,672] Trial 34 finished with value: 0.873015873015873 and parameters: {'num_leaves': 164, 'learning_rate': 0.1713293139476127, 'feature_fraction': 0.781105744475201, 'bagging_fraction': 0.968455473253082, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,699] Trial 35 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 163, 'learning_rate': 0.1265238966296447, 'feature_fraction': 0.7814307313950458, 'bagging_fraction': 0.8220594329104827, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,757] Trial 36 finished with value: 0.8492063492063493 and parameters: {'num_leaves': 142, 'learning_rate': 0.16552631629471676, 'feature_fraction': 0.8544003006934004, 'bagging_fraction': 0.9014974097211101, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,784] Trial 37 finished with value: 0.876984126984127 and parameters: {'num_leaves': 156, 'learning_rate': 0.18039883030735832, 'feature_fraction': 0.7147364908657796, 'bagging_fraction': 0.97422516316849, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,808] Trial 38 finished with value: 0.9087301587301587 and parameters: {'num_leaves': 221, 'learning_rate': 0.19145388819904471, 'feature_fraction': 0.7060763913437819, 'bagging_fraction': 0.9086826533296165, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,832] Trial 39 finished with value: 0.8611111111111112 and parameters: {'num_leaves': 228, 'learning_rate': 0.1311639560076995, 'feature_fraction': 0.6797778999713627, 'bagging_fraction': 0.9189599726828156, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,847] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 282, 'learning_rate': 0.11049408403508568, 'feature_fraction': 0.6623331779788771, 'bagging_fraction': 0.5754525485632422, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,870] Trial 41 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 207, 'learning_rate': 0.19094044855361691, 'feature_fraction': 0.7059243251893186, 'bagging_fraction': 0.9833641436961795, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,880] Trial 42 finished with value: 0.5 and parameters: {'num_leaves': 267, 'learning_rate': 0.199227173589394, 'feature_fraction': 0.7281624115905255, 'bagging_fraction': 0.9721165505510403, 'bagging_freq': 4, 'min_child_samples': 63}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,906] Trial 43 finished with value: 0.8690476190476191 and parameters: {'num_leaves': 237, 'learning_rate': 0.17574382328186167, 'feature_fraction': 0.7595996605118818, 'bagging_fraction': 0.8872987739681022, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,935] Trial 44 finished with value: 0.8531746031746033 and parameters: {'num_leaves': 115, 'learning_rate': 0.1409475896611382, 'feature_fraction': 0.6920914603817996, 'bagging_fraction': 0.9257310692255774, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:11,982] Trial 45 finished with value: 0.8412698412698414 and parameters: {'num_leaves': 197, 'learning_rate': 0.2559230914076962, 'feature_fraction': 0.5822595912065569, 'bagging_fraction': 0.9697360895425522, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:12,016] Trial 46 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 140, 'learning_rate': 0.1845194530818148, 'feature_fraction': 0.9267258695678932, 'bagging_fraction': 0.8321789288101615, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:12,068] Trial 47 finished with value: 0.8293650793650794 and parameters: {'num_leaves': 299, 'learning_rate': 0.2128923586798072, 'feature_fraction': 0.6149082622763193, 'bagging_fraction': 0.9235752388071852, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:12,082] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 153, 'learning_rate': 0.1496128467906364, 'feature_fraction': 0.7124620669611008, 'bagging_fraction': 0.6738607990249588, 'bagging_freq': 3, 'min_child_samples': 61}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:12,096] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 121, 'learning_rate': 0.09613174285282644, 'feature_fraction': 0.5704287126174121, 'bagging_fraction': 0.41539488081239817, 'bagging_freq': 4, 'min_child_samples': 73}. Best is trial 15 with value: 0.9285714285714286.
[I 2025-09-17 13:15:12,440] A new study created in memory with name: no-name-e7418e5e-03d0-4a3c-a1e5-3e941baaa92f
[I 2025-09-17 13:15:12,469] Trial 0 finished with value: 0.7222222222222223 and parameters: {'num_leaves': 191, 'learning_rate': 0.12574402161619763, 'feature_fraction': 0.9355706606887321, 'bagging_fraction': 0.8172094973434256, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,479] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 37, 'learning_rate': 0.2912233727056535, 'feature_fraction': 0.6827627120092858, 'bagging_fraction': 0.9377265807010835, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,491] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 65, 'learning_rate': 0.21837547612887032, 'feature_fraction': 0.6238193124338771, 'bagging_fraction': 0.5879543496197406, 'bagging_freq': 1, 'min_child_samples': 61}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,515] Trial 3 finished with value: 0.6309523809523809 and parameters: {'num_leaves': 218, 'learning_rate': 0.2786788186578269, 'feature_fraction': 0.8928385389901579, 'bagging_fraction': 0.6082042718236202, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,524] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 293, 'learning_rate': 0.1809192716086348, 'feature_fraction': 0.9624421898808406, 'bagging_fraction': 0.5654484954841387, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,565] Trial 5 finished with value: 0.6746031746031746 and parameters: {'num_leaves': 247, 'learning_rate': 0.19035104071194586, 'feature_fraction': 0.44023604175425624, 'bagging_fraction': 0.9344908523804002, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,581] Trial 6 finished with value: 0.623015873015873 and parameters: {'num_leaves': 259, 'learning_rate': 0.25712147362281756, 'feature_fraction': 0.9335375037627255, 'bagging_fraction': 0.6779235822647751, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,600] Trial 7 finished with value: 0.7003968253968254 and parameters: {'num_leaves': 200, 'learning_rate': 0.18228113656314907, 'feature_fraction': 0.5520092197321459, 'bagging_fraction': 0.6803712177769015, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,610] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 151, 'learning_rate': 0.2684993711024746, 'feature_fraction': 0.42975998309583147, 'bagging_fraction': 0.7458459123301264, 'bagging_freq': 7, 'min_child_samples': 63}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,620] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 248, 'learning_rate': 0.09329776946011904, 'feature_fraction': 0.4294146177313908, 'bagging_fraction': 0.8935905488226497, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,634] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 119, 'learning_rate': 0.023220999446000798, 'feature_fraction': 0.777510995097098, 'bagging_fraction': 0.40386450231877014, 'bagging_freq': 1, 'min_child_samples': 41}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,661] Trial 11 finished with value: 0.6626984126984128 and parameters: {'num_leaves': 189, 'learning_rate': 0.11685605368703202, 'feature_fraction': 0.570437266931344, 'bagging_fraction': 0.794586444793467, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,683] Trial 12 finished with value: 0.6706349206349207 and parameters: {'num_leaves': 171, 'learning_rate': 0.13873915576767756, 'feature_fraction': 0.8351808129039511, 'bagging_fraction': 0.8015110550925877, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,748] Trial 13 finished with value: 0.6626984126984128 and parameters: {'num_leaves': 107, 'learning_rate': 0.06550597319115178, 'feature_fraction': 0.5444108629054634, 'bagging_fraction': 0.6754934508892193, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,771] Trial 14 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 200, 'learning_rate': 0.15459921712223854, 'feature_fraction': 0.7488114448210562, 'bagging_fraction': 0.8410712404392535, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,827] Trial 15 finished with value: 0.376984126984127 and parameters: {'num_leaves': 137, 'learning_rate': 0.2166587114888923, 'feature_fraction': 0.997170655710699, 'bagging_fraction': 0.4908018462294602, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 0 with value: 0.7222222222222223.
[I 2025-09-17 13:15:12,846] Trial 16 finished with value: 0.7242063492063493 and parameters: {'num_leaves': 79, 'learning_rate': 0.07716497578153081, 'feature_fraction': 0.5291675995775126, 'bagging_fraction': 0.7335523770211007, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:12,860] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 91, 'learning_rate': 0.05265799213942793, 'feature_fraction': 0.6729082843163553, 'bagging_fraction': 0.8556362437614495, 'bagging_freq': 3, 'min_child_samples': 60}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:12,878] Trial 18 finished with value: 0.7123015873015874 and parameters: {'num_leaves': 26, 'learning_rate': 0.10015882634397713, 'feature_fraction': 0.8515986295146424, 'bagging_fraction': 0.7456453291769362, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:12,889] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 75, 'learning_rate': 0.06959155622345248, 'feature_fraction': 0.48767528737789323, 'bagging_fraction': 0.9921150492473454, 'bagging_freq': 4, 'min_child_samples': 81}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:12,910] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 57, 'learning_rate': 0.018789372490606276, 'feature_fraction': 0.7650739134320892, 'bagging_fraction': 0.7443227203594324, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:12,944] Trial 21 finished with value: 0.6825396825396827 and parameters: {'num_leaves': 20, 'learning_rate': 0.10103914859704288, 'feature_fraction': 0.8589684299543374, 'bagging_fraction': 0.7509796218360426, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:12,964] Trial 22 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 36, 'learning_rate': 0.11888030865021483, 'feature_fraction': 0.8417596968236807, 'bagging_fraction': 0.7955949818683176, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:12,998] Trial 23 finished with value: 0.6984126984126985 and parameters: {'num_leaves': 57, 'learning_rate': 0.1337169844559624, 'feature_fraction': 0.9299696552416541, 'bagging_fraction': 0.8219350958024343, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,021] Trial 24 finished with value: 0.7003968253968254 and parameters: {'num_leaves': 123, 'learning_rate': 0.04580452885805705, 'feature_fraction': 0.8074956131516836, 'bagging_fraction': 0.8829186397982476, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,038] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 98, 'learning_rate': 0.08306183232450695, 'feature_fraction': 0.6231390827879437, 'bagging_fraction': 0.7880845208200496, 'bagging_freq': 2, 'min_child_samples': 68}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,054] Trial 26 finished with value: 0.7023809523809523 and parameters: {'num_leaves': 43, 'learning_rate': 0.12311360777016467, 'feature_fraction': 0.7267347465195751, 'bagging_fraction': 0.6355272096922713, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,078] Trial 27 finished with value: 0.6607142857142857 and parameters: {'num_leaves': 158, 'learning_rate': 0.15330634301128548, 'feature_fraction': 0.9270140611978148, 'bagging_fraction': 0.7122826065143625, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,095] Trial 28 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 12, 'learning_rate': 0.11398723923188162, 'feature_fraction': 0.8794069745458526, 'bagging_fraction': 0.9290107852242715, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,114] Trial 29 finished with value: 0.6884920634920635 and parameters: {'num_leaves': 38, 'learning_rate': 0.08211315630139612, 'feature_fraction': 0.6843743134664138, 'bagging_fraction': 0.8783505495296691, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,125] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 88, 'learning_rate': 0.048056154288160194, 'feature_fraction': 0.9942000898590014, 'bagging_fraction': 0.9735972625259732, 'bagging_freq': 3, 'min_child_samples': 72}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,151] Trial 31 finished with value: 0.6547619047619048 and parameters: {'num_leaves': 27, 'learning_rate': 0.10351563602044128, 'feature_fraction': 0.8136672677565808, 'bagging_fraction': 0.7227871228846309, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,180] Trial 32 finished with value: 0.6984126984126984 and parameters: {'num_leaves': 45, 'learning_rate': 0.14223019163864736, 'feature_fraction': 0.8951377351679362, 'bagging_fraction': 0.7906229055399394, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,199] Trial 33 finished with value: 0.7023809523809524 and parameters: {'num_leaves': 79, 'learning_rate': 0.08264252865469052, 'feature_fraction': 0.839716099303663, 'bagging_fraction': 0.6347276839526597, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 16 with value: 0.7242063492063493.
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.520614
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.559451
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.493388
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.612857
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.418138
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.515375
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.487855
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.46035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.507006
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.490697
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.473012
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.480142
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.492779
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.495966
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.503428
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.510161
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.491708
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.509518
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.506819
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.603247
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.664408
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.636733
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.66541
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.628991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.650277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.635881
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.649003
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.631112
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.751936
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.626796
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.645089
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.633932
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.648097
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.628251
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.639543
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.646837
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.636088
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.636019
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.644266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.652248
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.629309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.652679
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:13,226] Trial 34 finished with value: 0.6547619047619048 and parameters: {'num_leaves': 67, 'learning_rate': 0.16938689827645295, 'feature_fraction': 0.6303037884597553, 'bagging_fraction': 0.7767724228060224, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,259] Trial 35 finished with value: 0.6666666666666667 and parameters: {'num_leaves': 11, 'learning_rate': 0.12343923370859927, 'feature_fraction': 0.8892752785993416, 'bagging_fraction': 0.8213631604030487, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,277] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.2127424032847493, 'feature_fraction': 0.9596445165208243, 'bagging_fraction': 0.5327895586986391, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,302] Trial 37 finished with value: 0.7023809523809523 and parameters: {'num_leaves': 34, 'learning_rate': 0.1666979413009635, 'feature_fraction': 0.7177944862515884, 'bagging_fraction': 0.7600640613251326, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,356] Trial 38 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 280, 'learning_rate': 0.03148574478032703, 'feature_fraction': 0.7975512450794763, 'bagging_fraction': 0.6991484552221391, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,372] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 53, 'learning_rate': 0.19646969424583757, 'feature_fraction': 0.4860721946462531, 'bagging_fraction': 0.6615020697489405, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,396] Trial 40 finished with value: 0.6349206349206349 and parameters: {'num_leaves': 228, 'learning_rate': 0.0664387367998574, 'feature_fraction': 0.9592680551873385, 'bagging_fraction': 0.9135165435311738, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 16 with value: 0.7242063492063493.
[I 2025-09-17 13:15:13,415] Trial 41 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 73, 'learning_rate': 0.09031548348241994, 'feature_fraction': 0.8493815800561666, 'bagging_fraction': 0.5926931422865491, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 41 with value: 0.7261904761904762.
[I 2025-09-17 13:15:13,442] Trial 42 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 69, 'learning_rate': 0.10361761289534213, 'feature_fraction': 0.9105040190688343, 'bagging_fraction': 0.7236772601653404, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 41 with value: 0.7261904761904762.
[I 2025-09-17 13:15:13,460] Trial 43 finished with value: 0.7182539682539684 and parameters: {'num_leaves': 174, 'learning_rate': 0.09221694835158967, 'feature_fraction': 0.8765713056129657, 'bagging_fraction': 0.5945527014712298, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 41 with value: 0.7261904761904762.
[I 2025-09-17 13:15:13,486] Trial 44 finished with value: 0.75 and parameters: {'num_leaves': 184, 'learning_rate': 0.29826176670468973, 'feature_fraction': 0.8214270342114631, 'bagging_fraction': 0.5741235186084306, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 44 with value: 0.75.
[I 2025-09-17 13:15:13,518] Trial 45 finished with value: 0.6746031746031746 and parameters: {'num_leaves': 181, 'learning_rate': 0.2669117929608137, 'feature_fraction': 0.8794376372286337, 'bagging_fraction': 0.5606019342409387, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 44 with value: 0.75.
[I 2025-09-17 13:15:13,542] Trial 46 finished with value: 0.6031746031746031 and parameters: {'num_leaves': 160, 'learning_rate': 0.2987035776211169, 'feature_fraction': 0.7991265427766151, 'bagging_fraction': 0.48161255457014635, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 44 with value: 0.75.
[I 2025-09-17 13:15:13,560] Trial 47 finished with value: 0.7281746031746033 and parameters: {'num_leaves': 146, 'learning_rate': 0.24976225421043285, 'feature_fraction': 0.40064920045349195, 'bagging_fraction': 0.6018692780581117, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 44 with value: 0.75.
[I 2025-09-17 13:15:13,602] Trial 48 finished with value: 0.5793650793650793 and parameters: {'num_leaves': 144, 'learning_rate': 0.241144921373393, 'feature_fraction': 0.40857530617340126, 'bagging_fraction': 0.5301258126841459, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 44 with value: 0.75.
[I 2025-09-17 13:15:13,627] Trial 49 finished with value: 0.6626984126984127 and parameters: {'num_leaves': 200, 'learning_rate': 0.2814755252010414, 'feature_fraction': 0.5039096092409402, 'bagging_fraction': 0.6114976417338581, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 44 with value: 0.75.
[I 2025-09-17 13:15:13,916] A new study created in memory with name: no-name-0147c8b2-1f24-474d-9b27-50fec688d7b6
[I 2025-09-17 13:15:13,939] Trial 0 finished with value: 0.8701754385964913 and parameters: {'num_leaves': 264, 'learning_rate': 0.07865740382023148, 'feature_fraction': 0.43493922170179955, 'bagging_fraction': 0.9413888568914323, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 0 with value: 0.8701754385964913.
[I 2025-09-17 13:15:13,947] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 276, 'learning_rate': 0.26867286713172545, 'feature_fraction': 0.9823342944501002, 'bagging_fraction': 0.8068556177072003, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 0 with value: 0.8701754385964913.
[I 2025-09-17 13:15:13,957] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 141, 'learning_rate': 0.1124722800724973, 'feature_fraction': 0.4935466098623987, 'bagging_fraction': 0.40720230905920535, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 0 with value: 0.8701754385964913.
[I 2025-09-17 13:15:13,972] Trial 3 finished with value: 0.8526315789473684 and parameters: {'num_leaves': 298, 'learning_rate': 0.22590900596349645, 'feature_fraction': 0.8485950587977357, 'bagging_fraction': 0.9208923462579189, 'bagging_freq': 6, 'min_child_samples': 50}. Best is trial 0 with value: 0.8701754385964913.
[I 2025-09-17 13:15:13,992] Trial 4 finished with value: 0.912280701754386 and parameters: {'num_leaves': 208, 'learning_rate': 0.18321708356422886, 'feature_fraction': 0.4023388425607214, 'bagging_fraction': 0.9460085917084028, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 4 with value: 0.912280701754386.
[I 2025-09-17 13:15:14,010] Trial 5 finished with value: 0.8473684210526315 and parameters: {'num_leaves': 36, 'learning_rate': 0.016984972657314575, 'feature_fraction': 0.9527165869619474, 'bagging_fraction': 0.4384034119923462, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 4 with value: 0.912280701754386.
[I 2025-09-17 13:15:14,084] Trial 6 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 116, 'learning_rate': 0.07400327385672512, 'feature_fraction': 0.6489101034190621, 'bagging_fraction': 0.7453049541305978, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 6 with value: 0.9403508771929825.
[I 2025-09-17 13:15:14,106] Trial 7 finished with value: 0.9087719298245615 and parameters: {'num_leaves': 238, 'learning_rate': 0.2876694130976044, 'feature_fraction': 0.8880978799669118, 'bagging_fraction': 0.8358460604695531, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 6 with value: 0.9403508771929825.
[I 2025-09-17 13:15:14,140] Trial 8 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 238, 'learning_rate': 0.10538173830930787, 'feature_fraction': 0.6456079516783944, 'bagging_fraction': 0.7017498089128068, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 6 with value: 0.9403508771929825.
[I 2025-09-17 13:15:14,149] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 149, 'learning_rate': 0.18251079414386454, 'feature_fraction': 0.8387733670294721, 'bagging_fraction': 0.8085022880910986, 'bagging_freq': 4, 'min_child_samples': 63}. Best is trial 6 with value: 0.9403508771929825.
[I 2025-09-17 13:15:14,221] Trial 10 finished with value: 0.9017543859649122 and parameters: {'num_leaves': 70, 'learning_rate': 0.01717585397532336, 'feature_fraction': 0.6675862270991235, 'bagging_fraction': 0.5642586496845962, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 6 with value: 0.9403508771929825.
[I 2025-09-17 13:15:14,345] Trial 11 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 104, 'learning_rate': 0.09480380632621602, 'feature_fraction': 0.6380173218883586, 'bagging_fraction': 0.6676681177410535, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 6 with value: 0.9403508771929825.
[I 2025-09-17 13:15:14,400] Trial 12 finished with value: 0.9473684210526316 and parameters: {'num_leaves': 205, 'learning_rate': 0.13049532146625956, 'feature_fraction': 0.5682944918092874, 'bagging_fraction': 0.6819637828514047, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 12 with value: 0.9473684210526316.
[I 2025-09-17 13:15:14,413] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 188, 'learning_rate': 0.058050439995092545, 'feature_fraction': 0.5609431099167576, 'bagging_fraction': 0.6259504800765444, 'bagging_freq': 1, 'min_child_samples': 87}. Best is trial 12 with value: 0.9473684210526316.
[I 2025-09-17 13:15:14,454] Trial 14 finished with value: 0.9649122807017545 and parameters: {'num_leaves': 101, 'learning_rate': 0.16061852836483967, 'feature_fraction': 0.7496148768090354, 'bagging_fraction': 0.734598510164669, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:14,490] Trial 15 finished with value: 0.9368421052631578 and parameters: {'num_leaves': 183, 'learning_rate': 0.1478008154561372, 'feature_fraction': 0.7330833864823894, 'bagging_fraction': 0.5393262776438993, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:14,532] Trial 16 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 18, 'learning_rate': 0.14148957054117334, 'feature_fraction': 0.7572593964359629, 'bagging_fraction': 0.5920806863833206, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:14,554] Trial 17 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 81, 'learning_rate': 0.2002173644010918, 'feature_fraction': 0.5610568939442704, 'bagging_fraction': 0.7331221194610893, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:14,567] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 174, 'learning_rate': 0.2349438375458663, 'feature_fraction': 0.7790986548484324, 'bagging_fraction': 0.4884180718233797, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:14,619] Trial 19 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 122, 'learning_rate': 0.13075753954723743, 'feature_fraction': 0.57889944889727, 'bagging_fraction': 0.8648370528365145, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:14,646] Trial 20 finished with value: 0.887719298245614 and parameters: {'num_leaves': 58, 'learning_rate': 0.17553865061074914, 'feature_fraction': 0.47820162187261595, 'bagging_fraction': 0.6491221019609712, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:14,816] Trial 21 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 109, 'learning_rate': 0.06360608459822162, 'feature_fraction': 0.6871342068535622, 'bagging_fraction': 0.7599522937674951, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:14,974] Trial 22 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 89, 'learning_rate': 0.05225134260814723, 'feature_fraction': 0.6974708198557261, 'bagging_fraction': 0.7419092013862176, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,048] Trial 23 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 143, 'learning_rate': 0.11673987208744815, 'feature_fraction': 0.6018994714436829, 'bagging_fraction': 0.7654480814663327, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,084] Trial 24 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 219, 'learning_rate': 0.1610686991782304, 'feature_fraction': 0.7233025120597908, 'bagging_fraction': 0.6882491689188014, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,112] Trial 25 finished with value: 0.856140350877193 and parameters: {'num_leaves': 171, 'learning_rate': 0.04976711920835353, 'feature_fraction': 0.5124706719819728, 'bagging_fraction': 0.7837777724410078, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,162] Trial 26 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 52, 'learning_rate': 0.2105449535053318, 'feature_fraction': 0.7914884831667074, 'bagging_fraction': 0.8763618509878058, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,249] Trial 27 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 100, 'learning_rate': 0.16140951243647406, 'feature_fraction': 0.7028513423628374, 'bagging_fraction': 0.6173656637754503, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,289] Trial 28 finished with value: 0.9508771929824562 and parameters: {'num_leaves': 127, 'learning_rate': 0.0882364971433123, 'feature_fraction': 0.59914245534676, 'bagging_fraction': 0.715822824841957, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,311] Trial 29 finished with value: 0.856140350877193 and parameters: {'num_leaves': 135, 'learning_rate': 0.09121930935851622, 'feature_fraction': 0.5215418572570689, 'bagging_fraction': 0.7085058949350368, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,336] Trial 30 finished with value: 0.8701754385964913 and parameters: {'num_leaves': 204, 'learning_rate': 0.13004536471206085, 'feature_fraction': 0.4545808670912507, 'bagging_fraction': 0.9937318032165054, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,383] Trial 31 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 120, 'learning_rate': 0.07828849635457097, 'feature_fraction': 0.6032352617209654, 'bagging_fraction': 0.6584188792713855, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,420] Trial 32 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 168, 'learning_rate': 0.03810953621779948, 'feature_fraction': 0.6770641896558525, 'bagging_fraction': 0.7942697684016934, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,465] Trial 33 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 93, 'learning_rate': 0.07028353344802209, 'feature_fraction': 0.5381119580514361, 'bagging_fraction': 0.7164437343841649, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,490] Trial 34 finished with value: 0.8421052631578948 and parameters: {'num_leaves': 156, 'learning_rate': 0.11957069780075351, 'feature_fraction': 0.6068134600020263, 'bagging_fraction': 0.831690606848417, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,521] Trial 35 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 275, 'learning_rate': 0.1024670646712504, 'feature_fraction': 0.7938872995945354, 'bagging_fraction': 0.7663835628668343, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,578] Trial 36 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 125, 'learning_rate': 0.029842280604861098, 'feature_fraction': 0.7462321366570102, 'bagging_fraction': 0.6785327979496393, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,601] Trial 37 finished with value: 0.8947368421052633 and parameters: {'num_leaves': 73, 'learning_rate': 0.25118550388356553, 'feature_fraction': 0.6235379508399771, 'bagging_fraction': 0.897052997269841, 'bagging_freq': 2, 'min_child_samples': 56}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,618] Trial 38 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 108, 'learning_rate': 0.13187208553960084, 'feature_fraction': 0.8812476640955754, 'bagging_fraction': 0.8241592902047142, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,700] Trial 39 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 234, 'learning_rate': 0.09190441357430101, 'feature_fraction': 0.40515478410144734, 'bagging_fraction': 0.6263005165187173, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,741] Trial 40 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 254, 'learning_rate': 0.0636352947000632, 'feature_fraction': 0.8278039988788184, 'bagging_fraction': 0.7553584473044994, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,787] Trial 41 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 131, 'learning_rate': 0.07703253274185684, 'feature_fraction': 0.5901411163257796, 'bagging_fraction': 0.6439731973649745, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 14 with value: 0.9649122807017545.
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.643257
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.643683
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.630537
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.638618
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.644968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.652813
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.613926
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655435
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.603806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.628653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.672762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.636773
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.698183
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.632807
Training model for P045... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.437131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.433268
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.374813
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.508486
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.334561
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.400998
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.327908
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.395861
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.297218
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.321026
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.294897
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.353886
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.341552
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.425408
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.32276
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.439876
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.299352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.319928
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.338293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.363379
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.440714
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.390509
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.38284
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.321598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.453324
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.454002
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.335943
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.344075
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.359453
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.45181
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.391572
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.343203
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.429808
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.422805
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.343295
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.327818
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.3326
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:15,841] Trial 42 finished with value: 0.9192982456140351 and parameters: {'num_leaves': 114, 'learning_rate': 0.08348762110361094, 'feature_fraction': 0.6710187033617541, 'bagging_fraction': 0.6652344092665344, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,890] Trial 43 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 160, 'learning_rate': 0.106054989961694, 'feature_fraction': 0.6327761706613839, 'bagging_fraction': 0.7120591398110409, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,911] Trial 44 finished with value: 0.8701754385964913 and parameters: {'num_leaves': 144, 'learning_rate': 0.1670694732088149, 'feature_fraction': 0.6981613193488767, 'bagging_fraction': 0.5667731839218964, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:15,990] Trial 45 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 199, 'learning_rate': 0.040305514456406816, 'feature_fraction': 0.5706593490204197, 'bagging_fraction': 0.599186579624138, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:16,029] Trial 46 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 300, 'learning_rate': 0.14557793743914144, 'feature_fraction': 0.5439374965272563, 'bagging_fraction': 0.727838978999255, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:16,045] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 118, 'learning_rate': 0.19952547700620182, 'feature_fraction': 0.6607406396980117, 'bagging_fraction': 0.6898390272834343, 'bagging_freq': 3, 'min_child_samples': 80}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:16,135] Trial 48 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 60, 'learning_rate': 0.07614099853098974, 'feature_fraction': 0.9731995337032995, 'bagging_fraction': 0.6540633806511503, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:16,161] Trial 49 finished with value: 0.8736842105263158 and parameters: {'num_leaves': 89, 'learning_rate': 0.12097951165876174, 'feature_fraction': 0.616628378544795, 'bagging_fraction': 0.5132840983202956, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 14 with value: 0.9649122807017545.
[I 2025-09-17 13:15:16,419] A new study created in memory with name: no-name-dbccaf7e-b776-4de6-93af-0f4b5d9925cf
[I 2025-09-17 13:15:16,434] Trial 0 finished with value: 0.8578947368421053 and parameters: {'num_leaves': 175, 'learning_rate': 0.06322018671132129, 'feature_fraction': 0.6580251966652018, 'bagging_fraction': 0.5315234954042586, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 0 with value: 0.8578947368421053.
[I 2025-09-17 13:15:16,500] Trial 1 finished with value: 0.8982456140350877 and parameters: {'num_leaves': 269, 'learning_rate': 0.25797576131680444, 'feature_fraction': 0.5857470560557458, 'bagging_fraction': 0.43585928781989364, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 1 with value: 0.8982456140350877.
[I 2025-09-17 13:15:16,566] Trial 2 finished with value: 0.9508771929824562 and parameters: {'num_leaves': 138, 'learning_rate': 0.2835031142007344, 'feature_fraction': 0.9284193279902826, 'bagging_fraction': 0.7226797503582119, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 2 with value: 0.9508771929824562.
[I 2025-09-17 13:15:16,599] Trial 3 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 181, 'learning_rate': 0.21867427534384018, 'feature_fraction': 0.6938070687621453, 'bagging_fraction': 0.6965390239398033, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 2 with value: 0.9508771929824562.
[I 2025-09-17 13:15:16,605] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 197, 'learning_rate': 0.14585694046675765, 'feature_fraction': 0.4362942812760372, 'bagging_fraction': 0.9222805312649147, 'bagging_freq': 1, 'min_child_samples': 80}. Best is trial 2 with value: 0.9508771929824562.
[I 2025-09-17 13:15:16,613] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 169, 'learning_rate': 0.14642584727835545, 'feature_fraction': 0.7012978151221375, 'bagging_fraction': 0.5264934182972911, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 2 with value: 0.9508771929824562.
[I 2025-09-17 13:15:16,619] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 65, 'learning_rate': 0.034196281827418434, 'feature_fraction': 0.8822363783537253, 'bagging_fraction': 0.844319679185822, 'bagging_freq': 1, 'min_child_samples': 75}. Best is trial 2 with value: 0.9508771929824562.
[I 2025-09-17 13:15:16,626] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 104, 'learning_rate': 0.014535240749195735, 'feature_fraction': 0.6190699771811468, 'bagging_fraction': 0.8766772491091721, 'bagging_freq': 1, 'min_child_samples': 78}. Best is trial 2 with value: 0.9508771929824562.
[I 2025-09-17 13:15:16,639] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 66, 'learning_rate': 0.05243938015949266, 'feature_fraction': 0.8701320919439198, 'bagging_fraction': 0.6310878624612953, 'bagging_freq': 7, 'min_child_samples': 77}. Best is trial 2 with value: 0.9508771929824562.
[I 2025-09-17 13:15:16,648] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 92, 'learning_rate': 0.024067999641049824, 'feature_fraction': 0.5141732438030369, 'bagging_fraction': 0.8212346425672863, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 2 with value: 0.9508771929824562.
[I 2025-09-17 13:15:16,715] Trial 10 finished with value: 0.9631578947368421 and parameters: {'num_leaves': 262, 'learning_rate': 0.29576626362949243, 'feature_fraction': 0.9888529341925991, 'bagging_fraction': 0.746850228541251, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:16,816] Trial 11 finished with value: 0.9473684210526316 and parameters: {'num_leaves': 292, 'learning_rate': 0.29186980319887024, 'feature_fraction': 0.9851799208510051, 'bagging_fraction': 0.7524283553455957, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:16,864] Trial 12 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 241, 'learning_rate': 0.2152854829662607, 'feature_fraction': 0.9986927816853202, 'bagging_fraction': 0.9859753676946867, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:16,894] Trial 13 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 126, 'learning_rate': 0.274452385284174, 'feature_fraction': 0.8449871749559549, 'bagging_fraction': 0.7002173919893268, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:16,915] Trial 14 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 224, 'learning_rate': 0.22423072525328247, 'feature_fraction': 0.8144241551977067, 'bagging_fraction': 0.6159922732291762, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:16,954] Trial 15 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 13, 'learning_rate': 0.298299380834301, 'feature_fraction': 0.9374584326459021, 'bagging_fraction': 0.7660750381392558, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:16,976] Trial 16 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 137, 'learning_rate': 0.18153300559763352, 'feature_fraction': 0.7704008978259531, 'bagging_fraction': 0.6337074480137143, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:16,997] Trial 17 finished with value: 0.8140350877192983 and parameters: {'num_leaves': 227, 'learning_rate': 0.10020563772937721, 'feature_fraction': 0.9142607689363293, 'bagging_fraction': 0.7757205919984242, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:17,030] Trial 18 finished with value: 0.9333333333333332 and parameters: {'num_leaves': 293, 'learning_rate': 0.24876656510806971, 'feature_fraction': 0.7810055889273232, 'bagging_fraction': 0.7016793422475055, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:17,053] Trial 19 finished with value: 0.9017543859649124 and parameters: {'num_leaves': 144, 'learning_rate': 0.18361994241166044, 'feature_fraction': 0.9463795855259886, 'bagging_fraction': 0.5644526099291837, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:17,066] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 203, 'learning_rate': 0.24977601438323976, 'feature_fraction': 0.9966387834274332, 'bagging_fraction': 0.4527648163978692, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 10 with value: 0.9631578947368421.
[I 2025-09-17 13:15:17,141] Trial 21 finished with value: 0.9649122807017545 and parameters: {'num_leaves': 298, 'learning_rate': 0.29392926580189127, 'feature_fraction': 0.9649697003905804, 'bagging_fraction': 0.7555708530785187, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,201] Trial 22 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 256, 'learning_rate': 0.2759227712371823, 'feature_fraction': 0.9182338965788077, 'bagging_fraction': 0.7992779242609072, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,244] Trial 23 finished with value: 0.943859649122807 and parameters: {'num_leaves': 270, 'learning_rate': 0.2985550229971622, 'feature_fraction': 0.9463152836160263, 'bagging_fraction': 0.7157644324390963, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,282] Trial 24 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 300, 'learning_rate': 0.2668252544343554, 'feature_fraction': 0.8290298469742629, 'bagging_fraction': 0.8835023572743681, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,367] Trial 25 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 265, 'learning_rate': 0.23209840498965312, 'feature_fraction': 0.7523065486754179, 'bagging_fraction': 0.6617608783290023, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,423] Trial 26 finished with value: 0.8947368421052633 and parameters: {'num_leaves': 114, 'learning_rate': 0.19170523285143568, 'feature_fraction': 0.8907856832767935, 'bagging_fraction': 0.7539962341201425, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,448] Trial 27 finished with value: 0.849122807017544 and parameters: {'num_leaves': 218, 'learning_rate': 0.11742043286512813, 'feature_fraction': 0.9582672960137821, 'bagging_fraction': 0.9461846905108257, 'bagging_freq': 4, 'min_child_samples': 63}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,484] Trial 28 finished with value: 0.8947368421052633 and parameters: {'num_leaves': 249, 'learning_rate': 0.27729660996295274, 'feature_fraction': 0.8656325663974668, 'bagging_fraction': 0.8318376688249967, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,498] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 171, 'learning_rate': 0.23976897516287649, 'feature_fraction': 0.9680678824334422, 'bagging_fraction': 0.5253462496603423, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,522] Trial 30 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 281, 'learning_rate': 0.20054319686309335, 'feature_fraction': 0.9084387769154213, 'bagging_fraction': 0.5786911094080396, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,586] Trial 31 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 299, 'learning_rate': 0.29874311620052385, 'feature_fraction': 0.9998520616271311, 'bagging_fraction': 0.7364200959136733, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,669] Trial 32 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 286, 'learning_rate': 0.2835807812907016, 'feature_fraction': 0.9675870126003727, 'bagging_fraction': 0.6707757023538589, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,701] Trial 33 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 272, 'learning_rate': 0.25913624746851405, 'feature_fraction': 0.9663715322891623, 'bagging_fraction': 0.7402487053697208, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,802] Trial 34 finished with value: 0.9649122807017544 and parameters: {'num_leaves': 241, 'learning_rate': 0.2893499073089355, 'feature_fraction': 0.914153300608898, 'bagging_fraction': 0.7827626052266551, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,860] Trial 35 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 196, 'learning_rate': 0.26335121564297487, 'feature_fraction': 0.7283430252179178, 'bagging_fraction': 0.7908738632921982, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,907] Trial 36 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 155, 'learning_rate': 0.2825685973804818, 'feature_fraction': 0.8092232278349905, 'bagging_fraction': 0.8764426107519365, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:17,943] Trial 37 finished with value: 0.9122807017543859 and parameters: {'num_leaves': 189, 'learning_rate': 0.20797410565316005, 'feature_fraction': 0.6430492554157865, 'bagging_fraction': 0.8114402234345512, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,004] Trial 38 finished with value: 0.9614035087719298 and parameters: {'num_leaves': 240, 'learning_rate': 0.16972135268130054, 'feature_fraction': 0.8961190890901054, 'bagging_fraction': 0.667212792751345, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,064] Trial 39 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 239, 'learning_rate': 0.16022460780716416, 'feature_fraction': 0.5571779137373302, 'bagging_fraction': 0.6661213846163504, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,077] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 255, 'learning_rate': 0.08783379134442013, 'feature_fraction': 0.8688641704886041, 'bagging_fraction': 0.5952667802556767, 'bagging_freq': 5, 'min_child_samples': 68}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,151] Trial 41 finished with value: 0.9473684210526316 and parameters: {'num_leaves': 212, 'learning_rate': 0.12980669241338477, 'feature_fraction': 0.9199958184197493, 'bagging_fraction': 0.7187291270473354, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,266] Trial 42 finished with value: 0.9649122807017545 and parameters: {'num_leaves': 237, 'learning_rate': 0.24210708139010326, 'feature_fraction': 0.8970292993799815, 'bagging_fraction': 0.6731014172988776, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,320] Trial 43 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 230, 'learning_rate': 0.16710934807815397, 'feature_fraction': 0.8954324504027302, 'bagging_fraction': 0.6771959447107914, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,334] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.23900407896842019, 'feature_fraction': 0.44004980700517154, 'bagging_fraction': 0.8456366953792285, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,433] Trial 45 finished with value: 0.9649122807017545 and parameters: {'num_leaves': 244, 'learning_rate': 0.2551248459011795, 'feature_fraction': 0.8496332729384132, 'bagging_fraction': 0.6516731269253885, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,557] Trial 46 finished with value: 0.9543859649122807 and parameters: {'num_leaves': 264, 'learning_rate': 0.25332768059436445, 'feature_fraction': 0.8477410783793973, 'bagging_fraction': 0.7861950175751872, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,575] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 249, 'learning_rate': 0.28686402076967676, 'feature_fraction': 0.9366729630992656, 'bagging_fraction': 0.6353373802538722, 'bagging_freq': 4, 'min_child_samples': 85}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,602] Trial 48 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 215, 'learning_rate': 0.2676431071889021, 'feature_fraction': 0.6896557960145703, 'bagging_fraction': 0.504736576567595, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,639] Trial 49 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 284, 'learning_rate': 0.22297905911373483, 'feature_fraction': 0.7966023948542759, 'bagging_fraction': 0.6965101579720109, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 21 with value: 0.9649122807017545.
[I 2025-09-17 13:15:18,833] A new study created in memory with name: no-name-dd28beed-bf13-442a-9923-76586d49d1c7
[I 2025-09-17 13:15:18,882] Trial 0 finished with value: 0.8982456140350877 and parameters: {'num_leaves': 275, 'learning_rate': 0.0204433535141166, 'feature_fraction': 0.49840522408363586, 'bagging_fraction': 0.6836595775224079, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 0 with value: 0.8982456140350877.
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.340662
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.337829
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.449845
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.317197
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.362555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.313295
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.420316
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.582174
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.470315
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.287035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.396158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.317374
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.337706
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.277648
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.398547
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.45316
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.323511
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.419327
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.611343
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.329395
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.414599
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.247653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.317596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.327067
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.348558
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.304383
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.397214
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.490379
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.391681
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.414513
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.40138
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.372656
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.330713
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.294651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.368765
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.321859
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.367469
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.311293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.370722
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.298965
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.242416
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.324241
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.278477
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.29241
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.390448
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.334026
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.437718
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:18,931] Trial 1 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 110, 'learning_rate': 0.06883323000845795, 'feature_fraction': 0.7292749148067096, 'bagging_fraction': 0.45503523982677335, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:18,938] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 14, 'learning_rate': 0.10497736529204794, 'feature_fraction': 0.8684397405808899, 'bagging_fraction': 0.5614955206254958, 'bagging_freq': 1, 'min_child_samples': 94}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:18,966] Trial 3 finished with value: 0.8403508771929824 and parameters: {'num_leaves': 271, 'learning_rate': 0.043428414412990286, 'feature_fraction': 0.7348256569196534, 'bagging_fraction': 0.842066018342885, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:18,974] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 163, 'learning_rate': 0.19127940072810473, 'feature_fraction': 0.8202281089222556, 'bagging_fraction': 0.5210746890282341, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:18,989] Trial 5 finished with value: 0.843859649122807 and parameters: {'num_leaves': 13, 'learning_rate': 0.20926871524741397, 'feature_fraction': 0.6716043964065777, 'bagging_fraction': 0.8429118236076634, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:18,997] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 125, 'learning_rate': 0.10530062632749039, 'feature_fraction': 0.8488917514358951, 'bagging_fraction': 0.550940958394925, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:19,009] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.23747815666943523, 'feature_fraction': 0.6126923190712947, 'bagging_fraction': 0.9023983608702797, 'bagging_freq': 6, 'min_child_samples': 88}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:19,016] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 228, 'learning_rate': 0.2513453196410683, 'feature_fraction': 0.8059887506973442, 'bagging_fraction': 0.41176334869265396, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:19,025] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 150, 'learning_rate': 0.03105968640070183, 'feature_fraction': 0.4983462298345017, 'bagging_fraction': 0.6380019066985472, 'bagging_freq': 5, 'min_child_samples': 62}. Best is trial 1 with value: 0.9017543859649123.
[I 2025-09-17 13:15:19,098] Trial 10 finished with value: 0.9087719298245615 and parameters: {'num_leaves': 90, 'learning_rate': 0.10903663782123899, 'feature_fraction': 0.9610606839990092, 'bagging_fraction': 0.42324824822896856, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 10 with value: 0.9087719298245615.
[I 2025-09-17 13:15:19,169] Trial 11 finished with value: 0.9157894736842106 and parameters: {'num_leaves': 78, 'learning_rate': 0.10995416298542111, 'feature_fraction': 0.9752744817032247, 'bagging_fraction': 0.41694203896873894, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,192] Trial 12 finished with value: 0.8385964912280702 and parameters: {'num_leaves': 73, 'learning_rate': 0.1394905865764627, 'feature_fraction': 0.9749001568052565, 'bagging_fraction': 0.40577056308246906, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,211] Trial 13 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 71, 'learning_rate': 0.15093850358451916, 'feature_fraction': 0.979466226522363, 'bagging_fraction': 0.5076403663532703, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,235] Trial 14 finished with value: 0.8842105263157893 and parameters: {'num_leaves': 80, 'learning_rate': 0.08972190528766477, 'feature_fraction': 0.9113483273362625, 'bagging_fraction': 0.6165949826994299, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,298] Trial 15 finished with value: 0.887719298245614 and parameters: {'num_leaves': 47, 'learning_rate': 0.13102200088422367, 'feature_fraction': 0.9960760478610411, 'bagging_fraction': 0.7211643075892605, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,370] Trial 16 finished with value: 0.9017543859649122 and parameters: {'num_leaves': 112, 'learning_rate': 0.19082330224572713, 'feature_fraction': 0.915703247357641, 'bagging_fraction': 0.47422186597102683, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,405] Trial 17 finished with value: 0.8982456140350877 and parameters: {'num_leaves': 170, 'learning_rate': 0.27675258883065224, 'feature_fraction': 0.4266309437525984, 'bagging_fraction': 0.9950798491775834, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,427] Trial 18 finished with value: 0.7456140350877194 and parameters: {'num_leaves': 46, 'learning_rate': 0.0625037982742338, 'feature_fraction': 0.9141191250559625, 'bagging_fraction': 0.598423057012252, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,455] Trial 19 finished with value: 0.9140350877192982 and parameters: {'num_leaves': 96, 'learning_rate': 0.16565939556120668, 'feature_fraction': 0.7894749603524369, 'bagging_fraction': 0.7495112174935343, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,484] Trial 20 finished with value: 0.8842105263157894 and parameters: {'num_leaves': 47, 'learning_rate': 0.17945602641866829, 'feature_fraction': 0.7744846052984049, 'bagging_fraction': 0.7625975040342701, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,595] Trial 21 finished with value: 0.887719298245614 and parameters: {'num_leaves': 99, 'learning_rate': 0.12514256058633605, 'feature_fraction': 0.6223072517813003, 'bagging_fraction': 0.76923838159267, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,622] Trial 22 finished with value: 0.887719298245614 and parameters: {'num_leaves': 136, 'learning_rate': 0.08662029367330967, 'feature_fraction': 0.9265600882828214, 'bagging_fraction': 0.45409839340271396, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,649] Trial 23 finished with value: 0.8736842105263158 and parameters: {'num_leaves': 87, 'learning_rate': 0.15899452929030683, 'feature_fraction': 0.865855480401131, 'bagging_fraction': 0.6762538285659643, 'bagging_freq': 1, 'min_child_samples': 36}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,677] Trial 24 finished with value: 0.912280701754386 and parameters: {'num_leaves': 190, 'learning_rate': 0.11618941751882808, 'feature_fraction': 0.9498087936566635, 'bagging_fraction': 0.8213044296722676, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,702] Trial 25 finished with value: 0.9087719298245613 and parameters: {'num_leaves': 197, 'learning_rate': 0.169632784539118, 'feature_fraction': 0.6634140549293204, 'bagging_fraction': 0.8197464811019829, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,719] Trial 26 finished with value: 0.8350877192982455 and parameters: {'num_leaves': 243, 'learning_rate': 0.2208670945914377, 'feature_fraction': 0.776408836111031, 'bagging_fraction': 0.9055026337054772, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,757] Trial 27 finished with value: 0.9052631578947368 and parameters: {'num_leaves': 180, 'learning_rate': 0.12385156323735431, 'feature_fraction': 0.8855619960561512, 'bagging_fraction': 0.7734604487026724, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,791] Trial 28 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 138, 'learning_rate': 0.06429581982177798, 'feature_fraction': 0.9379885560042496, 'bagging_fraction': 0.8975160634893232, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 11 with value: 0.9157894736842106.
[I 2025-09-17 13:15:19,834] Trial 29 finished with value: 0.9175438596491228 and parameters: {'num_leaves': 188, 'learning_rate': 0.15150118863050813, 'feature_fraction': 0.5696332128458972, 'bagging_fraction': 0.7086188723409738, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:19,897] Trial 30 finished with value: 0.912280701754386 and parameters: {'num_leaves': 274, 'learning_rate': 0.010951312144540037, 'feature_fraction': 0.56304889656198, 'bagging_fraction': 0.7007421625055525, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:19,919] Trial 31 finished with value: 0.8508771929824561 and parameters: {'num_leaves': 188, 'learning_rate': 0.15141780464368002, 'feature_fraction': 0.542090674828195, 'bagging_fraction': 0.7337790139675592, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:19,969] Trial 32 finished with value: 0.8982456140350877 and parameters: {'num_leaves': 218, 'learning_rate': 0.14124944167258102, 'feature_fraction': 0.728077563469701, 'bagging_fraction': 0.6661646515465861, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,017] Trial 33 finished with value: 0.8842105263157893 and parameters: {'num_leaves': 156, 'learning_rate': 0.09319185673750646, 'feature_fraction': 0.45553380499678003, 'bagging_fraction': 0.8180082275237112, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,090] Trial 34 finished with value: 0.8982456140350876 and parameters: {'num_leaves': 256, 'learning_rate': 0.11696522254739697, 'feature_fraction': 0.5972864956416641, 'bagging_fraction': 0.7918120816535416, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,119] Trial 35 finished with value: 0.9157894736842105 and parameters: {'num_leaves': 292, 'learning_rate': 0.16698962817584054, 'feature_fraction': 0.6995633675140661, 'bagging_fraction': 0.8698161684553599, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,140] Trial 36 finished with value: 0.8929824561403509 and parameters: {'num_leaves': 28, 'learning_rate': 0.20070702240708935, 'feature_fraction': 0.6940074262959821, 'bagging_fraction': 0.954129337451011, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,150] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 286, 'learning_rate': 0.17137766330245008, 'feature_fraction': 0.7497619993959951, 'bagging_fraction': 0.5855354509188107, 'bagging_freq': 1, 'min_child_samples': 72}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,184] Trial 38 finished with value: 0.9157894736842105 and parameters: {'num_leaves': 118, 'learning_rate': 0.21627555315188365, 'feature_fraction': 0.6505226545436489, 'bagging_fraction': 0.8763537630648502, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,202] Trial 39 finished with value: 0.8333333333333335 and parameters: {'num_leaves': 298, 'learning_rate': 0.22697303690975507, 'feature_fraction': 0.6513075380172421, 'bagging_fraction': 0.8772938490070158, 'bagging_freq': 1, 'min_child_samples': 47}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,217] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 129, 'learning_rate': 0.2580577656909785, 'feature_fraction': 0.5771848915239508, 'bagging_fraction': 0.9378731305963661, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,258] Trial 41 finished with value: 0.9087719298245613 and parameters: {'num_leaves': 116, 'learning_rate': 0.20824361763204738, 'feature_fraction': 0.5258451403495543, 'bagging_fraction': 0.8555377812510548, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,305] Trial 42 finished with value: 0.9017543859649122 and parameters: {'num_leaves': 101, 'learning_rate': 0.18950090974583675, 'feature_fraction': 0.6278107095019481, 'bagging_fraction': 0.6428340078229873, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,325] Trial 43 finished with value: 0.8824561403508773 and parameters: {'num_leaves': 59, 'learning_rate': 0.17210679979023755, 'feature_fraction': 0.7091473707209653, 'bagging_fraction': 0.7395166841755353, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,361] Trial 44 finished with value: 0.868421052631579 and parameters: {'num_leaves': 146, 'learning_rate': 0.29890342338870185, 'feature_fraction': 0.8268439043798904, 'bagging_fraction': 0.8584362263322249, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,387] Trial 45 finished with value: 0.912280701754386 and parameters: {'num_leaves': 100, 'learning_rate': 0.14153301236104673, 'feature_fraction': 0.6945228081667358, 'bagging_fraction': 0.9383071435033786, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,429] Trial 46 finished with value: 0.9157894736842105 and parameters: {'num_leaves': 258, 'learning_rate': 0.23390308656575756, 'feature_fraction': 0.6453266444009368, 'bagging_fraction': 0.7056422329152447, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 29 with value: 0.9175438596491228.
[I 2025-09-17 13:15:20,503] Trial 47 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 256, 'learning_rate': 0.2619575613013273, 'feature_fraction': 0.4873002674681956, 'bagging_fraction': 0.7044392480277476, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 47 with value: 0.9263157894736842.
[I 2025-09-17 13:15:20,560] Trial 48 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 232, 'learning_rate': 0.26022582178019993, 'feature_fraction': 0.4888883548258839, 'bagging_fraction': 0.5362674360200725, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 47 with value: 0.9263157894736842.
[I 2025-09-17 13:15:20,674] Trial 49 finished with value: 0.9087719298245613 and parameters: {'num_leaves': 285, 'learning_rate': 0.2764566169531325, 'feature_fraction': 0.4753775465052451, 'bagging_fraction': 0.7934570671879373, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 47 with value: 0.9263157894736842.
[I 2025-09-17 13:15:20,989] A new study created in memory with name: no-name-adb3ea97-f90d-4f0c-be88-6d7775dd1707
[I 2025-09-17 13:15:21,001] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 265, 'learning_rate': 0.29456093131983674, 'feature_fraction': 0.511819735077381, 'bagging_fraction': 0.7426627527491132, 'bagging_freq': 7, 'min_child_samples': 90}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:21,013] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 230, 'learning_rate': 0.21729634664647027, 'feature_fraction': 0.7728401713464987, 'bagging_fraction': 0.46774989964144464, 'bagging_freq': 1, 'min_child_samples': 85}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:21,025] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 294, 'learning_rate': 0.04492051652123128, 'feature_fraction': 0.8961454774663148, 'bagging_fraction': 0.5027147728524533, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:21,040] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 69, 'learning_rate': 0.24666541827817945, 'feature_fraction': 0.4770831396043413, 'bagging_fraction': 0.46211650110402647, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:21,049] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 240, 'learning_rate': 0.16037140861827376, 'feature_fraction': 0.5952079365831198, 'bagging_fraction': 0.6067731551489423, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:21,064] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 189, 'learning_rate': 0.22362252357689086, 'feature_fraction': 0.958620262338737, 'bagging_fraction': 0.4857911956417241, 'bagging_freq': 3, 'min_child_samples': 93}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:21,082] Trial 6 finished with value: 0.8561403508771931 and parameters: {'num_leaves': 158, 'learning_rate': 0.23189113369261197, 'feature_fraction': 0.5152377097335007, 'bagging_fraction': 0.6423675767707513, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 6 with value: 0.8561403508771931.
[I 2025-09-17 13:15:21,103] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 219, 'learning_rate': 0.24675589640749987, 'feature_fraction': 0.8434166552870805, 'bagging_fraction': 0.4524408530092229, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 6 with value: 0.8561403508771931.
[I 2025-09-17 13:15:21,114] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.02323113830394631, 'feature_fraction': 0.64837031161033, 'bagging_fraction': 0.5667367024624994, 'bagging_freq': 5, 'min_child_samples': 66}. Best is trial 6 with value: 0.8561403508771931.
[I 2025-09-17 13:15:21,143] Trial 9 finished with value: 0.9192982456140352 and parameters: {'num_leaves': 87, 'learning_rate': 0.16302059949221526, 'feature_fraction': 0.9033866151553819, 'bagging_fraction': 0.8417833390215423, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 9 with value: 0.9192982456140352.
[I 2025-09-17 13:15:21,212] Trial 10 finished with value: 0.9157894736842106 and parameters: {'num_leaves': 24, 'learning_rate': 0.09420292611284778, 'feature_fraction': 0.7413971542146106, 'bagging_fraction': 0.9397371113733162, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 9 with value: 0.9192982456140352.
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.443553
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.508477
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.507479
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.399978
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.378698
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.473134
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.507793
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.48433
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.441394
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.42763
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.407104
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.548674
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.379685
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.421881
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.431673
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.478607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.497118
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.406805
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.438014
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.498727
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.412928
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.43502
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.386593
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.470745
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.495859
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.409163
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.415331
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.409045
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.434379
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.477228
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.36204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.509052
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.384648
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.416098
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.473779
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.441188
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.408376
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.374882
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.362298
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.400482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.39847
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.440765
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.35456
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.381018
[I 2025-09-17 13:15:21,290] Trial 11 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 19, 'learning_rate': 0.09691809826448988, 'feature_fraction': 0.7623026436234778, 'bagging_fraction': 0.9427269488074767, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,360] Trial 12 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 10, 'learning_rate': 0.12704649372143306, 'feature_fraction': 0.9734656345798057, 'bagging_fraction': 0.9336082110214298, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,509] Trial 13 finished with value: 0.9157894736842105 and parameters: {'num_leaves': 18, 'learning_rate': 0.09553406674099177, 'feature_fraction': 0.98500851506068, 'bagging_fraction': 0.9902137061155776, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,540] Trial 14 finished with value: 0.9192982456140351 and parameters: {'num_leaves': 53, 'learning_rate': 0.11172558217603437, 'feature_fraction': 0.8042070338008203, 'bagging_fraction': 0.8381519655573988, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,578] Trial 15 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 134, 'learning_rate': 0.1378442954699539, 'feature_fraction': 0.6953562231394892, 'bagging_fraction': 0.8835577904328552, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,605] Trial 16 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 118, 'learning_rate': 0.06238497701745463, 'feature_fraction': 0.6683283690369173, 'bagging_fraction': 0.8177437755912008, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,660] Trial 17 finished with value: 0.9087719298245615 and parameters: {'num_leaves': 132, 'learning_rate': 0.18073261565301071, 'feature_fraction': 0.5892004429463175, 'bagging_fraction': 0.7409129934868464, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,689] Trial 18 finished with value: 0.8982456140350877 and parameters: {'num_leaves': 175, 'learning_rate': 0.07045966538528388, 'feature_fraction': 0.40563244073591526, 'bagging_fraction': 0.9066194868448261, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,737] Trial 19 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 121, 'learning_rate': 0.12833184073703227, 'feature_fraction': 0.7134799042422761, 'bagging_fraction': 0.9975129966786049, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,864] Trial 20 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 44, 'learning_rate': 0.189845733311448, 'feature_fraction': 0.8268924226536971, 'bagging_fraction': 0.7715256047481182, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,921] Trial 21 finished with value: 0.9192982456140352 and parameters: {'num_leaves': 14, 'learning_rate': 0.13920130630050903, 'feature_fraction': 0.8986698822730919, 'bagging_fraction': 0.9042004926525878, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:21,994] Trial 22 finished with value: 0.894736842105263 and parameters: {'num_leaves': 47, 'learning_rate': 0.13299056503132006, 'feature_fraction': 0.620802585799276, 'bagging_fraction': 0.9335107991705064, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,028] Trial 23 finished with value: 0.9192982456140352 and parameters: {'num_leaves': 94, 'learning_rate': 0.09270290394707253, 'feature_fraction': 0.761767190406613, 'bagging_fraction': 0.8867245598085495, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,072] Trial 24 finished with value: 0.9192982456140352 and parameters: {'num_leaves': 64, 'learning_rate': 0.1097594514127763, 'feature_fraction': 0.6895376018935464, 'bagging_fraction': 0.9678333857233969, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,096] Trial 25 finished with value: 0.887719298245614 and parameters: {'num_leaves': 33, 'learning_rate': 0.058903024974612944, 'feature_fraction': 0.8500841294745454, 'bagging_fraction': 0.871835831325144, 'bagging_freq': 7, 'min_child_samples': 45}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,193] Trial 26 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 197, 'learning_rate': 0.18880725276296087, 'feature_fraction': 0.7163387635708359, 'bagging_fraction': 0.7922937207805878, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,218] Trial 27 finished with value: 0.8982456140350876 and parameters: {'num_leaves': 102, 'learning_rate': 0.1413092814013191, 'feature_fraction': 0.933342208925585, 'bagging_fraction': 0.7046978614924299, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,296] Trial 28 finished with value: 0.8842105263157894 and parameters: {'num_leaves': 149, 'learning_rate': 0.02057819661535651, 'feature_fraction': 0.5455683352030142, 'bagging_fraction': 0.9374025433701392, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,318] Trial 29 finished with value: 0.887719298245614 and parameters: {'num_leaves': 271, 'learning_rate': 0.285143853112804, 'feature_fraction': 0.7983961441484856, 'bagging_fraction': 0.8564021498323147, 'bagging_freq': 7, 'min_child_samples': 40}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,352] Trial 30 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 61, 'learning_rate': 0.11526930043337497, 'feature_fraction': 0.8750871629328132, 'bagging_fraction': 0.7460904766335785, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,390] Trial 31 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 162, 'learning_rate': 0.12402816618482043, 'feature_fraction': 0.7193837565442703, 'bagging_fraction': 0.9764988845893111, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,482] Trial 32 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 147, 'learning_rate': 0.07921237567429879, 'feature_fraction': 0.7389710217483052, 'bagging_fraction': 0.9633514779931037, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,514] Trial 33 finished with value: 0.912280701754386 and parameters: {'num_leaves': 169, 'learning_rate': 0.15404149564201558, 'feature_fraction': 0.6577573414582706, 'bagging_fraction': 0.9141480839338676, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,526] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 210, 'learning_rate': 0.17821462681008415, 'feature_fraction': 0.7650115947140103, 'bagging_fraction': 0.97020706208877, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,585] Trial 35 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 238, 'learning_rate': 0.0463847407101924, 'feature_fraction': 0.6908317360926456, 'bagging_fraction': 0.8687280436540503, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:22,650] Trial 36 finished with value: 0.9508771929824562 and parameters: {'num_leaves': 75, 'learning_rate': 0.12369794254435629, 'feature_fraction': 0.6168430408773552, 'bagging_fraction': 0.9490063401836483, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,663] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 130, 'learning_rate': 0.15862153696096332, 'feature_fraction': 0.6062413285217615, 'bagging_fraction': 0.41912784602765996, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,692] Trial 38 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 180, 'learning_rate': 0.0817377402079514, 'feature_fraction': 0.5679697549517668, 'bagging_fraction': 0.9627884138081496, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,716] Trial 39 finished with value: 0.8912280701754387 and parameters: {'num_leaves': 82, 'learning_rate': 0.20635359303506595, 'feature_fraction': 0.5645770577635858, 'bagging_fraction': 0.8146833493182875, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,732] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 106, 'learning_rate': 0.08089136868540787, 'feature_fraction': 0.48005334673624045, 'bagging_fraction': 0.6373710360825013, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,769] Trial 41 finished with value: 0.9157894736842106 and parameters: {'num_leaves': 175, 'learning_rate': 0.10512752139304293, 'feature_fraction': 0.632652390757647, 'bagging_fraction': 0.9598186727443618, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,803] Trial 42 finished with value: 0.9122807017543859 and parameters: {'num_leaves': 192, 'learning_rate': 0.1214249922681943, 'feature_fraction': 0.550243210592176, 'bagging_fraction': 0.9892410713173603, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,820] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 162, 'learning_rate': 0.14555437475505878, 'feature_fraction': 0.5775593544760174, 'bagging_fraction': 0.9040718522354972, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,847] Trial 44 finished with value: 0.894736842105263 and parameters: {'num_leaves': 137, 'learning_rate': 0.04241688594901191, 'feature_fraction': 0.6692502466035049, 'bagging_fraction': 0.9541560785448668, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:22,902] Trial 45 finished with value: 0.9157894736842105 and parameters: {'num_leaves': 206, 'learning_rate': 0.10565704477072939, 'feature_fraction': 0.7398649415668267, 'bagging_fraction': 0.9189476541544406, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:23,025] Trial 46 finished with value: 0.9087719298245615 and parameters: {'num_leaves': 225, 'learning_rate': 0.08945492924002556, 'feature_fraction': 0.5262011256976914, 'bagging_fraction': 0.9981555463930872, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:23,081] Trial 47 finished with value: 0.9157894736842105 and parameters: {'num_leaves': 72, 'learning_rate': 0.1664312762930958, 'feature_fraction': 0.48541725749064046, 'bagging_fraction': 0.8934269977717509, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:23,109] Trial 48 finished with value: 0.8842105263157894 and parameters: {'num_leaves': 182, 'learning_rate': 0.12258844829109528, 'feature_fraction': 0.7875421003075501, 'bagging_fraction': 0.5766879648629146, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:23,150] Trial 49 finished with value: 0.9157894736842106 and parameters: {'num_leaves': 110, 'learning_rate': 0.07939149456204048, 'feature_fraction': 0.6425948423292179, 'bagging_fraction': 0.8391136012548894, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 36 with value: 0.9508771929824562.
[I 2025-09-17 13:15:23,523] A new study created in memory with name: no-name-a3e18d0c-dfb3-4fca-bbad-7700db8080f6
[I 2025-09-17 13:15:23,533] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 138, 'learning_rate': 0.1124306498795021, 'feature_fraction': 0.6896911833585299, 'bagging_fraction': 0.9546892859164805, 'bagging_freq': 7, 'min_child_samples': 82}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:23,542] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.2906696749373567, 'feature_fraction': 0.935689440852608, 'bagging_fraction': 0.8213055065865658, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:23,557] Trial 2 finished with value: 0.6578947368421052 and parameters: {'num_leaves': 108, 'learning_rate': 0.16700006429546416, 'feature_fraction': 0.9309031509630433, 'bagging_fraction': 0.7215335214606118, 'bagging_freq': 3, 'min_child_samples': 52}. Best is trial 2 with value: 0.6578947368421052.
[I 2025-09-17 13:15:23,583] Trial 3 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 115, 'learning_rate': 0.10123586867381945, 'feature_fraction': 0.9402298772640122, 'bagging_fraction': 0.8203321516474336, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,592] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 186, 'learning_rate': 0.1382088560479046, 'feature_fraction': 0.6186168682705199, 'bagging_fraction': 0.48637073992583185, 'bagging_freq': 7, 'min_child_samples': 73}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,599] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 202, 'learning_rate': 0.031511267437701294, 'feature_fraction': 0.9977345466647791, 'bagging_fraction': 0.5229618302516863, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,611] Trial 6 finished with value: 0.749122807017544 and parameters: {'num_leaves': 187, 'learning_rate': 0.1856998238315967, 'feature_fraction': 0.658753267369707, 'bagging_fraction': 0.8400765192177326, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,620] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.15258703730827317, 'feature_fraction': 0.8510923394121646, 'bagging_fraction': 0.4274755493686416, 'bagging_freq': 3, 'min_child_samples': 78}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,632] Trial 8 finished with value: 0.7807017543859649 and parameters: {'num_leaves': 11, 'learning_rate': 0.2659224065527893, 'feature_fraction': 0.8598313354270964, 'bagging_fraction': 0.814586689915803, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,648] Trial 9 finished with value: 0.7754385964912281 and parameters: {'num_leaves': 30, 'learning_rate': 0.0307819659267766, 'feature_fraction': 0.9971229619884387, 'bagging_fraction': 0.5425368492830204, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,712] Trial 10 finished with value: 0.8175438596491228 and parameters: {'num_leaves': 290, 'learning_rate': 0.08384013145373376, 'feature_fraction': 0.4209042940165829, 'bagging_fraction': 0.6422239519808193, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,764] Trial 11 finished with value: 0.8140350877192983 and parameters: {'num_leaves': 274, 'learning_rate': 0.0830039692350626, 'feature_fraction': 0.4107542483425694, 'bagging_fraction': 0.6493715772708499, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,872] Trial 12 finished with value: 0.8315789473684211 and parameters: {'num_leaves': 267, 'learning_rate': 0.08401665926661926, 'feature_fraction': 0.417918213933141, 'bagging_fraction': 0.6687530567715142, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,923] Trial 13 finished with value: 0.856140350877193 and parameters: {'num_leaves': 79, 'learning_rate': 0.06592268975179394, 'feature_fraction': 0.5405512861267102, 'bagging_fraction': 0.9660716927811399, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 3 with value: 0.8666666666666667.
[I 2025-09-17 13:15:23,950] Trial 14 finished with value: 0.8701754385964912 and parameters: {'num_leaves': 81, 'learning_rate': 0.21271806456356282, 'feature_fraction': 0.5550030765787526, 'bagging_fraction': 0.9755807848254475, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 14 with value: 0.8701754385964912.
[I 2025-09-17 13:15:23,974] Trial 15 finished with value: 0.856140350877193 and parameters: {'num_leaves': 63, 'learning_rate': 0.21123730919113834, 'feature_fraction': 0.7681767857247455, 'bagging_fraction': 0.9099426887763378, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 14 with value: 0.8701754385964912.
[I 2025-09-17 13:15:24,013] Trial 16 finished with value: 0.8736842105263158 and parameters: {'num_leaves': 127, 'learning_rate': 0.19873433709767457, 'feature_fraction': 0.5409670149882375, 'bagging_fraction': 0.902158662138635, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 16 with value: 0.8736842105263158.
[I 2025-09-17 13:15:24,030] Trial 17 finished with value: 0.7578947368421053 and parameters: {'num_leaves': 66, 'learning_rate': 0.22735032924535908, 'feature_fraction': 0.5350207975281018, 'bagging_fraction': 0.9920214273718815, 'bagging_freq': 5, 'min_child_samples': 62}. Best is trial 16 with value: 0.8736842105263158.
[I 2025-09-17 13:15:24,065] Trial 18 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 150, 'learning_rate': 0.2345105513200883, 'feature_fraction': 0.5133298912915604, 'bagging_fraction': 0.887094078083953, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 18 with value: 0.8912280701754386.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.327532
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.357352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.405893
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.362702
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.336703
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.413895
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.367396
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.41636
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.3539
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.398508
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.341553
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.426369
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.343741
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.36704
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.447319
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.4286
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.404352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.419863
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.425376
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.356764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.328477
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.399575
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.378237
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.373391
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.291119
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.357447
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.398712
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.366064
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.363857
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.417016
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.345314
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.367231
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.367976
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.442744
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.354574
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.604917
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.484197
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.600575
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.598528
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.602854
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.522627
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.544302
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.514815
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.468926
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.457115
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.486066
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.465431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.591092
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.461611
[I 2025-09-17 13:15:24,104] Trial 19 finished with value: 0.8631578947368422 and parameters: {'num_leaves': 234, 'learning_rate': 0.24796565714207555, 'feature_fraction': 0.47309957327176916, 'bagging_fraction': 0.8822703637837653, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 18 with value: 0.8912280701754386.
[I 2025-09-17 13:15:24,132] Trial 20 finished with value: 0.8631578947368421 and parameters: {'num_leaves': 151, 'learning_rate': 0.18673028748726195, 'feature_fraction': 0.6058244296579716, 'bagging_fraction': 0.7478673876239353, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 18 with value: 0.8912280701754386.
[I 2025-09-17 13:15:24,152] Trial 21 finished with value: 0.8385964912280702 and parameters: {'num_leaves': 109, 'learning_rate': 0.21527292863425693, 'feature_fraction': 0.5239416932326411, 'bagging_fraction': 0.9086954570067513, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 18 with value: 0.8912280701754386.
[I 2025-09-17 13:15:24,174] Trial 22 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 140, 'learning_rate': 0.24817008433522425, 'feature_fraction': 0.5833992098278672, 'bagging_fraction': 0.9349183242009822, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,214] Trial 23 finished with value: 0.8842105263157896 and parameters: {'num_leaves': 163, 'learning_rate': 0.25764631085873213, 'feature_fraction': 0.4745033853098142, 'bagging_fraction': 0.7697350483299293, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,253] Trial 24 finished with value: 0.8070175438596492 and parameters: {'num_leaves': 160, 'learning_rate': 0.2950823911671345, 'feature_fraction': 0.47623848701999244, 'bagging_fraction': 0.7607713640115727, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,268] Trial 25 finished with value: 0.7473684210526317 and parameters: {'num_leaves': 165, 'learning_rate': 0.2541143941697469, 'feature_fraction': 0.48050768541193245, 'bagging_fraction': 0.781174286581027, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,286] Trial 26 finished with value: 0.8403508771929824 and parameters: {'num_leaves': 221, 'learning_rate': 0.2387828611547546, 'feature_fraction': 0.5989321399552233, 'bagging_fraction': 0.8590030504579131, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,388] Trial 27 finished with value: 0.8491228070175438 and parameters: {'num_leaves': 167, 'learning_rate': 0.27310374098773454, 'feature_fraction': 0.7166822289143471, 'bagging_fraction': 0.9329523755582803, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,424] Trial 28 finished with value: 0.8771929824561403 and parameters: {'num_leaves': 234, 'learning_rate': 0.2745479483045512, 'feature_fraction': 0.4853535837519949, 'bagging_fraction': 0.6034931425347615, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,442] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.23975265567759524, 'feature_fraction': 0.6828844105881656, 'bagging_fraction': 0.7086926408114833, 'bagging_freq': 7, 'min_child_samples': 61}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,460] Trial 30 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 135, 'learning_rate': 0.2977483701754044, 'feature_fraction': 0.5768530257644744, 'bagging_fraction': 0.7935714784900497, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,495] Trial 31 finished with value: 0.8456140350877193 and parameters: {'num_leaves': 241, 'learning_rate': 0.2757429571416618, 'feature_fraction': 0.4801877096572393, 'bagging_fraction': 0.5932560456568083, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,551] Trial 32 finished with value: 0.8280701754385965 and parameters: {'num_leaves': 213, 'learning_rate': 0.2624467882957768, 'feature_fraction': 0.5081849729859375, 'bagging_fraction': 0.6077593951208373, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,614] Trial 33 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 172, 'learning_rate': 0.27906154726923016, 'feature_fraction': 0.444144379020587, 'bagging_fraction': 0.8684772212878239, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,646] Trial 34 finished with value: 0.8631578947368421 and parameters: {'num_leaves': 168, 'learning_rate': 0.22670983927611443, 'feature_fraction': 0.44704908499123674, 'bagging_fraction': 0.8517423739231205, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,716] Trial 35 finished with value: 0.8491228070175438 and parameters: {'num_leaves': 121, 'learning_rate': 0.28353084614645857, 'feature_fraction': 0.6378551120385285, 'bagging_fraction': 0.9498168715623894, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,733] Trial 36 finished with value: 0.7105263157894737 and parameters: {'num_leaves': 102, 'learning_rate': 0.25390982895213876, 'feature_fraction': 0.449562676622164, 'bagging_fraction': 0.8680721519629983, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,748] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 178, 'learning_rate': 0.17657813806872866, 'feature_fraction': 0.5712930637931797, 'bagging_fraction': 0.8187256750946703, 'bagging_freq': 6, 'min_child_samples': 94}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,780] Trial 38 finished with value: 0.9017543859649122 and parameters: {'num_leaves': 146, 'learning_rate': 0.23163078318937574, 'feature_fraction': 0.5103515421474212, 'bagging_fraction': 0.740350056611494, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,797] Trial 39 finished with value: 0.7087719298245614 and parameters: {'num_leaves': 153, 'learning_rate': 0.1384736111929195, 'feature_fraction': 0.7485521435349654, 'bagging_fraction': 0.7313592819927579, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,820] Trial 40 finished with value: 0.8210526315789474 and parameters: {'num_leaves': 93, 'learning_rate': 0.16511903349836868, 'feature_fraction': 0.5079898491280049, 'bagging_fraction': 0.9320511197586617, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,850] Trial 41 finished with value: 0.8350877192982455 and parameters: {'num_leaves': 199, 'learning_rate': 0.22901966064811213, 'feature_fraction': 0.44393561455329683, 'bagging_fraction': 0.6858563821314497, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,905] Trial 42 finished with value: 0.8842105263157896 and parameters: {'num_leaves': 128, 'learning_rate': 0.25938367485405356, 'feature_fraction': 0.573149796532424, 'bagging_fraction': 0.7845892059644635, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,940] Trial 43 finished with value: 0.8877192982456141 and parameters: {'num_leaves': 141, 'learning_rate': 0.28596093421869656, 'feature_fraction': 0.500720803590282, 'bagging_fraction': 0.8367586156823622, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:24,958] Trial 44 finished with value: 0.8157894736842106 and parameters: {'num_leaves': 178, 'learning_rate': 0.2871768567682279, 'feature_fraction': 0.6306188711379025, 'bagging_fraction': 0.8339259909020171, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:25,024] Trial 45 finished with value: 0.8631578947368421 and parameters: {'num_leaves': 142, 'learning_rate': 0.2413962215639304, 'feature_fraction': 0.5116897039224337, 'bagging_fraction': 0.8900437356039171, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:25,058] Trial 46 finished with value: 0.8543859649122808 and parameters: {'num_leaves': 146, 'learning_rate': 0.28113448730608986, 'feature_fraction': 0.4034017533598592, 'bagging_fraction': 0.8044963160275164, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:25,082] Trial 47 finished with value: 0.8175438596491228 and parameters: {'num_leaves': 118, 'learning_rate': 0.20224469446293436, 'feature_fraction': 0.44296279118627063, 'bagging_fraction': 0.9977545223136458, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:25,102] Trial 48 finished with value: 0.8052631578947369 and parameters: {'num_leaves': 186, 'learning_rate': 0.2685835757666245, 'feature_fraction': 0.6589543258683277, 'bagging_fraction': 0.9247388734299791, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:25,141] Trial 49 finished with value: 0.856140350877193 and parameters: {'num_leaves': 133, 'learning_rate': 0.29532437375208803, 'feature_fraction': 0.552270851113214, 'bagging_fraction': 0.836668265860514, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 22 with value: 0.9017543859649123.
[I 2025-09-17 13:15:25,403] A new study created in memory with name: no-name-9a75669b-0297-4cb6-b056-d42ed42916f4
[I 2025-09-17 13:15:25,421] Trial 0 finished with value: 0.9008264462809918 and parameters: {'num_leaves': 80, 'learning_rate': 0.08326932554506175, 'feature_fraction': 0.4854318227483889, 'bagging_fraction': 0.9557229548566483, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 0 with value: 0.9008264462809918.
[I 2025-09-17 13:15:25,438] Trial 1 finished with value: 0.6983471074380165 and parameters: {'num_leaves': 183, 'learning_rate': 0.24811128312397196, 'feature_fraction': 0.4119319062612623, 'bagging_fraction': 0.44667600111590927, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 0 with value: 0.9008264462809918.
[I 2025-09-17 13:15:25,463] Trial 2 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 242, 'learning_rate': 0.09149310914205612, 'feature_fraction': 0.9407661839768707, 'bagging_fraction': 0.606853316156746, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 2 with value: 0.9504132231404958.
[I 2025-09-17 13:15:25,495] Trial 3 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 76, 'learning_rate': 0.016167237394348256, 'feature_fraction': 0.5606913216679851, 'bagging_fraction': 0.5855014350435448, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,505] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 196, 'learning_rate': 0.2538206013820342, 'feature_fraction': 0.8374227026538268, 'bagging_fraction': 0.5277381104378379, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,515] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 12, 'learning_rate': 0.21782007997094965, 'feature_fraction': 0.9676515868600566, 'bagging_fraction': 0.6137977934389833, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,523] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 99, 'learning_rate': 0.2536661288774081, 'feature_fraction': 0.6780616013217823, 'bagging_fraction': 0.49260822369178825, 'bagging_freq': 1, 'min_child_samples': 51}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,568] Trial 7 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 13, 'learning_rate': 0.28049231939074787, 'feature_fraction': 0.5571407616259249, 'bagging_fraction': 0.8854411601647947, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,597] Trial 8 finished with value: 0.9297520661157026 and parameters: {'num_leaves': 43, 'learning_rate': 0.1954145576217429, 'feature_fraction': 0.8345407040175408, 'bagging_fraction': 0.9900485956983492, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,624] Trial 9 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 215, 'learning_rate': 0.08543466367729118, 'feature_fraction': 0.5123313834431727, 'bagging_fraction': 0.5992430781633022, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,639] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 290, 'learning_rate': 0.031344022011404286, 'feature_fraction': 0.6846297993504893, 'bagging_fraction': 0.7788473572301933, 'bagging_freq': 6, 'min_child_samples': 77}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,759] Trial 11 finished with value: 0.921487603305785 and parameters: {'num_leaves': 116, 'learning_rate': 0.15973075659797942, 'feature_fraction': 0.5895334978765806, 'bagging_fraction': 0.7980781700392001, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,830] Trial 12 finished with value: 0.9297520661157025 and parameters: {'num_leaves': 11, 'learning_rate': 0.295667618855696, 'feature_fraction': 0.5856113082229906, 'bagging_fraction': 0.8570609485039846, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,854] Trial 13 finished with value: 0.9173553719008264 and parameters: {'num_leaves': 63, 'learning_rate': 0.012966660864794172, 'feature_fraction': 0.5737613980522447, 'bagging_fraction': 0.7401672625882224, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,867] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 138, 'learning_rate': 0.13719497495280256, 'feature_fraction': 0.4209853615098442, 'bagging_fraction': 0.878685994201339, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,904] Trial 15 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 48, 'learning_rate': 0.14313869827661255, 'feature_fraction': 0.7716242706991014, 'bagging_fraction': 0.6765780549723852, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:25,927] Trial 16 finished with value: 0.7603305785123967 and parameters: {'num_leaves': 149, 'learning_rate': 0.04598275524784172, 'feature_fraction': 0.6310236364606939, 'bagging_fraction': 0.6832804341389878, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,029] Trial 17 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 33, 'learning_rate': 0.2876683584901567, 'feature_fraction': 0.5081067880297746, 'bagging_fraction': 0.8976265824580664, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,044] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 85, 'learning_rate': 0.18178561708256838, 'feature_fraction': 0.7261256642313854, 'bagging_fraction': 0.5453015795618498, 'bagging_freq': 2, 'min_child_samples': 100}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,075] Trial 19 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 109, 'learning_rate': 0.10405133970652056, 'feature_fraction': 0.47375552009964805, 'bagging_fraction': 0.4198562684496193, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,109] Trial 20 finished with value: 0.9462809917355371 and parameters: {'num_leaves': 67, 'learning_rate': 0.05991111190467095, 'feature_fraction': 0.5427958086665463, 'bagging_fraction': 0.8248562806945426, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,142] Trial 21 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 246, 'learning_rate': 0.10887303990773395, 'feature_fraction': 0.9901198939256737, 'bagging_fraction': 0.6227765375844275, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,190] Trial 22 finished with value: 0.9380165289256199 and parameters: {'num_leaves': 258, 'learning_rate': 0.05936131805593565, 'feature_fraction': 0.8919050517760279, 'bagging_fraction': 0.7269367889359427, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,213] Trial 23 finished with value: 0.9359504132231405 and parameters: {'num_leaves': 176, 'learning_rate': 0.11592279600237382, 'feature_fraction': 0.6356081863775517, 'bagging_fraction': 0.5648342120479086, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,272] Trial 24 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 244, 'learning_rate': 0.02183322692214537, 'feature_fraction': 0.7526074396229366, 'bagging_fraction': 0.6631781679171995, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,300] Trial 25 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 296, 'learning_rate': 0.06852543385716454, 'feature_fraction': 0.9014469608630906, 'bagging_fraction': 0.485762468855667, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,325] Trial 26 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 29, 'learning_rate': 0.17643184300746456, 'feature_fraction': 0.6536039714074322, 'bagging_fraction': 0.6392326483386691, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,339] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 139, 'learning_rate': 0.22663826978163865, 'feature_fraction': 0.8040463558092026, 'bagging_fraction': 0.5825206165753126, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 3 with value: 0.9628099173553719.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.488847
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.48204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.531773
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.437053
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.456786
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.524221
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.60285
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.524199
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.566581
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.500549
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.523914
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.495846
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.523206
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.449673
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.482985
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.484777
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.613641
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.481755
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.608253
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.498934
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.52438
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.460504
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.476173
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.554025
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.455576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.496051
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.532996
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.52911
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.481293
Training model for P046... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.520519
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.509625
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.342816
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.403234
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.297783
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.320875
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.330342
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.346131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.355635
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.562667
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.352749
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.549029
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.289875
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.372733
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.330824
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.35747
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.321479
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.364294
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.335102
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.369953
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.393965
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.636901
[I 2025-09-17 13:15:26,403] Trial 28 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 209, 'learning_rate': 0.1282206327299926, 'feature_fraction': 0.4600471925748764, 'bagging_fraction': 0.7258533476022451, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 3 with value: 0.9628099173553719.
[I 2025-09-17 13:15:26,492] Trial 29 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 208, 'learning_rate': 0.13281890268792582, 'feature_fraction': 0.4655053793160054, 'bagging_fraction': 0.9109193917328137, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 29 with value: 0.9669421487603306.
[I 2025-09-17 13:15:26,580] Trial 30 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 83, 'learning_rate': 0.1629606883702506, 'feature_fraction': 0.5478370893047854, 'bagging_fraction': 0.9731027369349957, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 29 with value: 0.9669421487603306.
[I 2025-09-17 13:15:26,677] Trial 31 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 223, 'learning_rate': 0.1336402154121679, 'feature_fraction': 0.4541897102423025, 'bagging_fraction': 0.9243859361391813, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 29 with value: 0.9669421487603306.
[I 2025-09-17 13:15:26,715] Trial 32 finished with value: 0.9793388429752066 and parameters: {'num_leaves': 168, 'learning_rate': 0.192924913228995, 'feature_fraction': 0.4366021651268914, 'bagging_fraction': 0.8872523202101306, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:26,745] Trial 33 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 168, 'learning_rate': 0.20540086874604138, 'feature_fraction': 0.40756621642509516, 'bagging_fraction': 0.9321396486252479, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:26,793] Trial 34 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 221, 'learning_rate': 0.1491896539554586, 'feature_fraction': 0.4526787192868241, 'bagging_fraction': 0.9366523323118028, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:26,821] Trial 35 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 193, 'learning_rate': 0.22834146577811865, 'feature_fraction': 0.4325611667660886, 'bagging_fraction': 0.929393679949913, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:26,835] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 268, 'learning_rate': 0.17777066789163176, 'feature_fraction': 0.5079226739928706, 'bagging_fraction': 0.8415782652794026, 'bagging_freq': 7, 'min_child_samples': 63}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:26,852] Trial 37 finished with value: 0.7685950413223142 and parameters: {'num_leaves': 158, 'learning_rate': 0.11958481892160455, 'feature_fraction': 0.401102652452447, 'bagging_fraction': 0.7798228666441012, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:26,868] Trial 38 finished with value: 0.5516528925619835 and parameters: {'num_leaves': 227, 'learning_rate': 0.09239635431997592, 'feature_fraction': 0.4865204665281733, 'bagging_fraction': 0.9129865831005834, 'bagging_freq': 7, 'min_child_samples': 54}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:26,914] Trial 39 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 193, 'learning_rate': 0.19775143764578773, 'feature_fraction': 0.43762311066777776, 'bagging_fraction': 0.9937894682868997, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:26,965] Trial 40 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 200, 'learning_rate': 0.2691095915306443, 'feature_fraction': 0.5260448579362345, 'bagging_fraction': 0.8670291021916702, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,084] Trial 41 finished with value: 0.9173553719008264 and parameters: {'num_leaves': 129, 'learning_rate': 0.2717919601653745, 'feature_fraction': 0.48831245847761995, 'bagging_fraction': 0.9597608968739461, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,156] Trial 42 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 169, 'learning_rate': 0.23161903545530776, 'feature_fraction': 0.5606260444163284, 'bagging_fraction': 0.8964885207579335, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,184] Trial 43 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 183, 'learning_rate': 0.20945709384966466, 'feature_fraction': 0.6042047798534675, 'bagging_fraction': 0.8130997108136269, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,238] Trial 44 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 232, 'learning_rate': 0.2438092036930058, 'feature_fraction': 0.4626495215324212, 'bagging_fraction': 0.8446858022663746, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,343] Trial 45 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 100, 'learning_rate': 0.09596543751842307, 'feature_fraction': 0.5239475849155877, 'bagging_fraction': 0.880993305591021, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,398] Trial 46 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 49, 'learning_rate': 0.13038314173299326, 'feature_fraction': 0.6106169692295417, 'bagging_fraction': 0.7619592993584337, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,415] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 23, 'learning_rate': 0.16448205888596706, 'feature_fraction': 0.49997670344260114, 'bagging_fraction': 0.9541499814965162, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,444] Trial 48 finished with value: 0.9586776859504131 and parameters: {'num_leaves': 267, 'learning_rate': 0.07200840333243744, 'feature_fraction': 0.4355160532234504, 'bagging_fraction': 0.9075024092773307, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,467] Trial 49 finished with value: 0.6322314049586776 and parameters: {'num_leaves': 282, 'learning_rate': 0.03956103267714145, 'feature_fraction': 0.4428543899789904, 'bagging_fraction': 0.500162378631207, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 32 with value: 0.9793388429752066.
[I 2025-09-17 13:15:27,750] A new study created in memory with name: no-name-b804658f-50c7-49a2-9684-9cf8ab1da9ff
[I 2025-09-17 13:15:27,770] Trial 0 finished with value: 0.6818181818181818 and parameters: {'num_leaves': 198, 'learning_rate': 0.05785352098098076, 'feature_fraction': 0.7033665409240787, 'bagging_fraction': 0.6527997167610644, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 0 with value: 0.6818181818181818.
[I 2025-09-17 13:15:27,791] Trial 1 finished with value: 0.6735537190082644 and parameters: {'num_leaves': 76, 'learning_rate': 0.22089677006638564, 'feature_fraction': 0.5016778390108475, 'bagging_fraction': 0.4262321741556668, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 0 with value: 0.6818181818181818.
[I 2025-09-17 13:15:27,803] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 174, 'learning_rate': 0.16971066700435544, 'feature_fraction': 0.6685938709272978, 'bagging_fraction': 0.4031770244741202, 'bagging_freq': 3, 'min_child_samples': 45}. Best is trial 0 with value: 0.6818181818181818.
[I 2025-09-17 13:15:27,811] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.04940166879101516, 'feature_fraction': 0.7593900839452358, 'bagging_fraction': 0.5665413919286558, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 0 with value: 0.6818181818181818.
[I 2025-09-17 13:15:27,830] Trial 4 finished with value: 0.7396694214876033 and parameters: {'num_leaves': 203, 'learning_rate': 0.18273468828222084, 'feature_fraction': 0.6784599162996922, 'bagging_fraction': 0.8525894368028752, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 4 with value: 0.7396694214876033.
[I 2025-09-17 13:15:27,837] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 105, 'learning_rate': 0.25376042356224704, 'feature_fraction': 0.4964418459544777, 'bagging_fraction': 0.5809172100362024, 'bagging_freq': 7, 'min_child_samples': 74}. Best is trial 4 with value: 0.7396694214876033.
[I 2025-09-17 13:15:27,848] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.041382917054037203, 'feature_fraction': 0.6405069287013935, 'bagging_fraction': 0.4311399972020016, 'bagging_freq': 2, 'min_child_samples': 86}. Best is trial 4 with value: 0.7396694214876033.
[I 2025-09-17 13:15:27,942] Trial 7 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 111, 'learning_rate': 0.15259223841944664, 'feature_fraction': 0.5486112101999455, 'bagging_fraction': 0.544894031879419, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 7 with value: 0.9669421487603306.
[I 2025-09-17 13:15:27,968] Trial 8 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 211, 'learning_rate': 0.09912341571377033, 'feature_fraction': 0.7238099465688905, 'bagging_fraction': 0.6559202820571722, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 7 with value: 0.9669421487603306.
[I 2025-09-17 13:15:27,992] Trial 9 finished with value: 0.9710743801652892 and parameters: {'num_leaves': 176, 'learning_rate': 0.038562451363529274, 'feature_fraction': 0.9280757627346393, 'bagging_fraction': 0.9332079009042162, 'bagging_freq': 5, 'min_child_samples': 39}. Best is trial 9 with value: 0.9710743801652892.
[I 2025-09-17 13:15:28,132] Trial 10 finished with value: 0.9669421487603305 and parameters: {'num_leaves': 266, 'learning_rate': 0.10770806284823442, 'feature_fraction': 0.9688624000648952, 'bagging_fraction': 0.9967594793422703, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 9 with value: 0.9710743801652892.
[I 2025-09-17 13:15:28,236] Trial 11 finished with value: 0.9793388429752066 and parameters: {'num_leaves': 30, 'learning_rate': 0.28783866816959147, 'feature_fraction': 0.9154449567871358, 'bagging_fraction': 0.8066681270109386, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.9793388429752066.
[I 2025-09-17 13:15:28,247] Trial 12 finished with value: 0.5 and parameters: {'num_leaves': 18, 'learning_rate': 0.2999605109627095, 'feature_fraction': 0.9644391661705528, 'bagging_fraction': 0.8326377108747429, 'bagging_freq': 1, 'min_child_samples': 66}. Best is trial 11 with value: 0.9793388429752066.
[I 2025-09-17 13:15:28,262] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 28, 'learning_rate': 0.29307621169036246, 'feature_fraction': 0.8475500496630513, 'bagging_fraction': 0.8336455654305037, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 11 with value: 0.9793388429752066.
[I 2025-09-17 13:15:28,315] Trial 14 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 263, 'learning_rate': 0.011429536131505783, 'feature_fraction': 0.8619886064319724, 'bagging_fraction': 0.9591264919109569, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 11 with value: 0.9793388429752066.
[I 2025-09-17 13:15:28,366] Trial 15 finished with value: 0.9752066115702479 and parameters: {'num_leaves': 63, 'learning_rate': 0.11684946437321819, 'feature_fraction': 0.8507612488453781, 'bagging_fraction': 0.9031646490579278, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 11 with value: 0.9793388429752066.
[I 2025-09-17 13:15:28,416] Trial 16 finished with value: 0.9793388429752067 and parameters: {'num_leaves': 56, 'learning_rate': 0.12468437735224339, 'feature_fraction': 0.8270634552181849, 'bagging_fraction': 0.7910870353835864, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 16 with value: 0.9793388429752067.
[I 2025-09-17 13:15:28,458] Trial 17 finished with value: 0.9834710743801653 and parameters: {'num_leaves': 48, 'learning_rate': 0.21523736339151994, 'feature_fraction': 0.8068710708376015, 'bagging_fraction': 0.767912770273772, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 17 with value: 0.9834710743801653.
[I 2025-09-17 13:15:28,517] Trial 18 finished with value: 0.9917355371900827 and parameters: {'num_leaves': 121, 'learning_rate': 0.21184545994246975, 'feature_fraction': 0.41168122722306266, 'bagging_fraction': 0.7595270397190742, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,530] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 126, 'learning_rate': 0.2107180765722251, 'feature_fraction': 0.4088982420404117, 'bagging_fraction': 0.714297485818744, 'bagging_freq': 2, 'min_child_samples': 60}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,577] Trial 20 finished with value: 0.9710743801652892 and parameters: {'num_leaves': 134, 'learning_rate': 0.24094339240109425, 'feature_fraction': 0.5862538795284673, 'bagging_fraction': 0.7309527231490697, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,620] Trial 21 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 71, 'learning_rate': 0.13504870165546573, 'feature_fraction': 0.7851290882038326, 'bagging_fraction': 0.7580957250233182, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,676] Trial 22 finished with value: 0.9793388429752066 and parameters: {'num_leaves': 51, 'learning_rate': 0.19385232048766093, 'feature_fraction': 0.8118876843862488, 'bagging_fraction': 0.7673887875689711, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,708] Trial 23 finished with value: 0.9586776859504131 and parameters: {'num_leaves': 92, 'learning_rate': 0.2544403182243931, 'feature_fraction': 0.7562896739474302, 'bagging_fraction': 0.6627134708640557, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,782] Trial 24 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 47, 'learning_rate': 0.14645721040472387, 'feature_fraction': 0.4422530802115732, 'bagging_fraction': 0.888021013317714, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,824] Trial 25 finished with value: 0.9917355371900827 and parameters: {'num_leaves': 11, 'learning_rate': 0.21051251697686296, 'feature_fraction': 0.6143246914053855, 'bagging_fraction': 0.764357889587189, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,864] Trial 26 finished with value: 0.9834710743801653 and parameters: {'num_leaves': 11, 'learning_rate': 0.22248949351444214, 'feature_fraction': 0.5762387806755791, 'bagging_fraction': 0.6999622430257068, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,887] Trial 27 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 300, 'learning_rate': 0.19837030598395508, 'feature_fraction': 0.6164606913464691, 'bagging_fraction': 0.6949366352883339, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,909] Trial 28 finished with value: 0.7933884297520661 and parameters: {'num_leaves': 87, 'learning_rate': 0.2709631476767129, 'feature_fraction': 0.4920506687627507, 'bagging_fraction': 0.8701679511452932, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,931] Trial 29 finished with value: 0.6942148760330579 and parameters: {'num_leaves': 37, 'learning_rate': 0.175071599058878, 'feature_fraction': 0.708537183231178, 'bagging_fraction': 0.6078015389720003, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:28,967] Trial 30 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 122, 'learning_rate': 0.23242620511817108, 'feature_fraction': 0.5389111633041994, 'bagging_fraction': 0.7608945370649349, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,004] Trial 31 finished with value: 0.9586776859504131 and parameters: {'num_leaves': 23, 'learning_rate': 0.21358938638385722, 'feature_fraction': 0.6073944692733984, 'bagging_fraction': 0.6951268067159959, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,073] Trial 32 finished with value: 0.9876033057851239 and parameters: {'num_leaves': 20, 'learning_rate': 0.22893801243021997, 'feature_fraction': 0.5597778224884187, 'bagging_fraction': 0.625247884811421, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,111] Trial 33 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 42, 'learning_rate': 0.2510283951001664, 'feature_fraction': 0.4444952012960422, 'bagging_fraction': 0.491068177196102, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,163] Trial 34 finished with value: 0.9586776859504132 and parameters: {'num_leaves': 11, 'learning_rate': 0.1997680725860636, 'feature_fraction': 0.652022301594434, 'bagging_fraction': 0.6243194045137266, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,209] Trial 35 finished with value: 0.9834710743801653 and parameters: {'num_leaves': 146, 'learning_rate': 0.27257802655318114, 'feature_fraction': 0.5253247237584175, 'bagging_fraction': 0.809004326098093, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 18 with value: 0.9917355371900827.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.31254
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.243839
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.266842
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.243554
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.265511
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.294995
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.278272
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.302016
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.581245
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.627
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.325943
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.301603
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.344658
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.322304
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.318026
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.316959
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.285542
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.290147
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.294314
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.616186
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.578262
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.562114
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.527343
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.292641
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.297604
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.314038
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.261673
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.243302
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.376133
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.237659
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.254593
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.241945
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.206907
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.273754
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.253918
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.220192
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.264854
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.349146
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.211386
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.21608
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.312573
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.519277
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.561278
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.271012
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.292291
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.180355
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.257806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.275168
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.184839
[I 2025-09-17 13:15:29,286] Trial 36 finished with value: 0.9793388429752066 and parameters: {'num_leaves': 85, 'learning_rate': 0.17385688303202984, 'feature_fraction': 0.46377014307360204, 'bagging_fraction': 0.7315692029315032, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,297] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 70, 'learning_rate': 0.2322164900766031, 'feature_fraction': 0.6841493772309788, 'bagging_fraction': 0.533957958631022, 'bagging_freq': 1, 'min_child_samples': 45}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,320] Trial 38 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 105, 'learning_rate': 0.16280485417257254, 'feature_fraction': 0.7299341092047938, 'bagging_fraction': 0.6247411082730299, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,393] Trial 39 finished with value: 0.987603305785124 and parameters: {'num_leaves': 32, 'learning_rate': 0.1829245655994216, 'feature_fraction': 0.5595521965435228, 'bagging_fraction': 0.6582964044937687, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,509] Trial 40 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 223, 'learning_rate': 0.19208489505653745, 'feature_fraction': 0.5075018351577785, 'bagging_fraction': 0.6700288074022825, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,586] Trial 41 finished with value: 0.9917355371900827 and parameters: {'num_leaves': 36, 'learning_rate': 0.21258722524937199, 'feature_fraction': 0.5685629152335767, 'bagging_fraction': 0.5953322227417713, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,651] Trial 42 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 30, 'learning_rate': 0.18019507454002223, 'feature_fraction': 0.5699595750249618, 'bagging_fraction': 0.5576364838085437, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,718] Trial 43 finished with value: 0.9793388429752066 and parameters: {'num_leaves': 33, 'learning_rate': 0.22784603079099588, 'feature_fraction': 0.6500109556296358, 'bagging_fraction': 0.5897176400047038, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,748] Trial 44 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 11, 'learning_rate': 0.08447338488822506, 'feature_fraction': 0.6139599327584561, 'bagging_fraction': 0.5165826903350687, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,780] Trial 45 finished with value: 0.9793388429752067 and parameters: {'num_leaves': 164, 'learning_rate': 0.20973684556727332, 'feature_fraction': 0.5585442693574705, 'bagging_fraction': 0.6827477077712352, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,827] Trial 46 finished with value: 0.9834710743801653 and parameters: {'num_leaves': 61, 'learning_rate': 0.24340170989317333, 'feature_fraction': 0.4768271140954564, 'bagging_fraction': 0.6458458215651768, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,919] Trial 47 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 194, 'learning_rate': 0.1608791931062524, 'feature_fraction': 0.4095388342176192, 'bagging_fraction': 0.47147472125960876, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,932] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 20, 'learning_rate': 0.18427775667619473, 'feature_fraction': 0.524364375321793, 'bagging_fraction': 0.5953446856304642, 'bagging_freq': 2, 'min_child_samples': 78}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:29,998] Trial 49 finished with value: 0.9710743801652892 and parameters: {'num_leaves': 99, 'learning_rate': 0.25816868557028994, 'feature_fraction': 0.6325119583768135, 'bagging_fraction': 0.7288714286254456, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 18 with value: 0.9917355371900827.
[I 2025-09-17 13:15:30,310] A new study created in memory with name: no-name-6873af63-15ef-4229-b86c-39546065c359
[I 2025-09-17 13:15:30,327] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 202, 'learning_rate': 0.2530493154871888, 'feature_fraction': 0.5430816638910158, 'bagging_fraction': 0.6537708906471034, 'bagging_freq': 3, 'min_child_samples': 51}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:30,349] Trial 1 finished with value: 0.8801652892561984 and parameters: {'num_leaves': 33, 'learning_rate': 0.2966148505298089, 'feature_fraction': 0.8805768167708035, 'bagging_fraction': 0.9390403703976467, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 1 with value: 0.8801652892561984.
[I 2025-09-17 13:15:30,382] Trial 2 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 243, 'learning_rate': 0.2551372352097897, 'feature_fraction': 0.5696396694420083, 'bagging_fraction': 0.6954263918775345, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 2 with value: 0.9132231404958677.
[I 2025-09-17 13:15:30,390] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 73, 'learning_rate': 0.27864803980063174, 'feature_fraction': 0.9281800161396442, 'bagging_fraction': 0.909683205933971, 'bagging_freq': 7, 'min_child_samples': 76}. Best is trial 2 with value: 0.9132231404958677.
[I 2025-09-17 13:15:30,396] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 52, 'learning_rate': 0.21991124158512043, 'feature_fraction': 0.9172028025730316, 'bagging_fraction': 0.7515139103679438, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 2 with value: 0.9132231404958677.
[I 2025-09-17 13:15:30,415] Trial 5 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 135, 'learning_rate': 0.27313114850466486, 'feature_fraction': 0.5895173477103426, 'bagging_fraction': 0.843066666082436, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 2 with value: 0.9132231404958677.
[I 2025-09-17 13:15:30,423] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 109, 'learning_rate': 0.19442044525566374, 'feature_fraction': 0.8476051698759106, 'bagging_fraction': 0.8237279475006929, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 2 with value: 0.9132231404958677.
[I 2025-09-17 13:15:30,431] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 117, 'learning_rate': 0.04942030004032475, 'feature_fraction': 0.6372016898993512, 'bagging_fraction': 0.46197884026385017, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 2 with value: 0.9132231404958677.
[I 2025-09-17 13:15:30,493] Trial 8 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 204, 'learning_rate': 0.11793944590165997, 'feature_fraction': 0.5337691743151097, 'bagging_fraction': 0.996547494225456, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 2 with value: 0.9132231404958677.
[I 2025-09-17 13:15:30,528] Trial 9 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 245, 'learning_rate': 0.22366637418487734, 'feature_fraction': 0.6792127851112973, 'bagging_fraction': 0.71053426145658, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 2 with value: 0.9132231404958677.
[I 2025-09-17 13:15:30,655] Trial 10 finished with value: 0.921487603305785 and parameters: {'num_leaves': 282, 'learning_rate': 0.14169376730079714, 'feature_fraction': 0.4429248090539316, 'bagging_fraction': 0.5609901343060162, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 10 with value: 0.921487603305785.
[I 2025-09-17 13:15:30,709] Trial 11 finished with value: 0.9173553719008265 and parameters: {'num_leaves': 284, 'learning_rate': 0.13526341440251785, 'feature_fraction': 0.4026058819965879, 'bagging_fraction': 0.5645759992462653, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 10 with value: 0.921487603305785.
[I 2025-09-17 13:15:30,757] Trial 12 finished with value: 0.8223140495867768 and parameters: {'num_leaves': 298, 'learning_rate': 0.12435065636868406, 'feature_fraction': 0.42916416626529774, 'bagging_fraction': 0.5468334334072656, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 10 with value: 0.921487603305785.
[I 2025-09-17 13:15:30,782] Trial 13 finished with value: 0.8884297520661157 and parameters: {'num_leaves': 297, 'learning_rate': 0.07019011192626225, 'feature_fraction': 0.4020319140435524, 'bagging_fraction': 0.5625943338370492, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 10 with value: 0.921487603305785.
[I 2025-09-17 13:15:30,840] Trial 14 finished with value: 0.9214876033057852 and parameters: {'num_leaves': 247, 'learning_rate': 0.15635661754543934, 'feature_fraction': 0.780009048345373, 'bagging_fraction': 0.42368957537767005, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 14 with value: 0.9214876033057852.
[I 2025-09-17 13:15:30,900] Trial 15 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 195, 'learning_rate': 0.171329274989113, 'feature_fraction': 0.7824497317901681, 'bagging_fraction': 0.4137614330899353, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 15 with value: 0.9256198347107438.
[I 2025-09-17 13:15:30,911] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 175, 'learning_rate': 0.1813053547150012, 'feature_fraction': 0.7916488947708169, 'bagging_fraction': 0.4038704360642548, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 15 with value: 0.9256198347107438.
[I 2025-09-17 13:15:30,931] Trial 17 finished with value: 0.8471074380165289 and parameters: {'num_leaves': 233, 'learning_rate': 0.07703500985832841, 'feature_fraction': 0.7664634939648949, 'bagging_fraction': 0.46627219920608726, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 15 with value: 0.9256198347107438.
[I 2025-09-17 13:15:30,942] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.17049681382957177, 'feature_fraction': 0.7487882983013829, 'bagging_fraction': 0.41395966218363867, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial 15 with value: 0.9256198347107438.
[I 2025-09-17 13:15:30,957] Trial 19 finished with value: 0.6239669421487604 and parameters: {'num_leaves': 212, 'learning_rate': 0.012907200185256373, 'feature_fraction': 0.8152731351111343, 'bagging_fraction': 0.5004677774954338, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 15 with value: 0.9256198347107438.
[I 2025-09-17 13:15:30,982] Trial 20 finished with value: 0.8884297520661156 and parameters: {'num_leaves': 161, 'learning_rate': 0.20739407311961697, 'feature_fraction': 0.9787986091278142, 'bagging_fraction': 0.635887877676727, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 15 with value: 0.9256198347107438.
[I 2025-09-17 13:15:31,022] Trial 21 finished with value: 0.8801652892561982 and parameters: {'num_leaves': 266, 'learning_rate': 0.14938688272872117, 'feature_fraction': 0.6961124957909195, 'bagging_fraction': 0.5192717572363914, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 15 with value: 0.9256198347107438.
[I 2025-09-17 13:15:31,105] Trial 22 finished with value: 0.8801652892561984 and parameters: {'num_leaves': 259, 'learning_rate': 0.11268970823469202, 'feature_fraction': 0.471070652058022, 'bagging_fraction': 0.45345354559509166, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 15 with value: 0.9256198347107438.
[I 2025-09-17 13:15:31,133] Trial 23 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 219, 'learning_rate': 0.16528370326917252, 'feature_fraction': 0.721254714478898, 'bagging_fraction': 0.5934190260452703, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,155] Trial 24 finished with value: 0.896694214876033 and parameters: {'num_leaves': 230, 'learning_rate': 0.16843699886460808, 'feature_fraction': 0.7459562003793849, 'bagging_fraction': 0.40151036595291956, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,196] Trial 25 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 186, 'learning_rate': 0.10364282096279623, 'feature_fraction': 0.6458232008419846, 'bagging_fraction': 0.6355532558740675, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,221] Trial 26 finished with value: 0.9008264462809916 and parameters: {'num_leaves': 148, 'learning_rate': 0.1893147077496423, 'feature_fraction': 0.722417635801928, 'bagging_fraction': 0.49304015039928495, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,235] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 216, 'learning_rate': 0.16350723392730215, 'feature_fraction': 0.8228038974247134, 'bagging_fraction': 0.4432574133365614, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,316] Trial 28 finished with value: 0.8471074380165289 and parameters: {'num_leaves': 265, 'learning_rate': 0.08413705571749953, 'feature_fraction': 0.8773129642941508, 'bagging_fraction': 0.5962719868685951, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,329] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.22673222661439044, 'feature_fraction': 0.6527570096993237, 'bagging_fraction': 0.672663359980382, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,360] Trial 30 finished with value: 0.8925619834710744 and parameters: {'num_leaves': 186, 'learning_rate': 0.24748300041126525, 'feature_fraction': 0.780531225458559, 'bagging_fraction': 0.6068515864381532, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,435] Trial 31 finished with value: 0.9008264462809917 and parameters: {'num_leaves': 276, 'learning_rate': 0.1447236471990485, 'feature_fraction': 0.706987317538302, 'bagging_fraction': 0.5133343609401823, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,527] Trial 32 finished with value: 0.8842975206611571 and parameters: {'num_leaves': 223, 'learning_rate': 0.15133822420423104, 'feature_fraction': 0.4932344094812113, 'bagging_fraction': 0.5946920084779738, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,558] Trial 33 finished with value: 0.8925619834710744 and parameters: {'num_leaves': 246, 'learning_rate': 0.13340319018585625, 'feature_fraction': 0.8503720982235956, 'bagging_fraction': 0.5485024506811871, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,581] Trial 34 finished with value: 0.871900826446281 and parameters: {'num_leaves': 249, 'learning_rate': 0.100311325124785, 'feature_fraction': 0.6001813326394351, 'bagging_fraction': 0.48377806803367196, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,617] Trial 35 finished with value: 0.8925619834710743 and parameters: {'num_leaves': 285, 'learning_rate': 0.19907820214597194, 'feature_fraction': 0.7362327864259739, 'bagging_fraction': 0.7251895895692111, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,676] Trial 36 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 199, 'learning_rate': 0.17771743322065817, 'feature_fraction': 0.8990664048001547, 'bagging_fraction': 0.7573168497297598, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,688] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 230, 'learning_rate': 0.2063072293787877, 'feature_fraction': 0.9594426471627175, 'bagging_fraction': 0.42851493915242883, 'bagging_freq': 2, 'min_child_samples': 88}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,721] Trial 38 finished with value: 0.9132231404958678 and parameters: {'num_leaves': 17, 'learning_rate': 0.1605681679766373, 'feature_fraction': 0.6745926730699111, 'bagging_fraction': 0.5297742457906951, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,735] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 85, 'learning_rate': 0.24146547704906093, 'feature_fraction': 0.6087798341744298, 'bagging_fraction': 0.6789662418395643, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,799] Trial 40 finished with value: 0.8801652892561983 and parameters: {'num_leaves': 163, 'learning_rate': 0.13632974185347746, 'feature_fraction': 0.5469476682373965, 'bagging_fraction': 0.8063465372296108, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,845] Trial 41 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 281, 'learning_rate': 0.13181304921331108, 'feature_fraction': 0.4003838514642814, 'bagging_fraction': 0.5656718594898209, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,906] Trial 42 finished with value: 0.8925619834710743 and parameters: {'num_leaves': 274, 'learning_rate': 0.18406880028226683, 'feature_fraction': 0.4462067122546725, 'bagging_fraction': 0.5877541186792002, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,931] Trial 43 finished with value: 0.9214876033057852 and parameters: {'num_leaves': 292, 'learning_rate': 0.14970207870996197, 'feature_fraction': 0.5160539884415916, 'bagging_fraction': 0.4764599641621473, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:31,957] Trial 44 finished with value: 0.8884297520661157 and parameters: {'num_leaves': 299, 'learning_rate': 0.15464120767058478, 'feature_fraction': 0.4865623913555532, 'bagging_fraction': 0.4748563384105616, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 23 with value: 0.9297520661157024.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.232891
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.294208
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.21705
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.266792
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.170292
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.256902
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.253198
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.295681
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.262564
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.236549
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.224924
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.24776
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.436153
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.359528
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.389525
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.431518
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.401406
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.359228
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.364166
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.495151
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.455503
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.408622
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.382133
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.542922
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.634254
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.391232
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.423353
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.397895
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.360902
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.396996
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.373644
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.365931
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.457763
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.399345
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.404806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.429921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.409455
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.427941
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.399762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.491617
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.366177
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.440729
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.404975
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.420811
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.34881
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.378621
[I 2025-09-17 13:15:31,989] Trial 45 finished with value: 0.9132231404958678 and parameters: {'num_leaves': 254, 'learning_rate': 0.11541818726352414, 'feature_fraction': 0.5509927774250702, 'bagging_fraction': 0.4394317807379982, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:32,019] Trial 46 finished with value: 0.9256198347107437 and parameters: {'num_leaves': 238, 'learning_rate': 0.173406189753218, 'feature_fraction': 0.518979510340488, 'bagging_fraction': 0.43371727972053264, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:32,034] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 239, 'learning_rate': 0.21518441269076757, 'feature_fraction': 0.516045487473904, 'bagging_fraction': 0.4228021661694301, 'bagging_freq': 3, 'min_child_samples': 45}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:32,057] Trial 48 finished with value: 0.7727272727272727 and parameters: {'num_leaves': 213, 'learning_rate': 0.17390864657356897, 'feature_fraction': 0.8071988157714958, 'bagging_fraction': 0.45999581609995166, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:32,102] Trial 49 finished with value: 0.9049586776859505 and parameters: {'num_leaves': 137, 'learning_rate': 0.2717225742467232, 'feature_fraction': 0.8412694131358222, 'bagging_fraction': 0.8866748467451464, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 23 with value: 0.9297520661157024.
[I 2025-09-17 13:15:32,348] A new study created in memory with name: no-name-b46cca7e-4c02-47d6-b9cc-29a08b76e5c7
[I 2025-09-17 13:15:32,356] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 176, 'learning_rate': 0.25940112346814775, 'feature_fraction': 0.6147781100528856, 'bagging_fraction': 0.618808564981803, 'bagging_freq': 3, 'min_child_samples': 92}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:32,364] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.02693443771571155, 'feature_fraction': 0.5746077128827142, 'bagging_fraction': 0.9184770598199566, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:32,467] Trial 2 finished with value: 0.9173553719008265 and parameters: {'num_leaves': 258, 'learning_rate': 0.23167946564034142, 'feature_fraction': 0.7942359516259523, 'bagging_fraction': 0.7967196944078556, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,477] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 253, 'learning_rate': 0.06080419538101322, 'feature_fraction': 0.9644633968719479, 'bagging_fraction': 0.9268946168396044, 'bagging_freq': 3, 'min_child_samples': 85}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,488] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 118, 'learning_rate': 0.15546750862896214, 'feature_fraction': 0.9074915439296357, 'bagging_fraction': 0.4251736230627682, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,498] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 151, 'learning_rate': 0.29889343980523947, 'feature_fraction': 0.8307894262200517, 'bagging_fraction': 0.9330457639334789, 'bagging_freq': 2, 'min_child_samples': 100}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,518] Trial 6 finished with value: 0.8471074380165289 and parameters: {'num_leaves': 206, 'learning_rate': 0.10452998629112889, 'feature_fraction': 0.523792000743396, 'bagging_fraction': 0.8805775078837017, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,540] Trial 7 finished with value: 0.8471074380165289 and parameters: {'num_leaves': 283, 'learning_rate': 0.1548651057564024, 'feature_fraction': 0.5443044481432497, 'bagging_fraction': 0.6456877524911356, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,547] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 295, 'learning_rate': 0.10301452659160006, 'feature_fraction': 0.6419922649876966, 'bagging_fraction': 0.4222158356583431, 'bagging_freq': 2, 'min_child_samples': 71}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,562] Trial 9 finished with value: 0.6549586776859504 and parameters: {'num_leaves': 275, 'learning_rate': 0.09915779432617214, 'feature_fraction': 0.5545463720156758, 'bagging_fraction': 0.9985071542985277, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,635] Trial 10 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 32, 'learning_rate': 0.2189518326398972, 'feature_fraction': 0.4047397597626404, 'bagging_fraction': 0.7609128929044835, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,762] Trial 11 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 20, 'learning_rate': 0.23145792391941739, 'feature_fraction': 0.40481949746455004, 'bagging_fraction': 0.7723141161585174, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,835] Trial 12 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 13, 'learning_rate': 0.21839477075090036, 'feature_fraction': 0.7529733985103626, 'bagging_fraction': 0.7565216395647231, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,882] Trial 13 finished with value: 0.9008264462809916 and parameters: {'num_leaves': 81, 'learning_rate': 0.19246107393408832, 'feature_fraction': 0.7536955030325696, 'bagging_fraction': 0.7860314922410824, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 2 with value: 0.9173553719008265.
[I 2025-09-17 13:15:32,920] Trial 14 finished with value: 0.9380165289256198 and parameters: {'num_leaves': 69, 'learning_rate': 0.27703302238423866, 'feature_fraction': 0.4201859119064664, 'bagging_fraction': 0.5626738235526085, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:32,947] Trial 15 finished with value: 0.8884297520661157 and parameters: {'num_leaves': 77, 'learning_rate': 0.2873582241982003, 'feature_fraction': 0.8387332210204155, 'bagging_fraction': 0.5489704358488996, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:32,967] Trial 16 finished with value: 0.6446280991735537 and parameters: {'num_leaves': 120, 'learning_rate': 0.26008528351507954, 'feature_fraction': 0.7068720000846542, 'bagging_fraction': 0.5320703462282076, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,022] Trial 17 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 222, 'learning_rate': 0.17314127954695552, 'feature_fraction': 0.4684802292976804, 'bagging_fraction': 0.6720252940275284, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,050] Trial 18 finished with value: 0.8305785123966942 and parameters: {'num_leaves': 63, 'learning_rate': 0.2639393107420178, 'feature_fraction': 0.8787032586329376, 'bagging_fraction': 0.5602576684215705, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,097] Trial 19 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 238, 'learning_rate': 0.24334826603530338, 'feature_fraction': 0.673240341215082, 'bagging_fraction': 0.8332215162247019, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,115] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 130, 'learning_rate': 0.1949749246454176, 'feature_fraction': 0.742786234994516, 'bagging_fraction': 0.4884642555206328, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,179] Trial 21 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 34, 'learning_rate': 0.21287232966047748, 'feature_fraction': 0.400242250905879, 'bagging_fraction': 0.7283312998512679, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,291] Trial 22 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 51, 'learning_rate': 0.2822355306623122, 'feature_fraction': 0.4643793581745612, 'bagging_fraction': 0.7021124305064983, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,332] Trial 23 finished with value: 0.9049586776859505 and parameters: {'num_leaves': 91, 'learning_rate': 0.2395788163796268, 'feature_fraction': 0.47556033690919497, 'bagging_fraction': 0.8244469727201075, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,378] Trial 24 finished with value: 0.9380165289256198 and parameters: {'num_leaves': 43, 'learning_rate': 0.1976627871957701, 'feature_fraction': 0.8123781472826067, 'bagging_fraction': 0.5925680615595007, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,403] Trial 25 finished with value: 0.8801652892561983 and parameters: {'num_leaves': 110, 'learning_rate': 0.16970307490770128, 'feature_fraction': 0.8128361962462005, 'bagging_fraction': 0.5965643178323596, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,441] Trial 26 finished with value: 0.8636363636363638 and parameters: {'num_leaves': 147, 'learning_rate': 0.13113293890849434, 'feature_fraction': 0.9928734262307418, 'bagging_fraction': 0.47259248747868116, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,472] Trial 27 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 54, 'learning_rate': 0.1974424430685898, 'feature_fraction': 0.9181220165144014, 'bagging_fraction': 0.5958978939739268, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,490] Trial 28 finished with value: 0.5785123966942148 and parameters: {'num_leaves': 100, 'learning_rate': 0.271538519632147, 'feature_fraction': 0.7903079922135637, 'bagging_fraction': 0.660533926904311, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,522] Trial 29 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 179, 'learning_rate': 0.24280185523516823, 'feature_fraction': 0.6195250776791059, 'bagging_fraction': 0.6267138080261923, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,556] Trial 30 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 64, 'learning_rate': 0.2503684107054366, 'feature_fraction': 0.7003725132225833, 'bagging_fraction': 0.47272019752130734, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,623] Trial 31 finished with value: 0.8801652892561984 and parameters: {'num_leaves': 38, 'learning_rate': 0.21629928517220992, 'feature_fraction': 0.434209375713874, 'bagging_fraction': 0.70806317002672, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,665] Trial 32 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 34, 'learning_rate': 0.21815183842029795, 'feature_fraction': 0.5171025140383662, 'bagging_fraction': 0.8043761317212426, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,707] Trial 33 finished with value: 0.8925619834710744 and parameters: {'num_leaves': 43, 'learning_rate': 0.19302621801173123, 'feature_fraction': 0.5024102089018216, 'bagging_fraction': 0.8312350905667258, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,734] Trial 34 finished with value: 0.8553719008264462 and parameters: {'num_leaves': 202, 'learning_rate': 0.011140639797655033, 'feature_fraction': 0.6005730479955258, 'bagging_fraction': 0.521314160123332, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,759] Trial 35 finished with value: 0.8801652892561983 and parameters: {'num_leaves': 164, 'learning_rate': 0.27559432771894504, 'feature_fraction': 0.8679501969488124, 'bagging_fraction': 0.881960468791983, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,771] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.2286556219779464, 'feature_fraction': 0.7865411165736562, 'bagging_fraction': 0.8825841192044749, 'bagging_freq': 5, 'min_child_samples': 80}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,784] Trial 37 finished with value: 0.628099173553719 and parameters: {'num_leaves': 258, 'learning_rate': 0.17622519130547734, 'feature_fraction': 0.5776728830738074, 'bagging_fraction': 0.5808744810469143, 'bagging_freq': 1, 'min_child_samples': 43}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,825] Trial 38 finished with value: 0.9173553719008265 and parameters: {'num_leaves': 78, 'learning_rate': 0.299927389501277, 'feature_fraction': 0.6509625701971302, 'bagging_fraction': 0.8125933978711194, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,844] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.13884477149201066, 'feature_fraction': 0.9125449909585366, 'bagging_fraction': 0.7335726599244935, 'bagging_freq': 2, 'min_child_samples': 95}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,869] Trial 40 finished with value: 0.768595041322314 and parameters: {'num_leaves': 28, 'learning_rate': 0.2068236328825981, 'feature_fraction': 0.5115706895548661, 'bagging_fraction': 0.9436058722469673, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,912] Trial 41 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 73, 'learning_rate': 0.28864820642722117, 'feature_fraction': 0.6594296383686912, 'bagging_fraction': 0.7976017128319791, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,957] Trial 42 finished with value: 0.871900826446281 and parameters: {'num_leaves': 60, 'learning_rate': 0.25618823836539706, 'feature_fraction': 0.7285321573362042, 'bagging_fraction': 0.684913219946516, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:33,990] Trial 43 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 70, 'learning_rate': 0.28712076301041406, 'feature_fraction': 0.7821121167960171, 'bagging_fraction': 0.865498178809191, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,076] Trial 44 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 94, 'learning_rate': 0.23416769405758425, 'feature_fraction': 0.8506898598147805, 'bagging_fraction': 0.8006144201526187, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,140] Trial 45 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 98, 'learning_rate': 0.05575811019381886, 'feature_fraction': 0.9387696430374646, 'bagging_fraction': 0.632627786845934, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,171] Trial 46 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 87, 'learning_rate': 0.22935111421420246, 'feature_fraction': 0.867203730209151, 'bagging_fraction': 0.7973032035564528, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,198] Trial 47 finished with value: 0.8760330578512396 and parameters: {'num_leaves': 109, 'learning_rate': 0.26660208194174106, 'feature_fraction': 0.5517343727405069, 'bagging_fraction': 0.7542076052138847, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,231] Trial 48 finished with value: 0.859504132231405 and parameters: {'num_leaves': 48, 'learning_rate': 0.2886380923852553, 'feature_fraction': 0.8427945652095439, 'bagging_fraction': 0.9121785194336711, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,310] Trial 49 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 19, 'learning_rate': 0.25381818815900226, 'feature_fraction': 0.4343786482035748, 'bagging_fraction': 0.8581009196532083, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 14 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,555] A new study created in memory with name: no-name-c33aca43-68cd-401b-8689-8fab31ce8d07
[I 2025-09-17 13:15:34,565] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 244, 'learning_rate': 0.10835085553961138, 'feature_fraction': 0.7515119874605038, 'bagging_fraction': 0.7834631705232664, 'bagging_freq': 2, 'min_child_samples': 97}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:34,576] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.10124223126055507, 'feature_fraction': 0.9302918667142547, 'bagging_fraction': 0.4650021255428445, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:34,596] Trial 2 finished with value: 0.8925619834710744 and parameters: {'num_leaves': 183, 'learning_rate': 0.19875012579472554, 'feature_fraction': 0.6911913119573583, 'bagging_fraction': 0.8228822538672826, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 2 with value: 0.8925619834710744.
[I 2025-09-17 13:15:34,617] Trial 3 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 34, 'learning_rate': 0.021980024082287525, 'feature_fraction': 0.5758546392540751, 'bagging_fraction': 0.8387174091179281, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 2 with value: 0.8925619834710744.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.358246
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.380661
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.505473
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.425359
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.351804
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.461316
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.449414
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.617009
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.402461
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.356588
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.416794
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.381576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.327498
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.452208
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.586178
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.388637
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.46223
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.362469
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.358474
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.389293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.382186
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.315875
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.430429
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.455927
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.420367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.635111
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.371055
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.454499
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.412349
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.357273
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.409267
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.547514
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.434635
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.629282
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.369745
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.582507
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.308978
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.414026
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.445804
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.346884
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.449535
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.448715
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.402584
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.429305
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.363082
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.416666
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.47204
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:34,640] Trial 4 finished with value: 0.884297520661157 and parameters: {'num_leaves': 144, 'learning_rate': 0.033386555995572456, 'feature_fraction': 0.48035309669132564, 'bagging_fraction': 0.8148063610799255, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 2 with value: 0.8925619834710744.
[I 2025-09-17 13:15:34,646] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 213, 'learning_rate': 0.25437210738760213, 'feature_fraction': 0.5113132837195603, 'bagging_fraction': 0.7215160125117634, 'bagging_freq': 1, 'min_child_samples': 88}. Best is trial 2 with value: 0.8925619834710744.
[I 2025-09-17 13:15:34,650] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 192, 'learning_rate': 0.018360503820302083, 'feature_fraction': 0.951018708475114, 'bagging_fraction': 0.9871855011835399, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 2 with value: 0.8925619834710744.
[I 2025-09-17 13:15:34,659] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 252, 'learning_rate': 0.059810228857158046, 'feature_fraction': 0.8711088246411354, 'bagging_fraction': 0.5011916101397521, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial 2 with value: 0.8925619834710744.
[I 2025-09-17 13:15:34,666] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 170, 'learning_rate': 0.14243851424341727, 'feature_fraction': 0.5364476900176908, 'bagging_fraction': 0.5540550703070173, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 2 with value: 0.8925619834710744.
[I 2025-09-17 13:15:34,681] Trial 9 finished with value: 0.7024793388429752 and parameters: {'num_leaves': 124, 'learning_rate': 0.21493594054370638, 'feature_fraction': 0.5532971198130862, 'bagging_fraction': 0.5197150989049708, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 2 with value: 0.8925619834710744.
[I 2025-09-17 13:15:34,776] Trial 10 finished with value: 0.9380165289256198 and parameters: {'num_leaves': 79, 'learning_rate': 0.20164649929855943, 'feature_fraction': 0.7051526953502459, 'bagging_fraction': 0.9783805270908175, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,872] Trial 11 finished with value: 0.9173553719008264 and parameters: {'num_leaves': 75, 'learning_rate': 0.1965246896270007, 'feature_fraction': 0.6826650640831238, 'bagging_fraction': 0.9993087361069629, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:34,951] Trial 12 finished with value: 0.8925619834710744 and parameters: {'num_leaves': 68, 'learning_rate': 0.28764580743785384, 'feature_fraction': 0.6893462148050662, 'bagging_fraction': 0.9989938992304442, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:35,040] Trial 13 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 92, 'learning_rate': 0.18644789599406403, 'feature_fraction': 0.7933858581682789, 'bagging_fraction': 0.9198111517687196, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:35,072] Trial 14 finished with value: 0.884297520661157 and parameters: {'num_leaves': 11, 'learning_rate': 0.23537053589621001, 'feature_fraction': 0.6236534882742949, 'bagging_fraction': 0.9115488420658743, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:35,099] Trial 15 finished with value: 0.9008264462809917 and parameters: {'num_leaves': 85, 'learning_rate': 0.1630927307085861, 'feature_fraction': 0.8362895474865466, 'bagging_fraction': 0.6217729503396691, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:35,126] Trial 16 finished with value: 0.9111570247933884 and parameters: {'num_leaves': 118, 'learning_rate': 0.2948766118072266, 'feature_fraction': 0.6269568248299648, 'bagging_fraction': 0.9037741354078536, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:35,139] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 56, 'learning_rate': 0.1445184643757258, 'feature_fraction': 0.7407070379195825, 'bagging_fraction': 0.6835522481504699, 'bagging_freq': 7, 'min_child_samples': 61}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:35,162] Trial 18 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 103, 'learning_rate': 0.2390961193757245, 'feature_fraction': 0.44916191612970136, 'bagging_fraction': 0.407541035103324, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 10 with value: 0.9380165289256198.
[I 2025-09-17 13:15:35,302] Trial 19 finished with value: 0.9669421487603305 and parameters: {'num_leaves': 41, 'learning_rate': 0.17982115008093794, 'feature_fraction': 0.41138104811378173, 'bagging_fraction': 0.9483054754488717, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 19 with value: 0.9669421487603305.
[I 2025-09-17 13:15:35,329] Trial 20 finished with value: 0.9008264462809917 and parameters: {'num_leaves': 13, 'learning_rate': 0.10165241362506841, 'feature_fraction': 0.9978287330310505, 'bagging_fraction': 0.8890321223484713, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 19 with value: 0.9669421487603305.
[I 2025-09-17 13:15:35,460] Trial 21 finished with value: 0.9214876033057852 and parameters: {'num_leaves': 51, 'learning_rate': 0.17347855967744427, 'feature_fraction': 0.42189947501779596, 'bagging_fraction': 0.9600884485470034, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 19 with value: 0.9669421487603305.
[I 2025-09-17 13:15:35,517] Trial 22 finished with value: 0.9876033057851239 and parameters: {'num_leaves': 45, 'learning_rate': 0.16122443531704211, 'feature_fraction': 0.40297681423874565, 'bagging_fraction': 0.9417095080458643, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,566] Trial 23 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 36, 'learning_rate': 0.136659733682353, 'feature_fraction': 0.40881752631143603, 'bagging_fraction': 0.8752281038491894, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,611] Trial 24 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 37, 'learning_rate': 0.21381637902073858, 'feature_fraction': 0.6094345245491859, 'bagging_fraction': 0.9441526193608992, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,636] Trial 25 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 145, 'learning_rate': 0.17190658244588777, 'feature_fraction': 0.4750708622812094, 'bagging_fraction': 0.7314464070832164, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,709] Trial 26 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 109, 'learning_rate': 0.13083814479498587, 'feature_fraction': 0.40304434046732596, 'bagging_fraction': 0.8602243628534946, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,721] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 60, 'learning_rate': 0.259143753546615, 'feature_fraction': 0.5058100329552853, 'bagging_fraction': 0.7636393545352622, 'bagging_freq': 7, 'min_child_samples': 73}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,739] Trial 28 finished with value: 0.859504132231405 and parameters: {'num_leaves': 24, 'learning_rate': 0.22196251333966427, 'feature_fraction': 0.5890377710280434, 'bagging_fraction': 0.9541805165011688, 'bagging_freq': 6, 'min_child_samples': 50}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,795] Trial 29 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 81, 'learning_rate': 0.07164115623061022, 'feature_fraction': 0.741605681898867, 'bagging_fraction': 0.7825124178550209, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,836] Trial 30 finished with value: 0.9297520661157025 and parameters: {'num_leaves': 45, 'learning_rate': 0.11817959175606241, 'feature_fraction': 0.8059584366310885, 'bagging_fraction': 0.9398303025701983, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:35,876] Trial 31 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 47, 'learning_rate': 0.12412735852535925, 'feature_fraction': 0.8278724222684612, 'bagging_fraction': 0.9422985600801365, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,009] Trial 32 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 65, 'learning_rate': 0.1125733551656138, 'feature_fraction': 0.7860290743858005, 'bagging_fraction': 0.9637674752183943, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,084] Trial 33 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 88, 'learning_rate': 0.07871576594801202, 'feature_fraction': 0.6525724332951354, 'bagging_fraction': 0.8571763123461061, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,114] Trial 34 finished with value: 0.921487603305785 and parameters: {'num_leaves': 69, 'learning_rate': 0.15937973605509723, 'feature_fraction': 0.7704797503583197, 'bagging_fraction': 0.968190987805949, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,207] Trial 35 finished with value: 0.8884297520661157 and parameters: {'num_leaves': 128, 'learning_rate': 0.18228991119110935, 'feature_fraction': 0.8724105603847834, 'bagging_fraction': 0.8269048066862043, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,257] Trial 36 finished with value: 0.9008264462809917 and parameters: {'num_leaves': 19, 'learning_rate': 0.08953772079105701, 'feature_fraction': 0.7182816152160084, 'bagging_fraction': 0.9095305846885033, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,325] Trial 37 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 298, 'learning_rate': 0.19336865805773443, 'feature_fraction': 0.4550097932115163, 'bagging_fraction': 0.7970860372080454, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,356] Trial 38 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 29, 'learning_rate': 0.1535283928347942, 'feature_fraction': 0.6633521957491082, 'bagging_fraction': 0.9786925159994618, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,399] Trial 39 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 238, 'learning_rate': 0.04460440360890927, 'feature_fraction': 0.7117795524027053, 'bagging_fraction': 0.6465488992598352, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,468] Trial 40 finished with value: 0.9008264462809917 and parameters: {'num_leaves': 102, 'learning_rate': 0.1085557441745995, 'feature_fraction': 0.9063911177279622, 'bagging_fraction': 0.8438846777697468, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,497] Trial 41 finished with value: 0.9028925619834711 and parameters: {'num_leaves': 43, 'learning_rate': 0.11693132210126791, 'feature_fraction': 0.804126261342752, 'bagging_fraction': 0.9328665410637358, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,521] Trial 42 finished with value: 0.8429752066115702 and parameters: {'num_leaves': 60, 'learning_rate': 0.1498607597611685, 'feature_fraction': 0.7688573634660075, 'bagging_fraction': 0.8770172574866271, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,553] Trial 43 finished with value: 0.9194214876033058 and parameters: {'num_leaves': 69, 'learning_rate': 0.20207744411518136, 'feature_fraction': 0.852626714045835, 'bagging_fraction': 0.9720441444583989, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,679] Trial 44 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 30, 'learning_rate': 0.09123499289273658, 'feature_fraction': 0.8003081079871601, 'bagging_fraction': 0.998988744734355, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,743] Trial 45 finished with value: 0.921487603305785 and parameters: {'num_leaves': 55, 'learning_rate': 0.1168867769896086, 'feature_fraction': 0.9061346572008677, 'bagging_fraction': 0.9361134882312913, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,776] Trial 46 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 167, 'learning_rate': 0.17001809314219646, 'feature_fraction': 0.5381444987641167, 'bagging_fraction': 0.8932270234027345, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,818] Trial 47 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 276, 'learning_rate': 0.20790728390687652, 'feature_fraction': 0.7701671681619454, 'bagging_fraction': 0.9295920457637383, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,886] Trial 48 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 194, 'learning_rate': 0.18507050966182745, 'feature_fraction': 0.7271096611095492, 'bagging_fraction': 0.9716369322373166, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:36,924] Trial 49 finished with value: 0.884297520661157 and parameters: {'num_leaves': 93, 'learning_rate': 0.2324238161065228, 'feature_fraction': 0.4329226324004688, 'bagging_fraction': 0.5901026400554317, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 22 with value: 0.9876033057851239.
[I 2025-09-17 13:15:37,329] A new study created in memory with name: no-name-9e1eccf3-90c3-4f38-a2f7-3d698e58022d
[I 2025-09-17 13:15:37,337] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 115, 'learning_rate': 0.17314038333880438, 'feature_fraction': 0.8730401952454987, 'bagging_fraction': 0.6312406804768954, 'bagging_freq': 5, 'min_child_samples': 63}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:37,374] Trial 1 finished with value: 0.8857142857142858 and parameters: {'num_leaves': 145, 'learning_rate': 0.19201543441229285, 'feature_fraction': 0.6175039513516128, 'bagging_fraction': 0.7572042221396597, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,409] Trial 2 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 110, 'learning_rate': 0.27095857301132703, 'feature_fraction': 0.7758390846936891, 'bagging_fraction': 0.9645603754476234, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,434] Trial 3 finished with value: 0.780952380952381 and parameters: {'num_leaves': 281, 'learning_rate': 0.062317462483323295, 'feature_fraction': 0.7720654843210284, 'bagging_fraction': 0.7742741343436338, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,444] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 37, 'learning_rate': 0.10332513599452789, 'feature_fraction': 0.6199604771783331, 'bagging_fraction': 0.5909115791704886, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,454] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 82, 'learning_rate': 0.22766201915580023, 'feature_fraction': 0.8230861000380952, 'bagging_fraction': 0.8961453738147225, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,498] Trial 6 finished with value: 0.8714285714285714 and parameters: {'num_leaves': 80, 'learning_rate': 0.05504662978116035, 'feature_fraction': 0.7905641148800173, 'bagging_fraction': 0.9143617001880506, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,519] Trial 7 finished with value: 0.8 and parameters: {'num_leaves': 55, 'learning_rate': 0.2588370775059829, 'feature_fraction': 0.6401554876926788, 'bagging_fraction': 0.7253371126433698, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,527] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 113, 'learning_rate': 0.26591843593189407, 'feature_fraction': 0.5804435435051181, 'bagging_fraction': 0.9221988627040841, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,546] Trial 9 finished with value: 0.7380952380952381 and parameters: {'num_leaves': 111, 'learning_rate': 0.05266831250616304, 'feature_fraction': 0.4187970955732807, 'bagging_fraction': 0.7509184918573055, 'bagging_freq': 7, 'min_child_samples': 39}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,623] Trial 10 finished with value: 0.8095238095238094 and parameters: {'num_leaves': 226, 'learning_rate': 0.17149278033811152, 'feature_fraction': 0.4412006794810398, 'bagging_fraction': 0.46574926673528516, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 1 with value: 0.8857142857142858.
[I 2025-09-17 13:15:37,703] Trial 11 finished with value: 0.9238095238095239 and parameters: {'num_leaves': 181, 'learning_rate': 0.11635336811517069, 'feature_fraction': 0.9593768553488681, 'bagging_fraction': 0.8345525892876965, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:37,816] Trial 12 finished with value: 0.9238095238095239 and parameters: {'num_leaves': 197, 'learning_rate': 0.1215735024156929, 'feature_fraction': 0.9431304468128838, 'bagging_fraction': 0.8336042322872936, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.9238095238095239.
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.452211
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.585818
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.351022
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.385687
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.397404
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.404724
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.387
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.400328
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.380818
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.519843
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.275062
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.379808
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.306826
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.251896
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.377275
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.317001
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.352447
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.31732
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.496302
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.409798
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.365004
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.383693
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.365504
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.3644
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.380217
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.398173
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.377132
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.370701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.389183
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.377202
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.384236
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.387996
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.472938
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.366908
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.386077
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.369618
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.37753
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.338243
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.336328
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.435329
Training model for P048... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.450504
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.474921
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.569474
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.495103
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.561
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.602295
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.562611
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.36004
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.344324
[I 2025-09-17 13:15:37,922] Trial 13 finished with value: 0.9095238095238095 and parameters: {'num_leaves': 195, 'learning_rate': 0.11344817543587195, 'feature_fraction': 0.9836041550329842, 'bagging_fraction': 0.8243458921042784, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:37,946] Trial 14 finished with value: 0.7238095238095238 and parameters: {'num_leaves': 203, 'learning_rate': 0.12086411143634052, 'feature_fraction': 0.98860118103099, 'bagging_fraction': 0.8471159560750755, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:37,958] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 264, 'learning_rate': 0.01635836667877534, 'feature_fraction': 0.897075905251615, 'bagging_fraction': 0.6461145687747905, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:37,995] Trial 16 finished with value: 0.8857142857142857 and parameters: {'num_leaves': 177, 'learning_rate': 0.1336182906169864, 'feature_fraction': 0.9172413224969609, 'bagging_fraction': 0.9974336692404981, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,005] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 232, 'learning_rate': 0.09245879281630577, 'feature_fraction': 0.9381173960526826, 'bagging_fraction': 0.8309540994664735, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,042] Trial 18 finished with value: 0.8047619047619048 and parameters: {'num_leaves': 157, 'learning_rate': 0.21346795178831737, 'feature_fraction': 0.7036894493097599, 'bagging_fraction': 0.5114347701524351, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,068] Trial 19 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 244, 'learning_rate': 0.1472883186024278, 'feature_fraction': 0.8562510568748217, 'bagging_fraction': 0.8607323288454196, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,124] Trial 20 finished with value: 0.8619047619047617 and parameters: {'num_leaves': 152, 'learning_rate': 0.08231497859682801, 'feature_fraction': 0.5064243382958793, 'bagging_fraction': 0.6814610933048677, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,195] Trial 21 finished with value: 0.8904761904761905 and parameters: {'num_leaves': 193, 'learning_rate': 0.11977824946483392, 'feature_fraction': 0.9825452443296958, 'bagging_fraction': 0.8020882230287474, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,290] Trial 22 finished with value: 0.9142857142857143 and parameters: {'num_leaves': 198, 'learning_rate': 0.14521562852589354, 'feature_fraction': 0.977813946323561, 'bagging_fraction': 0.8104762074438341, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,328] Trial 23 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 215, 'learning_rate': 0.15409088039714494, 'feature_fraction': 0.9331692641692177, 'bagging_fraction': 0.8845574414578662, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,387] Trial 24 finished with value: 0.9142857142857144 and parameters: {'num_leaves': 300, 'learning_rate': 0.19195164272977883, 'feature_fraction': 0.7227500192597544, 'bagging_fraction': 0.7911677483043862, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,413] Trial 25 finished with value: 0.8047619047619047 and parameters: {'num_leaves': 292, 'learning_rate': 0.20528539126843404, 'feature_fraction': 0.7228428599233109, 'bagging_fraction': 0.6858248258889695, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,435] Trial 26 finished with value: 0.6714285714285714 and parameters: {'num_leaves': 171, 'learning_rate': 0.24228720443890267, 'feature_fraction': 0.8455189305067057, 'bagging_fraction': 0.7835986653068535, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,512] Trial 27 finished with value: 0.9238095238095237 and parameters: {'num_leaves': 256, 'learning_rate': 0.29886781861072964, 'feature_fraction': 0.549414092484175, 'bagging_fraction': 0.9478610858764893, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,567] Trial 28 finished with value: 0.8714285714285714 and parameters: {'num_leaves': 257, 'learning_rate': 0.29459927953258114, 'feature_fraction': 0.5445407072339689, 'bagging_fraction': 0.9520803436833507, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,575] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.1753471849681177, 'feature_fraction': 0.4739653956510901, 'bagging_fraction': 0.986435507478936, 'bagging_freq': 1, 'min_child_samples': 73}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,647] Trial 30 finished with value: 0.9142857142857143 and parameters: {'num_leaves': 269, 'learning_rate': 0.16843723225252102, 'feature_fraction': 0.6780758075033009, 'bagging_fraction': 0.9344933062326959, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,714] Trial 31 finished with value: 0.8666666666666666 and parameters: {'num_leaves': 246, 'learning_rate': 0.07712667951852277, 'feature_fraction': 0.8846615284527424, 'bagging_fraction': 0.8715771859096366, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,751] Trial 32 finished with value: 0.8714285714285713 and parameters: {'num_leaves': 299, 'learning_rate': 0.1890472997756214, 'feature_fraction': 0.5663077600665553, 'bagging_fraction': 0.7290799667659608, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,810] Trial 33 finished with value: 0.8761904761904762 and parameters: {'num_leaves': 176, 'learning_rate': 0.13528549341283286, 'feature_fraction': 0.8166629716183921, 'bagging_fraction': 0.8854604156516899, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:38,844] Trial 34 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 279, 'learning_rate': 0.2991127141928152, 'feature_fraction': 0.5264253088630881, 'bagging_fraction': 0.7643157559668149, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,007] Trial 35 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 219, 'learning_rate': 0.03845767859964609, 'feature_fraction': 0.7586425109252973, 'bagging_fraction': 0.9617392053460786, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,038] Trial 36 finished with value: 0.7761904761904762 and parameters: {'num_leaves': 130, 'learning_rate': 0.1030191245022605, 'feature_fraction': 0.6552690612053145, 'bagging_fraction': 0.5842472575819587, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,076] Trial 37 finished with value: 0.8904761904761905 and parameters: {'num_leaves': 250, 'learning_rate': 0.2447767998156637, 'feature_fraction': 0.5954620211171738, 'bagging_fraction': 0.7216147527335717, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,104] Trial 38 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 280, 'learning_rate': 0.28453329824026957, 'feature_fraction': 0.7464914677337398, 'bagging_fraction': 0.7931601718946755, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,116] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 237, 'learning_rate': 0.1934391318256539, 'feature_fraction': 0.949360049796837, 'bagging_fraction': 0.849944706121337, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,143] Trial 40 finished with value: 0.6857142857142857 and parameters: {'num_leaves': 271, 'learning_rate': 0.1306362475533009, 'feature_fraction': 0.796590625836256, 'bagging_fraction': 0.40372712381689735, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,224] Trial 41 finished with value: 0.9095238095238095 and parameters: {'num_leaves': 204, 'learning_rate': 0.14450478952327178, 'feature_fraction': 0.965573798997472, 'bagging_fraction': 0.8180469678536721, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,305] Trial 42 finished with value: 0.8761904761904762 and parameters: {'num_leaves': 162, 'learning_rate': 0.10018422682867077, 'feature_fraction': 0.9034153705342778, 'bagging_fraction': 0.9158359620408083, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,390] Trial 43 finished with value: 0.8428571428571429 and parameters: {'num_leaves': 186, 'learning_rate': 0.1610197940564444, 'feature_fraction': 0.9980297974390098, 'bagging_fraction': 0.7446621059046163, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,455] Trial 44 finished with value: 0.9142857142857143 and parameters: {'num_leaves': 89, 'learning_rate': 0.08019285583399625, 'feature_fraction': 0.8669027667641538, 'bagging_fraction': 0.8102549924720959, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,510] Trial 45 finished with value: 0.8714285714285716 and parameters: {'num_leaves': 211, 'learning_rate': 0.06406697615881649, 'feature_fraction': 0.6236717284045226, 'bagging_fraction': 0.8997888270292322, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:15:39,585] Trial 46 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 290, 'learning_rate': 0.22466285228941862, 'feature_fraction': 0.9648316387883117, 'bagging_fraction': 0.7692859332117169, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 46 with value: 0.9333333333333333.
[I 2025-09-17 13:15:39,615] Trial 47 finished with value: 0.819047619047619 and parameters: {'num_leaves': 289, 'learning_rate': 0.22299631378168422, 'feature_fraction': 0.9208585576271469, 'bagging_fraction': 0.6607766724724251, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 46 with value: 0.9333333333333333.
[I 2025-09-17 13:15:39,649] Trial 48 finished with value: 0.8380952380952381 and parameters: {'num_leaves': 11, 'learning_rate': 0.2506864895867499, 'feature_fraction': 0.4018653252509042, 'bagging_fraction': 0.5999508214275181, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 46 with value: 0.9333333333333333.
[I 2025-09-17 13:15:39,661] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 261, 'learning_rate': 0.23277723522810398, 'feature_fraction': 0.8342561210608213, 'bagging_fraction': 0.7674168666571087, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 46 with value: 0.9333333333333333.
[I 2025-09-17 13:15:39,888] A new study created in memory with name: no-name-608b4dbe-724d-4eb7-a1e8-00109a8f4088
[I 2025-09-17 13:15:39,896] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 234, 'learning_rate': 0.28212179634124473, 'feature_fraction': 0.40682640435956335, 'bagging_fraction': 0.5008306212690655, 'bagging_freq': 2, 'min_child_samples': 64}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:39,906] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 72, 'learning_rate': 0.18067712853839143, 'feature_fraction': 0.8035847821943494, 'bagging_fraction': 0.7819819613513815, 'bagging_freq': 2, 'min_child_samples': 72}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:39,917] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 160, 'learning_rate': 0.2548840381105564, 'feature_fraction': 0.976171774917864, 'bagging_fraction': 0.6373279038948365, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:39,927] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 214, 'learning_rate': 0.2908545126944922, 'feature_fraction': 0.902242049733487, 'bagging_fraction': 0.4990887035174091, 'bagging_freq': 6, 'min_child_samples': 71}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:39,937] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 272, 'learning_rate': 0.226257951143519, 'feature_fraction': 0.8349207619846919, 'bagging_fraction': 0.5577121768799187, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:39,944] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.2016278640509799, 'feature_fraction': 0.9804828700794546, 'bagging_fraction': 0.8751177870274343, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:39,962] Trial 6 finished with value: 0.7571428571428571 and parameters: {'num_leaves': 237, 'learning_rate': 0.1043837858843728, 'feature_fraction': 0.9581237923303154, 'bagging_fraction': 0.9876637519254633, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 6 with value: 0.7571428571428571.
[I 2025-09-17 13:15:39,970] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 255, 'learning_rate': 0.02402516710900044, 'feature_fraction': 0.9487025580324459, 'bagging_fraction': 0.4055181823255668, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 6 with value: 0.7571428571428571.
[I 2025-09-17 13:15:40,004] Trial 8 finished with value: 0.838095238095238 and parameters: {'num_leaves': 19, 'learning_rate': 0.28925739781720305, 'feature_fraction': 0.5710436117509934, 'bagging_fraction': 0.5733886416457347, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 8 with value: 0.838095238095238.
[I 2025-09-17 13:15:40,012] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 273, 'learning_rate': 0.013763122324407562, 'feature_fraction': 0.5686989333523867, 'bagging_fraction': 0.7539293067824797, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 8 with value: 0.838095238095238.
[I 2025-09-17 13:15:40,075] Trial 10 finished with value: 0.919047619047619 and parameters: {'num_leaves': 11, 'learning_rate': 0.11252534663179765, 'feature_fraction': 0.623588207069172, 'bagging_fraction': 0.6499836873494528, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 10 with value: 0.919047619047619.
[I 2025-09-17 13:15:40,147] Trial 11 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 10, 'learning_rate': 0.11500674271783116, 'feature_fraction': 0.6448250517153495, 'bagging_fraction': 0.6508528671335334, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 11 with value: 0.9333333333333333.
[I 2025-09-17 13:15:40,245] Trial 12 finished with value: 0.9380952380952381 and parameters: {'num_leaves': 17, 'learning_rate': 0.11643467552545517, 'feature_fraction': 0.6557940191311289, 'bagging_fraction': 0.6880667394269786, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 12 with value: 0.9380952380952381.
[I 2025-09-17 13:15:40,270] Trial 13 finished with value: 0.8714285714285714 and parameters: {'num_leaves': 77, 'learning_rate': 0.12181154225569521, 'feature_fraction': 0.6963481648808671, 'bagging_fraction': 0.729753393649969, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 12 with value: 0.9380952380952381.
[I 2025-09-17 13:15:40,317] Trial 14 finished with value: 0.8238095238095239 and parameters: {'num_leaves': 73, 'learning_rate': 0.05964683967436137, 'feature_fraction': 0.4710993790574617, 'bagging_fraction': 0.8519603484575464, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 12 with value: 0.9380952380952381.
[I 2025-09-17 13:15:40,342] Trial 15 finished with value: 0.7857142857142856 and parameters: {'num_leaves': 120, 'learning_rate': 0.15021468610418068, 'feature_fraction': 0.6913375788163585, 'bagging_fraction': 0.6530946928556465, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 12 with value: 0.9380952380952381.
[I 2025-09-17 13:15:40,460] Trial 16 finished with value: 0.942857142857143 and parameters: {'num_leaves': 37, 'learning_rate': 0.07019449786930958, 'feature_fraction': 0.8018284506494107, 'bagging_fraction': 0.8597157933041982, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 16 with value: 0.942857142857143.
[I 2025-09-17 13:15:40,510] Trial 17 finished with value: 0.9238095238095239 and parameters: {'num_leaves': 47, 'learning_rate': 0.07223319949732074, 'feature_fraction': 0.7942767342407306, 'bagging_fraction': 0.9747697138642468, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 16 with value: 0.942857142857143.
[I 2025-09-17 13:15:40,537] Trial 18 finished with value: 0.8047619047619048 and parameters: {'num_leaves': 120, 'learning_rate': 0.07624705072305236, 'feature_fraction': 0.7745035648197699, 'bagging_fraction': 0.8364019219517677, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 16 with value: 0.942857142857143.
[I 2025-09-17 13:15:40,662] Trial 19 finished with value: 0.9523809523809524 and parameters: {'num_leaves': 173, 'learning_rate': 0.15189724656851572, 'feature_fraction': 0.8753350102846308, 'bagging_fraction': 0.9125682879318439, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:40,674] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 163, 'learning_rate': 0.15516804305511128, 'feature_fraction': 0.8832853875360118, 'bagging_fraction': 0.9279797531925963, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 19 with value: 0.9523809523809524.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.357306
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.602387
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.453346
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.529111
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.479441
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.473323
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.424665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.3742
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.476921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.369217
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.530852
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.60486
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.362203
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.449498
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.390632
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.453916
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.474665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.416904
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.492879
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.42018
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.579269
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.433199
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.542933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.600966
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.401734
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.433072
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.465288
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.371861
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.451069
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.335202
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.518923
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.492379
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.574671
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.432266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.394834
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.347358
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.418678
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.468304
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.523355
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.590575
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.331367
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.435051
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.559409
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.270842
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds[I 2025-09-17 13:15:40,712] Trial 21 finished with value: 0.9238095238095237 and parameters: {'num_leaves': 124, 'learning_rate': 0.1485892129191266, 'feature_fraction': 0.7462740126620736, 'bagging_fraction': 0.9176625085046638, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:40,843] Trial 22 finished with value: 0.919047619047619 and parameters: {'num_leaves': 170, 'learning_rate': 0.04626326250804717, 'feature_fraction': 0.8633520631525339, 'bagging_fraction': 0.7929225120449914, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:40,865] Trial 23 finished with value: 0.8285714285714285 and parameters: {'num_leaves': 41, 'learning_rate': 0.08973697637318781, 'feature_fraction': 0.7429662872169613, 'bagging_fraction': 0.7043696542444178, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:40,913] Trial 24 finished with value: 0.9190476190476191 and parameters: {'num_leaves': 97, 'learning_rate': 0.17877722146212602, 'feature_fraction': 0.9140502777987479, 'bagging_fraction': 0.91184745573899, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:40,942] Trial 25 finished with value: 0.8142857142857143 and parameters: {'num_leaves': 194, 'learning_rate': 0.1364417341221313, 'feature_fraction': 0.8307093272092475, 'bagging_fraction': 0.7977617004112906, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:40,996] Trial 26 finished with value: 0.9523809523809524 and parameters: {'num_leaves': 42, 'learning_rate': 0.03893839214016031, 'feature_fraction': 0.7293552553820899, 'bagging_fraction': 0.8741362037516744, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:41,051] Trial 27 finished with value: 0.9380952380952381 and parameters: {'num_leaves': 50, 'learning_rate': 0.03980912844470952, 'feature_fraction': 0.745962885275281, 'bagging_fraction': 0.955752997218314, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:41,121] Trial 28 finished with value: 0.9428571428571428 and parameters: {'num_leaves': 140, 'learning_rate': 0.03239975668032693, 'feature_fraction': 0.8479693972083621, 'bagging_fraction': 0.8760559965278575, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:41,149] Trial 29 finished with value: 0.7904761904761904 and parameters: {'num_leaves': 297, 'learning_rate': 0.05501345431732421, 'feature_fraction': 0.40201309620187664, 'bagging_fraction': 0.8269810640669166, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:41,195] Trial 30 finished with value: 0.8761904761904762 and parameters: {'num_leaves': 186, 'learning_rate': 0.2649828963270492, 'feature_fraction': 0.4699252473229598, 'bagging_fraction': 0.898744891324657, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 19 with value: 0.9523809523809524.
[I 2025-09-17 13:15:41,263] Trial 31 finished with value: 0.9571428571428572 and parameters: {'num_leaves': 137, 'learning_rate': 0.029811371378960477, 'feature_fraction': 0.8413866979687357, 'bagging_fraction': 0.8681622633655408, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,423] Trial 32 finished with value: 0.9380952380952381 and parameters: {'num_leaves': 102, 'learning_rate': 0.010861588785018084, 'feature_fraction': 0.7996779248336886, 'bagging_fraction': 0.9527947090081101, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,481] Trial 33 finished with value: 0.9571428571428572 and parameters: {'num_leaves': 143, 'learning_rate': 0.08729953715995738, 'feature_fraction': 0.9215365225828142, 'bagging_fraction': 0.9990061596518934, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,494] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 140, 'learning_rate': 0.09005534889257742, 'feature_fraction': 0.9262304987482798, 'bagging_fraction': 0.944512875606425, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,543] Trial 35 finished with value: 0.9523809523809524 and parameters: {'num_leaves': 186, 'learning_rate': 0.17458010369674903, 'feature_fraction': 0.8823150664553767, 'bagging_fraction': 0.9977026004959154, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,581] Trial 36 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 209, 'learning_rate': 0.2234165599247625, 'feature_fraction': 0.8392341256217608, 'bagging_fraction': 0.8881915866898039, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,604] Trial 37 finished with value: 0.7904761904761904 and parameters: {'num_leaves': 144, 'learning_rate': 0.09520791205460025, 'feature_fraction': 0.9999535956825161, 'bagging_fraction': 0.8179597393377945, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,627] Trial 38 finished with value: 0.8285714285714285 and parameters: {'num_leaves': 96, 'learning_rate': 0.02696791951829744, 'feature_fraction': 0.9334292287905558, 'bagging_fraction': 0.9813510268990153, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,652] Trial 39 finished with value: 0.7952380952380952 and parameters: {'num_leaves': 151, 'learning_rate': 0.05270510642982704, 'feature_fraction': 0.888588304769634, 'bagging_fraction': 0.7737555501050456, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,698] Trial 40 finished with value: 0.9571428571428572 and parameters: {'num_leaves': 173, 'learning_rate': 0.20266748548477848, 'feature_fraction': 0.9741397835985252, 'bagging_fraction': 0.9515762223750941, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 31 with value: 0.9571428571428572.
[I 2025-09-17 13:15:41,744] Trial 41 finished with value: 0.9714285714285714 and parameters: {'num_leaves': 171, 'learning_rate': 0.2324575658904925, 'feature_fraction': 0.9672201635200497, 'bagging_fraction': 0.9473073779803005, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:41,811] Trial 42 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 174, 'learning_rate': 0.22025079120035296, 'feature_fraction': 0.9712184632904209, 'bagging_fraction': 0.9369877002364085, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:41,823] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 228, 'learning_rate': 0.2019659710136277, 'feature_fraction': 0.9980031863937007, 'bagging_fraction': 0.968959192229145, 'bagging_freq': 3, 'min_child_samples': 77}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:41,862] Trial 44 finished with value: 0.8904761904761904 and parameters: {'num_leaves': 201, 'learning_rate': 0.24584279794841052, 'feature_fraction': 0.9528791527974378, 'bagging_fraction': 0.9962482731408473, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:41,919] Trial 45 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 178, 'learning_rate': 0.1953355880826442, 'feature_fraction': 0.9190133871798225, 'bagging_fraction': 0.9333187540494624, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:41,941] Trial 46 finished with value: 0.8142857142857143 and parameters: {'num_leaves': 155, 'learning_rate': 0.19669241678823218, 'feature_fraction': 0.9110629167767232, 'bagging_fraction': 0.9562470196824563, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:41,991] Trial 47 finished with value: 0.9047619047619048 and parameters: {'num_leaves': 127, 'learning_rate': 0.23997929233704718, 'feature_fraction': 0.962182332197222, 'bagging_fraction': 0.5931303769617875, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:42,011] Trial 48 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 233, 'learning_rate': 0.1960104884150498, 'feature_fraction': 0.9365227091979734, 'bagging_fraction': 0.43432918981644303, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:42,062] Trial 49 finished with value: 0.9714285714285714 and parameters: {'num_leaves': 185, 'learning_rate': 0.27585863870613014, 'feature_fraction': 0.9784792626388246, 'bagging_fraction': 0.9335917018580981, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 41 with value: 0.9714285714285714.
[I 2025-09-17 13:15:42,309] A new study created in memory with name: no-name-0c26e965-7e7f-4b14-97d5-fce686f505c2
[I 2025-09-17 13:15:42,320] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 93, 'learning_rate': 0.1719209934154147, 'feature_fraction': 0.5072409974333536, 'bagging_fraction': 0.5960729726149304, 'bagging_freq': 3, 'min_child_samples': 92}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:42,349] Trial 1 finished with value: 0.9375 and parameters: {'num_leaves': 16, 'learning_rate': 0.2532447267193909, 'feature_fraction': 0.9023753607125652, 'bagging_fraction': 0.6138780620076895, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,369] Trial 2 finished with value: 0.7232142857142857 and parameters: {'num_leaves': 16, 'learning_rate': 0.06283199147540544, 'feature_fraction': 0.6733315971863829, 'bagging_fraction': 0.9202435768953916, 'bagging_freq': 2, 'min_child_samples': 51}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,378] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 285, 'learning_rate': 0.269985077402448, 'feature_fraction': 0.9686535928619657, 'bagging_fraction': 0.428204909071418, 'bagging_freq': 1, 'min_child_samples': 71}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,383] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 62, 'learning_rate': 0.10028159561868513, 'feature_fraction': 0.6623944453656085, 'bagging_fraction': 0.9740538290032235, 'bagging_freq': 6, 'min_child_samples': 79}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,412] Trial 5 finished with value: 0.8660714285714285 and parameters: {'num_leaves': 180, 'learning_rate': 0.14002701483829266, 'feature_fraction': 0.6950368921539689, 'bagging_fraction': 0.8898102760269372, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,420] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 31, 'learning_rate': 0.07418246472775926, 'feature_fraction': 0.8269966342477093, 'bagging_fraction': 0.7086053773947169, 'bagging_freq': 3, 'min_child_samples': 78}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,499] Trial 7 finished with value: 0.9375 and parameters: {'num_leaves': 47, 'learning_rate': 0.07511178025483654, 'feature_fraction': 0.8095337198857373, 'bagging_fraction': 0.4636788791202819, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,507] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 110, 'learning_rate': 0.05900892312626341, 'feature_fraction': 0.5227182005174769, 'bagging_fraction': 0.8633545606377928, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,611] Trial 9 finished with value: 0.9375 and parameters: {'num_leaves': 57, 'learning_rate': 0.10001570068176997, 'feature_fraction': 0.49007187384452155, 'bagging_fraction': 0.9807461217328378, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,637] Trial 10 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 187, 'learning_rate': 0.2996842796299003, 'feature_fraction': 0.9950050164449334, 'bagging_fraction': 0.7051861141264714, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,683] Trial 11 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 131, 'learning_rate': 0.23035256891138603, 'feature_fraction': 0.8393731009741041, 'bagging_fraction': 0.45760803517285253, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,706] Trial 12 finished with value: 0.7678571428571428 and parameters: {'num_leaves': 245, 'learning_rate': 0.013092548749426197, 'feature_fraction': 0.8477089321144954, 'bagging_fraction': 0.5576704125944609, 'bagging_freq': 7, 'min_child_samples': 32}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,739] Trial 13 finished with value: 0.8616071428571429 and parameters: {'num_leaves': 13, 'learning_rate': 0.20494429056462699, 'feature_fraction': 0.8809437518650358, 'bagging_fraction': 0.5546664433777777, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,752] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 69, 'learning_rate': 0.15186668896362415, 'feature_fraction': 0.7651788617713084, 'bagging_fraction': 0.6363527369510776, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,788] Trial 15 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 148, 'learning_rate': 0.22888085336310227, 'feature_fraction': 0.9124418692840055, 'bagging_fraction': 0.4919673864756529, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,818] Trial 16 finished with value: 0.7946428571428572 and parameters: {'num_leaves': 92, 'learning_rate': 0.016458186631762045, 'feature_fraction': 0.7462342942812226, 'bagging_fraction': 0.7447639914691931, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,844] Trial 17 finished with value: 0.8125 and parameters: {'num_leaves': 48, 'learning_rate': 0.19188005516868054, 'feature_fraction': 0.4071836000756011, 'bagging_fraction': 0.4054640061196136, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,921] Trial 18 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 196, 'learning_rate': 0.12973306028892262, 'feature_fraction': 0.9216574557696758, 'bagging_fraction': 0.7837407993033899, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,950] Trial 19 finished with value: 0.8883928571428571 and parameters: {'num_leaves': 111, 'learning_rate': 0.2949033290569665, 'feature_fraction': 0.604236174302765, 'bagging_fraction': 0.5079537552567766, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:42,970] Trial 20 finished with value: 0.6852678571428572 and parameters: {'num_leaves': 40, 'learning_rate': 0.2544364829973252, 'feature_fraction': 0.7626357160350162, 'bagging_fraction': 0.6388308172422649, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,137] Trial 21 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 69, 'learning_rate': 0.10502320724667603, 'feature_fraction': 0.41482410180796714, 'bagging_fraction': 0.8245309526975744, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,179] Trial 22 finished with value: 0.9330357142857143 and parameters: {'num_leaves': 16, 'learning_rate': 0.10631134662309444, 'feature_fraction': 0.795615847350828, 'bagging_fraction': 0.6450175719145433, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,256] Trial 23 finished with value: 0.9375 and parameters: {'num_leaves': 59, 'learning_rate': 0.04080406429147071, 'feature_fraction': 0.6090652230222754, 'bagging_fraction': 0.9963412936535806, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,287] Trial 24 finished with value: 0.8169642857142857 and parameters: {'num_leaves': 83, 'learning_rate': 0.08262505210702518, 'feature_fraction': 0.4807417908357079, 'bagging_fraction': 0.5431907641451498, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,336] Trial 25 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 35, 'learning_rate': 0.04209330180892837, 'feature_fraction': 0.6061042603012268, 'bagging_fraction': 0.4916917978699879, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,359] Trial 26 finished with value: 0.7723214285714286 and parameters: {'num_leaves': 39, 'learning_rate': 0.1152643148691592, 'feature_fraction': 0.9322732175464932, 'bagging_fraction': 0.6023149681116147, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,393] Trial 27 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 119, 'learning_rate': 0.1738667735963802, 'feature_fraction': 0.8778260700514742, 'bagging_fraction': 0.8054953729005352, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,410] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 157, 'learning_rate': 0.08648596622100901, 'feature_fraction': 0.7172824938089116, 'bagging_fraction': 0.75539624018371, 'bagging_freq': 6, 'min_child_samples': 59}. Best is trial 1 with value: 0.9375.

Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.402142
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.364013
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.556364
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.395732
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.529744
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.354907
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.371234
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.377261
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.557312
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.44443
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.330399
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.393299
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.354058
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.347361
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.43266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.565377
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.572945
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.581743
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.302846
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.304515
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.324524
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.438769
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.285064
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.534806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.437196
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.584105
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.332214
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.315567
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.600354
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.472835
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.289758
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.314132
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.394146
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.374128
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.641156
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.476556
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.416973
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.607431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.581545
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.378298
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.401266
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.631151
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.352731
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.347433
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.360637
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.545749
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.388098
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.554838
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.47001
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.691035
[I 2025-09-17 13:15:43,424] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 85, 'learning_rate': 0.1625237502024385, 'feature_fraction': 0.5135097743105107, 'bagging_fraction': 0.5940964997442543, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,473] Trial 30 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 218, 'learning_rate': 0.12874856866690265, 'feature_fraction': 0.7986105457302858, 'bagging_fraction': 0.6776038894795446, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,551] Trial 31 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 64, 'learning_rate': 0.03581111839622312, 'feature_fraction': 0.5837061545225539, 'bagging_fraction': 0.9775992853373819, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,607] Trial 32 finished with value: 0.8973214285714285 and parameters: {'num_leaves': 55, 'learning_rate': 0.04768852194805828, 'feature_fraction': 0.5755288077921196, 'bagging_fraction': 0.9442380584057709, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,747] Trial 33 finished with value: 0.9241071428571428 and parameters: {'num_leaves': 12, 'learning_rate': 0.030009682853778294, 'feature_fraction': 0.4473000992703165, 'bagging_fraction': 0.9982610092816316, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,815] Trial 34 finished with value: 0.9330357142857143 and parameters: {'num_leaves': 29, 'learning_rate': 0.06330713001309791, 'feature_fraction': 0.6460876341058885, 'bagging_fraction': 0.9193673723854523, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,845] Trial 35 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 293, 'learning_rate': 0.08815598574330892, 'feature_fraction': 0.5468255369681526, 'bagging_fraction': 0.8442892064885725, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,940] Trial 36 finished with value: 0.8839285714285714 and parameters: {'num_leaves': 73, 'learning_rate': 0.06644772949052263, 'feature_fraction': 0.6351169745754146, 'bagging_fraction': 0.9121817095370947, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:43,969] Trial 37 finished with value: 0.7723214285714286 and parameters: {'num_leaves': 101, 'learning_rate': 0.053393231275958554, 'feature_fraction': 0.7009819337312547, 'bagging_fraction': 0.951438947560296, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:44,023] Trial 38 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 56, 'learning_rate': 0.027580087264263177, 'feature_fraction': 0.4741957029228626, 'bagging_fraction': 0.8841839980032653, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:44,040] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 30, 'learning_rate': 0.09373877035037273, 'feature_fraction': 0.9745410814172129, 'bagging_fraction': 0.43285693285243965, 'bagging_freq': 6, 'min_child_samples': 85}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:44,072] Trial 40 finished with value: 0.8080357142857143 and parameters: {'num_leaves': 134, 'learning_rate': 0.11904320175026925, 'feature_fraction': 0.5409282940674898, 'bagging_fraction': 0.9969067510390871, 'bagging_freq': 7, 'min_child_samples': 34}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:44,119] Trial 41 finished with value: 0.9196428571428571 and parameters: {'num_leaves': 23, 'learning_rate': 0.10804872882577099, 'feature_fraction': 0.8096224284293205, 'bagging_fraction': 0.6630448943016288, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:44,158] Trial 42 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 14, 'learning_rate': 0.07270058334460688, 'feature_fraction': 0.87541410256638, 'bagging_fraction': 0.5922420037363416, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 1 with value: 0.9375.
[I 2025-09-17 13:15:44,231] Trial 43 finished with value: 0.9419642857142857 and parameters: {'num_leaves': 48, 'learning_rate': 0.14350512315164027, 'feature_fraction': 0.7882150414112516, 'bagging_fraction': 0.6298587685626517, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 43 with value: 0.9419642857142857.
[I 2025-09-17 13:15:44,325] Trial 44 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 48, 'learning_rate': 0.139180560545984, 'feature_fraction': 0.722872217426818, 'bagging_fraction': 0.721016966959584, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 43 with value: 0.9419642857142857.
[I 2025-09-17 13:15:44,383] Trial 45 finished with value: 0.9821428571428571 and parameters: {'num_leaves': 78, 'learning_rate': 0.2018636241499045, 'feature_fraction': 0.6682885320702981, 'bagging_fraction': 0.5194939691210669, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 45 with value: 0.9821428571428571.
[I 2025-09-17 13:15:44,408] Trial 46 finished with value: 0.8169642857142857 and parameters: {'num_leaves': 79, 'learning_rate': 0.22695499847516531, 'feature_fraction': 0.676107369973109, 'bagging_fraction': 0.5256881301145421, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 45 with value: 0.9821428571428571.
[I 2025-09-17 13:15:44,462] Trial 47 finished with value: 0.9241071428571428 and parameters: {'num_leaves': 267, 'learning_rate': 0.19114428946403153, 'feature_fraction': 0.8508203937511625, 'bagging_fraction': 0.45227441000273044, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 45 with value: 0.9821428571428571.
[I 2025-09-17 13:15:44,478] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 97, 'learning_rate': 0.2538645554750632, 'feature_fraction': 0.7767092310930891, 'bagging_fraction': 0.5707072342696926, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 45 with value: 0.9821428571428571.
[I 2025-09-17 13:15:44,504] Trial 49 finished with value: 0.8794642857142857 and parameters: {'num_leaves': 44, 'learning_rate': 0.18074446213011003, 'feature_fraction': 0.9455658356532356, 'bagging_fraction': 0.4740158497647186, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 45 with value: 0.9821428571428571.
[I 2025-09-17 13:15:44,729] A new study created in memory with name: no-name-98f69476-137e-41f2-a7c0-780c18a9d117
[I 2025-09-17 13:15:44,737] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 118, 'learning_rate': 0.013642835574169301, 'feature_fraction': 0.6692815150098586, 'bagging_fraction': 0.45061003754534734, 'bagging_freq': 6, 'min_child_samples': 96}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:44,746] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 160, 'learning_rate': 0.06245081512827403, 'feature_fraction': 0.6642496246504703, 'bagging_fraction': 0.5669210445546184, 'bagging_freq': 1, 'min_child_samples': 72}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:44,777] Trial 2 finished with value: 0.9196428571428571 and parameters: {'num_leaves': 16, 'learning_rate': 0.19443736885639457, 'feature_fraction': 0.9147118322341959, 'bagging_fraction': 0.8709840470519117, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:44,785] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.23864783922693705, 'feature_fraction': 0.9579835751255347, 'bagging_fraction': 0.5073837047581322, 'bagging_freq': 1, 'min_child_samples': 85}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:44,793] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 227, 'learning_rate': 0.1913802836151363, 'feature_fraction': 0.6597073680072868, 'bagging_fraction': 0.640414414972676, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:44,837] Trial 5 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 233, 'learning_rate': 0.09959566166994424, 'feature_fraction': 0.7802155516148247, 'bagging_fraction': 0.9633345164666735, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:44,845] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 274, 'learning_rate': 0.1439498760136141, 'feature_fraction': 0.6587228554597864, 'bagging_fraction': 0.5949489252213714, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:44,852] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.2563818466339297, 'feature_fraction': 0.8771939222196038, 'bagging_fraction': 0.7962101062923905, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:44,885] Trial 8 finished with value: 0.8839285714285713 and parameters: {'num_leaves': 48, 'learning_rate': 0.16858040788296944, 'feature_fraction': 0.9724520753380137, 'bagging_fraction': 0.4401222197516226, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:44,896] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 160, 'learning_rate': 0.12730586467713406, 'feature_fraction': 0.7717137327364318, 'bagging_fraction': 0.545424479729524, 'bagging_freq': 2, 'min_child_samples': 62}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:44,920] Trial 10 finished with value: 0.8705357142857143 and parameters: {'num_leaves': 20, 'learning_rate': 0.2889092760764972, 'feature_fraction': 0.456358918745441, 'bagging_fraction': 0.8115850151902115, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 2 with value: 0.9196428571428571.
[I 2025-09-17 13:15:45,030] Trial 11 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 287, 'learning_rate': 0.0896710774283719, 'feature_fraction': 0.8177940692553032, 'bagging_fraction': 0.9793469225256949, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,065] Trial 12 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 78, 'learning_rate': 0.20037233413977001, 'feature_fraction': 0.8591928923361873, 'bagging_fraction': 0.9655119958803912, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,188] Trial 13 finished with value: 0.9196428571428572 and parameters: {'num_leaves': 284, 'learning_rate': 0.07060544617612786, 'feature_fraction': 0.8665294704624338, 'bagging_fraction': 0.859930602961225, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,314] Trial 14 finished with value: 0.9196428571428571 and parameters: {'num_leaves': 300, 'learning_rate': 0.06776858859069233, 'feature_fraction': 0.7942400404353576, 'bagging_fraction': 0.869871994235817, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,342] Trial 15 finished with value: 0.7276785714285714 and parameters: {'num_leaves': 245, 'learning_rate': 0.011999957729414784, 'feature_fraction': 0.5769303829379521, 'bagging_fraction': 0.7325129132000427, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,364] Trial 16 finished with value: 0.7589285714285714 and parameters: {'num_leaves': 201, 'learning_rate': 0.06799929382411293, 'feature_fraction': 0.8344822300879802, 'bagging_fraction': 0.9905906232824968, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,406] Trial 17 finished with value: 0.8883928571428572 and parameters: {'num_leaves': 299, 'learning_rate': 0.09977788191948446, 'feature_fraction': 0.7460431730265908, 'bagging_fraction': 0.8912285378239265, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,430] Trial 18 finished with value: 0.7767857142857143 and parameters: {'num_leaves': 262, 'learning_rate': 0.0367513450737365, 'feature_fraction': 0.5554152400214796, 'bagging_fraction': 0.7172178524554135, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,543] Trial 19 finished with value: 0.9285714285714285 and parameters: {'num_leaves': 200, 'learning_rate': 0.10761060217499938, 'feature_fraction': 0.9098101176377427, 'bagging_fraction': 0.9188722500415875, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,567] Trial 20 finished with value: 0.75 and parameters: {'num_leaves': 203, 'learning_rate': 0.11350914279300886, 'feature_fraction': 0.9951050496361226, 'bagging_fraction': 0.9355048517850367, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,677] Trial 21 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 272, 'learning_rate': 0.08558783322063035, 'feature_fraction': 0.928943900772141, 'bagging_fraction': 0.8055845981517641, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,716] Trial 22 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 254, 'learning_rate': 0.13273682662490194, 'feature_fraction': 0.8951335801148131, 'bagging_fraction': 0.9223594315412987, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,748] Trial 23 finished with value: 0.8616071428571429 and parameters: {'num_leaves': 214, 'learning_rate': 0.041997873914809136, 'feature_fraction': 0.8111812261224064, 'bagging_fraction': 0.8474366589025706, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,793] Trial 24 finished with value: 0.9241071428571428 and parameters: {'num_leaves': 282, 'learning_rate': 0.1605731307475019, 'feature_fraction': 0.7114585947032909, 'bagging_fraction': 0.9191008325929064, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,835] Trial 25 finished with value: 0.8973214285714286 and parameters: {'num_leaves': 176, 'learning_rate': 0.1631672583184562, 'feature_fraction': 0.7148576198833826, 'bagging_fraction': 0.9909574370224132, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,854] Trial 26 finished with value: 0.8080357142857143 and parameters: {'num_leaves': 132, 'learning_rate': 0.17334996436831493, 'feature_fraction': 0.5990872639331382, 'bagging_fraction': 0.7603293855033939, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,898] Trial 27 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 239, 'learning_rate': 0.12015103123923959, 'feature_fraction': 0.7318537368186416, 'bagging_fraction': 0.9142938280125124, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,916] Trial 28 finished with value: 0.6785714285714286 and parameters: {'num_leaves': 102, 'learning_rate': 0.14940409255050108, 'feature_fraction': 0.49447258654927845, 'bagging_fraction': 0.6597874160519364, 'bagging_freq': 7, 'min_child_samples': 40}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,945] Trial 29 finished with value: 0.8883928571428572 and parameters: {'num_leaves': 282, 'learning_rate': 0.2203860945023799, 'feature_fraction': 0.8256165606874853, 'bagging_fraction': 0.9454389290880958, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:45,999] Trial 30 finished with value: 0.875 and parameters: {'num_leaves': 218, 'learning_rate': 0.10300785963030235, 'feature_fraction': 0.6169333672787105, 'bagging_fraction': 0.8248580480602986, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,121] Trial 31 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 289, 'learning_rate': 0.08691009337272579, 'feature_fraction': 0.8713238137132205, 'bagging_fraction': 0.8896086680196809, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,135] Trial 32 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.04700456015045773, 'feature_fraction': 0.9292767804037205, 'bagging_fraction': 0.9099680199842206, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,184] Trial 33 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 275, 'learning_rate': 0.07986055803755271, 'feature_fraction': 0.6911397380641784, 'bagging_fraction': 0.8489974174210625, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,197] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.026667094353786364, 'feature_fraction': 0.8519265340553626, 'bagging_fraction': 0.7774116560114424, 'bagging_freq': 2, 'min_child_samples': 77}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,237] Trial 35 finished with value: 0.90625 and parameters: {'num_leaves': 288, 'learning_rate': 0.057782486929146434, 'feature_fraction': 0.9068231030724743, 'bagging_fraction': 0.9949084615158058, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 11 with value: 0.9285714285714286.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.359214
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.387973
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.403093
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.360022
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.33649
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.497277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.403348
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.583424
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.443679
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.532211
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.413284
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.394327
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.310292
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.302941
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.192789
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.512249
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.379493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.462291
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.371138
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.371693
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.412504
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.45838
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.328551
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.454888
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.358648
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.343551
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.631032
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.571094
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.414847
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.599316
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.359411
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.592365
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.362118
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.379758
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.491402
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.353007
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.36058
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.562608
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.376684
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.639806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.426138
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.424931
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.361098
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.419019
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.439606
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:46,302] Trial 36 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 182, 'learning_rate': 0.1395291512832434, 'feature_fraction': 0.9563674088289892, 'bagging_fraction': 0.8547305705768151, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,319] Trial 37 finished with value: 0.6964285714285714 and parameters: {'num_leaves': 232, 'learning_rate': 0.18273226108576818, 'feature_fraction': 0.7472130963312595, 'bagging_fraction': 0.9486979288234819, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,333] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.10981726064609904, 'feature_fraction': 0.7769318022957061, 'bagging_fraction': 0.9648986554690413, 'bagging_freq': 3, 'min_child_samples': 88}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,385] Trial 39 finished with value: 0.8883928571428572 and parameters: {'num_leaves': 246, 'learning_rate': 0.07942264925535777, 'feature_fraction': 0.6808874951897146, 'bagging_fraction': 0.8894243015893611, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,412] Trial 40 finished with value: 0.7455357142857143 and parameters: {'num_leaves': 268, 'learning_rate': 0.1530147369803611, 'feature_fraction': 0.6400710876693361, 'bagging_fraction': 0.6765292069083013, 'bagging_freq': 2, 'min_child_samples': 37}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,450] Trial 41 finished with value: 0.8973214285714285 and parameters: {'num_leaves': 107, 'learning_rate': 0.2073179281247174, 'feature_fraction': 0.9233750419363544, 'bagging_fraction': 0.4036618068529478, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 11 with value: 0.9285714285714286.
[I 2025-09-17 13:15:46,511] Trial 42 finished with value: 0.9419642857142857 and parameters: {'num_leaves': 63, 'learning_rate': 0.24036083079814752, 'feature_fraction': 0.8897264423824617, 'bagging_fraction': 0.8301342618143478, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 42 with value: 0.9419642857142857.
[I 2025-09-17 13:15:46,563] Trial 43 finished with value: 0.9419642857142857 and parameters: {'num_leaves': 68, 'learning_rate': 0.21571176228442207, 'feature_fraction': 0.8921403344045383, 'bagging_fraction': 0.9053546358109384, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 42 with value: 0.9419642857142857.
[I 2025-09-17 13:15:46,594] Trial 44 finished with value: 0.8616071428571428 and parameters: {'num_leaves': 66, 'learning_rate': 0.2577916659220876, 'feature_fraction': 0.8987262964777736, 'bagging_fraction': 0.9026967456703187, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 42 with value: 0.9419642857142857.
[I 2025-09-17 13:15:46,644] Trial 45 finished with value: 0.9598214285714286 and parameters: {'num_leaves': 47, 'learning_rate': 0.24616868466443087, 'feature_fraction': 0.959156869194236, 'bagging_fraction': 0.965726199327412, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 45 with value: 0.9598214285714286.
[I 2025-09-17 13:15:46,684] Trial 46 finished with value: 0.9017857142857142 and parameters: {'num_leaves': 29, 'learning_rate': 0.2652274722943585, 'feature_fraction': 0.9623521202030515, 'bagging_fraction': 0.9673419781184572, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 45 with value: 0.9598214285714286.
[I 2025-09-17 13:15:46,748] Trial 47 finished with value: 0.9308035714285714 and parameters: {'num_leaves': 42, 'learning_rate': 0.23954753369655296, 'feature_fraction': 0.9831696739337222, 'bagging_fraction': 0.9441811978726112, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 45 with value: 0.9598214285714286.
[I 2025-09-17 13:15:46,780] Trial 48 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 48, 'learning_rate': 0.22689627862948067, 'feature_fraction': 0.9777301384875565, 'bagging_fraction': 0.9698124877761332, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 45 with value: 0.9598214285714286.
[I 2025-09-17 13:15:46,830] Trial 49 finished with value: 0.9241071428571428 and parameters: {'num_leaves': 83, 'learning_rate': 0.28591041251173943, 'feature_fraction': 0.9908957678878775, 'bagging_fraction': 0.8277702759038972, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 45 with value: 0.9598214285714286.
[I 2025-09-17 13:15:47,099] A new study created in memory with name: no-name-99407a89-3556-4d6c-8f42-c72a1207b7a0
[I 2025-09-17 13:15:47,107] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.14457283528017395, 'feature_fraction': 0.6490752630958387, 'bagging_fraction': 0.8492128473070302, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:47,114] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 62, 'learning_rate': 0.061534284684251456, 'feature_fraction': 0.7686322385175, 'bagging_fraction': 0.4456924659968031, 'bagging_freq': 1, 'min_child_samples': 60}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:15:47,129] Trial 2 finished with value: 0.8125 and parameters: {'num_leaves': 269, 'learning_rate': 0.2930987928667866, 'feature_fraction': 0.4352191203632837, 'bagging_fraction': 0.8550658843987508, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,137] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.0835464524973218, 'feature_fraction': 0.6240572566389584, 'bagging_fraction': 0.7818592528327446, 'bagging_freq': 6, 'min_child_samples': 70}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,145] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 84, 'learning_rate': 0.014535966007155319, 'feature_fraction': 0.8272306839409653, 'bagging_fraction': 0.9092523904201065, 'bagging_freq': 7, 'min_child_samples': 57}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,174] Trial 5 finished with value: 0.8080357142857143 and parameters: {'num_leaves': 129, 'learning_rate': 0.08170769926533754, 'feature_fraction': 0.8174197423197498, 'bagging_fraction': 0.6020950234861153, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,184] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 221, 'learning_rate': 0.03311084380230383, 'feature_fraction': 0.5109782713434005, 'bagging_fraction': 0.9314890062733876, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,192] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 273, 'learning_rate': 0.06079049450499582, 'feature_fraction': 0.4966390803643231, 'bagging_fraction': 0.5596836252482789, 'bagging_freq': 2, 'min_child_samples': 88}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,200] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 147, 'learning_rate': 0.11029347176123429, 'feature_fraction': 0.4721263092873674, 'bagging_fraction': 0.47754553004709993, 'bagging_freq': 2, 'min_child_samples': 75}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,209] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 145, 'learning_rate': 0.1476421118410084, 'feature_fraction': 0.7347809580523351, 'bagging_fraction': 0.4012157362410055, 'bagging_freq': 5, 'min_child_samples': 95}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,233] Trial 10 finished with value: 0.7946428571428572 and parameters: {'num_leaves': 290, 'learning_rate': 0.2974647550331583, 'feature_fraction': 0.9451276597480792, 'bagging_fraction': 0.7166215775785757, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 2 with value: 0.8125.
[I 2025-09-17 13:15:47,291] Trial 11 finished with value: 0.8303571428571428 and parameters: {'num_leaves': 10, 'learning_rate': 0.2518345641140973, 'feature_fraction': 0.8927760336650791, 'bagging_fraction': 0.6386403702307372, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 11 with value: 0.8303571428571428.
[I 2025-09-17 13:15:47,364] Trial 12 finished with value: 0.8482142857142857 and parameters: {'num_leaves': 27, 'learning_rate': 0.2802535408622532, 'feature_fraction': 0.9924786401122835, 'bagging_fraction': 0.9970443572368661, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 12 with value: 0.8482142857142857.
[I 2025-09-17 13:15:47,411] Trial 13 finished with value: 0.7946428571428572 and parameters: {'num_leaves': 21, 'learning_rate': 0.2386819270321683, 'feature_fraction': 0.9988776047468274, 'bagging_fraction': 0.6479392219487123, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 12 with value: 0.8482142857142857.
[I 2025-09-17 13:15:47,479] Trial 14 finished with value: 0.8794642857142856 and parameters: {'num_leaves': 17, 'learning_rate': 0.22220119764511784, 'feature_fraction': 0.9023017146238304, 'bagging_fraction': 0.9908545608927118, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 14 with value: 0.8794642857142856.
[I 2025-09-17 13:15:47,517] Trial 15 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 59, 'learning_rate': 0.20498152219299423, 'feature_fraction': 0.9948254300740536, 'bagging_fraction': 0.989829095068209, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 14 with value: 0.8794642857142856.
[I 2025-09-17 13:15:47,540] Trial 16 finished with value: 0.8125 and parameters: {'num_leaves': 94, 'learning_rate': 0.1908744178075374, 'feature_fraction': 0.8875606712471699, 'bagging_fraction': 0.9695945793276056, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 14 with value: 0.8794642857142856.
[I 2025-09-17 13:15:47,578] Trial 17 finished with value: 0.8794642857142857 and parameters: {'num_leaves': 46, 'learning_rate': 0.2577680893117706, 'feature_fraction': 0.8983792388337709, 'bagging_fraction': 0.7886296222301377, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 17 with value: 0.8794642857142857.
[I 2025-09-17 13:15:47,607] Trial 18 finished with value: 0.90625 and parameters: {'num_leaves': 107, 'learning_rate': 0.20310869950544075, 'feature_fraction': 0.8941177874013878, 'bagging_fraction': 0.7830125558982949, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,636] Trial 19 finished with value: 0.8258928571428571 and parameters: {'num_leaves': 178, 'learning_rate': 0.18764872676958783, 'feature_fraction': 0.8135673412574842, 'bagging_fraction': 0.7593745260405476, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,662] Trial 20 finished with value: 0.8125 and parameters: {'num_leaves': 109, 'learning_rate': 0.25241639724109866, 'feature_fraction': 0.6773989111414069, 'bagging_fraction': 0.8152359261443332, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,694] Trial 21 finished with value: 0.8303571428571428 and parameters: {'num_leaves': 49, 'learning_rate': 0.22282839000816035, 'feature_fraction': 0.9028270023066898, 'bagging_fraction': 0.7129423352034905, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,721] Trial 22 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 49, 'learning_rate': 0.16902629421223975, 'feature_fraction': 0.8510819622156117, 'bagging_fraction': 0.8835290676676539, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,753] Trial 23 finished with value: 0.8526785714285714 and parameters: {'num_leaves': 79, 'learning_rate': 0.26778959458633467, 'feature_fraction': 0.9346121197204005, 'bagging_fraction': 0.7609671398516352, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,782] Trial 24 finished with value: 0.8303571428571429 and parameters: {'num_leaves': 116, 'learning_rate': 0.21662123063320113, 'feature_fraction': 0.5959668359401586, 'bagging_fraction': 0.8114748797773957, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,825] Trial 25 finished with value: 0.8973214285714286 and parameters: {'num_leaves': 37, 'learning_rate': 0.2359995694723475, 'feature_fraction': 0.7624881777465937, 'bagging_fraction': 0.9379032411180226, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,863] Trial 26 finished with value: 0.9017857142857143 and parameters: {'num_leaves': 175, 'learning_rate': 0.24026256812707442, 'feature_fraction': 0.760373662554879, 'bagging_fraction': 0.922324934545238, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,889] Trial 27 finished with value: 0.8258928571428571 and parameters: {'num_leaves': 171, 'learning_rate': 0.17203820096423972, 'feature_fraction': 0.7430771680350792, 'bagging_fraction': 0.9279443233141248, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,915] Trial 28 finished with value: 0.8125 and parameters: {'num_leaves': 211, 'learning_rate': 0.12438245310047163, 'feature_fraction': 0.7646548239135592, 'bagging_fraction': 0.879214099595865, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,931] Trial 29 finished with value: 0.7678571428571428 and parameters: {'num_leaves': 192, 'learning_rate': 0.23845987262271567, 'feature_fraction': 0.6974089673523538, 'bagging_fraction': 0.8389293142240631, 'bagging_freq': 1, 'min_child_samples': 51}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:47,975] Trial 30 finished with value: 0.8839285714285714 and parameters: {'num_leaves': 230, 'learning_rate': 0.18804838371504104, 'feature_fraction': 0.5796913262295933, 'bagging_fraction': 0.9413676971700351, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,019] Trial 31 finished with value: 0.8973214285714286 and parameters: {'num_leaves': 241, 'learning_rate': 0.19906895970415694, 'feature_fraction': 0.5760856564394637, 'bagging_fraction': 0.92268838602469, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,045] Trial 32 finished with value: 0.8415178571428572 and parameters: {'num_leaves': 241, 'learning_rate': 0.2020021947749958, 'feature_fraction': 0.6583546727447296, 'bagging_fraction': 0.8863914413999461, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,088] Trial 33 finished with value: 0.90625 and parameters: {'num_leaves': 256, 'learning_rate': 0.1673703993020694, 'feature_fraction': 0.7211814004254584, 'bagging_fraction': 0.8584867745696974, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,138] Trial 34 finished with value: 0.84375 and parameters: {'num_leaves': 174, 'learning_rate': 0.16470273864115065, 'feature_fraction': 0.7911272502131436, 'bagging_fraction': 0.8558447841556325, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,169] Trial 35 finished with value: 0.8526785714285714 and parameters: {'num_leaves': 262, 'learning_rate': 0.2405493429515631, 'feature_fraction': 0.7185628586437227, 'bagging_fraction': 0.9579228464720427, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,212] Trial 36 finished with value: 0.8660714285714286 and parameters: {'num_leaves': 194, 'learning_rate': 0.12984774604094484, 'feature_fraction': 0.7774725999574222, 'bagging_fraction': 0.8521735371220135, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,309] Trial 37 finished with value: 0.8616071428571429 and parameters: {'num_leaves': 73, 'learning_rate': 0.28227417267029864, 'feature_fraction': 0.8544233412775972, 'bagging_fraction': 0.8977944037788264, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,336] Trial 38 finished with value: 0.8125 and parameters: {'num_leaves': 127, 'learning_rate': 0.21618231604968557, 'feature_fraction': 0.6373636076542516, 'bagging_fraction': 0.7400220595171592, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,366] Trial 39 finished with value: 0.8482142857142857 and parameters: {'num_leaves': 156, 'learning_rate': 0.17491555379336093, 'feature_fraction': 0.7003476807524063, 'bagging_fraction': 0.8190119162256909, 'bagging_freq': 2, 'min_child_samples': 37}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,379] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 96, 'learning_rate': 0.1360969429315986, 'feature_fraction': 0.7523209184559675, 'bagging_fraction': 0.6802507354880378, 'bagging_freq': 5, 'min_child_samples': 68}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,440] Trial 41 finished with value: 0.8883928571428571 and parameters: {'num_leaves': 250, 'learning_rate': 0.20182041590265692, 'feature_fraction': 0.54458497140016, 'bagging_fraction': 0.9167006231713309, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,497] Trial 42 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 288, 'learning_rate': 0.15461467682594612, 'feature_fraction': 0.6060780430721652, 'bagging_fraction': 0.9430214326491155, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,556] Trial 43 finished with value: 0.8660714285714286 and parameters: {'num_leaves': 224, 'learning_rate': 0.232320337856797, 'feature_fraction': 0.4299707082408333, 'bagging_fraction': 0.8540162319473336, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,606] Trial 44 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 269, 'learning_rate': 0.193128899006156, 'feature_fraction': 0.5574938883067782, 'bagging_fraction': 0.9118559136799533, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 18 with value: 0.90625.
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.380918
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.627756
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.397889
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.577224
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.428969
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.36997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.318281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.474478
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.319345
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.411523
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.362661
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.444723
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.370541
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.536782
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.533972
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.556063
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.56682
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.48714
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.542794
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.451766
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.497162
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.527557
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.435383
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.457122
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.499734
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.525103
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.51287
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.512376
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.485775
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.497986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.461865
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.442998
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.535277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.55186
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.598416
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.448588
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.443458
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.505196
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.416657
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.47851
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.492372
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.474874
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.450486
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.517773
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.509264
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.43905
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.472313
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.462158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.440381
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:15:48,646] Trial 45 finished with value: 0.8169642857142857 and parameters: {'num_leaves': 248, 'learning_rate': 0.27019642249442033, 'feature_fraction': 0.811302319425546, 'bagging_fraction': 0.7983738232642656, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,706] Trial 46 finished with value: 0.8973214285714285 and parameters: {'num_leaves': 203, 'learning_rate': 0.2123554431261069, 'feature_fraction': 0.40633046155830504, 'bagging_fraction': 0.5345273684397128, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,719] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.09571632492252335, 'feature_fraction': 0.7183943419219622, 'bagging_fraction': 0.9640735473768174, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,750] Trial 48 finished with value: 0.7723214285714286 and parameters: {'num_leaves': 154, 'learning_rate': 0.2300957525799316, 'feature_fraction': 0.8430988223899745, 'bagging_fraction': 0.8365630159846097, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:48,881] Trial 49 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 133, 'learning_rate': 0.1429229402727784, 'feature_fraction': 0.670080679029943, 'bagging_fraction': 0.8712440625281062, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 18 with value: 0.90625.
[I 2025-09-17 13:15:49,200] A new study created in memory with name: no-name-99d2e050-b555-451e-86bc-4cf6e0a4aafc
[I 2025-09-17 13:15:49,231] Trial 0 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 58, 'learning_rate': 0.10731102946878443, 'feature_fraction': 0.6035984758404, 'bagging_fraction': 0.5998691362955493, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 0 with value: 0.8076923076923077.
[I 2025-09-17 13:15:49,242] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 42, 'learning_rate': 0.2265302576077495, 'feature_fraction': 0.7444711243163438, 'bagging_fraction': 0.6123256476347096, 'bagging_freq': 2, 'min_child_samples': 69}. Best is trial 0 with value: 0.8076923076923077.
[I 2025-09-17 13:15:49,307] Trial 2 finished with value: 0.8671328671328671 and parameters: {'num_leaves': 271, 'learning_rate': 0.11050774986713041, 'feature_fraction': 0.7987637141968222, 'bagging_fraction': 0.7423354835419497, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 2 with value: 0.8671328671328671.
[I 2025-09-17 13:15:49,363] Trial 3 finished with value: 0.8006993006993006 and parameters: {'num_leaves': 174, 'learning_rate': 0.16001888141811343, 'feature_fraction': 0.92743884887687, 'bagging_fraction': 0.9492879449336229, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 2 with value: 0.8671328671328671.
[I 2025-09-17 13:15:49,412] Trial 4 finished with value: 0.8356643356643356 and parameters: {'num_leaves': 42, 'learning_rate': 0.1076513604208426, 'feature_fraction': 0.7089757300764499, 'bagging_fraction': 0.8370616297048243, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 2 with value: 0.8671328671328671.
[I 2025-09-17 13:15:49,443] Trial 5 finished with value: 0.6958041958041958 and parameters: {'num_leaves': 21, 'learning_rate': 0.102512318577462, 'feature_fraction': 0.6827613902005698, 'bagging_fraction': 0.5517782540130172, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 2 with value: 0.8671328671328671.
[I 2025-09-17 13:15:49,558] Trial 6 finished with value: 0.756993006993007 and parameters: {'num_leaves': 207, 'learning_rate': 0.25043016011107594, 'feature_fraction': 0.6001679624838834, 'bagging_fraction': 0.9897444763303839, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 2 with value: 0.8671328671328671.
[I 2025-09-17 13:15:49,566] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 113, 'learning_rate': 0.021609110714368537, 'feature_fraction': 0.5247870815849254, 'bagging_fraction': 0.42165751012737607, 'bagging_freq': 6, 'min_child_samples': 90}. Best is trial 2 with value: 0.8671328671328671.
[I 2025-09-17 13:15:49,593] Trial 8 finished with value: 0.8916083916083916 and parameters: {'num_leaves': 146, 'learning_rate': 0.1945254763012985, 'feature_fraction': 0.6426239228112175, 'bagging_fraction': 0.4891212626056884, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,625] Trial 9 finished with value: 0.7832167832167831 and parameters: {'num_leaves': 25, 'learning_rate': 0.01934848948443502, 'feature_fraction': 0.6318220642715302, 'bagging_fraction': 0.7527858735572233, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,643] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 115, 'learning_rate': 0.2831133586335104, 'feature_fraction': 0.40337116603689144, 'bagging_fraction': 0.4125552527650666, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,657] Trial 11 finished with value: 0.6031468531468531 and parameters: {'num_leaves': 284, 'learning_rate': 0.18913225941469206, 'feature_fraction': 0.8419567460292102, 'bagging_fraction': 0.747825358625062, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,671] Trial 12 finished with value: 0.37412587412587417 and parameters: {'num_leaves': 262, 'learning_rate': 0.17686155739877218, 'feature_fraction': 0.8172871213362283, 'bagging_fraction': 0.5273769091030744, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,683] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 224, 'learning_rate': 0.07741566532840757, 'feature_fraction': 0.9669881089464295, 'bagging_fraction': 0.6812660203658553, 'bagging_freq': 5, 'min_child_samples': 69}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,731] Trial 14 finished with value: 0.8461538461538461 and parameters: {'num_leaves': 140, 'learning_rate': 0.22073258468375695, 'feature_fraction': 0.8362233098041663, 'bagging_fraction': 0.8310745601030363, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,752] Trial 15 finished with value: 0.583916083916084 and parameters: {'num_leaves': 180, 'learning_rate': 0.14387370378953754, 'feature_fraction': 0.509814138437453, 'bagging_fraction': 0.4797255292756525, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,764] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 243, 'learning_rate': 0.051442521694102995, 'feature_fraction': 0.7648735959336463, 'bagging_fraction': 0.6703618018335943, 'bagging_freq': 5, 'min_child_samples': 63}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,819] Trial 17 finished with value: 0.8286713286713286 and parameters: {'num_leaves': 298, 'learning_rate': 0.13446782516285746, 'feature_fraction': 0.9002792419453106, 'bagging_fraction': 0.8821806655945559, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,832] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 80, 'learning_rate': 0.20687136424221766, 'feature_fraction': 0.5473679814329031, 'bagging_fraction': 0.7535292249323366, 'bagging_freq': 3, 'min_child_samples': 86}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,850] Trial 19 finished with value: 0.7115384615384616 and parameters: {'num_leaves': 206, 'learning_rate': 0.2962161027542756, 'feature_fraction': 0.4454172608604329, 'bagging_fraction': 0.6177814988812417, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,910] Trial 20 finished with value: 0.7622377622377623 and parameters: {'num_leaves': 145, 'learning_rate': 0.25450142256244385, 'feature_fraction': 0.6572316947874283, 'bagging_fraction': 0.4861627789688513, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,952] Trial 21 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 140, 'learning_rate': 0.2092931972326815, 'feature_fraction': 0.8291525965118047, 'bagging_fraction': 0.8384905798077437, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 8 with value: 0.8916083916083916.
[I 2025-09-17 13:15:49,998] Trial 22 finished with value: 0.8986013986013985 and parameters: {'num_leaves': 107, 'learning_rate': 0.2370645880834112, 'feature_fraction': 0.7747563696986157, 'bagging_fraction': 0.8140009635983012, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,063] Trial 23 finished with value: 0.8461538461538461 and parameters: {'num_leaves': 95, 'learning_rate': 0.2535066723427816, 'feature_fraction': 0.7604039838956583, 'bagging_fraction': 0.7840175330025907, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,100] Trial 24 finished with value: 0.8496503496503496 and parameters: {'num_leaves': 169, 'learning_rate': 0.17089655360734038, 'feature_fraction': 0.7148783035123532, 'bagging_fraction': 0.898515475419533, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,112] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 119, 'learning_rate': 0.23257093927269487, 'feature_fraction': 0.7852595223298344, 'bagging_fraction': 0.7107777041485843, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,168] Trial 26 finished with value: 0.8111888111888113 and parameters: {'num_leaves': 75, 'learning_rate': 0.1280071709791304, 'feature_fraction': 0.9219571971970543, 'bagging_fraction': 0.7959986604343594, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,181] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 189, 'learning_rate': 0.19622368352780517, 'feature_fraction': 0.8643579989691155, 'bagging_fraction': 0.7050271631943615, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,201] Trial 28 finished with value: 0.6503496503496503 and parameters: {'num_leaves': 96, 'learning_rate': 0.06608296331299482, 'feature_fraction': 0.6728131454642281, 'bagging_fraction': 0.6546407310171115, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,233] Trial 29 finished with value: 0.6853146853146853 and parameters: {'num_leaves': 158, 'learning_rate': 0.11503307074027098, 'feature_fraction': 0.5742992088929152, 'bagging_fraction': 0.5640911628035594, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,346] Trial 30 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 256, 'learning_rate': 0.08908829044869035, 'feature_fraction': 0.7952104292591464, 'bagging_fraction': 0.9091051805743058, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,389] Trial 31 finished with value: 0.8671328671328671 and parameters: {'num_leaves': 155, 'learning_rate': 0.1606204620067259, 'feature_fraction': 0.7225496164372823, 'bagging_fraction': 0.8781037309423805, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,439] Trial 32 finished with value: 0.8496503496503496 and parameters: {'num_leaves': 127, 'learning_rate': 0.161643382422348, 'feature_fraction': 0.7360949255470849, 'bagging_fraction': 0.8672768247990794, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,482] Trial 33 finished with value: 0.881118881118881 and parameters: {'num_leaves': 158, 'learning_rate': 0.14662400377627552, 'feature_fraction': 0.7105758026346133, 'bagging_fraction': 0.954845068022388, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,551] Trial 34 finished with value: 0.8146853146853146 and parameters: {'num_leaves': 55, 'learning_rate': 0.1441970277143567, 'feature_fraction': 0.637376997760195, 'bagging_fraction': 0.9419886746465764, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,609] Trial 35 finished with value: 0.8461538461538461 and parameters: {'num_leaves': 99, 'learning_rate': 0.18396437490338186, 'feature_fraction': 0.7026571764469816, 'bagging_fraction': 0.9861432543742226, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,646] Trial 36 finished with value: 0.8076923076923076 and parameters: {'num_leaves': 197, 'learning_rate': 0.23213934900565777, 'feature_fraction': 0.6045514240381465, 'bagging_fraction': 0.6324962670509777, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,705] Trial 37 finished with value: 0.8496503496503496 and parameters: {'num_leaves': 225, 'learning_rate': 0.11953621083052887, 'feature_fraction': 0.8764092703739439, 'bagging_fraction': 0.8081659739640121, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,750] Trial 38 finished with value: 0.7727272727272727 and parameters: {'num_leaves': 10, 'learning_rate': 0.04383844265635542, 'feature_fraction': 0.786593381081546, 'bagging_fraction': 0.9502437819493776, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,833] Trial 39 finished with value: 0.7062937062937062 and parameters: {'num_leaves': 77, 'learning_rate': 0.09914891533081363, 'feature_fraction': 0.6696781885363959, 'bagging_fraction': 0.9329245101578525, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,846] Trial 40 finished with value: 0.5506993006993007 and parameters: {'num_leaves': 49, 'learning_rate': 0.27847770283029144, 'feature_fraction': 0.9932057111552799, 'bagging_fraction': 0.5714678801740891, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,885] Trial 41 finished with value: 0.8461538461538461 and parameters: {'num_leaves': 161, 'learning_rate': 0.15349494123893, 'feature_fraction': 0.740662538125563, 'bagging_fraction': 0.8524181732790254, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,930] Trial 42 finished with value: 0.8601398601398602 and parameters: {'num_leaves': 129, 'learning_rate': 0.16293413578456994, 'feature_fraction': 0.699861035089511, 'bagging_fraction': 0.7308236873918567, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:50,976] Trial 43 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 176, 'learning_rate': 0.19416312337261196, 'feature_fraction': 0.7257531824597938, 'bagging_fraction': 0.9772769851897192, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,029] Trial 44 finished with value: 0.8426573426573427 and parameters: {'num_leaves': 152, 'learning_rate': 0.1474847975651271, 'feature_fraction': 0.6325140865340526, 'bagging_fraction': 0.7680188206187584, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,057] Trial 45 finished with value: 0.7587412587412588 and parameters: {'num_leaves': 129, 'learning_rate': 0.17693264454223806, 'feature_fraction': 0.7660048024191928, 'bagging_fraction': 0.8176953781742625, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,083] Trial 46 finished with value: 0.8041958041958042 and parameters: {'num_leaves': 109, 'learning_rate': 0.21106701373092543, 'feature_fraction': 0.8056426390673268, 'bagging_fraction': 0.9123737331107447, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,145] Trial 47 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 274, 'learning_rate': 0.13329997252202228, 'feature_fraction': 0.6925156281753335, 'bagging_fraction': 0.8668691593453614, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,171] Trial 48 finished with value: 0.6730769230769231 and parameters: {'num_leaves': 227, 'learning_rate': 0.24435559115259298, 'feature_fraction': 0.6043953301958935, 'bagging_fraction': 0.9652934153027305, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,207] Trial 49 finished with value: 0.8146853146853147 and parameters: {'num_leaves': 214, 'learning_rate': 0.26533005794070563, 'feature_fraction': 0.6496702748049489, 'bagging_fraction': 0.7821993817746327, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 22 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,494] A new study created in memory with name: no-name-76c9c779-ec1d-4091-b0da-ff92516732ff
[I 2025-09-17 13:15:51,515] Trial 0 finished with value: 0.7272727272727273 and parameters: {'num_leaves': 45, 'learning_rate': 0.2626369441821148, 'feature_fraction': 0.5153549029845769, 'bagging_fraction': 0.8094775667153855, 'bagging_freq': 6, 'min_child_samples': 60}. Best is trial 0 with value: 0.7272727272727273.
[I 2025-09-17 13:15:51,525] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 169, 'learning_rate': 0.1585141507157929, 'feature_fraction': 0.6833527996982798, 'bagging_fraction': 0.77881482000265, 'bagging_freq': 6, 'min_child_samples': 90}. Best is trial 0 with value: 0.7272727272727273.
[I 2025-09-17 13:15:51,549] Trial 2 finished with value: 0.8286713286713286 and parameters: {'num_leaves': 119, 'learning_rate': 0.21861306251311136, 'feature_fraction': 0.44398248989568534, 'bagging_fraction': 0.9250205937645211, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 2 with value: 0.8286713286713286.
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.540689
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.400041
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.549696
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.459101
Training model for P050... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.520838
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.489961
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.500806
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.469931
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.573675
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.549825
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.421148
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.570071
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.648968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.47408
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.652463
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.490715
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.601134
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.575396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.500469
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.460115
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.505336
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.471872
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.521889
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.631951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.615974
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.51339
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.433072
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.4945
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.427154
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.510834
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.460208
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.514202
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.488406
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.548452
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.584815
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.65513
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.459061
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.461679
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.490009
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.502119
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.528338
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.533469
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.507737
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.614846
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.490805
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.593111
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.49532
[I 2025-09-17 13:15:51,567] Trial 3 finished with value: 0.7867132867132867 and parameters: {'num_leaves': 143, 'learning_rate': 0.24199611325005427, 'feature_fraction': 0.6147301078308245, 'bagging_fraction': 0.8722978984928752, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 2 with value: 0.8286713286713286.
[I 2025-09-17 13:15:51,648] Trial 4 finished with value: 0.8986013986013985 and parameters: {'num_leaves': 89, 'learning_rate': 0.17080262186136336, 'feature_fraction': 0.5135343688727935, 'bagging_fraction': 0.9105763387468908, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,657] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 53, 'learning_rate': 0.1045198992095192, 'feature_fraction': 0.9722609967199629, 'bagging_fraction': 0.5042196245826566, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,665] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 196, 'learning_rate': 0.04833672784529773, 'feature_fraction': 0.8333979133779198, 'bagging_fraction': 0.7569811284104097, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,673] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 34, 'learning_rate': 0.0110475270910275, 'feature_fraction': 0.7069720875823653, 'bagging_fraction': 0.5305537053441369, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,681] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 153, 'learning_rate': 0.08370329188115923, 'feature_fraction': 0.8644567370762454, 'bagging_fraction': 0.4679815002115898, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,700] Trial 9 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 184, 'learning_rate': 0.18871246262450955, 'feature_fraction': 0.8086278946383447, 'bagging_fraction': 0.8186965647467745, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,773] Trial 10 finished with value: 0.8601398601398601 and parameters: {'num_leaves': 289, 'learning_rate': 0.2962038908290109, 'feature_fraction': 0.4039705388799891, 'bagging_fraction': 0.6243552480140929, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,896] Trial 11 finished with value: 0.8461538461538461 and parameters: {'num_leaves': 290, 'learning_rate': 0.2918845603301728, 'feature_fraction': 0.42067368345110034, 'bagging_fraction': 0.6115304996998678, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:51,990] Trial 12 finished with value: 0.8811188811188811 and parameters: {'num_leaves': 275, 'learning_rate': 0.12094450569511506, 'feature_fraction': 0.5251217110235016, 'bagging_fraction': 0.6500866401375959, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,044] Trial 13 finished with value: 0.8741258741258742 and parameters: {'num_leaves': 231, 'learning_rate': 0.12827890287914537, 'feature_fraction': 0.5358801479111177, 'bagging_fraction': 0.9904415091807838, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,075] Trial 14 finished with value: 0.8111888111888113 and parameters: {'num_leaves': 85, 'learning_rate': 0.16314488185818637, 'feature_fraction': 0.5651799552178731, 'bagging_fraction': 0.6841099434061246, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,111] Trial 15 finished with value: 0.8706293706293706 and parameters: {'num_leaves': 95, 'learning_rate': 0.19816922103329146, 'feature_fraction': 0.6467072820337242, 'bagging_fraction': 0.665983721130531, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,142] Trial 16 finished with value: 0.8041958041958042 and parameters: {'num_leaves': 237, 'learning_rate': 0.12946662300660222, 'feature_fraction': 0.4942645490756723, 'bagging_fraction': 0.5652964642577293, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,155] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 10, 'learning_rate': 0.06522412011733188, 'feature_fraction': 0.5934593688810665, 'bagging_fraction': 0.7257385653711749, 'bagging_freq': 7, 'min_child_samples': 80}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,201] Trial 18 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 246, 'learning_rate': 0.13779386556941986, 'feature_fraction': 0.4835812667281595, 'bagging_fraction': 0.42009246225493435, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,231] Trial 19 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 202, 'learning_rate': 0.18135767322062352, 'feature_fraction': 0.7425027102181246, 'bagging_fraction': 0.9810081687153404, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,271] Trial 20 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 120, 'learning_rate': 0.09779108204809253, 'feature_fraction': 0.5594405726062119, 'bagging_fraction': 0.8712977350699689, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 4 with value: 0.8986013986013985.
[I 2025-09-17 13:15:52,341] Trial 21 finished with value: 0.9055944055944056 and parameters: {'num_leaves': 249, 'learning_rate': 0.11768294423019088, 'feature_fraction': 0.5352461316226135, 'bagging_fraction': 0.9997583663005578, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 21 with value: 0.9055944055944056.
[I 2025-09-17 13:15:52,448] Trial 22 finished with value: 0.9195804195804196 and parameters: {'num_leaves': 263, 'learning_rate': 0.11484867012554667, 'feature_fraction': 0.48925098001794753, 'bagging_fraction': 0.9299982517757288, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,534] Trial 23 finished with value: 0.916083916083916 and parameters: {'num_leaves': 253, 'learning_rate': 0.04598731363332528, 'feature_fraction': 0.46131245484612554, 'bagging_fraction': 0.9443580869663114, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,568] Trial 24 finished with value: 0.8426573426573427 and parameters: {'num_leaves': 263, 'learning_rate': 0.025489911494305656, 'feature_fraction': 0.4609096183023725, 'bagging_fraction': 0.9456913312459356, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,640] Trial 25 finished with value: 0.8881118881118881 and parameters: {'num_leaves': 215, 'learning_rate': 0.061410448921858124, 'feature_fraction': 0.45565824128500965, 'bagging_fraction': 0.8700764678300852, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,697] Trial 26 finished with value: 0.8286713286713286 and parameters: {'num_leaves': 263, 'learning_rate': 0.03928485958012147, 'feature_fraction': 0.6102392420473117, 'bagging_fraction': 0.9553386639124927, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,737] Trial 27 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 300, 'learning_rate': 0.08523189755964859, 'feature_fraction': 0.41427350365986026, 'bagging_fraction': 0.9017544444370226, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,800] Trial 28 finished with value: 0.8846153846153846 and parameters: {'num_leaves': 226, 'learning_rate': 0.10721338664113603, 'feature_fraction': 0.5706323085005116, 'bagging_fraction': 0.996675876499145, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,812] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 252, 'learning_rate': 0.06919600341982307, 'feature_fraction': 0.6419490556423435, 'bagging_fraction': 0.8221359021725179, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,833] Trial 30 finished with value: 0.7412587412587412 and parameters: {'num_leaves': 211, 'learning_rate': 0.1455592151793553, 'feature_fraction': 0.4859512135939336, 'bagging_fraction': 0.8433393691059867, 'bagging_freq': 1, 'min_child_samples': 57}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,904] Trial 31 finished with value: 0.8741258741258742 and parameters: {'num_leaves': 271, 'learning_rate': 0.16209747821186823, 'feature_fraction': 0.522391377956901, 'bagging_fraction': 0.9219246244717826, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:52,962] Trial 32 finished with value: 0.9020979020979021 and parameters: {'num_leaves': 176, 'learning_rate': 0.17237438649869827, 'feature_fraction': 0.5045832678501889, 'bagging_fraction': 0.8928498204010423, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:53,015] Trial 33 finished with value: 0.8356643356643356 and parameters: {'num_leaves': 186, 'learning_rate': 0.19939344616611201, 'feature_fraction': 0.45112687927518835, 'bagging_fraction': 0.769164509329028, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:53,038] Trial 34 finished with value: 0.8251748251748251 and parameters: {'num_leaves': 168, 'learning_rate': 0.22945560318271568, 'feature_fraction': 0.5512150204997379, 'bagging_fraction': 0.9564861265580972, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:53,213] Trial 35 finished with value: 0.8881118881118881 and parameters: {'num_leaves': 250, 'learning_rate': 0.1514119322080698, 'feature_fraction': 0.487986110147852, 'bagging_fraction': 0.8930185029424432, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:53,259] Trial 36 finished with value: 0.8601398601398601 and parameters: {'num_leaves': 220, 'learning_rate': 0.11392797459744193, 'feature_fraction': 0.43906320976368113, 'bagging_fraction': 0.9413100084903886, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 22 with value: 0.9195804195804196.
[I 2025-09-17 13:15:53,314] Trial 37 finished with value: 0.93006993006993 and parameters: {'num_leaves': 130, 'learning_rate': 0.2161176240787008, 'feature_fraction': 0.6461092109950797, 'bagging_fraction': 0.8500905941010869, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 37 with value: 0.93006993006993.
[I 2025-09-17 13:15:53,348] Trial 38 finished with value: 0.8671328671328671 and parameters: {'num_leaves': 138, 'learning_rate': 0.2588546981467392, 'feature_fraction': 0.6520703836008259, 'bagging_fraction': 0.8457120245166748, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 37 with value: 0.93006993006993.
[I 2025-09-17 13:15:53,375] Trial 39 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 102, 'learning_rate': 0.21220606187393037, 'feature_fraction': 0.6999628115415611, 'bagging_fraction': 0.79796269475456, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 37 with value: 0.93006993006993.
[I 2025-09-17 13:15:53,401] Trial 40 finished with value: 0.8006993006993006 and parameters: {'num_leaves': 68, 'learning_rate': 0.2737271089323614, 'feature_fraction': 0.7461011751058996, 'bagging_fraction': 0.7355294343811813, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 37 with value: 0.93006993006993.
[I 2025-09-17 13:15:53,470] Trial 41 finished with value: 0.8671328671328672 and parameters: {'num_leaves': 130, 'learning_rate': 0.17624182605631472, 'feature_fraction': 0.5898804811505085, 'bagging_fraction': 0.9698426078768582, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 37 with value: 0.93006993006993.
[I 2025-09-17 13:15:53,519] Trial 42 finished with value: 0.8881118881118881 and parameters: {'num_leaves': 159, 'learning_rate': 0.24229833785911423, 'feature_fraction': 0.9350414277539748, 'bagging_fraction': 0.9206110964593175, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 37 with value: 0.93006993006993.
[I 2025-09-17 13:15:53,580] Trial 43 finished with value: 0.8671328671328671 and parameters: {'num_leaves': 182, 'learning_rate': 0.08655394764955472, 'feature_fraction': 0.5154591491833506, 'bagging_fraction': 0.891485497036644, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 37 with value: 0.93006993006993.
[I 2025-09-17 13:15:53,678] Trial 44 finished with value: 0.9405594405594405 and parameters: {'num_leaves': 283, 'learning_rate': 0.21320285379982074, 'feature_fraction': 0.47189843297756034, 'bagging_fraction': 0.932543736782998, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 44 with value: 0.9405594405594405.
[I 2025-09-17 13:15:53,785] Trial 45 finished with value: 0.8671328671328671 and parameters: {'num_leaves': 284, 'learning_rate': 0.22166333124677895, 'feature_fraction': 0.4316789030455227, 'bagging_fraction': 0.9999033788689968, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 44 with value: 0.9405594405594405.
[I 2025-09-17 13:15:53,814] Trial 46 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 277, 'learning_rate': 0.24182627795035214, 'feature_fraction': 0.401196393091639, 'bagging_fraction': 0.9328103653728439, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 44 with value: 0.9405594405594405.
[I 2025-09-17 13:15:53,953] Trial 47 finished with value: 0.8881118881118881 and parameters: {'num_leaves': 262, 'learning_rate': 0.20805321041195757, 'feature_fraction': 0.45865412498119845, 'bagging_fraction': 0.8509544713390323, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 44 with value: 0.9405594405594405.
[I 2025-09-17 13:15:53,997] Trial 48 finished with value: 0.8426573426573427 and parameters: {'num_leaves': 299, 'learning_rate': 0.017753391621757583, 'feature_fraction': 0.6678073729532775, 'bagging_fraction': 0.9703382085658288, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 44 with value: 0.9405594405594405.
[I 2025-09-17 13:15:54,099] Trial 49 finished with value: 0.9055944055944055 and parameters: {'num_leaves': 234, 'learning_rate': 0.040229422485187086, 'feature_fraction': 0.6255541541286145, 'bagging_fraction': 0.9237081102228374, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 44 with value: 0.9405594405594405.
[I 2025-09-17 13:15:54,506] A new study created in memory with name: no-name-b0757f1e-b0d3-4d61-8e3d-8f478a29bc69
[I 2025-09-17 13:15:54,526] Trial 0 finished with value: 0.7604895104895105 and parameters: {'num_leaves': 120, 'learning_rate': 0.2373007713106915, 'feature_fraction': 0.8772422007951486, 'bagging_fraction': 0.9811016042008092, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 0 with value: 0.7604895104895105.
[I 2025-09-17 13:15:54,554] Trial 1 finished with value: 0.7272727272727273 and parameters: {'num_leaves': 67, 'learning_rate': 0.18293035672438915, 'feature_fraction': 0.6103762621655409, 'bagging_fraction': 0.6325776641549048, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 0 with value: 0.7604895104895105.
[I 2025-09-17 13:15:54,583] Trial 2 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 256, 'learning_rate': 0.2628860383627621, 'feature_fraction': 0.5035246053474327, 'bagging_fraction': 0.7447963609571937, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,623] Trial 3 finished with value: 0.6223776223776224 and parameters: {'num_leaves': 237, 'learning_rate': 0.20505323568253672, 'feature_fraction': 0.7380556346204541, 'bagging_fraction': 0.4590917712197129, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,631] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 77, 'learning_rate': 0.24568749967343728, 'feature_fraction': 0.7319474658083989, 'bagging_fraction': 0.8617716034174776, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,648] Trial 5 finished with value: 0.7097902097902098 and parameters: {'num_leaves': 217, 'learning_rate': 0.06962190595048279, 'feature_fraction': 0.7834416442817222, 'bagging_fraction': 0.5802924448232113, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,657] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 35, 'learning_rate': 0.016336115148999318, 'feature_fraction': 0.6601948426701334, 'bagging_fraction': 0.8809687092580542, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,676] Trial 7 finished with value: 0.4930069930069931 and parameters: {'num_leaves': 288, 'learning_rate': 0.11347020803081238, 'feature_fraction': 0.9753932114080173, 'bagging_fraction': 0.40649367852118445, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,686] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 260, 'learning_rate': 0.26950454856245937, 'feature_fraction': 0.8028346889111865, 'bagging_fraction': 0.4320733862059585, 'bagging_freq': 1, 'min_child_samples': 57}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,695] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.1994551236600904, 'feature_fraction': 0.5941805854851392, 'bagging_fraction': 0.7501837598891377, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,750] Trial 10 finished with value: 0.8146853146853147 and parameters: {'num_leaves': 171, 'learning_rate': 0.28845114350661955, 'feature_fraction': 0.4388562285543728, 'bagging_fraction': 0.7530588822695742, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,806] Trial 11 finished with value: 0.7622377622377623 and parameters: {'num_leaves': 161, 'learning_rate': 0.29941235315697856, 'feature_fraction': 0.4055256421561952, 'bagging_fraction': 0.7389452792649435, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 2 with value: 0.8216783216783217.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.521202
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.412672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.476869
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.461764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.523438
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.421034
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.428524
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.505185
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.45595
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.524707
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.530723
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.519792
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.478227
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.408037
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.355065
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.382904
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.510845
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.412655
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.482278
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.46884
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.413601
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.565655
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.433558
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.405952
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.473358
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.482918
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.431173
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.458932
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.367481
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.444637
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.528749
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.492858
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.423835
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.425501
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.44204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.333767
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.444382
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.504242
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.435471
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.518671
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.398878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.521018
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.562783
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.500063
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.64565
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.599413
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.654976
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.512185
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.576784
[I 2025-09-17 13:15:54,839] Trial 12 finished with value: 0.6730769230769231 and parameters: {'num_leaves': 168, 'learning_rate': 0.2896281134764608, 'feature_fraction': 0.43010299203786645, 'bagging_fraction': 0.8195016322119235, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,877] Trial 13 finished with value: 0.7342657342657343 and parameters: {'num_leaves': 294, 'learning_rate': 0.15213801207311406, 'feature_fraction': 0.5086394821524558, 'bagging_fraction': 0.6499607104644166, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,907] Trial 14 finished with value: 0.7867132867132867 and parameters: {'num_leaves': 190, 'learning_rate': 0.24491809562456437, 'feature_fraction': 0.5138038452176318, 'bagging_fraction': 0.548909465275037, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:54,944] Trial 15 finished with value: 0.7762237762237763 and parameters: {'num_leaves': 115, 'learning_rate': 0.14595409169194168, 'feature_fraction': 0.50184973482311, 'bagging_fraction': 0.7900776125346436, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 2 with value: 0.8216783216783217.
[I 2025-09-17 13:15:55,047] Trial 16 finished with value: 0.8566433566433567 and parameters: {'num_leaves': 254, 'learning_rate': 0.2655100099613093, 'feature_fraction': 0.5626355959516904, 'bagging_fraction': 0.6879868286591974, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,123] Trial 17 finished with value: 0.8409090909090909 and parameters: {'num_leaves': 263, 'learning_rate': 0.2239300134585582, 'feature_fraction': 0.5858648165773985, 'bagging_fraction': 0.6764930071860484, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,208] Trial 18 finished with value: 0.8356643356643357 and parameters: {'num_leaves': 261, 'learning_rate': 0.21632132047227523, 'feature_fraction': 0.594209508097667, 'bagging_fraction': 0.6651998016426166, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,220] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 233, 'learning_rate': 0.16708535440237318, 'feature_fraction': 0.6592619402123623, 'bagging_fraction': 0.5257429424209276, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,265] Trial 20 finished with value: 0.7237762237762237 and parameters: {'num_leaves': 297, 'learning_rate': 0.1158428024578623, 'feature_fraction': 0.5801815667659601, 'bagging_fraction': 0.5876053639965635, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,354] Trial 21 finished with value: 0.805944055944056 and parameters: {'num_leaves': 267, 'learning_rate': 0.21296545419558482, 'feature_fraction': 0.5775329393340599, 'bagging_fraction': 0.6603660155513473, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,393] Trial 22 finished with value: 0.7552447552447553 and parameters: {'num_leaves': 238, 'learning_rate': 0.22304135738629036, 'feature_fraction': 0.6474511345115547, 'bagging_fraction': 0.6935581218812116, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,499] Trial 23 finished with value: 0.7622377622377623 and parameters: {'num_leaves': 272, 'learning_rate': 0.26590472635430645, 'feature_fraction': 0.5539553426162465, 'bagging_fraction': 0.6845011506125683, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,529] Trial 24 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 221, 'learning_rate': 0.1923587372988592, 'feature_fraction': 0.6966166768529644, 'bagging_fraction': 0.4955875304553524, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,571] Trial 25 finished with value: 0.8146853146853147 and parameters: {'num_leaves': 197, 'learning_rate': 0.22949704355773054, 'feature_fraction': 0.5435523344951492, 'bagging_fraction': 0.6082168313785, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,598] Trial 26 finished with value: 0.7167832167832168 and parameters: {'num_leaves': 247, 'learning_rate': 0.25476658051186496, 'feature_fraction': 0.4601398679390982, 'bagging_fraction': 0.7140276121994062, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,635] Trial 27 finished with value: 0.7937062937062938 and parameters: {'num_leaves': 133, 'learning_rate': 0.17639424094775016, 'feature_fraction': 0.6260612928785102, 'bagging_fraction': 0.7970614188688213, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,655] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 275, 'learning_rate': 0.22207355525420752, 'feature_fraction': 0.5474246943763625, 'bagging_fraction': 0.6300274083096904, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,714] Trial 29 finished with value: 0.7657342657342657 and parameters: {'num_leaves': 126, 'learning_rate': 0.133383009728869, 'feature_fraction': 0.9032976626932376, 'bagging_fraction': 0.9584833562814605, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,738] Trial 30 finished with value: 0.8461538461538461 and parameters: {'num_leaves': 188, 'learning_rate': 0.2766578400303583, 'feature_fraction': 0.7005842628498821, 'bagging_fraction': 0.5530686429157783, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,766] Trial 31 finished with value: 0.7447552447552448 and parameters: {'num_leaves': 182, 'learning_rate': 0.2767504081192615, 'feature_fraction': 0.7125356008673772, 'bagging_fraction': 0.5294770444247289, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,870] Trial 32 finished with value: 0.8409090909090908 and parameters: {'num_leaves': 212, 'learning_rate': 0.23856282729685843, 'feature_fraction': 0.6855507508723898, 'bagging_fraction': 0.6742486432736935, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,898] Trial 33 finished with value: 0.8356643356643356 and parameters: {'num_leaves': 211, 'learning_rate': 0.23715375509311204, 'feature_fraction': 0.7823957068692657, 'bagging_fraction': 0.5698409869992009, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,940] Trial 34 finished with value: 0.7395104895104895 and parameters: {'num_leaves': 147, 'learning_rate': 0.2571789130851804, 'feature_fraction': 0.688173188843199, 'bagging_fraction': 0.6188338242229853, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,968] Trial 35 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 235, 'learning_rate': 0.2792592397052434, 'feature_fraction': 0.8426221399651472, 'bagging_fraction': 0.4767389825038241, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:55,994] Trial 36 finished with value: 0.7587412587412588 and parameters: {'num_leaves': 216, 'learning_rate': 0.24177223529005681, 'feature_fraction': 0.7542717392559946, 'bagging_fraction': 0.6837190388479534, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:15:56,042] Trial 37 finished with value: 0.8811188811188811 and parameters: {'num_leaves': 91, 'learning_rate': 0.25625049966305286, 'feature_fraction': 0.6783849740720516, 'bagging_fraction': 0.723169989220075, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,068] Trial 38 finished with value: 0.7447552447552448 and parameters: {'num_leaves': 72, 'learning_rate': 0.2560644757235537, 'feature_fraction': 0.6286226656112383, 'bagging_fraction': 0.719581679953522, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,081] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 13, 'learning_rate': 0.29422256822258896, 'feature_fraction': 0.7541277149600253, 'bagging_fraction': 0.8533246946816079, 'bagging_freq': 4, 'min_child_samples': 97}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,180] Trial 40 finished with value: 0.7482517482517482 and parameters: {'num_leaves': 91, 'learning_rate': 0.013891672304914587, 'feature_fraction': 0.6283582486486663, 'bagging_fraction': 0.9299719932502775, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,246] Trial 41 finished with value: 0.8356643356643356 and parameters: {'num_leaves': 250, 'learning_rate': 0.2735969623191462, 'feature_fraction': 0.666904357332366, 'bagging_fraction': 0.7791816725708144, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,357] Trial 42 finished with value: 0.8041958041958042 and parameters: {'num_leaves': 102, 'learning_rate': 0.2345471187776328, 'feature_fraction': 0.7162783609308833, 'bagging_fraction': 0.7234273925692095, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,400] Trial 43 finished with value: 0.7097902097902098 and parameters: {'num_leaves': 49, 'learning_rate': 0.046433621167334196, 'feature_fraction': 0.6747300684673364, 'bagging_fraction': 0.6024764419615145, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,427] Trial 44 finished with value: 0.8426573426573426 and parameters: {'num_leaves': 146, 'learning_rate': 0.20488848819499483, 'feature_fraction': 0.7326644346322284, 'bagging_fraction': 0.6482317890688489, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,450] Trial 45 finished with value: 0.8321678321678322 and parameters: {'num_leaves': 146, 'learning_rate': 0.20189950880001206, 'feature_fraction': 0.8213092557154866, 'bagging_fraction': 0.7517010172368679, 'bagging_freq': 7, 'min_child_samples': 34}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,470] Trial 46 finished with value: 0.6503496503496503 and parameters: {'num_leaves': 96, 'learning_rate': 0.18945505219553932, 'feature_fraction': 0.7422533866278335, 'bagging_fraction': 0.644698522541134, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,505] Trial 47 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 55, 'learning_rate': 0.28429607820559544, 'feature_fraction': 0.4867222117633216, 'bagging_fraction': 0.5562718273439874, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,529] Trial 48 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 180, 'learning_rate': 0.20974673978118635, 'feature_fraction': 0.6165674491973071, 'bagging_fraction': 0.8264396825264981, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,557] Trial 49 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 285, 'learning_rate': 0.2494598918914493, 'feature_fraction': 0.7790131617146249, 'bagging_fraction': 0.769136653242849, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 37 with value: 0.8811188811188811.
[I 2025-09-17 13:15:56,786] A new study created in memory with name: no-name-18ef7d8a-85ec-4fe4-b3ce-e3fb142f7540
[I 2025-09-17 13:15:56,803] Trial 0 finished with value: 0.5384615384615384 and parameters: {'num_leaves': 140, 'learning_rate': 0.043287563252941585, 'feature_fraction': 0.4095301236935407, 'bagging_fraction': 0.6472975499908739, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 0 with value: 0.5384615384615384.
[I 2025-09-17 13:15:56,844] Trial 1 finished with value: 0.8321678321678322 and parameters: {'num_leaves': 230, 'learning_rate': 0.09629433437845944, 'feature_fraction': 0.9461806672546722, 'bagging_fraction': 0.9388749654270617, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 1 with value: 0.8321678321678322.
[I 2025-09-17 13:15:56,854] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 261, 'learning_rate': 0.136586108100407, 'feature_fraction': 0.5262223444431304, 'bagging_fraction': 0.6525834576764584, 'bagging_freq': 3, 'min_child_samples': 80}. Best is trial 1 with value: 0.8321678321678322.
[I 2025-09-17 13:15:56,963] Trial 3 finished with value: 0.8461538461538461 and parameters: {'num_leaves': 99, 'learning_rate': 0.15100710792469121, 'feature_fraction': 0.9236918685158082, 'bagging_fraction': 0.6541992232301983, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:56,970] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 276, 'learning_rate': 0.15705081165992624, 'feature_fraction': 0.5054358490954268, 'bagging_fraction': 0.941361192258501, 'bagging_freq': 1, 'min_child_samples': 71}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:56,979] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 103, 'learning_rate': 0.24229965636871467, 'feature_fraction': 0.7738157444872685, 'bagging_fraction': 0.7416653258181023, 'bagging_freq': 2, 'min_child_samples': 65}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,011] Trial 6 finished with value: 0.8146853146853147 and parameters: {'num_leaves': 295, 'learning_rate': 0.09336781730528636, 'feature_fraction': 0.5763405464185781, 'bagging_fraction': 0.9508996739042456, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,061] Trial 7 finished with value: 0.7937062937062938 and parameters: {'num_leaves': 13, 'learning_rate': 0.1459642935566143, 'feature_fraction': 0.798297357457027, 'bagging_fraction': 0.5358471523553888, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,071] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 34, 'learning_rate': 0.020293820831481256, 'feature_fraction': 0.5595884979649677, 'bagging_fraction': 0.4515675333513159, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,113] Trial 9 finished with value: 0.7342657342657342 and parameters: {'num_leaves': 173, 'learning_rate': 0.011114153667955004, 'feature_fraction': 0.5952907368885866, 'bagging_fraction': 0.7209626119113619, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,221] Trial 10 finished with value: 0.8391608391608392 and parameters: {'num_leaves': 70, 'learning_rate': 0.25141949295811883, 'feature_fraction': 0.9950547128463552, 'bagging_fraction': 0.8225288129125972, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,326] Trial 11 finished with value: 0.8216783216783218 and parameters: {'num_leaves': 71, 'learning_rate': 0.2846725067407232, 'feature_fraction': 0.9680823890760809, 'bagging_fraction': 0.8174384280947272, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,358] Trial 12 finished with value: 0.7482517482517482 and parameters: {'num_leaves': 90, 'learning_rate': 0.2065684915841098, 'feature_fraction': 0.8817308857188023, 'bagging_fraction': 0.8424961405940964, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,377] Trial 13 finished with value: 0.6206293706293707 and parameters: {'num_leaves': 148, 'learning_rate': 0.20463007049239418, 'feature_fraction': 0.9959974753811088, 'bagging_fraction': 0.569721975170307, 'bagging_freq': 6, 'min_child_samples': 42}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,482] Trial 14 finished with value: 0.8041958041958042 and parameters: {'num_leaves': 59, 'learning_rate': 0.2621013791676724, 'feature_fraction': 0.8938028611446945, 'bagging_fraction': 0.819201277638611, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,509] Trial 15 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 112, 'learning_rate': 0.1907665612949021, 'feature_fraction': 0.7306605793595708, 'bagging_fraction': 0.5787432673389049, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,522] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.229772229917773, 'feature_fraction': 0.8509789287874537, 'bagging_fraction': 0.4108599410851453, 'bagging_freq': 3, 'min_child_samples': 52}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,577] Trial 17 finished with value: 0.7762237762237763 and parameters: {'num_leaves': 48, 'learning_rate': 0.10358675959712393, 'feature_fraction': 0.688673263489564, 'bagging_fraction': 0.7850732379175287, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,595] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 123, 'learning_rate': 0.17408965903656098, 'feature_fraction': 0.9248091470050751, 'bagging_fraction': 0.8966658800523742, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,620] Trial 19 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 79, 'learning_rate': 0.291966740255954, 'feature_fraction': 0.8344164803643468, 'bagging_fraction': 0.6724610816689597, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,676] Trial 20 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 174, 'learning_rate': 0.06847636921746804, 'feature_fraction': 0.6657843126155194, 'bagging_fraction': 0.7587740446362078, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 3 with value: 0.8461538461538461.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.612693
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.577235
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.516997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.527941
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.492819
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.481394
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.486233
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.579838
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.526584
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.558126
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.555616
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.511357
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.501886
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.575876
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.520028
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.555112
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.464982
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.570231
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.495904
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.479775
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.613841
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.48918
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.555727
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.473231
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.534412
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.546657
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.484217
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.523737
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.60929
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.451441
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.486566
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.629355
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.503435
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.50894
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.493445
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.656114
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.487688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.441752
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.492937
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.519158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.596764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.50368
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.518054
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.557964
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.626257
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.503296
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.487249
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.535917
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.520294
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.492336
[I 2025-09-17 13:15:57,715] Trial 21 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 230, 'learning_rate': 0.10625157265363765, 'feature_fraction': 0.9380961397353335, 'bagging_fraction': 0.9938230907849297, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 3 with value: 0.8461538461538461.
[I 2025-09-17 13:15:57,769] Trial 22 finished with value: 0.8566433566433568 and parameters: {'num_leaves': 228, 'learning_rate': 0.12401091806164775, 'feature_fraction': 0.998472857006699, 'bagging_fraction': 0.8851542516082268, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 22 with value: 0.8566433566433568.
[I 2025-09-17 13:15:57,880] Trial 23 finished with value: 0.8006993006993007 and parameters: {'num_leaves': 214, 'learning_rate': 0.12212796518349059, 'feature_fraction': 0.9976261944835865, 'bagging_fraction': 0.86199337177968, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 22 with value: 0.8566433566433568.
[I 2025-09-17 13:15:57,923] Trial 24 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 173, 'learning_rate': 0.16295174870638104, 'feature_fraction': 0.898161760942596, 'bagging_fraction': 0.888611424674044, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 24 with value: 0.8636363636363636.
[I 2025-09-17 13:15:57,969] Trial 25 finished with value: 0.8636363636363635 and parameters: {'num_leaves': 182, 'learning_rate': 0.1700253870075725, 'feature_fraction': 0.8930128527275453, 'bagging_fraction': 0.8927829335774509, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 24 with value: 0.8636363636363636.
[I 2025-09-17 13:15:57,996] Trial 26 finished with value: 0.8006993006993006 and parameters: {'num_leaves': 177, 'learning_rate': 0.1868697250490095, 'feature_fraction': 0.8238869780015992, 'bagging_fraction': 0.8993594459649138, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 24 with value: 0.8636363636363636.
[I 2025-09-17 13:15:58,035] Trial 27 finished with value: 0.9020979020979022 and parameters: {'num_leaves': 199, 'learning_rate': 0.17061111451720679, 'feature_fraction': 0.8830307374355955, 'bagging_fraction': 0.9983307404119482, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,062] Trial 28 finished with value: 0.8321678321678322 and parameters: {'num_leaves': 195, 'learning_rate': 0.17547115958459136, 'feature_fraction': 0.7486206838093576, 'bagging_fraction': 0.999255631051864, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,099] Trial 29 finished with value: 0.8356643356643356 and parameters: {'num_leaves': 134, 'learning_rate': 0.22728132271190624, 'feature_fraction': 0.8738964086493182, 'bagging_fraction': 0.9652464222996087, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,127] Trial 30 finished with value: 0.7797202797202797 and parameters: {'num_leaves': 158, 'learning_rate': 0.06622749455709567, 'feature_fraction': 0.7971409310677483, 'bagging_fraction': 0.9167639562206727, 'bagging_freq': 1, 'min_child_samples': 59}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,179] Trial 31 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 245, 'learning_rate': 0.12109530500683365, 'feature_fraction': 0.8944522631859964, 'bagging_fraction': 0.8709838004285604, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,221] Trial 32 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 249, 'learning_rate': 0.15576595678676491, 'feature_fraction': 0.8928778015685688, 'bagging_fraction': 0.8664457034119198, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,256] Trial 33 finished with value: 0.8041958041958043 and parameters: {'num_leaves': 199, 'learning_rate': 0.16749809435775734, 'feature_fraction': 0.4391997766665226, 'bagging_fraction': 0.9243177765545418, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,284] Trial 34 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 253, 'learning_rate': 0.12998987034211124, 'feature_fraction': 0.8535524130586896, 'bagging_fraction': 0.9514050407506609, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,322] Trial 35 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 216, 'learning_rate': 0.20560955941864603, 'feature_fraction': 0.9054253828882086, 'bagging_fraction': 0.9905595509557386, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,374] Trial 36 finished with value: 0.8286713286713286 and parameters: {'num_leaves': 268, 'learning_rate': 0.08301659383061191, 'feature_fraction': 0.9527490134549326, 'bagging_fraction': 0.796281351868292, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,436] Trial 37 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 243, 'learning_rate': 0.13727209542040916, 'feature_fraction': 0.8003330687225721, 'bagging_fraction': 0.8694754296548364, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,474] Trial 38 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 288, 'learning_rate': 0.16163619734321102, 'feature_fraction': 0.9218590011072548, 'bagging_fraction': 0.9613919973706628, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,521] Trial 39 finished with value: 0.8496503496503497 and parameters: {'num_leaves': 158, 'learning_rate': 0.14328132700025373, 'feature_fraction': 0.7521159574689361, 'bagging_fraction': 0.9156289107744979, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,550] Trial 40 finished with value: 0.7272727272727273 and parameters: {'num_leaves': 181, 'learning_rate': 0.11268805328303394, 'feature_fraction': 0.6553778545658113, 'bagging_fraction': 0.6972624626057176, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,597] Trial 41 finished with value: 0.8916083916083917 and parameters: {'num_leaves': 217, 'learning_rate': 0.12295688806789432, 'feature_fraction': 0.9615245565988315, 'bagging_fraction': 0.8829890145013954, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,676] Trial 42 finished with value: 0.8741258741258742 and parameters: {'num_leaves': 192, 'learning_rate': 0.1497447907497111, 'feature_fraction': 0.9578157080961212, 'bagging_fraction': 0.8556123401396023, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,749] Trial 43 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 214, 'learning_rate': 0.1478927398996696, 'feature_fraction': 0.9584467636559214, 'bagging_fraction': 0.765598597805972, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,800] Trial 44 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 235, 'learning_rate': 0.08407782763793867, 'feature_fraction': 0.962072681356305, 'bagging_fraction': 0.840469988642471, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,879] Trial 45 finished with value: 0.8496503496503496 and parameters: {'num_leaves': 278, 'learning_rate': 0.1863049460021817, 'feature_fraction': 0.8572023678613027, 'bagging_fraction': 0.9365271000452132, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,930] Trial 46 finished with value: 0.8041958041958042 and parameters: {'num_leaves': 190, 'learning_rate': 0.12130208382083627, 'feature_fraction': 0.9231851836892329, 'bagging_fraction': 0.7933401268429207, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:58,943] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 211, 'learning_rate': 0.13794935120788793, 'feature_fraction': 0.9755345290694188, 'bagging_fraction': 0.8324403613619878, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:59,036] Trial 48 finished with value: 0.8111888111888111 and parameters: {'num_leaves': 160, 'learning_rate': 0.04841975236956496, 'feature_fraction': 0.8194968874253385, 'bagging_fraction': 0.8508413720967223, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:59,077] Trial 49 finished with value: 0.8041958041958042 and parameters: {'num_leaves': 141, 'learning_rate': 0.09327331831141833, 'feature_fraction': 0.9382185100818184, 'bagging_fraction': 0.732237282903277, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 27 with value: 0.9020979020979022.
[I 2025-09-17 13:15:59,382] A new study created in memory with name: no-name-95abe344-d2da-428d-9de4-d38314847ea3
[I 2025-09-17 13:15:59,400] Trial 0 finished with value: 0.7797202797202798 and parameters: {'num_leaves': 220, 'learning_rate': 0.1521058819932154, 'feature_fraction': 0.5607564211028528, 'bagging_fraction': 0.5844572666792223, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 0 with value: 0.7797202797202798.
[I 2025-09-17 13:15:59,408] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 91, 'learning_rate': 0.23357637155564956, 'feature_fraction': 0.6266957373626463, 'bagging_fraction': 0.737075140756213, 'bagging_freq': 7, 'min_child_samples': 61}. Best is trial 0 with value: 0.7797202797202798.
[I 2025-09-17 13:15:59,435] Trial 2 finished with value: 0.8391608391608393 and parameters: {'num_leaves': 270, 'learning_rate': 0.24403745295888793, 'feature_fraction': 0.694088789365772, 'bagging_fraction': 0.9653970061218144, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 2 with value: 0.8391608391608393.
[I 2025-09-17 13:15:59,453] Trial 3 finished with value: 0.8321678321678322 and parameters: {'num_leaves': 288, 'learning_rate': 0.2688092729114615, 'feature_fraction': 0.7614015490126071, 'bagging_fraction': 0.652163919781512, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 2 with value: 0.8391608391608393.
[I 2025-09-17 13:15:59,463] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 295, 'learning_rate': 0.10942800715341265, 'feature_fraction': 0.8651163669777109, 'bagging_fraction': 0.46617480757292856, 'bagging_freq': 6, 'min_child_samples': 65}. Best is trial 2 with value: 0.8391608391608393.
[I 2025-09-17 13:15:59,481] Trial 5 finished with value: 0.7762237762237763 and parameters: {'num_leaves': 38, 'learning_rate': 0.03989228650909814, 'feature_fraction': 0.7953260392806725, 'bagging_fraction': 0.5719626833030087, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 2 with value: 0.8391608391608393.
[I 2025-09-17 13:15:59,503] Trial 6 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 33, 'learning_rate': 0.19350991729449069, 'feature_fraction': 0.4738978259414457, 'bagging_fraction': 0.6449424382409192, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 2 with value: 0.8391608391608393.
[I 2025-09-17 13:15:59,515] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.15994053089603685, 'feature_fraction': 0.6981755636252012, 'bagging_fraction': 0.4563025367947774, 'bagging_freq': 5, 'min_child_samples': 69}. Best is trial 2 with value: 0.8391608391608393.
[I 2025-09-17 13:15:59,524] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 98, 'learning_rate': 0.26016817730509495, 'feature_fraction': 0.8982305271000429, 'bagging_fraction': 0.5720216390719, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 2 with value: 0.8391608391608393.
[I 2025-09-17 13:15:59,537] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.2507215314070388, 'feature_fraction': 0.9148469679859066, 'bagging_fraction': 0.8247146703345138, 'bagging_freq': 7, 'min_child_samples': 98}. Best is trial 2 with value: 0.8391608391608393.
[I 2025-09-17 13:15:59,647] Trial 10 finished with value: 0.8426573426573427 and parameters: {'num_leaves': 192, 'learning_rate': 0.07963518044220229, 'feature_fraction': 0.4250604615827909, 'bagging_fraction': 0.996814365590251, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 10 with value: 0.8426573426573427.
[I 2025-09-17 13:15:59,773] Trial 11 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 178, 'learning_rate': 0.0450249063692587, 'feature_fraction': 0.4883804024013938, 'bagging_fraction': 0.996736644329792, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 10 with value: 0.8426573426573427.
[I 2025-09-17 13:15:59,842] Trial 12 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 221, 'learning_rate': 0.09602262982939594, 'feature_fraction': 0.41656794714931683, 'bagging_fraction': 0.9968415312765678, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 10 with value: 0.8426573426573427.
[I 2025-09-17 13:15:59,878] Trial 13 finished with value: 0.7902097902097901 and parameters: {'num_leaves': 230, 'learning_rate': 0.08790309236402805, 'feature_fraction': 0.9798952927358475, 'bagging_fraction': 0.892333916748778, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 10 with value: 0.8426573426573427.
[I 2025-09-17 13:15:59,911] Trial 14 finished with value: 0.791958041958042 and parameters: {'num_leaves': 159, 'learning_rate': 0.19997526545074654, 'feature_fraction': 0.6018775139011169, 'bagging_fraction': 0.8873304251737063, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 10 with value: 0.8426573426573427.
[I 2025-09-17 13:15:59,923] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 248, 'learning_rate': 0.13018891419621148, 'feature_fraction': 0.6785119917680114, 'bagging_fraction': 0.8989428495577575, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 10 with value: 0.8426573426573427.
[I 2025-09-17 13:15:59,971] Trial 16 finished with value: 0.8181818181818182 and parameters: {'num_leaves': 187, 'learning_rate': 0.010923268054388924, 'feature_fraction': 0.5220643609541441, 'bagging_fraction': 0.7772785815719327, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 10 with value: 0.8426573426573427.
[I 2025-09-17 13:16:00,094] Trial 17 finished with value: 0.8951048951048951 and parameters: {'num_leaves': 118, 'learning_rate': 0.28866072771058854, 'feature_fraction': 0.40878674624390854, 'bagging_fraction': 0.9414614770808281, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,211] Trial 18 finished with value: 0.7097902097902098 and parameters: {'num_leaves': 118, 'learning_rate': 0.29785608949131964, 'feature_fraction': 0.40896391069504817, 'bagging_fraction': 0.8244969044170354, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,272] Trial 19 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 127, 'learning_rate': 0.06322964578648804, 'feature_fraction': 0.43827900912118567, 'bagging_fraction': 0.927398361246632, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,311] Trial 20 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 68, 'learning_rate': 0.19512418960448638, 'feature_fraction': 0.5133205132958607, 'bagging_fraction': 0.8051816144838909, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,343] Trial 21 finished with value: 0.8164335664335663 and parameters: {'num_leaves': 66, 'learning_rate': 0.20749614518515197, 'feature_fraction': 0.5312094626354275, 'bagging_fraction': 0.8260669897594003, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,398] Trial 22 finished with value: 0.7937062937062938 and parameters: {'num_leaves': 142, 'learning_rate': 0.1661730898923983, 'feature_fraction': 0.4627960179828086, 'bagging_fraction': 0.9399288970074952, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,433] Trial 23 finished with value: 0.7972027972027972 and parameters: {'num_leaves': 75, 'learning_rate': 0.2882759630195574, 'feature_fraction': 0.4012449889448787, 'bagging_fraction': 0.8581663200306249, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,453] Trial 24 finished with value: 0.784965034965035 and parameters: {'num_leaves': 55, 'learning_rate': 0.22002222339067962, 'feature_fraction': 0.5771209531033308, 'bagging_fraction': 0.7846153409072435, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,574] Trial 25 finished with value: 0.7797202797202798 and parameters: {'num_leaves': 18, 'learning_rate': 0.1264120804613172, 'feature_fraction': 0.5106231190924561, 'bagging_fraction': 0.9467438921994246, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,614] Trial 26 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 192, 'learning_rate': 0.17392984484418061, 'feature_fraction': 0.643784579186198, 'bagging_fraction': 0.7365485747134267, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,644] Trial 27 finished with value: 0.8286713286713288 and parameters: {'num_leaves': 98, 'learning_rate': 0.17867316833388774, 'feature_fraction': 0.646373096434202, 'bagging_fraction': 0.7183145959040099, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,669] Trial 28 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 157, 'learning_rate': 0.2773018761194385, 'feature_fraction': 0.757168508836191, 'bagging_fraction': 0.6717876352453408, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,692] Trial 29 finished with value: 0.7832167832167831 and parameters: {'num_leaves': 131, 'learning_rate': 0.18235029009297443, 'feature_fraction': 0.5455164535839176, 'bagging_fraction': 0.7729472551338255, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 17 with value: 0.8951048951048951.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.513683
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.464158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.520204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.44821
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.45516
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.537334
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.517839
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.502769
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.486634
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.574869
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.454932
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.447722
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.494425
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.557207
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.474516
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.498739
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.511892
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.53375
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.466373
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.591628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.46209
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.433302
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.505678
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.50346
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.470627
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.503631
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.508465
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.518887
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.554044
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.527838
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.494379
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.585989
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.508322
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.511622
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.529039
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.535058
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.552953
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.544455
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.571976
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.432023
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.58191
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.521365
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.488582
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.506854
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.5281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.547212
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.555361
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.533662
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.506563
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.52759
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.512569
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.543831
[I 2025-09-17 13:16:00,733] Trial 30 finished with value: 0.8496503496503496 and parameters: {'num_leaves': 202, 'learning_rate': 0.14787826835891177, 'feature_fraction': 0.5688245266385656, 'bagging_fraction': 0.6083482869495799, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,774] Trial 31 finished with value: 0.7972027972027972 and parameters: {'num_leaves': 203, 'learning_rate': 0.13691700147373714, 'feature_fraction': 0.5821228221552288, 'bagging_fraction': 0.5396745679929336, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,807] Trial 32 finished with value: 0.846153846153846 and parameters: {'num_leaves': 247, 'learning_rate': 0.15003326248761353, 'feature_fraction': 0.6260316961871691, 'bagging_fraction': 0.6857257611628276, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,834] Trial 33 finished with value: 0.7937062937062938 and parameters: {'num_leaves': 169, 'learning_rate': 0.22043124236076447, 'feature_fraction': 0.6465256217424045, 'bagging_fraction': 0.6196634141787927, 'bagging_freq': 1, 'min_child_samples': 36}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,882] Trial 34 finished with value: 0.798951048951049 and parameters: {'num_leaves': 109, 'learning_rate': 0.22408913047370066, 'feature_fraction': 0.561211512881444, 'bagging_fraction': 0.7368579532311151, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,898] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.11133439190239608, 'feature_fraction': 0.49664886301416455, 'bagging_fraction': 0.5354397251085429, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,924] Trial 36 finished with value: 0.7762237762237761 and parameters: {'num_leaves': 77, 'learning_rate': 0.14812312147679263, 'feature_fraction': 0.7375333935852495, 'bagging_fraction': 0.6112082084123545, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,953] Trial 37 finished with value: 0.8321678321678321 and parameters: {'num_leaves': 145, 'learning_rate': 0.17600035807829773, 'feature_fraction': 0.45384898414327945, 'bagging_fraction': 0.49052956264975656, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:00,981] Trial 38 finished with value: 0.8041958041958043 and parameters: {'num_leaves': 210, 'learning_rate': 0.11826619796314683, 'feature_fraction': 0.6008091681797844, 'bagging_fraction': 0.697664373826496, 'bagging_freq': 1, 'min_child_samples': 36}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,022] Trial 39 finished with value: 0.7377622377622377 and parameters: {'num_leaves': 49, 'learning_rate': 0.2410591949521218, 'feature_fraction': 0.6780210188575114, 'bagging_fraction': 0.7517457379473655, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,046] Trial 40 finished with value: 0.7517482517482517 and parameters: {'num_leaves': 243, 'learning_rate': 0.19810788925949377, 'feature_fraction': 0.8351816829914123, 'bagging_fraction': 0.6371505439583193, 'bagging_freq': 2, 'min_child_samples': 44}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,082] Trial 41 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 263, 'learning_rate': 0.1469381622968853, 'feature_fraction': 0.6250042766262909, 'bagging_fraction': 0.7036771396284659, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,118] Trial 42 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 233, 'learning_rate': 0.15982266255603106, 'feature_fraction': 0.6511109017884714, 'bagging_fraction': 0.6834959664895245, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,146] Trial 43 finished with value: 0.7972027972027972 and parameters: {'num_leaves': 177, 'learning_rate': 0.14058931028522964, 'feature_fraction': 0.7106431776185511, 'bagging_fraction': 0.6650791867277694, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,199] Trial 44 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 258, 'learning_rate': 0.16999257734299517, 'feature_fraction': 0.6188265020537719, 'bagging_fraction': 0.6062772826057499, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,241] Trial 45 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 285, 'learning_rate': 0.18830328887025144, 'feature_fraction': 0.5623336903177522, 'bagging_fraction': 0.58868356362143, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,292] Trial 46 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 215, 'learning_rate': 0.1710056701267638, 'feature_fraction': 0.4764465376170063, 'bagging_fraction': 0.5185025616697075, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,332] Trial 47 finished with value: 0.8356643356643357 and parameters: {'num_leaves': 269, 'learning_rate': 0.26360967951186387, 'feature_fraction': 0.6010617737413528, 'bagging_fraction': 0.5941256389664034, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,403] Trial 48 finished with value: 0.7832167832167831 and parameters: {'num_leaves': 83, 'learning_rate': 0.23163546434633597, 'feature_fraction': 0.5372862957604998, 'bagging_fraction': 0.8104268182510432, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,417] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 260, 'learning_rate': 0.20818144997263613, 'feature_fraction': 0.49891742996869437, 'bagging_fraction': 0.43029576539397263, 'bagging_freq': 4, 'min_child_samples': 72}. Best is trial 17 with value: 0.8951048951048951.
[I 2025-09-17 13:16:01,838] A new study created in memory with name: no-name-1c363304-ce43-41fb-b768-9e8593191e06
[I 2025-09-17 13:16:01,904] Trial 0 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 105, 'learning_rate': 0.08699659243773945, 'feature_fraction': 0.40155682648398033, 'bagging_fraction': 0.8630372531810772, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 0 with value: 0.8492063492063492.
[I 2025-09-17 13:16:01,928] Trial 1 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 191, 'learning_rate': 0.26198104123735927, 'feature_fraction': 0.7137419292695089, 'bagging_fraction': 0.50107447671817, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 0 with value: 0.8492063492063492.
[I 2025-09-17 13:16:02,006] Trial 2 finished with value: 0.9087301587301588 and parameters: {'num_leaves': 283, 'learning_rate': 0.040410028014956766, 'feature_fraction': 0.42202785076633886, 'bagging_fraction': 0.804040024509809, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,044] Trial 3 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 165, 'learning_rate': 0.2960765463836199, 'feature_fraction': 0.5733170172546367, 'bagging_fraction': 0.8311625520319614, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,053] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 60, 'learning_rate': 0.14670904530173806, 'feature_fraction': 0.8816654284733616, 'bagging_fraction': 0.41788753605387824, 'bagging_freq': 5, 'min_child_samples': 61}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,062] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 88, 'learning_rate': 0.2502446303172031, 'feature_fraction': 0.7793432449174932, 'bagging_fraction': 0.4610599814243684, 'bagging_freq': 3, 'min_child_samples': 69}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,102] Trial 6 finished with value: 0.8452380952380951 and parameters: {'num_leaves': 249, 'learning_rate': 0.17025627283826833, 'feature_fraction': 0.4787312868793737, 'bagging_fraction': 0.7506747692249341, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,114] Trial 7 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 53, 'learning_rate': 0.24673994183003137, 'feature_fraction': 0.8611114515888849, 'bagging_fraction': 0.6110401135759214, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,140] Trial 8 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 63, 'learning_rate': 0.06612581371927737, 'feature_fraction': 0.4971751547359228, 'bagging_fraction': 0.9199603454986701, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,160] Trial 9 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 120, 'learning_rate': 0.0836627061610867, 'feature_fraction': 0.9985369333796644, 'bagging_fraction': 0.49210986027490444, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,167] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.01806473541851463, 'feature_fraction': 0.6214274635129377, 'bagging_fraction': 0.9785531085175759, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,295] Trial 11 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 215, 'learning_rate': 0.0104637184591366, 'feature_fraction': 0.40380117559473566, 'bagging_fraction': 0.8204308269479031, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,407] Trial 12 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 228, 'learning_rate': 0.01159138919601695, 'feature_fraction': 0.4093966338728839, 'bagging_fraction': 0.7038669860746228, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,500] Trial 13 finished with value: 0.8888888888888888 and parameters: {'num_leaves': 288, 'learning_rate': 0.04762355386525506, 'feature_fraction': 0.5492746187353773, 'bagging_fraction': 0.7831262166006854, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,512] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.13533892183421742, 'feature_fraction': 0.5661766020920234, 'bagging_fraction': 0.6092667085181195, 'bagging_freq': 5, 'min_child_samples': 82}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,631] Trial 15 finished with value: 0.876984126984127 and parameters: {'num_leaves': 261, 'learning_rate': 0.057802747541127276, 'feature_fraction': 0.6510817623793943, 'bagging_fraction': 0.7654083693552515, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,644] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 269, 'learning_rate': 0.11360838779070281, 'feature_fraction': 0.4985261502907408, 'bagging_fraction': 0.6344705220776502, 'bagging_freq': 3, 'min_child_samples': 54}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,705] Trial 17 finished with value: 0.8531746031746031 and parameters: {'num_leaves': 153, 'learning_rate': 0.1794221903283877, 'feature_fraction': 0.551244288841032, 'bagging_fraction': 0.9145310249589527, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,736] Trial 18 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 23, 'learning_rate': 0.04379424675972866, 'feature_fraction': 0.47404599719662177, 'bagging_fraction': 0.6785823514350586, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,759] Trial 19 finished with value: 0.746031746031746 and parameters: {'num_leaves': 198, 'learning_rate': 0.20973829781952458, 'feature_fraction': 0.6844413161335068, 'bagging_fraction': 0.7743507341171109, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,814] Trial 20 finished with value: 0.8531746031746031 and parameters: {'num_leaves': 280, 'learning_rate': 0.10630744524659026, 'feature_fraction': 0.5906803075599466, 'bagging_fraction': 0.553743222258047, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:02,947] Trial 21 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 256, 'learning_rate': 0.0507684903504088, 'feature_fraction': 0.6641844725023595, 'bagging_fraction': 0.7363518017293464, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,069] Trial 22 finished with value: 0.8849206349206349 and parameters: {'num_leaves': 238, 'learning_rate': 0.03768545044300731, 'feature_fraction': 0.7642492864810876, 'bagging_fraction': 0.7169282591750581, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,136] Trial 23 finished with value: 0.876984126984127 and parameters: {'num_leaves': 282, 'learning_rate': 0.07432763347567312, 'feature_fraction': 0.5197840708639438, 'bagging_fraction': 0.8207690357327553, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,180] Trial 24 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 247, 'learning_rate': 0.0377202666022801, 'feature_fraction': 0.6342140554617086, 'bagging_fraction': 0.8865022787124147, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,258] Trial 25 finished with value: 0.876984126984127 and parameters: {'num_leaves': 213, 'learning_rate': 0.10686459591005643, 'feature_fraction': 0.4505675291118497, 'bagging_fraction': 0.7834416691428796, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,296] Trial 26 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 272, 'learning_rate': 0.05009718995326919, 'feature_fraction': 0.7300602617281078, 'bagging_fraction': 0.6660873739457023, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,477] Trial 27 finished with value: 0.876984126984127 and parameters: {'num_leaves': 160, 'learning_rate': 0.12375676040976137, 'feature_fraction': 0.5289506428518078, 'bagging_fraction': 0.9855076532123206, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,495] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 296, 'learning_rate': 0.03047119276411196, 'feature_fraction': 0.6695240526696046, 'bagging_fraction': 0.7299429457175188, 'bagging_freq': 4, 'min_child_samples': 76}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,579] Trial 29 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 254, 'learning_rate': 0.08812253531641237, 'feature_fraction': 0.4367458483318539, 'bagging_fraction': 0.8692648169988402, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,628] Trial 30 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 229, 'learning_rate': 0.08803980605363751, 'feature_fraction': 0.6085470454292642, 'bagging_fraction': 0.8026333670391874, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,700] Trial 31 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 239, 'learning_rate': 0.03433233754902369, 'feature_fraction': 0.7970779072609865, 'bagging_fraction': 0.7163813028429096, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,759] Trial 32 finished with value: 0.8968253968253967 and parameters: {'num_leaves': 281, 'learning_rate': 0.06308803468451166, 'feature_fraction': 0.8336896804931863, 'bagging_fraction': 0.6647376864092129, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,796] Trial 33 finished with value: 0.8531746031746031 and parameters: {'num_leaves': 176, 'learning_rate': 0.0684748994747709, 'feature_fraction': 0.8393878984928945, 'bagging_fraction': 0.6507245048229052, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,827] Trial 34 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 267, 'learning_rate': 0.030622213181882997, 'feature_fraction': 0.949162183465265, 'bagging_fraction': 0.5601906047523801, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,883] Trial 35 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 203, 'learning_rate': 0.05963667285832608, 'feature_fraction': 0.8197249235025302, 'bagging_fraction': 0.6945764451424267, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 2 with value: 0.9087301587301588.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.52112
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.537968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.524602
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.515721
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.547968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.576987
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.491505
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.520762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.559976
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.530115
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.542184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.563083
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.539105
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.493543
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.512166
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.535096
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.503357
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.522758
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.660144
Training model for P052... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.431455
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.432285
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.381389
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.479409
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.460768
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.579515
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.505563
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.521396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.492728
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.512732
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.372976
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.379669
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.443907
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.548171
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.565341
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.447946
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.367995
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.390631
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.393622
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.495563
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.418604
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.50816
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.384729
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.455313
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.46664
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.371286
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.396009
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.433169
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.557076
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.467648
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:03,917] Trial 36 finished with value: 0.7976190476190476 and parameters: {'num_leaves': 139, 'learning_rate': 0.09514931299191096, 'feature_fraction': 0.9105852154782106, 'bagging_fraction': 0.7382415867394971, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:03,978] Trial 37 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 184, 'learning_rate': 0.02230462293130453, 'feature_fraction': 0.7909587819704451, 'bagging_fraction': 0.5666642273453466, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:04,030] Trial 38 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 241, 'learning_rate': 0.06951817113487782, 'feature_fraction': 0.7285964251991436, 'bagging_fraction': 0.845198355069177, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:04,062] Trial 39 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 224, 'learning_rate': 0.15435673838583636, 'feature_fraction': 0.9078420367337814, 'bagging_fraction': 0.6002476929763834, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:04,087] Trial 40 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 258, 'learning_rate': 0.19837657636637165, 'feature_fraction': 0.7587388688936944, 'bagging_fraction': 0.7423390804699546, 'bagging_freq': 5, 'min_child_samples': 39}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:04,179] Trial 41 finished with value: 0.873015873015873 and parameters: {'num_leaves': 286, 'learning_rate': 0.04983115276738192, 'feature_fraction': 0.7990998949791231, 'bagging_fraction': 0.7924755333704352, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 2 with value: 0.9087301587301588.
[I 2025-09-17 13:16:04,253] Trial 42 finished with value: 0.9126984126984126 and parameters: {'num_leaves': 287, 'learning_rate': 0.2993525387122332, 'feature_fraction': 0.8562877294743578, 'bagging_fraction': 0.6910738558568348, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 42 with value: 0.9126984126984126.
[I 2025-09-17 13:16:04,309] Trial 43 finished with value: 0.8809523809523809 and parameters: {'num_leaves': 278, 'learning_rate': 0.29863419970277977, 'feature_fraction': 0.8465483884867565, 'bagging_fraction': 0.6883492038087802, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 42 with value: 0.9126984126984126.
[I 2025-09-17 13:16:04,346] Trial 44 finished with value: 0.8531746031746031 and parameters: {'num_leaves': 255, 'learning_rate': 0.2694678054683104, 'feature_fraction': 0.8933878617345455, 'bagging_fraction': 0.6424320014172882, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 42 with value: 0.9126984126984126.
[I 2025-09-17 13:16:04,517] Trial 45 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 99, 'learning_rate': 0.07950682044499485, 'feature_fraction': 0.8648508093652789, 'bagging_fraction': 0.758407347408284, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 42 with value: 0.9126984126984126.
[I 2025-09-17 13:16:04,555] Trial 46 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 300, 'learning_rate': 0.22569770664401012, 'feature_fraction': 0.9637804462676011, 'bagging_fraction': 0.7127762621920481, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 42 with value: 0.9126984126984126.
[I 2025-09-17 13:16:04,574] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 270, 'learning_rate': 0.023738960858350196, 'feature_fraction': 0.7080400597351535, 'bagging_fraction': 0.65999050235243, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 42 with value: 0.9126984126984126.
[I 2025-09-17 13:16:04,648] Trial 48 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 240, 'learning_rate': 0.2834144899610984, 'feature_fraction': 0.8086344993302683, 'bagging_fraction': 0.8449599221279516, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 42 with value: 0.9126984126984126.
[I 2025-09-17 13:16:04,666] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 265, 'learning_rate': 0.24437701878180604, 'feature_fraction': 0.9391535119461853, 'bagging_fraction': 0.42794507459944386, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 42 with value: 0.9126984126984126.
[I 2025-09-17 13:16:04,832] A new study created in memory with name: no-name-67100447-1d03-48b3-bedc-1b24b4418df4
[I 2025-09-17 13:16:04,866] Trial 0 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 222, 'learning_rate': 0.14997049942306703, 'feature_fraction': 0.6531095307894794, 'bagging_fraction': 0.7432712226085918, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,881] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.13582531482500157, 'feature_fraction': 0.49473702866174407, 'bagging_fraction': 0.888125852167448, 'bagging_freq': 7, 'min_child_samples': 93}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,888] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 228, 'learning_rate': 0.10271085294870427, 'feature_fraction': 0.9073304966321567, 'bagging_fraction': 0.6318784653843784, 'bagging_freq': 1, 'min_child_samples': 77}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,898] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.11525886453179156, 'feature_fraction': 0.4100106521856707, 'bagging_fraction': 0.443173263963396, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,912] Trial 4 finished with value: 0.6091269841269841 and parameters: {'num_leaves': 26, 'learning_rate': 0.28268195566922383, 'feature_fraction': 0.7627407639075272, 'bagging_fraction': 0.6697574638223078, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,921] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.266692348441094, 'feature_fraction': 0.7482243663715735, 'bagging_fraction': 0.6471377661107092, 'bagging_freq': 7, 'min_child_samples': 54}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,932] Trial 6 finished with value: 0.7103174603174605 and parameters: {'num_leaves': 149, 'learning_rate': 0.19552352733093295, 'feature_fraction': 0.8841449181771912, 'bagging_fraction': 0.5662954437923735, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,947] Trial 7 finished with value: 0.6527777777777777 and parameters: {'num_leaves': 267, 'learning_rate': 0.25299960444018466, 'feature_fraction': 0.4550273839135529, 'bagging_fraction': 0.9538745510204286, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,959] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 225, 'learning_rate': 0.09826714554325532, 'feature_fraction': 0.48298639110388364, 'bagging_fraction': 0.5682768426604448, 'bagging_freq': 2, 'min_child_samples': 67}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:04,974] Trial 9 finished with value: 0.6309523809523809 and parameters: {'num_leaves': 36, 'learning_rate': 0.14369205451483144, 'feature_fraction': 0.5307076650036829, 'bagging_fraction': 0.9700758017580563, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 0 with value: 0.7341269841269841.
[I 2025-09-17 13:16:05,073] Trial 10 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 133, 'learning_rate': 0.016010810443928436, 'feature_fraction': 0.6232516502247195, 'bagging_fraction': 0.805803858675212, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 10 with value: 0.8174603174603174.
[I 2025-09-17 13:16:05,239] Trial 11 finished with value: 0.8373015873015872 and parameters: {'num_leaves': 122, 'learning_rate': 0.012078133748756468, 'feature_fraction': 0.6284152097410267, 'bagging_fraction': 0.8032328656192563, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 11 with value: 0.8373015873015872.
[I 2025-09-17 13:16:05,303] Trial 12 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 109, 'learning_rate': 0.035993933203558565, 'feature_fraction': 0.6437085110060883, 'bagging_fraction': 0.7981255743496037, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 11 with value: 0.8373015873015872.
[I 2025-09-17 13:16:05,486] Trial 13 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 96, 'learning_rate': 0.015420012394516942, 'feature_fraction': 0.5863921441464469, 'bagging_fraction': 0.8310365785573579, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,527] Trial 14 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 79, 'learning_rate': 0.058159688594108847, 'feature_fraction': 0.5699118320071852, 'bagging_fraction': 0.8702268416376437, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,651] Trial 15 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 77, 'learning_rate': 0.07165591640667682, 'feature_fraction': 0.8106371324376921, 'bagging_fraction': 0.7437949872396834, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,697] Trial 16 finished with value: 0.6666666666666666 and parameters: {'num_leaves': 172, 'learning_rate': 0.01666873537416134, 'feature_fraction': 0.9865230864864034, 'bagging_fraction': 0.8664917104239469, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,730] Trial 17 finished with value: 0.5912698412698413 and parameters: {'num_leaves': 93, 'learning_rate': 0.20239011503166687, 'feature_fraction': 0.5789139550789942, 'bagging_fraction': 0.7876258894132968, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,753] Trial 18 finished with value: 0.621031746031746 and parameters: {'num_leaves': 58, 'learning_rate': 0.051950856883578096, 'feature_fraction': 0.7081316011819493, 'bagging_fraction': 0.9177569468437543, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,766] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 124, 'learning_rate': 0.07893991590984907, 'feature_fraction': 0.6817450824120312, 'bagging_fraction': 0.41469131492320915, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,865] Trial 20 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 172, 'learning_rate': 0.18147423147776648, 'feature_fraction': 0.5773879140563405, 'bagging_fraction': 0.7179917548686573, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,948] Trial 21 finished with value: 0.753968253968254 and parameters: {'num_leaves': 141, 'learning_rate': 0.011404149137940363, 'feature_fraction': 0.6181997651356423, 'bagging_fraction': 0.8337955175905465, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:05,994] Trial 22 finished with value: 0.6666666666666666 and parameters: {'num_leaves': 118, 'learning_rate': 0.03609049932758834, 'feature_fraction': 0.6121537743319729, 'bagging_fraction': 0.799999017236867, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:16:06,218] Trial 23 finished with value: 0.865079365079365 and parameters: {'num_leaves': 56, 'learning_rate': 0.010952144701915207, 'feature_fraction': 0.5293698938942119, 'bagging_fraction': 0.9969712840386655, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,255] Trial 24 finished with value: 0.6626984126984127 and parameters: {'num_leaves': 55, 'learning_rate': 0.04143485945491224, 'feature_fraction': 0.5326997641358565, 'bagging_fraction': 0.9923856351834618, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,306] Trial 25 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 96, 'learning_rate': 0.07365345025521125, 'feature_fraction': 0.44168176956546223, 'bagging_fraction': 0.9288967513412416, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,516] Trial 26 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 63, 'learning_rate': 0.028625232314019533, 'feature_fraction': 0.5244030970340943, 'bagging_fraction': 0.9120162285958013, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,541] Trial 27 finished with value: 0.6428571428571428 and parameters: {'num_leaves': 169, 'learning_rate': 0.056334866827886736, 'feature_fraction': 0.7139053380380969, 'bagging_fraction': 0.995853499018341, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,565] Trial 28 finished with value: 0.6369047619047619 and parameters: {'num_leaves': 41, 'learning_rate': 0.0862548359459412, 'feature_fraction': 0.5632072017386909, 'bagging_fraction': 0.8417875084448564, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,605] Trial 29 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 100, 'learning_rate': 0.22667075591512437, 'feature_fraction': 0.6732072034931287, 'bagging_fraction': 0.7486311939243246, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,645] Trial 30 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 197, 'learning_rate': 0.1286385610341541, 'feature_fraction': 0.7910803731330758, 'bagging_fraction': 0.6959624641927122, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,818] Trial 31 finished with value: 0.8253968253968255 and parameters: {'num_leaves': 68, 'learning_rate': 0.028007229204873772, 'feature_fraction': 0.5160705481943432, 'bagging_fraction': 0.9046172926190653, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:06,921] Trial 32 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 79, 'learning_rate': 0.026876329061098266, 'feature_fraction': 0.49095480025641947, 'bagging_fraction': 0.9416510248188992, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,021] Trial 33 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 84, 'learning_rate': 0.05039567385051737, 'feature_fraction': 0.47661006174895637, 'bagging_fraction': 0.9507631241046353, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,084] Trial 34 finished with value: 0.6984126984126984 and parameters: {'num_leaves': 106, 'learning_rate': 0.022533985955091453, 'feature_fraction': 0.40584170413462256, 'bagging_fraction': 0.8669289745594069, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,170] Trial 35 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 47, 'learning_rate': 0.010737770692037438, 'feature_fraction': 0.5959248957501296, 'bagging_fraction': 0.8346061249729815, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,180] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 17, 'learning_rate': 0.16933964944681829, 'feature_fraction': 0.6462227141197436, 'bagging_fraction': 0.7692410849848077, 'bagging_freq': 1, 'min_child_samples': 83}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,217] Trial 37 finished with value: 0.6785714285714285 and parameters: {'num_leaves': 122, 'learning_rate': 0.1190030028135274, 'feature_fraction': 0.4460866722463062, 'bagging_fraction': 0.9421679982210187, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,236] Trial 38 finished with value: 0.6706349206349206 and parameters: {'num_leaves': 154, 'learning_rate': 0.09596058633695945, 'feature_fraction': 0.49330450282381394, 'bagging_fraction': 0.8901215785822354, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,338] Trial 39 finished with value: 0.761904761904762 and parameters: {'num_leaves': 294, 'learning_rate': 0.06116404206593567, 'feature_fraction': 0.5365017266718649, 'bagging_fraction': 0.9789356162364072, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,357] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 36, 'learning_rate': 0.04679326250288806, 'feature_fraction': 0.5539631310242322, 'bagging_fraction': 0.6076573036233895, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,464] Trial 41 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 81, 'learning_rate': 0.03970984269805407, 'feature_fraction': 0.4679776850022632, 'bagging_fraction': 0.9555776565366704, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,542] Trial 42 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 81, 'learning_rate': 0.029108557304363757, 'feature_fraction': 0.5092144107565441, 'bagging_fraction': 0.9535104951683994, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,619] Trial 43 finished with value: 0.7261904761904763 and parameters: {'num_leaves': 90, 'learning_rate': 0.012843575478333778, 'feature_fraction': 0.4288152740071434, 'bagging_fraction': 0.5089650574348037, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 23 with value: 0.865079365079365.
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.493473
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.479811
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.457505
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.435534
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.490766
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.383639
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.436905
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.426155
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.447025
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.456494
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.449543
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.485377
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.5945
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.647021
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.620684
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.625071
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.624734
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.517172
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.506829
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.548486
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.488301
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.603431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.532109
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.620766
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.639248
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.632941
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.541271
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.561045
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.615838
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.499742
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.625097
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.585971
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.503737
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.643513
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.630971
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.61557
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.598003
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.502074
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.51045
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.500186
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.594705
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.546179
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.605575
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.628932
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.536771
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.509973
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.579801
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.59137
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:07,660] Trial 44 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 112, 'learning_rate': 0.06581086305817117, 'feature_fraction': 0.4817010190121744, 'bagging_fraction': 0.931348833468876, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,692] Trial 45 finished with value: 0.6706349206349206 and parameters: {'num_leaves': 69, 'learning_rate': 0.04442551575023878, 'feature_fraction': 0.5971455417629152, 'bagging_fraction': 0.8951147456691827, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,707] Trial 46 finished with value: 0.4920634920634921 and parameters: {'num_leaves': 136, 'learning_rate': 0.024597205297216148, 'feature_fraction': 0.4883874577478896, 'bagging_fraction': 0.9684665181892509, 'bagging_freq': 7, 'min_child_samples': 66}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,765] Trial 47 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 88, 'learning_rate': 0.08680724412448959, 'feature_fraction': 0.5494663224008033, 'bagging_fraction': 0.8542936397664032, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,885] Trial 48 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 248, 'learning_rate': 0.056234820145154754, 'feature_fraction': 0.4237408126352232, 'bagging_fraction': 0.8179578636425471, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:07,903] Trial 49 finished with value: 0.5753968253968254 and parameters: {'num_leaves': 28, 'learning_rate': 0.2858017408422953, 'feature_fraction': 0.6317079033013657, 'bagging_fraction': 0.9991691124417561, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 23 with value: 0.865079365079365.
[I 2025-09-17 13:16:10,632] A new study created in memory with name: no-name-322c0b6c-1944-4923-959b-e2b106e606f8
[I 2025-09-17 13:16:10,655] Trial 0 finished with value: 0.6924603174603174 and parameters: {'num_leaves': 102, 'learning_rate': 0.23151985041387643, 'feature_fraction': 0.48804505072828197, 'bagging_fraction': 0.42454815682847297, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 0 with value: 0.6924603174603174.
[I 2025-09-17 13:16:10,664] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 214, 'learning_rate': 0.014972468853371394, 'feature_fraction': 0.6288192229280805, 'bagging_fraction': 0.4358116796306643, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 0 with value: 0.6924603174603174.
[I 2025-09-17 13:16:10,677] Trial 2 finished with value: 0.5158730158730158 and parameters: {'num_leaves': 173, 'learning_rate': 0.1197307474856651, 'feature_fraction': 0.6364902500026142, 'bagging_fraction': 0.9729046028800119, 'bagging_freq': 3, 'min_child_samples': 66}. Best is trial 0 with value: 0.6924603174603174.
[I 2025-09-17 13:16:10,733] Trial 3 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 202, 'learning_rate': 0.289339480061569, 'feature_fraction': 0.7129816155996125, 'bagging_fraction': 0.7027046849652084, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 3 with value: 0.8571428571428571.
[I 2025-09-17 13:16:10,777] Trial 4 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 218, 'learning_rate': 0.19093651261115155, 'feature_fraction': 0.8234013005545904, 'bagging_fraction': 0.891263856941407, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 3 with value: 0.8571428571428571.
[I 2025-09-17 13:16:10,785] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 202, 'learning_rate': 0.13079133516492666, 'feature_fraction': 0.5914915994312011, 'bagging_fraction': 0.8671232861463921, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 3 with value: 0.8571428571428571.
[I 2025-09-17 13:16:10,801] Trial 6 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 283, 'learning_rate': 0.23260040547024072, 'feature_fraction': 0.6587254042936596, 'bagging_fraction': 0.8378464230005269, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 3 with value: 0.8571428571428571.
[I 2025-09-17 13:16:10,818] Trial 7 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 172, 'learning_rate': 0.2061746918663634, 'feature_fraction': 0.46005642759949383, 'bagging_fraction': 0.5443078592938607, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 3 with value: 0.8571428571428571.
[I 2025-09-17 13:16:10,845] Trial 8 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 134, 'learning_rate': 0.09181896206546461, 'feature_fraction': 0.4822668751870368, 'bagging_fraction': 0.7589682048896937, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 3 with value: 0.8571428571428571.
[I 2025-09-17 13:16:10,884] Trial 9 finished with value: 0.861111111111111 and parameters: {'num_leaves': 216, 'learning_rate': 0.2912606069663526, 'feature_fraction': 0.6413238838138113, 'bagging_fraction': 0.46237283026341286, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 9 with value: 0.861111111111111.
[I 2025-09-17 13:16:10,897] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.28738594046228744, 'feature_fraction': 0.9906033990279726, 'bagging_fraction': 0.5756160607618308, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 9 with value: 0.861111111111111.
[I 2025-09-17 13:16:10,983] Trial 11 finished with value: 0.7023809523809523 and parameters: {'num_leaves': 269, 'learning_rate': 0.29261957628392815, 'feature_fraction': 0.7826613872661652, 'bagging_fraction': 0.6519348784949702, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 9 with value: 0.861111111111111.
[I 2025-09-17 13:16:11,031] Trial 12 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 245, 'learning_rate': 0.29914827801021593, 'feature_fraction': 0.774230240986272, 'bagging_fraction': 0.6893655972514494, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 9 with value: 0.861111111111111.
[I 2025-09-17 13:16:11,059] Trial 13 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 100, 'learning_rate': 0.2502954111264928, 'feature_fraction': 0.8874293468238129, 'bagging_fraction': 0.5524662234028279, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 9 with value: 0.861111111111111.
[I 2025-09-17 13:16:11,082] Trial 14 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 296, 'learning_rate': 0.17312238150809872, 'feature_fraction': 0.5620100756196688, 'bagging_fraction': 0.774720276362437, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 9 with value: 0.861111111111111.
[I 2025-09-17 13:16:11,120] Trial 15 finished with value: 0.8373015873015873 and parameters: {'num_leaves': 139, 'learning_rate': 0.26283638124736736, 'feature_fraction': 0.718877173832146, 'bagging_fraction': 0.6186811661079437, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 9 with value: 0.861111111111111.
[I 2025-09-17 13:16:11,211] Trial 16 finished with value: 0.8690476190476191 and parameters: {'num_leaves': 244, 'learning_rate': 0.05286953176519586, 'feature_fraction': 0.7113284030750322, 'bagging_fraction': 0.49533719706315243, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,224] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 256, 'learning_rate': 0.048409964397515895, 'feature_fraction': 0.5482261517829606, 'bagging_fraction': 0.48156869829618054, 'bagging_freq': 3, 'min_child_samples': 94}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,319] Trial 18 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 235, 'learning_rate': 0.08827135175323009, 'feature_fraction': 0.40380964325486557, 'bagging_fraction': 0.4887464325953283, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,332] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 39, 'learning_rate': 0.01936604137303851, 'feature_fraction': 0.8826396228948998, 'bagging_fraction': 0.4949389794102789, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,354] Trial 20 finished with value: 0.757936507936508 and parameters: {'num_leaves': 158, 'learning_rate': 0.05683287713731289, 'feature_fraction': 0.6921639581262389, 'bagging_fraction': 0.4253856694178188, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,396] Trial 21 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 196, 'learning_rate': 0.2669977040770608, 'feature_fraction': 0.7259002789407532, 'bagging_fraction': 0.7460082192515546, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,437] Trial 22 finished with value: 0.865079365079365 and parameters: {'num_leaves': 235, 'learning_rate': 0.15003453197126201, 'feature_fraction': 0.7675651546725042, 'bagging_fraction': 0.609657628182552, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,477] Trial 23 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 238, 'learning_rate': 0.14985144350046126, 'feature_fraction': 0.790185696516482, 'bagging_fraction': 0.605808642897153, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,506] Trial 24 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 267, 'learning_rate': 0.09004176175292605, 'feature_fraction': 0.8366971875058642, 'bagging_fraction': 0.5230056494941294, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,523] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 221, 'learning_rate': 0.17067714026560826, 'feature_fraction': 0.746354219910075, 'bagging_fraction': 0.4047732062724957, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,624] Trial 26 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 181, 'learning_rate': 0.11906973309856958, 'feature_fraction': 0.6799231161114454, 'bagging_fraction': 0.46876397141947124, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,680] Trial 27 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 300, 'learning_rate': 0.058358183579529294, 'feature_fraction': 0.6150046405410797, 'bagging_fraction': 0.6084732138158023, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,699] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 256, 'learning_rate': 0.21147970097648405, 'feature_fraction': 0.9426582589149783, 'bagging_fraction': 0.5148032271017738, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,737] Trial 29 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 104, 'learning_rate': 0.1449856274031338, 'feature_fraction': 0.5561648896829005, 'bagging_fraction': 0.4531108522468569, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,766] Trial 30 finished with value: 0.753968253968254 and parameters: {'num_leaves': 227, 'learning_rate': 0.03451141547723552, 'feature_fraction': 0.8716417707576979, 'bagging_fraction': 0.6523853334584837, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 16 with value: 0.8690476190476191.
[I 2025-09-17 13:16:11,801] Trial 31 finished with value: 0.876984126984127 and parameters: {'num_leaves': 243, 'learning_rate': 0.154893949519337, 'feature_fraction': 0.8010361690825443, 'bagging_fraction': 0.578480170350556, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:11,843] Trial 32 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 277, 'learning_rate': 0.17258985267986024, 'feature_fraction': 0.7595246672652939, 'bagging_fraction': 0.5702391862670234, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:11,871] Trial 33 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 250, 'learning_rate': 0.10717644601631243, 'feature_fraction': 0.8139869502469065, 'bagging_fraction': 0.5276326310104503, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:11,934] Trial 34 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 193, 'learning_rate': 0.07400267575729859, 'feature_fraction': 0.6485417855917942, 'bagging_fraction': 0.4389418682750469, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:11,948] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 219, 'learning_rate': 0.1961444892935859, 'feature_fraction': 0.8469538445042979, 'bagging_fraction': 0.6453693398251101, 'bagging_freq': 6, 'min_child_samples': 65}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:11,991] Trial 36 finished with value: 0.876984126984127 and parameters: {'num_leaves': 209, 'learning_rate': 0.13804635174673194, 'feature_fraction': 0.687902647017112, 'bagging_fraction': 0.5811864409487152, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,038] Trial 37 finished with value: 0.8373015873015873 and parameters: {'num_leaves': 206, 'learning_rate': 0.1368210112418029, 'feature_fraction': 0.682415068000279, 'bagging_fraction': 0.9912223711828452, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,070] Trial 38 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 176, 'learning_rate': 0.1598825329443905, 'feature_fraction': 0.7394696613204617, 'bagging_fraction': 0.693410943049412, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,083] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 287, 'learning_rate': 0.11858095982824549, 'feature_fraction': 0.8071379520924725, 'bagging_fraction': 0.5756299957717779, 'bagging_freq': 5, 'min_child_samples': 82}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,109] Trial 40 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 264, 'learning_rate': 0.2218616288543357, 'feature_fraction': 0.594088383359975, 'bagging_fraction': 0.9367340779575707, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,165] Trial 41 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 236, 'learning_rate': 0.18559086480341172, 'feature_fraction': 0.6561921911402467, 'bagging_fraction': 0.5917276716942972, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,207] Trial 42 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 212, 'learning_rate': 0.15916320907145276, 'feature_fraction': 0.7113994828585153, 'bagging_fraction': 0.5121871337622015, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,274] Trial 43 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 188, 'learning_rate': 0.1355062497032758, 'feature_fraction': 0.6198315955010351, 'bagging_fraction': 0.5502161628023463, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,298] Trial 44 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 161, 'learning_rate': 0.10006190518629265, 'feature_fraction': 0.756001674905671, 'bagging_fraction': 0.6444438687580882, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,327] Trial 45 finished with value: 0.7380952380952381 and parameters: {'num_leaves': 209, 'learning_rate': 0.2383488844502628, 'feature_fraction': 0.6809296228914025, 'bagging_fraction': 0.4020071384729497, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,386] Trial 46 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 228, 'learning_rate': 0.12513043701563673, 'feature_fraction': 0.7841948240144058, 'bagging_fraction': 0.7295962214397937, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,415] Trial 47 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 240, 'learning_rate': 0.18941146429550934, 'feature_fraction': 0.7112773010227081, 'bagging_fraction': 0.46434095034892103, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 31 with value: 0.876984126984127.
[I 2025-09-17 13:16:12,563] Trial 48 finished with value: 0.8809523809523809 and parameters: {'num_leaves': 276, 'learning_rate': 0.07779181884059658, 'feature_fraction': 0.9249528157228915, 'bagging_fraction': 0.8045536831720937, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 48 with value: 0.8809523809523809.
[I 2025-09-17 13:16:12,728] Trial 49 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 280, 'learning_rate': 0.026529898680529296, 'feature_fraction': 0.9252028594138468, 'bagging_fraction': 0.8160421551054622, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 49 with value: 0.8928571428571429.
[I 2025-09-17 13:16:14,024] A new study created in memory with name: no-name-eaab36f3-5682-4e4e-8a25-8eb5e8afa5c7
[I 2025-09-17 13:16:14,033] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 30, 'learning_rate': 0.013918602508452935, 'feature_fraction': 0.4467611550898813, 'bagging_fraction': 0.7539843483805229, 'bagging_freq': 2, 'min_child_samples': 67}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:14,046] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 162, 'learning_rate': 0.04205950875114527, 'feature_fraction': 0.9485998258922089, 'bagging_fraction': 0.42393874304073886, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 0 with value: 0.5.
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.570394
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.605043
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.530572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.514695
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.641651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.606184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.652701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.455535
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.530818
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.547102
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.510443
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.485166
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.477122
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.652768
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.575048
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.431477
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.498563
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.488474
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.41929
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.499934
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.541681
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.523552
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.443548
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.478062
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.484317
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.564303
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.523942
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.475366
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.557536
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.440644
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.510045
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.467529
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.517563
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.421304
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.479202
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.48582
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.495162
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.498006
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.472877
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.539959
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.516687
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.530361
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.471545
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.470458
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.440791
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.432928
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:14,060] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 297, 'learning_rate': 0.12245183233151188, 'feature_fraction': 0.5017487955692598, 'bagging_fraction': 0.8932558393370433, 'bagging_freq': 3, 'min_child_samples': 66}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:14,095] Trial 3 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 140, 'learning_rate': 0.12154061175555665, 'feature_fraction': 0.8872120602423826, 'bagging_fraction': 0.5910800791692434, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 3 with value: 0.7817460317460317.
[I 2025-09-17 13:16:14,107] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 64, 'learning_rate': 0.06115914170995757, 'feature_fraction': 0.539684507704232, 'bagging_fraction': 0.5473104449630964, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 3 with value: 0.7817460317460317.
[I 2025-09-17 13:16:14,118] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 281, 'learning_rate': 0.19528221975509924, 'feature_fraction': 0.9432468217770683, 'bagging_fraction': 0.4454397681860933, 'bagging_freq': 5, 'min_child_samples': 61}. Best is trial 3 with value: 0.7817460317460317.
[I 2025-09-17 13:16:14,128] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 163, 'learning_rate': 0.02119997168692089, 'feature_fraction': 0.7056765194576702, 'bagging_fraction': 0.43952659183913123, 'bagging_freq': 6, 'min_child_samples': 54}. Best is trial 3 with value: 0.7817460317460317.
[I 2025-09-17 13:16:14,137] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 205, 'learning_rate': 0.13083626224470057, 'feature_fraction': 0.7372479055266512, 'bagging_fraction': 0.4587564081030008, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 3 with value: 0.7817460317460317.
[I 2025-09-17 13:16:14,196] Trial 8 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 266, 'learning_rate': 0.11980629672500982, 'feature_fraction': 0.9949883438470575, 'bagging_fraction': 0.8580391380986157, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 8 with value: 0.8571428571428571.
[I 2025-09-17 13:16:14,240] Trial 9 finished with value: 0.8353174603174603 and parameters: {'num_leaves': 71, 'learning_rate': 0.1982182853890607, 'feature_fraction': 0.7124055468289856, 'bagging_fraction': 0.7058946429546684, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 8 with value: 0.8571428571428571.
[I 2025-09-17 13:16:14,264] Trial 10 finished with value: 0.6646825396825395 and parameters: {'num_leaves': 240, 'learning_rate': 0.2898310744875918, 'feature_fraction': 0.8271959646808004, 'bagging_fraction': 0.9873380961307978, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 8 with value: 0.8571428571428571.
[I 2025-09-17 13:16:14,381] Trial 11 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 96, 'learning_rate': 0.2109358495648788, 'feature_fraction': 0.5815888211776047, 'bagging_fraction': 0.7575158167703803, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 8 with value: 0.8571428571428571.
[I 2025-09-17 13:16:14,411] Trial 12 finished with value: 0.757936507936508 and parameters: {'num_leaves': 13, 'learning_rate': 0.1806503329435272, 'feature_fraction': 0.804730487989257, 'bagging_fraction': 0.8466983286944302, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 8 with value: 0.8571428571428571.
[I 2025-09-17 13:16:14,556] Trial 13 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 109, 'learning_rate': 0.24660984638211025, 'feature_fraction': 0.6032387366818613, 'bagging_fraction': 0.6430718296496819, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 13 with value: 0.8928571428571429.
[I 2025-09-17 13:16:14,575] Trial 14 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 228, 'learning_rate': 0.2774449013084918, 'feature_fraction': 0.6033365041139216, 'bagging_fraction': 0.6187949723883283, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 13 with value: 0.8928571428571429.
[I 2025-09-17 13:16:14,610] Trial 15 finished with value: 0.753968253968254 and parameters: {'num_leaves': 122, 'learning_rate': 0.236622866571992, 'feature_fraction': 0.6330883175277338, 'bagging_fraction': 0.8275901480275694, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 13 with value: 0.8928571428571429.
[I 2025-09-17 13:16:14,635] Trial 16 finished with value: 0.6845238095238094 and parameters: {'num_leaves': 258, 'learning_rate': 0.09294176088784095, 'feature_fraction': 0.9925818170324846, 'bagging_fraction': 0.9806610570239315, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 13 with value: 0.8928571428571429.
[I 2025-09-17 13:16:14,762] Trial 17 finished with value: 0.9484126984126984 and parameters: {'num_leaves': 193, 'learning_rate': 0.24447893507297486, 'feature_fraction': 0.40187552617016375, 'bagging_fraction': 0.6786502233383092, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:14,775] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 196, 'learning_rate': 0.24938271165079562, 'feature_fraction': 0.40317771942265457, 'bagging_fraction': 0.6464997217808641, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:14,807] Trial 19 finished with value: 0.75 and parameters: {'num_leaves': 189, 'learning_rate': 0.24951236462765933, 'feature_fraction': 0.4916337702880291, 'bagging_fraction': 0.5579471511008463, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:14,825] Trial 20 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 111, 'learning_rate': 0.15469304106567397, 'feature_fraction': 0.6449879177331077, 'bagging_fraction': 0.6878374071636527, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:14,917] Trial 21 finished with value: 0.888888888888889 and parameters: {'num_leaves': 259, 'learning_rate': 0.16202442586839444, 'feature_fraction': 0.7766077931911419, 'bagging_fraction': 0.730263864604275, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,033] Trial 22 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 235, 'learning_rate': 0.22735996848737175, 'feature_fraction': 0.7867177796808668, 'bagging_fraction': 0.7614321895972653, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,076] Trial 23 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 177, 'learning_rate': 0.16459069049616262, 'feature_fraction': 0.6589010965003401, 'bagging_fraction': 0.6834982526010547, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,111] Trial 24 finished with value: 0.7063492063492063 and parameters: {'num_leaves': 217, 'learning_rate': 0.2727130361531834, 'feature_fraction': 0.7611884442428646, 'bagging_fraction': 0.5181663832766807, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,206] Trial 25 finished with value: 0.8551587301587302 and parameters: {'num_leaves': 136, 'learning_rate': 0.26466250203591873, 'feature_fraction': 0.4022520046122073, 'bagging_fraction': 0.6440679790595927, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,239] Trial 26 finished with value: 0.746031746031746 and parameters: {'num_leaves': 76, 'learning_rate': 0.21848506719239766, 'feature_fraction': 0.8489330388016072, 'bagging_fraction': 0.7914905868555188, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,294] Trial 27 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 260, 'learning_rate': 0.2998514511935695, 'feature_fraction': 0.5662229927975642, 'bagging_fraction': 0.7185745582957724, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,315] Trial 28 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 102, 'learning_rate': 0.15430894066894196, 'feature_fraction': 0.46910272338222236, 'bagging_fraction': 0.6547171386564832, 'bagging_freq': 7, 'min_child_samples': 45}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,349] Trial 29 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 45, 'learning_rate': 0.08106072022786523, 'feature_fraction': 0.6766606206818908, 'bagging_fraction': 0.5003240685794708, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,412] Trial 30 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 142, 'learning_rate': 0.25086828147815676, 'feature_fraction': 0.5245112306526257, 'bagging_fraction': 0.7241327737533475, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,535] Trial 31 finished with value: 0.9047619047619049 and parameters: {'num_leaves': 232, 'learning_rate': 0.2281492243960512, 'feature_fraction': 0.7783701490701259, 'bagging_fraction': 0.7581349613989187, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,623] Trial 32 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 244, 'learning_rate': 0.18441964545372855, 'feature_fraction': 0.8787880192029157, 'bagging_fraction': 0.7884446962990518, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,662] Trial 33 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 213, 'learning_rate': 0.20267245092352343, 'feature_fraction': 0.8875023554767876, 'bagging_fraction': 0.9000384633836955, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,675] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.2338269403759945, 'feature_fraction': 0.871457843420272, 'bagging_fraction': 0.7887700294397889, 'bagging_freq': 3, 'min_child_samples': 93}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,735] Trial 35 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 286, 'learning_rate': 0.18162892873887043, 'feature_fraction': 0.44407412301692595, 'bagging_fraction': 0.607535859605904, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,755] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 163, 'learning_rate': 0.2603063154955342, 'feature_fraction': 0.8991889956097336, 'bagging_fraction': 0.7852870407537272, 'bagging_freq': 5, 'min_child_samples': 74}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,798] Trial 37 finished with value: 0.7638888888888888 and parameters: {'num_leaves': 238, 'learning_rate': 0.22132783055428906, 'feature_fraction': 0.9323157277575282, 'bagging_fraction': 0.9105496963138835, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,820] Trial 38 finished with value: 0.8075396825396826 and parameters: {'num_leaves': 221, 'learning_rate': 0.18738082327238015, 'feature_fraction': 0.8338749993376307, 'bagging_fraction': 0.5885427275244356, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,846] Trial 39 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 202, 'learning_rate': 0.23630053274405854, 'feature_fraction': 0.7538855335484475, 'bagging_fraction': 0.8228131198945535, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,864] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.20912977137211236, 'feature_fraction': 0.7192185574026533, 'bagging_fraction': 0.6695653921887939, 'bagging_freq': 6, 'min_child_samples': 60}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:15,949] Trial 41 finished with value: 0.8809523809523808 and parameters: {'num_leaves': 253, 'learning_rate': 0.13422191528575306, 'feature_fraction': 0.7795997915372901, 'bagging_fraction': 0.7357895485759948, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,013] Trial 42 finished with value: 0.8809523809523809 and parameters: {'num_leaves': 278, 'learning_rate': 0.16738301017551493, 'feature_fraction': 0.797523182632152, 'bagging_fraction': 0.7641979830878569, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,118] Trial 43 finished with value: 0.8849206349206349 and parameters: {'num_leaves': 245, 'learning_rate': 0.16745168224037502, 'feature_fraction': 0.6867668003674503, 'bagging_fraction': 0.7212429724769664, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,177] Trial 44 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 270, 'learning_rate': 0.14100994432558983, 'feature_fraction': 0.9142531541356193, 'bagging_fraction': 0.7000928299007242, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,261] Trial 45 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 152, 'learning_rate': 0.19412152943914376, 'feature_fraction': 0.8625951143684722, 'bagging_fraction': 0.8737780536794887, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,318] Trial 46 finished with value: 0.8611111111111112 and parameters: {'num_leaves': 155, 'learning_rate': 0.19854654874746483, 'feature_fraction': 0.8638019098891757, 'bagging_fraction': 0.8701664138052756, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,408] Trial 47 finished with value: 0.9126984126984127 and parameters: {'num_leaves': 181, 'learning_rate': 0.28284672815927475, 'feature_fraction': 0.820939760253857, 'bagging_fraction': 0.8145084083261632, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,442] Trial 48 finished with value: 0.7242063492063493 and parameters: {'num_leaves': 180, 'learning_rate': 0.286184488234963, 'feature_fraction': 0.8155589222411654, 'bagging_fraction': 0.8203285399426633, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,508] Trial 49 finished with value: 0.8888888888888888 and parameters: {'num_leaves': 87, 'learning_rate': 0.2801069838390272, 'feature_fraction': 0.9699927083820583, 'bagging_fraction': 0.9296580290161635, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 17 with value: 0.9484126984126984.
[I 2025-09-17 13:16:16,860] A new study created in memory with name: no-name-24df77bd-3e66-4010-b6e7-bc39269cf796
[I 2025-09-17 13:16:16,881] Trial 0 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 118, 'learning_rate': 0.06894085980339157, 'feature_fraction': 0.4724051532399569, 'bagging_fraction': 0.6149577793807818, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 0 with value: 0.7579365079365079.
[I 2025-09-17 13:16:16,911] Trial 1 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 151, 'learning_rate': 0.2809923727614656, 'feature_fraction': 0.7766469050917313, 'bagging_fraction': 0.7868089925201157, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 0 with value: 0.7579365079365079.
[I 2025-09-17 13:16:16,919] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 250, 'learning_rate': 0.1464518417103294, 'feature_fraction': 0.7648425458336212, 'bagging_fraction': 0.6189138756626689, 'bagging_freq': 3, 'min_child_samples': 71}. Best is trial 0 with value: 0.7579365079365079.
[I 2025-09-17 13:16:16,945] Trial 3 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 241, 'learning_rate': 0.2793630931920246, 'feature_fraction': 0.6956103340879876, 'bagging_fraction': 0.8636706635843594, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 3 with value: 0.7976190476190477.
[I 2025-09-17 13:16:16,965] Trial 4 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 72, 'learning_rate': 0.20750771802197424, 'feature_fraction': 0.5501982756840822, 'bagging_fraction': 0.8612447964981642, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 3 with value: 0.7976190476190477.
[I 2025-09-17 13:16:16,977] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 266, 'learning_rate': 0.09529900699292382, 'feature_fraction': 0.8635937064793054, 'bagging_fraction': 0.4835106578744944, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 3 with value: 0.7976190476190477.
[I 2025-09-17 13:16:17,006] Trial 6 finished with value: 0.746031746031746 and parameters: {'num_leaves': 154, 'learning_rate': 0.09114784607113136, 'feature_fraction': 0.6116220833647815, 'bagging_fraction': 0.9731062651810664, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 3 with value: 0.7976190476190477.
[I 2025-09-17 13:16:17,014] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 103, 'learning_rate': 0.1485784378139801, 'feature_fraction': 0.9644144028838029, 'bagging_fraction': 0.7708390133952875, 'bagging_freq': 3, 'min_child_samples': 74}. Best is trial 3 with value: 0.7976190476190477.
[I 2025-09-17 13:16:17,023] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.07671755236793158, 'feature_fraction': 0.4538379851553662, 'bagging_fraction': 0.4278000926558764, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 3 with value: 0.7976190476190477.
[I 2025-09-17 13:16:17,031] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 149, 'learning_rate': 0.14132065957794426, 'feature_fraction': 0.7103837956452175, 'bagging_fraction': 0.9462131668163686, 'bagging_freq': 1, 'min_child_samples': 74}. Best is trial 3 with value: 0.7976190476190477.
[I 2025-09-17 13:16:17,041] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 23, 'learning_rate': 0.2876329837123295, 'feature_fraction': 0.5932132601383977, 'bagging_fraction': 0.6739922316517817, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 3 with value: 0.7976190476190477.
[I 2025-09-17 13:16:17,093] Trial 11 finished with value: 0.8611111111111112 and parameters: {'num_leaves': 37, 'learning_rate': 0.22610682887415595, 'feature_fraction': 0.5671962314512822, 'bagging_fraction': 0.8598679363922184, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 11 with value: 0.8611111111111112.
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.545298
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.434938
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.479628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.609287
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.521069
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.578246
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.479123
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.583105
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.578634
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.605492
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.31487
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.616732
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.606354
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.443495
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.46023
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.551584
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.582921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.476166
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.583498
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.467441
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.602839
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.566066
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.50762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.39812
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.358208
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.525032
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.515941
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.560244
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.569505
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.613556
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.429507
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.464427
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.419681
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.573853
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.422517
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.428048
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.415787
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.582192
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.400889
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.566239
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.560762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.566217
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.536146
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.542947
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.457417
[I 2025-09-17 13:16:17,129] Trial 12 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 207, 'learning_rate': 0.22964600007590227, 'feature_fraction': 0.6344831004960017, 'bagging_fraction': 0.8527023916830954, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 11 with value: 0.8611111111111112.
[I 2025-09-17 13:16:17,224] Trial 13 finished with value: 0.9206349206349206 and parameters: {'num_leaves': 207, 'learning_rate': 0.21697945641700267, 'feature_fraction': 0.5352093572961962, 'bagging_fraction': 0.881452293117481, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,362] Trial 14 finished with value: 0.8849206349206349 and parameters: {'num_leaves': 198, 'learning_rate': 0.21304958141768637, 'feature_fraction': 0.5219810975245093, 'bagging_fraction': 0.9924427083691812, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,468] Trial 15 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 200, 'learning_rate': 0.1831866529218705, 'feature_fraction': 0.4079479679693585, 'bagging_fraction': 0.9784301807480894, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,520] Trial 16 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 296, 'learning_rate': 0.018063659067716564, 'feature_fraction': 0.5082597174935135, 'bagging_fraction': 0.9995458298035589, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,649] Trial 17 finished with value: 0.873015873015873 and parameters: {'num_leaves': 199, 'learning_rate': 0.25106749668782297, 'feature_fraction': 0.5194980250563429, 'bagging_fraction': 0.9174478685816434, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,692] Trial 18 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 182, 'learning_rate': 0.1847169985004801, 'feature_fraction': 0.40647379961019864, 'bagging_fraction': 0.7843857877518847, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,715] Trial 19 finished with value: 0.6666666666666666 and parameters: {'num_leaves': 220, 'learning_rate': 0.1837561493499285, 'feature_fraction': 0.6693124308520684, 'bagging_fraction': 0.8995989864942527, 'bagging_freq': 7, 'min_child_samples': 61}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,729] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.2504357638975164, 'feature_fraction': 0.4625019698540035, 'bagging_fraction': 0.727066655634487, 'bagging_freq': 6, 'min_child_samples': 98}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,858] Trial 21 finished with value: 0.8849206349206349 and parameters: {'num_leaves': 189, 'learning_rate': 0.2534790851456662, 'feature_fraction': 0.5259839461641089, 'bagging_fraction': 0.9196816168175749, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:17,999] Trial 22 finished with value: 0.9007936507936508 and parameters: {'num_leaves': 175, 'learning_rate': 0.25132461648328974, 'feature_fraction': 0.5253866322377937, 'bagging_fraction': 0.9240708100904435, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,029] Trial 23 finished with value: 0.726190476190476 and parameters: {'num_leaves': 117, 'learning_rate': 0.20597083684498402, 'feature_fraction': 0.6294336537908654, 'bagging_fraction': 0.8242106682031709, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,088] Trial 24 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 219, 'learning_rate': 0.2281286594162728, 'feature_fraction': 0.4766023463666593, 'bagging_fraction': 0.9936130315861974, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,142] Trial 25 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 167, 'learning_rate': 0.17026376166156426, 'feature_fraction': 0.5675921354370959, 'bagging_fraction': 0.9348543558513868, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,198] Trial 26 finished with value: 0.8611111111111112 and parameters: {'num_leaves': 285, 'learning_rate': 0.262039372531291, 'feature_fraction': 0.5051607015282725, 'bagging_fraction': 0.8993229183558703, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,225] Trial 27 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 131, 'learning_rate': 0.2984630938919044, 'feature_fraction': 0.7474868000862691, 'bagging_fraction': 0.7249951161914421, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,330] Trial 28 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 85, 'learning_rate': 0.21530711216444617, 'feature_fraction': 0.6580093896940068, 'bagging_fraction': 0.8176028934933569, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,354] Trial 29 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 84, 'learning_rate': 0.11011804798936889, 'feature_fraction': 0.8435418813558, 'bagging_fraction': 0.8122890242050584, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,423] Trial 30 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 62, 'learning_rate': 0.03421817165127443, 'feature_fraction': 0.6815041963639855, 'bagging_fraction': 0.6735525076167941, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,557] Trial 31 finished with value: 0.9007936507936507 and parameters: {'num_leaves': 129, 'learning_rate': 0.2017282363882687, 'feature_fraction': 0.5937627913203484, 'bagging_fraction': 0.941727027034114, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,597] Trial 32 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 125, 'learning_rate': 0.20099358807154322, 'feature_fraction': 0.6477767984102117, 'bagging_fraction': 0.8223788412763485, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,640] Trial 33 finished with value: 0.8055555555555555 and parameters: {'num_leaves': 94, 'learning_rate': 0.2336505121201954, 'feature_fraction': 0.5940456115258638, 'bagging_fraction': 0.8891571530360385, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,698] Trial 34 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 145, 'learning_rate': 0.2707128819084282, 'feature_fraction': 0.7330614115961357, 'bagging_fraction': 0.9495319188472389, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,713] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 62, 'learning_rate': 0.1660224192823935, 'feature_fraction': 0.7942890141443998, 'bagging_fraction': 0.8791303279892381, 'bagging_freq': 6, 'min_child_samples': 89}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,749] Trial 36 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 169, 'learning_rate': 0.24327634571447437, 'feature_fraction': 0.555360163367072, 'bagging_fraction': 0.7656520992552118, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,775] Trial 37 finished with value: 0.753968253968254 and parameters: {'num_leaves': 108, 'learning_rate': 0.13051366446335713, 'feature_fraction': 0.5977385049979268, 'bagging_fraction': 0.5817415187677306, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,809] Trial 38 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 141, 'learning_rate': 0.21580580841723182, 'feature_fraction': 0.6564841516480457, 'bagging_fraction': 0.8434947079091957, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,832] Trial 39 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 235, 'learning_rate': 0.19455025729356967, 'feature_fraction': 0.9755978598542114, 'bagging_fraction': 0.9639917195437588, 'bagging_freq': 5, 'min_child_samples': 62}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,905] Trial 40 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 165, 'learning_rate': 0.16374588212805716, 'feature_fraction': 0.711906497293587, 'bagging_fraction': 0.5596555403167699, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,957] Trial 41 finished with value: 0.876984126984127 and parameters: {'num_leaves': 165, 'learning_rate': 0.16342006569087195, 'feature_fraction': 0.6911970400032748, 'bagging_fraction': 0.565493796437069, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:18,987] Trial 42 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 138, 'learning_rate': 0.13437628759297734, 'feature_fraction': 0.8255328256787897, 'bagging_fraction': 0.4934517789544227, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:19,068] Trial 43 finished with value: 0.8531746031746033 and parameters: {'num_leaves': 86, 'learning_rate': 0.19487744594296627, 'feature_fraction': 0.6178700448797261, 'bagging_fraction': 0.6273461820639438, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:19,094] Trial 44 finished with value: 0.6825396825396826 and parameters: {'num_leaves': 112, 'learning_rate': 0.15460353596601145, 'feature_fraction': 0.8912500205970925, 'bagging_fraction': 0.4167102294555182, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:19,153] Trial 45 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 159, 'learning_rate': 0.21700348599534583, 'feature_fraction': 0.7169167251045337, 'bagging_fraction': 0.48896474546598395, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:19,199] Trial 46 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 217, 'learning_rate': 0.2764094570465078, 'feature_fraction': 0.7725412786846945, 'bagging_fraction': 0.5293159979799631, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:19,241] Trial 47 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 231, 'learning_rate': 0.2399445840971251, 'feature_fraction': 0.5808957248924248, 'bagging_fraction': 0.74236366450857, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:19,268] Trial 48 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 183, 'learning_rate': 0.11487816887549362, 'feature_fraction': 0.48418649786017887, 'bagging_fraction': 0.6448637394701549, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:19,287] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 260, 'learning_rate': 0.176680834238514, 'feature_fraction': 0.44109279001219814, 'bagging_fraction': 0.801816293565917, 'bagging_freq': 7, 'min_child_samples': 83}. Best is trial 13 with value: 0.9206349206349206.
[I 2025-09-17 13:16:19,677] A new study created in memory with name: no-name-f22049d1-8fc9-44c9-a420-6a5999bd7101
[I 2025-09-17 13:16:19,690] Trial 0 finished with value: 0.6746411483253588 and parameters: {'num_leaves': 51, 'learning_rate': 0.18098862250103648, 'feature_fraction': 0.9562181029832638, 'bagging_fraction': 0.684287336257549, 'bagging_freq': 1, 'min_child_samples': 43}. Best is trial 0 with value: 0.6746411483253588.
[I 2025-09-17 13:16:19,700] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 122, 'learning_rate': 0.05605725894145017, 'feature_fraction': 0.7137849238192986, 'bagging_fraction': 0.8656358717151418, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 0 with value: 0.6746411483253588.
[I 2025-09-17 13:16:19,710] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 167, 'learning_rate': 0.03088799730571084, 'feature_fraction': 0.5172215196254408, 'bagging_fraction': 0.8440846369856516, 'bagging_freq': 3, 'min_child_samples': 93}. Best is trial 0 with value: 0.6746411483253588.
[I 2025-09-17 13:16:19,728] Trial 3 finished with value: 0.7751196172248803 and parameters: {'num_leaves': 210, 'learning_rate': 0.28657994856468577, 'feature_fraction': 0.9453979676171872, 'bagging_fraction': 0.9832403787067494, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 3 with value: 0.7751196172248803.
[I 2025-09-17 13:16:19,735] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 188, 'learning_rate': 0.28087898201893513, 'feature_fraction': 0.697283611223533, 'bagging_fraction': 0.6269055907110653, 'bagging_freq': 7, 'min_child_samples': 60}. Best is trial 3 with value: 0.7751196172248803.
[I 2025-09-17 13:16:19,744] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 242, 'learning_rate': 0.013232948470784083, 'feature_fraction': 0.5633084561868228, 'bagging_fraction': 0.9265769647696798, 'bagging_freq': 7, 'min_child_samples': 68}. Best is trial 3 with value: 0.7751196172248803.
[I 2025-09-17 13:16:19,764] Trial 6 finished with value: 0.8229665071770335 and parameters: {'num_leaves': 28, 'learning_rate': 0.15174933020757636, 'feature_fraction': 0.7106883968569059, 'bagging_fraction': 0.8909503526949896, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 6 with value: 0.8229665071770335.
[I 2025-09-17 13:16:19,807] Trial 7 finished with value: 0.8708133971291866 and parameters: {'num_leaves': 288, 'learning_rate': 0.14807978699029015, 'feature_fraction': 0.4423679646228309, 'bagging_fraction': 0.588637150944465, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 7 with value: 0.8708133971291866.
[I 2025-09-17 13:16:19,827] Trial 8 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 57, 'learning_rate': 0.01935212087992951, 'feature_fraction': 0.7241050032248806, 'bagging_fraction': 0.9250464166559874, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 7 with value: 0.8708133971291866.
[I 2025-09-17 13:16:19,837] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 246, 'learning_rate': 0.054626659433251235, 'feature_fraction': 0.610649922623426, 'bagging_fraction': 0.5804575926767068, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 7 with value: 0.8708133971291866.
[I 2025-09-17 13:16:19,914] Trial 10 finished with value: 0.8755980861244019 and parameters: {'num_leaves': 299, 'learning_rate': 0.14033610196422275, 'feature_fraction': 0.40877099453688154, 'bagging_fraction': 0.4517726390561271, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 10 with value: 0.8755980861244019.
[I 2025-09-17 13:16:19,972] Trial 11 finished with value: 0.770334928229665 and parameters: {'num_leaves': 288, 'learning_rate': 0.14247177379583656, 'feature_fraction': 0.4074327295354032, 'bagging_fraction': 0.42268026655367635, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 10 with value: 0.8755980861244019.
[I 2025-09-17 13:16:20,025] Trial 12 finished with value: 0.8373205741626795 and parameters: {'num_leaves': 300, 'learning_rate': 0.0973432240442387, 'feature_fraction': 0.41114491551107396, 'bagging_fraction': 0.4600892140713131, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 10 with value: 0.8755980861244019.
[I 2025-09-17 13:16:20,055] Trial 13 finished with value: 0.715311004784689 and parameters: {'num_leaves': 260, 'learning_rate': 0.21159148238800995, 'feature_fraction': 0.47350691532555095, 'bagging_fraction': 0.5243508071251091, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 10 with value: 0.8755980861244019.
[I 2025-09-17 13:16:20,107] Trial 14 finished with value: 0.861244019138756 and parameters: {'num_leaves': 117, 'learning_rate': 0.10636822827217757, 'feature_fraction': 0.6041006848379802, 'bagging_fraction': 0.765504920435593, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 10 with value: 0.8755980861244019.
[I 2025-09-17 13:16:20,200] Trial 15 finished with value: 0.9138755980861244 and parameters: {'num_leaves': 216, 'learning_rate': 0.22337095144961266, 'feature_fraction': 0.47870016451977193, 'bagging_fraction': 0.514712364885938, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,217] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 222, 'learning_rate': 0.23446912334657521, 'feature_fraction': 0.841828205179327, 'bagging_fraction': 0.49434258427786065, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,244] Trial 17 finished with value: 0.7177033492822965 and parameters: {'num_leaves': 136, 'learning_rate': 0.24409502825483534, 'feature_fraction': 0.48589934260782197, 'bagging_fraction': 0.4030545823532097, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,334] Trial 18 finished with value: 0.7416267942583732 and parameters: {'num_leaves': 190, 'learning_rate': 0.19402172169110826, 'feature_fraction': 0.5347800819462765, 'bagging_fraction': 0.5459667190842926, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,348] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 267, 'learning_rate': 0.10751383084784674, 'feature_fraction': 0.6350274106712316, 'bagging_fraction': 0.6897560878650957, 'bagging_freq': 5, 'min_child_samples': 80}. Best is trial 15 with value: 0.9138755980861244.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.528917
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.38052
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.420725
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.466341
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.550625
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.437966
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.511152
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.612353
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.428998
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.433909
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.573822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.512025
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.482065
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.445396
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.565019
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.387807
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.53527
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.46014
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.403331
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.555156
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.495785
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.484172
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.580891
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.563389
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.47265
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.583707
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.393046
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.484069
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.588706
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.489296
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.614664
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.507415
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.48079
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.521672
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.570889
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.655607
Training model for P056... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.609913
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.542101
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.502286
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.449501
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.576989
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.465966
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.532555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.497686
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.58297
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.471084
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.366765
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.583304
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.528973
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:20,363] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.2605082959065569, 'feature_fraction': 0.7897747314592678, 'bagging_fraction': 0.4702323655090356, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,418] Trial 21 finished with value: 0.7607655502392344 and parameters: {'num_leaves': 277, 'learning_rate': 0.1339786705153875, 'feature_fraction': 0.45177099423222855, 'bagging_fraction': 0.6082964286667953, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,448] Trial 22 finished with value: 0.8181818181818182 and parameters: {'num_leaves': 299, 'learning_rate': 0.17741911611080255, 'feature_fraction': 0.40410569393551915, 'bagging_fraction': 0.5543244864974701, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,472] Trial 23 finished with value: 0.8708133971291866 and parameters: {'num_leaves': 237, 'learning_rate': 0.21406711816854454, 'feature_fraction': 0.4769166658377361, 'bagging_fraction': 0.6450248668573499, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,530] Trial 24 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 269, 'learning_rate': 0.12365007617378487, 'feature_fraction': 0.5586125119475853, 'bagging_fraction': 0.7572287409505987, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,545] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 192, 'learning_rate': 0.16457798281002467, 'feature_fraction': 0.45723106129638313, 'bagging_fraction': 0.50999413482226, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,566] Trial 26 finished with value: 0.4832535885167464 and parameters: {'num_leaves': 252, 'learning_rate': 0.08920757368743536, 'feature_fraction': 0.5070176117832318, 'bagging_fraction': 0.43675068404002604, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,598] Trial 27 finished with value: 0.770334928229665 and parameters: {'num_leaves': 164, 'learning_rate': 0.20200378251985246, 'feature_fraction': 0.44615034238722595, 'bagging_fraction': 0.599045473126165, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,632] Trial 28 finished with value: 0.8755980861244019 and parameters: {'num_leaves': 281, 'learning_rate': 0.15648156427271265, 'feature_fraction': 0.5698073386778648, 'bagging_fraction': 0.4848610412923861, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,653] Trial 29 finished with value: 0.8421052631578946 and parameters: {'num_leaves': 217, 'learning_rate': 0.18140180723713073, 'feature_fraction': 0.6634944951523278, 'bagging_fraction': 0.4778974341467757, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,668] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 86, 'learning_rate': 0.2258251612606756, 'feature_fraction': 0.5643941183353688, 'bagging_fraction': 0.43734472751564013, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,725] Trial 31 finished with value: 0.8660287081339713 and parameters: {'num_leaves': 280, 'learning_rate': 0.16386762725453038, 'feature_fraction': 0.42793791446280816, 'bagging_fraction': 0.5577868913957128, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,853] Trial 32 finished with value: 0.84688995215311 and parameters: {'num_leaves': 284, 'learning_rate': 0.07679631550475469, 'feature_fraction': 0.5173322988908203, 'bagging_fraction': 0.6528836051084121, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,895] Trial 33 finished with value: 0.8660287081339713 and parameters: {'num_leaves': 259, 'learning_rate': 0.12372216772515648, 'feature_fraction': 0.498279624546351, 'bagging_fraction': 0.5225676142603674, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,934] Trial 34 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 235, 'learning_rate': 0.18149769826841952, 'feature_fraction': 0.5417972514427224, 'bagging_fraction': 0.7433705941512477, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,956] Trial 35 finished with value: 0.7033492822966507 and parameters: {'num_leaves': 298, 'learning_rate': 0.1470024424975916, 'feature_fraction': 0.5897956749203699, 'bagging_fraction': 0.5715885667489675, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:20,998] Trial 36 finished with value: 0.8516746411483254 and parameters: {'num_leaves': 203, 'learning_rate': 0.26575707868878723, 'feature_fraction': 0.4402392511955357, 'bagging_fraction': 0.4973402015815348, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,023] Trial 37 finished with value: 0.8373205741626795 and parameters: {'num_leaves': 230, 'learning_rate': 0.0699205325367855, 'feature_fraction': 0.928196868792236, 'bagging_fraction': 0.5304432104943743, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,042] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 176, 'learning_rate': 0.1252086181014466, 'feature_fraction': 0.5118426528274226, 'bagging_fraction': 0.45220007209844154, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,066] Trial 39 finished with value: 0.8373205741626795 and parameters: {'num_leaves': 145, 'learning_rate': 0.16132547975533393, 'feature_fraction': 0.6465028226893674, 'bagging_fraction': 0.40139082659206965, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,169] Trial 40 finished with value: 0.8133971291866028 and parameters: {'num_leaves': 251, 'learning_rate': 0.2926471203410198, 'feature_fraction': 0.4005764998401001, 'bagging_fraction': 0.7217200291044149, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,189] Trial 41 finished with value: 0.8157894736842105 and parameters: {'num_leaves': 272, 'learning_rate': 0.20354192493036055, 'feature_fraction': 0.4710788523404858, 'bagging_fraction': 0.6223587230181199, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,243] Trial 42 finished with value: 0.7368421052631579 and parameters: {'num_leaves': 241, 'learning_rate': 0.22388574253073038, 'feature_fraction': 0.43259604230757503, 'bagging_fraction': 0.6647387217531563, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,280] Trial 43 finished with value: 0.784688995215311 and parameters: {'num_leaves': 286, 'learning_rate': 0.18946396844201657, 'feature_fraction': 0.48217138691592726, 'bagging_fraction': 0.6614183651323908, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,292] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 262, 'learning_rate': 0.25250137582943566, 'feature_fraction': 0.5820471005070298, 'bagging_fraction': 0.813921060700462, 'bagging_freq': 2, 'min_child_samples': 55}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,325] Trial 45 finished with value: 0.7799043062200958 and parameters: {'num_leaves': 235, 'learning_rate': 0.27586937881640605, 'feature_fraction': 0.532418214019043, 'bagging_fraction': 0.5965562484284826, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,383] Trial 46 finished with value: 0.7942583732057416 and parameters: {'num_leaves': 288, 'learning_rate': 0.13990149893153359, 'feature_fraction': 0.4683705087821073, 'bagging_fraction': 0.6377260039589239, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,392] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 204, 'learning_rate': 0.20970159958641998, 'feature_fraction': 0.747328100739699, 'bagging_fraction': 0.9908725211026048, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,419] Trial 48 finished with value: 0.8325358851674641 and parameters: {'num_leaves': 12, 'learning_rate': 0.21963178507591835, 'feature_fraction': 0.42607573788753056, 'bagging_fraction': 0.48749862720833337, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,458] Trial 49 finished with value: 0.7703349282296651 and parameters: {'num_leaves': 250, 'learning_rate': 0.23817730641741658, 'feature_fraction': 0.47576770576168786, 'bagging_fraction': 0.5398284427963544, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 15 with value: 0.9138755980861244.
[I 2025-09-17 13:16:21,776] A new study created in memory with name: no-name-d4f400f6-e463-4cfd-b187-e64766e64f79
[I 2025-09-17 13:16:21,856] Trial 0 finished with value: 0.7559808612440192 and parameters: {'num_leaves': 171, 'learning_rate': 0.12982034244772567, 'feature_fraction': 0.43476717543114995, 'bagging_fraction': 0.8812956152388989, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 0 with value: 0.7559808612440192.
[I 2025-09-17 13:16:21,862] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 17, 'learning_rate': 0.18226140765501972, 'feature_fraction': 0.8922726990402001, 'bagging_fraction': 0.6194290107288478, 'bagging_freq': 1, 'min_child_samples': 85}. Best is trial 0 with value: 0.7559808612440192.
[I 2025-09-17 13:16:21,880] Trial 2 finished with value: 0.6889952153110048 and parameters: {'num_leaves': 188, 'learning_rate': 0.053848825669902685, 'feature_fraction': 0.6978453957451582, 'bagging_fraction': 0.8240889270895229, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 0 with value: 0.7559808612440192.
[I 2025-09-17 13:16:21,904] Trial 3 finished with value: 0.6698564593301435 and parameters: {'num_leaves': 299, 'learning_rate': 0.08847800220688275, 'feature_fraction': 0.49396593841185543, 'bagging_fraction': 0.4843055440579464, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 0 with value: 0.7559808612440192.
[I 2025-09-17 13:16:21,914] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 28, 'learning_rate': 0.1317706542529534, 'feature_fraction': 0.9871776341805597, 'bagging_fraction': 0.5571486982661216, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 0 with value: 0.7559808612440192.
[I 2025-09-17 13:16:21,928] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 121, 'learning_rate': 0.24697279189505314, 'feature_fraction': 0.728265501732992, 'bagging_fraction': 0.4700307859763935, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 0 with value: 0.7559808612440192.
[I 2025-09-17 13:16:21,979] Trial 6 finished with value: 0.7272727272727273 and parameters: {'num_leaves': 227, 'learning_rate': 0.18450624964351264, 'feature_fraction': 0.4910055855838647, 'bagging_fraction': 0.7318127107598154, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 0 with value: 0.7559808612440192.
[I 2025-09-17 13:16:21,987] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 174, 'learning_rate': 0.11114889185124958, 'feature_fraction': 0.6091541047106734, 'bagging_fraction': 0.5209679747221603, 'bagging_freq': 5, 'min_child_samples': 93}. Best is trial 0 with value: 0.7559808612440192.
[I 2025-09-17 13:16:22,028] Trial 8 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 159, 'learning_rate': 0.14919481540949803, 'feature_fraction': 0.4600191930893462, 'bagging_fraction': 0.9311031590760855, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 8 with value: 0.8038277511961722.
[I 2025-09-17 13:16:22,037] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 175, 'learning_rate': 0.2246798025687272, 'feature_fraction': 0.6309679678962669, 'bagging_fraction': 0.9318409488625318, 'bagging_freq': 3, 'min_child_samples': 74}. Best is trial 8 with value: 0.8038277511961722.
[I 2025-09-17 13:16:22,061] Trial 10 finished with value: 0.7129186602870814 and parameters: {'num_leaves': 81, 'learning_rate': 0.03564563266675998, 'feature_fraction': 0.8027070746211223, 'bagging_fraction': 0.9709528966684008, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 8 with value: 0.8038277511961722.
[I 2025-09-17 13:16:22,130] Trial 11 finished with value: 0.7177033492822966 and parameters: {'num_leaves': 234, 'learning_rate': 0.16901680578246672, 'feature_fraction': 0.4121632177504953, 'bagging_fraction': 0.863268196276683, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 8 with value: 0.8038277511961722.
[I 2025-09-17 13:16:22,167] Trial 12 finished with value: 0.7942583732057417 and parameters: {'num_leaves': 118, 'learning_rate': 0.2843019737155314, 'feature_fraction': 0.4139981208441499, 'bagging_fraction': 0.772477940879562, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 8 with value: 0.8038277511961722.
[I 2025-09-17 13:16:22,196] Trial 13 finished with value: 0.7703349282296651 and parameters: {'num_leaves': 114, 'learning_rate': 0.29684780047769144, 'feature_fraction': 0.5427762812394, 'bagging_fraction': 0.7551400290079241, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 8 with value: 0.8038277511961722.
[I 2025-09-17 13:16:22,226] Trial 14 finished with value: 0.7751196172248803 and parameters: {'num_leaves': 83, 'learning_rate': 0.2829518669148589, 'feature_fraction': 0.4031842753436129, 'bagging_fraction': 0.6519808412239536, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 8 with value: 0.8038277511961722.
[I 2025-09-17 13:16:22,237] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 115, 'learning_rate': 0.21982956078700616, 'feature_fraction': 0.5641884466527027, 'bagging_fraction': 0.7903623096506686, 'bagging_freq': 3, 'min_child_samples': 60}. Best is trial 8 with value: 0.8038277511961722.
[I 2025-09-17 13:16:22,281] Trial 16 finished with value: 0.8086124401913876 and parameters: {'num_leaves': 64, 'learning_rate': 0.07755733196090926, 'feature_fraction': 0.48462257948909243, 'bagging_fraction': 0.9294020865214272, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 16 with value: 0.8086124401913876.
[I 2025-09-17 13:16:22,336] Trial 17 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 64, 'learning_rate': 0.09025031953157833, 'feature_fraction': 0.5167620750593169, 'bagging_fraction': 0.9962320134089684, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 17 with value: 0.8181818181818181.
[I 2025-09-17 13:16:22,366] Trial 18 finished with value: 0.770334928229665 and parameters: {'num_leaves': 59, 'learning_rate': 0.06884845863026716, 'feature_fraction': 0.666984321517035, 'bagging_fraction': 0.40297040753986757, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 17 with value: 0.8181818181818181.
[I 2025-09-17 13:16:22,420] Trial 19 finished with value: 0.7846889952153111 and parameters: {'num_leaves': 48, 'learning_rate': 0.019637132003730934, 'feature_fraction': 0.5475412273105611, 'bagging_fraction': 0.9966501770174242, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 17 with value: 0.8181818181818181.
[I 2025-09-17 13:16:22,445] Trial 20 finished with value: 0.7655502392344498 and parameters: {'num_leaves': 83, 'learning_rate': 0.09351593183809857, 'feature_fraction': 0.7722525158190072, 'bagging_fraction': 0.8912600623848762, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 17 with value: 0.8181818181818181.
[I 2025-09-17 13:16:22,483] Trial 21 finished with value: 0.84688995215311 and parameters: {'num_leaves': 144, 'learning_rate': 0.1449877456898501, 'feature_fraction': 0.48315471807964694, 'bagging_fraction': 0.9370722581405055, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:22,543] Trial 22 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 51, 'learning_rate': 0.07197418772346155, 'feature_fraction': 0.5064976307201963, 'bagging_fraction': 0.9471232647927631, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:22,569] Trial 23 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 140, 'learning_rate': 0.11170012614047639, 'feature_fraction': 0.6010897701376755, 'bagging_fraction': 0.9923601261707482, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:22,628] Trial 24 finished with value: 0.784688995215311 and parameters: {'num_leaves': 12, 'learning_rate': 0.042880847133242986, 'feature_fraction': 0.5365802373400065, 'bagging_fraction': 0.8598193711097263, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:22,643] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 214, 'learning_rate': 0.1474587487601614, 'feature_fraction': 0.5066870294798236, 'bagging_fraction': 0.9319481068420286, 'bagging_freq': 6, 'min_child_samples': 63}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:22,667] Trial 26 finished with value: 0.7511961722488039 and parameters: {'num_leaves': 39, 'learning_rate': 0.11378464632560145, 'feature_fraction': 0.5759070566070599, 'bagging_fraction': 0.8176633239468595, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:22,721] Trial 27 finished with value: 0.7990430622009569 and parameters: {'num_leaves': 89, 'learning_rate': 0.05987638481774446, 'feature_fraction': 0.6504496248018448, 'bagging_fraction': 0.9618305372871065, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:22,856] Trial 28 finished with value: 0.8229665071770335 and parameters: {'num_leaves': 273, 'learning_rate': 0.08981221348780795, 'feature_fraction': 0.45406377843372375, 'bagging_fraction': 0.6886874609036596, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 21 with value: 0.84688995215311.
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.551882
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.528769
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.484927
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.497996
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.655387
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.54944
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.49704
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.537742
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.423736
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.454601
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.477201
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.477126
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.607749
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.471064
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.505677
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.540295
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.549582
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.522985
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.571305
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.520111
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.520843
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.521653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.518762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.578393
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.53682
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.609119
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.606501
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.573749
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.516905
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.5876
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.581797
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.545755
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.53521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.536161
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.511533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.508598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.534984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.538483
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.570795
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.485901
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.472417
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.527183
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.542267
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.570854
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.515137
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.495183
[I 2025-09-17 13:16:22,952] Trial 29 finished with value: 0.8325358851674641 and parameters: {'num_leaves': 283, 'learning_rate': 0.13488231108493956, 'feature_fraction': 0.45586454069086924, 'bagging_fraction': 0.6808343592399897, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,084] Trial 30 finished with value: 0.8373205741626794 and parameters: {'num_leaves': 264, 'learning_rate': 0.1357251507754301, 'feature_fraction': 0.4618356453764516, 'bagging_fraction': 0.6054660511239983, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,224] Trial 31 finished with value: 0.8325358851674641 and parameters: {'num_leaves': 260, 'learning_rate': 0.1302084219336244, 'feature_fraction': 0.44442479959749015, 'bagging_fraction': 0.5980423364642486, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,277] Trial 32 finished with value: 0.722488038277512 and parameters: {'num_leaves': 299, 'learning_rate': 0.17312002473003188, 'feature_fraction': 0.4523939206075441, 'bagging_fraction': 0.6511863619130485, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,362] Trial 33 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 201, 'learning_rate': 0.19072021785209262, 'feature_fraction': 0.4838732347637328, 'bagging_fraction': 0.7043828605033037, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,395] Trial 34 finished with value: 0.7942583732057417 and parameters: {'num_leaves': 274, 'learning_rate': 0.20210469627035577, 'feature_fraction': 0.5735284226055977, 'bagging_fraction': 0.5982481519599675, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,496] Trial 35 finished with value: 0.7942583732057416 and parameters: {'num_leaves': 254, 'learning_rate': 0.16223549865284848, 'feature_fraction': 0.43627351278047394, 'bagging_fraction': 0.5610036853401972, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,541] Trial 36 finished with value: 0.7607655502392345 and parameters: {'num_leaves': 285, 'learning_rate': 0.13435721895890085, 'feature_fraction': 0.8777431164966905, 'bagging_fraction': 0.6631334693004287, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,564] Trial 37 finished with value: 0.7464114832535885 and parameters: {'num_leaves': 245, 'learning_rate': 0.14848374613382587, 'feature_fraction': 0.5228779329035348, 'bagging_fraction': 0.7190186639588874, 'bagging_freq': 7, 'min_child_samples': 34}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,582] Trial 38 finished with value: 0.5358851674641149 and parameters: {'num_leaves': 136, 'learning_rate': 0.11343551413864414, 'feature_fraction': 0.48591749010905577, 'bagging_fraction': 0.8291131440376847, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,643] Trial 39 finished with value: 0.784688995215311 and parameters: {'num_leaves': 226, 'learning_rate': 0.01513956072200727, 'feature_fraction': 0.5993941865992415, 'bagging_fraction': 0.5405772766302389, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,656] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 192, 'learning_rate': 0.1250697111909637, 'feature_fraction': 0.7086225967815796, 'bagging_fraction': 0.6215179952499651, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 21 with value: 0.84688995215311.
[I 2025-09-17 13:16:23,763] Trial 41 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 257, 'learning_rate': 0.14381157448869888, 'feature_fraction': 0.4380522217654791, 'bagging_fraction': 0.5868394234289841, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:23,820] Trial 42 finished with value: 0.8229665071770335 and parameters: {'num_leaves': 280, 'learning_rate': 0.1432847360949443, 'feature_fraction': 0.4707074449728602, 'bagging_fraction': 0.5127242787761405, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:23,854] Trial 43 finished with value: 0.7703349282296651 and parameters: {'num_leaves': 257, 'learning_rate': 0.1026854443583238, 'feature_fraction': 0.40379164012479984, 'bagging_fraction': 0.6170919400840985, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:23,926] Trial 44 finished with value: 0.7607655502392344 and parameters: {'num_leaves': 300, 'learning_rate': 0.16564600633694448, 'feature_fraction': 0.44099425547000953, 'bagging_fraction': 0.6789157861477992, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:23,979] Trial 45 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 217, 'learning_rate': 0.19511057332163897, 'feature_fraction': 0.5068031261815724, 'bagging_fraction': 0.5821301661729956, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:24,008] Trial 46 finished with value: 0.69377990430622 and parameters: {'num_leaves': 163, 'learning_rate': 0.1782966310909027, 'feature_fraction': 0.42724998439930717, 'bagging_fraction': 0.4981972577815842, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:24,089] Trial 47 finished with value: 0.7799043062200957 and parameters: {'num_leaves': 238, 'learning_rate': 0.12408134534240745, 'feature_fraction': 0.4629327017812583, 'bagging_fraction': 0.7420582981594736, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:24,101] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 26, 'learning_rate': 0.16094288914297944, 'feature_fraction': 0.9358967824210269, 'bagging_fraction': 0.6283081534753611, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:24,168] Trial 49 finished with value: 0.784688995215311 and parameters: {'num_leaves': 105, 'learning_rate': 0.2087660580942879, 'feature_fraction': 0.4247107069646539, 'bagging_fraction': 0.4533540549878752, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 41 with value: 0.8947368421052632.
[I 2025-09-17 13:16:24,584] A new study created in memory with name: no-name-48223538-3d5c-4869-91f1-1c776af02a15
[I 2025-09-17 13:16:24,646] Trial 0 finished with value: 0.7268518518518519 and parameters: {'num_leaves': 37, 'learning_rate': 0.02800089562147623, 'feature_fraction': 0.5276676055163537, 'bagging_fraction': 0.8228332006372729, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 0 with value: 0.7268518518518519.
[I 2025-09-17 13:16:24,657] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.1353467406911687, 'feature_fraction': 0.7751397651325271, 'bagging_fraction': 0.4538785010254156, 'bagging_freq': 2, 'min_child_samples': 67}. Best is trial 0 with value: 0.7268518518518519.
[I 2025-09-17 13:16:24,672] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 210, 'learning_rate': 0.1342432205458527, 'feature_fraction': 0.9807986222513904, 'bagging_fraction': 0.4312231374863328, 'bagging_freq': 2, 'min_child_samples': 69}. Best is trial 0 with value: 0.7268518518518519.
[I 2025-09-17 13:16:24,683] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.23777606144342905, 'feature_fraction': 0.5218568434609813, 'bagging_fraction': 0.5732538417113677, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 0 with value: 0.7268518518518519.
[I 2025-09-17 13:16:24,689] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 159, 'learning_rate': 0.15710494749794268, 'feature_fraction': 0.8278357702543725, 'bagging_fraction': 0.72414828387972, 'bagging_freq': 1, 'min_child_samples': 59}. Best is trial 0 with value: 0.7268518518518519.
[I 2025-09-17 13:16:24,702] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 257, 'learning_rate': 0.26872682196953895, 'feature_fraction': 0.8038754594911734, 'bagging_fraction': 0.732811181142712, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 0 with value: 0.7268518518518519.
[I 2025-09-17 13:16:24,718] Trial 6 finished with value: 0.7824074074074076 and parameters: {'num_leaves': 208, 'learning_rate': 0.23476450191255305, 'feature_fraction': 0.6325304753820158, 'bagging_fraction': 0.6464025587942294, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 6 with value: 0.7824074074074076.
[I 2025-09-17 13:16:24,737] Trial 7 finished with value: 0.7546296296296297 and parameters: {'num_leaves': 178, 'learning_rate': 0.03004366699246399, 'feature_fraction': 0.5465965617128844, 'bagging_fraction': 0.6458359728559495, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 6 with value: 0.7824074074074076.
[I 2025-09-17 13:16:24,747] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 91, 'learning_rate': 0.12389526157036082, 'feature_fraction': 0.9641887699372694, 'bagging_fraction': 0.4590585694347897, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 6 with value: 0.7824074074074076.
[I 2025-09-17 13:16:24,755] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 239, 'learning_rate': 0.1889428086685404, 'feature_fraction': 0.9542257928395367, 'bagging_fraction': 0.6110846737303567, 'bagging_freq': 7, 'min_child_samples': 53}. Best is trial 6 with value: 0.7824074074074076.
[I 2025-09-17 13:16:24,770] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 295, 'learning_rate': 0.2854952822990691, 'feature_fraction': 0.6624968801279192, 'bagging_fraction': 0.9193109400851563, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 6 with value: 0.7824074074074076.
[I 2025-09-17 13:16:24,802] Trial 11 finished with value: 0.7916666666666667 and parameters: {'num_leaves': 116, 'learning_rate': 0.013884588372239593, 'feature_fraction': 0.4019982044731588, 'bagging_fraction': 0.6175758274563444, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 11 with value: 0.7916666666666667.
[I 2025-09-17 13:16:24,862] Trial 12 finished with value: 0.7824074074074074 and parameters: {'num_leaves': 105, 'learning_rate': 0.087836861228546, 'feature_fraction': 0.6696952001460117, 'bagging_fraction': 0.5510672000402681, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 11 with value: 0.7916666666666667.
[I 2025-09-17 13:16:24,892] Trial 13 finished with value: 0.7453703703703703 and parameters: {'num_leaves': 114, 'learning_rate': 0.20993404472667693, 'feature_fraction': 0.42753632113629136, 'bagging_fraction': 0.820450394053081, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 11 with value: 0.7916666666666667.
[I 2025-09-17 13:16:24,919] Trial 14 finished with value: 0.8240740740740741 and parameters: {'num_leaves': 10, 'learning_rate': 0.07923416481489141, 'feature_fraction': 0.4090585006361783, 'bagging_fraction': 0.6788294294170545, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 14 with value: 0.8240740740740741.
[I 2025-09-17 13:16:24,973] Trial 15 finished with value: 0.7916666666666667 and parameters: {'num_leaves': 13, 'learning_rate': 0.07086130412941827, 'feature_fraction': 0.4336453426349078, 'bagging_fraction': 0.8053211574449001, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 14 with value: 0.8240740740740741.
[I 2025-09-17 13:16:25,004] Trial 16 finished with value: 0.8472222222222222 and parameters: {'num_leaves': 61, 'learning_rate': 0.06988812669600869, 'feature_fraction': 0.4242662524320913, 'bagging_fraction': 0.5267572510799798, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,018] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 60, 'learning_rate': 0.0744263048118824, 'feature_fraction': 0.47985119722051367, 'bagging_fraction': 0.5170845127687111, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,168] Trial 18 finished with value: 0.8055555555555555 and parameters: {'num_leaves': 65, 'learning_rate': 0.09735817367077232, 'feature_fraction': 0.6014078002765847, 'bagging_fraction': 0.9984715338009276, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,186] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 24, 'learning_rate': 0.04891586033259179, 'feature_fraction': 0.4994049420403749, 'bagging_fraction': 0.507207185219183, 'bagging_freq': 1, 'min_child_samples': 89}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,226] Trial 20 finished with value: 0.787037037037037 and parameters: {'num_leaves': 60, 'learning_rate': 0.10865414793993737, 'feature_fraction': 0.5829770089432642, 'bagging_fraction': 0.7691639228182179, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,272] Trial 21 finished with value: 0.7268518518518519 and parameters: {'num_leaves': 65, 'learning_rate': 0.09528506356448273, 'feature_fraction': 0.5880226184593143, 'bagging_fraction': 0.9990332057747682, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,418] Trial 22 finished with value: 0.7361111111111112 and parameters: {'num_leaves': 37, 'learning_rate': 0.058792571870608115, 'feature_fraction': 0.4459150696944084, 'bagging_fraction': 0.8887868858313127, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,493] Trial 23 finished with value: 0.7685185185185185 and parameters: {'num_leaves': 81, 'learning_rate': 0.1518446349331321, 'feature_fraction': 0.7176667041103519, 'bagging_fraction': 0.6857621362497459, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,515] Trial 24 finished with value: 0.8194444444444445 and parameters: {'num_leaves': 134, 'learning_rate': 0.10923702884977665, 'feature_fraction': 0.4601469834756158, 'bagging_fraction': 0.8933332755288934, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,547] Trial 25 finished with value: 0.7453703703703703 and parameters: {'num_leaves': 134, 'learning_rate': 0.050427585889699394, 'feature_fraction': 0.46964474857816957, 'bagging_fraction': 0.9086825954042785, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,560] Trial 26 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.16937875397026864, 'feature_fraction': 0.40096971576812224, 'bagging_fraction': 0.40268357362022067, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,598] Trial 27 finished with value: 0.7638888888888888 and parameters: {'num_leaves': 142, 'learning_rate': 0.1121709782072446, 'feature_fraction': 0.47580447863234865, 'bagging_fraction': 0.6857393577224322, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,627] Trial 28 finished with value: 0.7453703703703703 and parameters: {'num_leaves': 39, 'learning_rate': 0.07745610516800913, 'feature_fraction': 0.5264473074181011, 'bagging_fraction': 0.8612937347449353, 'bagging_freq': 1, 'min_child_samples': 41}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,686] Trial 29 finished with value: 0.7268518518518519 and parameters: {'num_leaves': 47, 'learning_rate': 0.03462532231861771, 'feature_fraction': 0.5698200726130551, 'bagging_fraction': 0.9449973830948071, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,757] Trial 30 finished with value: 0.7083333333333333 and parameters: {'num_leaves': 97, 'learning_rate': 0.012460434689774216, 'feature_fraction': 0.4491718169708436, 'bagging_fraction': 0.7695790911272545, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,820] Trial 31 finished with value: 0.7685185185185185 and parameters: {'num_leaves': 77, 'learning_rate': 0.10044212071365799, 'feature_fraction': 0.6194908522325795, 'bagging_fraction': 0.9993977911541846, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,864] Trial 32 finished with value: 0.7824074074074074 and parameters: {'num_leaves': 36, 'learning_rate': 0.12145507941208447, 'feature_fraction': 0.4918831339377698, 'bagging_fraction': 0.9516737417235441, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,895] Trial 33 finished with value: 0.7916666666666666 and parameters: {'num_leaves': 134, 'learning_rate': 0.14422245083025192, 'feature_fraction': 0.7403804801833119, 'bagging_fraction': 0.8596434284555201, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,909] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 70, 'learning_rate': 0.0885434245575756, 'feature_fraction': 0.5296028450396, 'bagging_fraction': 0.9631563599944515, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,966] Trial 35 finished with value: 0.7361111111111112 and parameters: {'num_leaves': 160, 'learning_rate': 0.05693065664667183, 'feature_fraction': 0.4066725209205889, 'bagging_fraction': 0.8646736819263303, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:25,979] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 25, 'learning_rate': 0.16708130966082935, 'feature_fraction': 0.8715164022195837, 'bagging_fraction': 0.5640352713741082, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 16 with value: 0.8472222222222222.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.489925
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.573705
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.533958
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.565239
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.584806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.516467
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.549383
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.547239
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.561438
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.646407
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.55221
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.395513
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.501948
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.550024
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.540095
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.522252
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.608923
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.566422
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.598058
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.586722
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.553244
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.578082
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.598709
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.548378
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.587223
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.546197
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.528309
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.523159
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.53919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.547614
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.563773
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.582549
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.587085
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.549166
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.567857
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.548388
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.574165
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.584097
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.589664
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.565005
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.552864
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.553478
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.5695
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:26,005] Trial 37 finished with value: 0.7268518518518519 and parameters: {'num_leaves': 50, 'learning_rate': 0.12969511453141847, 'feature_fraction': 0.5056228728327696, 'bagging_fraction': 0.49945733213749643, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,020] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.11233419591701116, 'feature_fraction': 0.565580695722443, 'bagging_fraction': 0.729083751276149, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,051] Trial 39 finished with value: 0.8055555555555555 and parameters: {'num_leaves': 85, 'learning_rate': 0.03756589327642085, 'feature_fraction': 0.45534955143542105, 'bagging_fraction': 0.7793368139064453, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,065] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 117, 'learning_rate': 0.06989677161071503, 'feature_fraction': 0.6078290613569546, 'bagging_fraction': 0.606223628549378, 'bagging_freq': 3, 'min_child_samples': 76}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,100] Trial 41 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 87, 'learning_rate': 0.03860524763655046, 'feature_fraction': 0.4548392055799949, 'bagging_fraction': 0.7729040095507133, 'bagging_freq': 1, 'min_child_samples': 36}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,129] Trial 42 finished with value: 0.7037037037037036 and parameters: {'num_leaves': 99, 'learning_rate': 0.08487662601534846, 'feature_fraction': 0.5447633363427555, 'bagging_fraction': 0.6535838555101199, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,157] Trial 43 finished with value: 0.6851851851851852 and parameters: {'num_leaves': 51, 'learning_rate': 0.05826398445068145, 'feature_fraction': 0.42796247618549427, 'bagging_fraction': 0.8006129840684557, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,199] Trial 44 finished with value: 0.7592592592592593 and parameters: {'num_leaves': 152, 'learning_rate': 0.02278053258571333, 'feature_fraction': 0.5054142181244115, 'bagging_fraction': 0.9220196727217675, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,212] Trial 45 finished with value: 0.5 and parameters: {'num_leaves': 81, 'learning_rate': 0.04397328376851929, 'feature_fraction': 0.6472580995608727, 'bagging_fraction': 0.7109628399624831, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,259] Trial 46 finished with value: 0.7777777777777777 and parameters: {'num_leaves': 112, 'learning_rate': 0.06744566883342859, 'feature_fraction': 0.42556639950449027, 'bagging_fraction': 0.837597216792771, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,322] Trial 47 finished with value: 0.7453703703703703 and parameters: {'num_leaves': 125, 'learning_rate': 0.09973859286167983, 'feature_fraction': 0.4587796442626953, 'bagging_fraction': 0.8898250381416958, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,352] Trial 48 finished with value: 0.7407407407407407 and parameters: {'num_leaves': 191, 'learning_rate': 0.1396526068018893, 'feature_fraction': 0.7689682859352263, 'bagging_fraction': 0.9709118893408164, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,386] Trial 49 finished with value: 0.7499999999999999 and parameters: {'num_leaves': 25, 'learning_rate': 0.08391457292022597, 'feature_fraction': 0.6784876540352702, 'bagging_fraction': 0.7429180728069107, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 16 with value: 0.8472222222222222.
[I 2025-09-17 13:16:26,677] A new study created in memory with name: no-name-febbaeaa-198f-4d73-9f7d-2c32141a8dee
[I 2025-09-17 13:16:26,695] Trial 0 finished with value: 0.8194444444444444 and parameters: {'num_leaves': 22, 'learning_rate': 0.1939483628123372, 'feature_fraction': 0.5838024344050063, 'bagging_fraction': 0.8113657753423715, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 0 with value: 0.8194444444444444.
[I 2025-09-17 13:16:26,742] Trial 1 finished with value: 0.8009259259259259 and parameters: {'num_leaves': 177, 'learning_rate': 0.24304430604781627, 'feature_fraction': 0.6961343457868198, 'bagging_fraction': 0.733590699360319, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 0 with value: 0.8194444444444444.
[I 2025-09-17 13:16:26,751] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 220, 'learning_rate': 0.13861303422540683, 'feature_fraction': 0.4869044485093008, 'bagging_fraction': 0.7618273712567767, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 0 with value: 0.8194444444444444.
[I 2025-09-17 13:16:26,760] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 131, 'learning_rate': 0.20499108156054938, 'feature_fraction': 0.45375358825765255, 'bagging_fraction': 0.8347840475445365, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 0 with value: 0.8194444444444444.
[I 2025-09-17 13:16:26,768] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 193, 'learning_rate': 0.05457382603958805, 'feature_fraction': 0.5147146356136134, 'bagging_fraction': 0.5952422570817697, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 0 with value: 0.8194444444444444.
[I 2025-09-17 13:16:26,784] Trial 5 finished with value: 0.9027777777777778 and parameters: {'num_leaves': 146, 'learning_rate': 0.2578134272023012, 'feature_fraction': 0.5188387514691828, 'bagging_fraction': 0.9279534759207865, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:26,819] Trial 6 finished with value: 0.7268518518518519 and parameters: {'num_leaves': 293, 'learning_rate': 0.012895518694312881, 'feature_fraction': 0.7907445615046333, 'bagging_fraction': 0.7334990361329056, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:26,845] Trial 7 finished with value: 0.7685185185185185 and parameters: {'num_leaves': 298, 'learning_rate': 0.19560776934922863, 'feature_fraction': 0.9968316657037007, 'bagging_fraction': 0.5960028001889712, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:26,854] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 256, 'learning_rate': 0.19935921544065294, 'feature_fraction': 0.7234647223961176, 'bagging_fraction': 0.4812805261520095, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:26,869] Trial 9 finished with value: 0.5694444444444444 and parameters: {'num_leaves': 29, 'learning_rate': 0.16992296230123757, 'feature_fraction': 0.5023169858150748, 'bagging_fraction': 0.7266932958963987, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:26,889] Trial 10 finished with value: 0.6203703703703703 and parameters: {'num_leaves': 112, 'learning_rate': 0.29997504357132354, 'feature_fraction': 0.6373925752724273, 'bagging_fraction': 0.9707704341609625, 'bagging_freq': 1, 'min_child_samples': 53}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:26,905] Trial 11 finished with value: 0.8101851851851852 and parameters: {'num_leaves': 16, 'learning_rate': 0.28854206518214204, 'feature_fraction': 0.6140647331254947, 'bagging_fraction': 0.9433000075999822, 'bagging_freq': 7, 'min_child_samples': 40}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:26,936] Trial 12 finished with value: 0.7592592592592593 and parameters: {'num_leaves': 77, 'learning_rate': 0.12930030326748326, 'feature_fraction': 0.4086663032454021, 'bagging_fraction': 0.8715358594297055, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,006] Trial 13 finished with value: 0.8171296296296297 and parameters: {'num_leaves': 67, 'learning_rate': 0.24895787312792603, 'feature_fraction': 0.5653107718505261, 'bagging_fraction': 0.8492650772540348, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,024] Trial 14 finished with value: 0.5324074074074074 and parameters: {'num_leaves': 83, 'learning_rate': 0.09727403831098727, 'feature_fraction': 0.7897532749283965, 'bagging_fraction': 0.9064553983714957, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,043] Trial 15 finished with value: 0.7499999999999999 and parameters: {'num_leaves': 144, 'learning_rate': 0.25508806798160505, 'feature_fraction': 0.5809768519996549, 'bagging_fraction': 0.8091745469609746, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,073] Trial 16 finished with value: 0.7407407407407407 and parameters: {'num_leaves': 46, 'learning_rate': 0.24626542779381488, 'feature_fraction': 0.950940678679716, 'bagging_fraction': 0.6435666468191162, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,098] Trial 17 finished with value: 0.8379629629629629 and parameters: {'num_leaves': 109, 'learning_rate': 0.1717542465252892, 'feature_fraction': 0.6799131593553205, 'bagging_fraction': 0.9663354815367912, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,124] Trial 18 finished with value: 0.6712962962962963 and parameters: {'num_leaves': 110, 'learning_rate': 0.10042327790791068, 'feature_fraction': 0.8822437554674947, 'bagging_fraction': 0.9618402131770107, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,139] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.15898527235611112, 'feature_fraction': 0.7597098246333274, 'bagging_fraction': 0.9976199353856797, 'bagging_freq': 6, 'min_child_samples': 65}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,177] Trial 20 finished with value: 0.7268518518518519 and parameters: {'num_leaves': 210, 'learning_rate': 0.22476107511606092, 'feature_fraction': 0.679923780356068, 'bagging_fraction': 0.9088813210843948, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,199] Trial 21 finished with value: 0.787037037037037 and parameters: {'num_leaves': 119, 'learning_rate': 0.17798706458848826, 'feature_fraction': 0.5561565242851233, 'bagging_fraction': 0.7972163966377023, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,221] Trial 22 finished with value: 0.8379629629629629 and parameters: {'num_leaves': 160, 'learning_rate': 0.27059343193912316, 'feature_fraction': 0.6277697698029805, 'bagging_fraction': 0.9080691528749139, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,250] Trial 23 finished with value: 0.699074074074074 and parameters: {'num_leaves': 160, 'learning_rate': 0.27538013460534505, 'feature_fraction': 0.6533269264466918, 'bagging_fraction': 0.9061987686871686, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,272] Trial 24 finished with value: 0.6203703703703703 and parameters: {'num_leaves': 159, 'learning_rate': 0.22880090157805946, 'feature_fraction': 0.8529055245869552, 'bagging_fraction': 0.4354565668975444, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,288] Trial 25 finished with value: 0.6481481481481481 and parameters: {'num_leaves': 233, 'learning_rate': 0.2741839751771371, 'feature_fraction': 0.4000165283236614, 'bagging_fraction': 0.9957915956820005, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,322] Trial 26 finished with value: 0.8009259259259259 and parameters: {'num_leaves': 96, 'learning_rate': 0.22090329600746564, 'feature_fraction': 0.7360390202131631, 'bagging_fraction': 0.8881322325079063, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,341] Trial 27 finished with value: 0.7685185185185185 and parameters: {'num_leaves': 138, 'learning_rate': 0.2677987514805327, 'feature_fraction': 0.5328243676356496, 'bagging_fraction': 0.9277365781321301, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,387] Trial 28 finished with value: 0.8009259259259258 and parameters: {'num_leaves': 164, 'learning_rate': 0.10074928495330834, 'feature_fraction': 0.621371865512802, 'bagging_fraction': 0.8654123200856563, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,412] Trial 29 finished with value: 0.6898148148148148 and parameters: {'num_leaves': 192, 'learning_rate': 0.13921295360791722, 'feature_fraction': 0.459634712500272, 'bagging_fraction': 0.655465604460286, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,435] Trial 30 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 56, 'learning_rate': 0.21848449054474392, 'feature_fraction': 0.6039102095059772, 'bagging_fraction': 0.7851904367154843, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,488] Trial 31 finished with value: 0.7870370370370371 and parameters: {'num_leaves': 98, 'learning_rate': 0.18438137835024898, 'feature_fraction': 0.6804466537549835, 'bagging_fraction': 0.9460616156376191, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,523] Trial 32 finished with value: 0.8240740740740741 and parameters: {'num_leaves': 10, 'learning_rate': 0.23578019987132984, 'feature_fraction': 0.6672167226233027, 'bagging_fraction': 0.8236430110173772, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,553] Trial 33 finished with value: 0.7939814814814815 and parameters: {'num_leaves': 46, 'learning_rate': 0.2563380036561281, 'feature_fraction': 0.6671373692197028, 'bagging_fraction': 0.8426468482977061, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,576] Trial 34 finished with value: 0.6851851851851851 and parameters: {'num_leaves': 124, 'learning_rate': 0.2344763326564979, 'feature_fraction': 0.5500700718790351, 'bagging_fraction': 0.9596551472503354, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,599] Trial 35 finished with value: 0.7175925925925927 and parameters: {'num_leaves': 147, 'learning_rate': 0.28933161723988576, 'feature_fraction': 0.7136057908238732, 'bagging_fraction': 0.7660582294429992, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,613] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 180, 'learning_rate': 0.26594884378891764, 'feature_fraction': 0.5932499648248569, 'bagging_fraction': 0.8195209547932115, 'bagging_freq': 6, 'min_child_samples': 93}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,655] Trial 37 finished with value: 0.8101851851851851 and parameters: {'num_leaves': 212, 'learning_rate': 0.21201982119913462, 'feature_fraction': 0.46180093592304566, 'bagging_fraction': 0.8748472743308333, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,687] Trial 38 finished with value: 0.8078703703703703 and parameters: {'num_leaves': 244, 'learning_rate': 0.23832484443870422, 'feature_fraction': 0.7541073905191161, 'bagging_fraction': 0.9215688630766682, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,714] Trial 39 finished with value: 0.6435185185185185 and parameters: {'num_leaves': 196, 'learning_rate': 0.19919942168090365, 'feature_fraction': 0.8281303675894761, 'bagging_fraction': 0.9823565010809888, 'bagging_freq': 6, 'min_child_samples': 59}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,742] Trial 40 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 132, 'learning_rate': 0.06434251212680192, 'feature_fraction': 0.6476446590894991, 'bagging_fraction': 0.7107906174760018, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,760] Trial 41 finished with value: 0.6157407407407408 and parameters: {'num_leaves': 10, 'learning_rate': 0.1895016557857923, 'feature_fraction': 0.4968906953342984, 'bagging_fraction': 0.7745504793979934, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,797] Trial 42 finished with value: 0.7916666666666667 and parameters: {'num_leaves': 29, 'learning_rate': 0.16718060937435517, 'feature_fraction': 0.6964389695800969, 'bagging_fraction': 0.8371641751880152, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,830] Trial 43 finished with value: 0.7870370370370371 and parameters: {'num_leaves': 45, 'learning_rate': 0.14860749177901186, 'feature_fraction': 0.5306606703426504, 'bagging_fraction': 0.8882536568542008, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,890] Trial 44 finished with value: 0.7314814814814814 and parameters: {'num_leaves': 27, 'learning_rate': 0.20952384684443176, 'feature_fraction': 0.6172318099378605, 'bagging_fraction': 0.5509809597740055, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,908] Trial 45 finished with value: 0.8564814814814814 and parameters: {'num_leaves': 69, 'learning_rate': 0.29914108294698166, 'feature_fraction': 0.5833579988782517, 'bagging_fraction': 0.9362317703973206, 'bagging_freq': 5, 'min_child_samples': 39}. Best is trial 5 with value: 0.9027777777777778.
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.596702
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.556636
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.562707
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.594565
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.612393
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.589479
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.540186
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.57864
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.590042
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.573164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.52997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.57535
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.492498
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.612585
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.554243
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.657976
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.663396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.563968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.558498
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.554676
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.671236
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.585854
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.581104
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.483363
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.626872
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.601842
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.543382
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.505695
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.62265
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.635986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.657266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.54036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.576027
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.529486
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.622175
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.545096
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.53651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.513751
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.547126
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.621704
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.595736
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.519143
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.532891
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.645485
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.599804
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.667769
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.531157
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.549791
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.601254
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.529535
[I 2025-09-17 13:16:27,927] Trial 46 finished with value: 0.8009259259259259 and parameters: {'num_leaves': 91, 'learning_rate': 0.296644447562, 'feature_fraction': 0.5885321318278207, 'bagging_fraction': 0.9372447635199798, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,945] Trial 47 finished with value: 0.6597222222222222 and parameters: {'num_leaves': 106, 'learning_rate': 0.2814665671812353, 'feature_fraction': 0.6344082651847451, 'bagging_fraction': 0.9536501357311831, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,970] Trial 48 finished with value: 0.8472222222222222 and parameters: {'num_leaves': 70, 'learning_rate': 0.2581778892821145, 'feature_fraction': 0.5707046138324058, 'bagging_fraction': 0.8584381490363072, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:27,992] Trial 49 finished with value: 0.8287037037037037 and parameters: {'num_leaves': 72, 'learning_rate': 0.26214892657997974, 'feature_fraction': 0.48756754943147795, 'bagging_fraction': 0.9743510314060022, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 5 with value: 0.9027777777777778.
[I 2025-09-17 13:16:28,309] A new study created in memory with name: no-name-451e335b-b54f-4025-b572-0c50021768eb
[I 2025-09-17 13:16:28,375] Trial 0 finished with value: 0.8287037037037037 and parameters: {'num_leaves': 244, 'learning_rate': 0.021733718794195098, 'feature_fraction': 0.5942617318457963, 'bagging_fraction': 0.8688030001980391, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 0 with value: 0.8287037037037037.
[I 2025-09-17 13:16:28,383] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 120, 'learning_rate': 0.10629949324081496, 'feature_fraction': 0.695215836460459, 'bagging_fraction': 0.4711424224248271, 'bagging_freq': 7, 'min_child_samples': 55}. Best is trial 0 with value: 0.8287037037037037.
[I 2025-09-17 13:16:28,395] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.12823296088854, 'feature_fraction': 0.6003174896230626, 'bagging_fraction': 0.6643944437425665, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 0 with value: 0.8287037037037037.
[I 2025-09-17 13:16:28,412] Trial 3 finished with value: 0.611111111111111 and parameters: {'num_leaves': 100, 'learning_rate': 0.035010854897406636, 'feature_fraction': 0.9649064623997103, 'bagging_fraction': 0.9879723862279685, 'bagging_freq': 3, 'min_child_samples': 54}. Best is trial 0 with value: 0.8287037037037037.
[I 2025-09-17 13:16:28,429] Trial 4 finished with value: 0.6481481481481481 and parameters: {'num_leaves': 90, 'learning_rate': 0.022184802554385243, 'feature_fraction': 0.40639341478399393, 'bagging_fraction': 0.5676146010164929, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 0 with value: 0.8287037037037037.
[I 2025-09-17 13:16:28,526] Trial 5 finished with value: 0.9074074074074074 and parameters: {'num_leaves': 261, 'learning_rate': 0.1716555414100054, 'feature_fraction': 0.4724437613746566, 'bagging_fraction': 0.9961643580457766, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,601] Trial 6 finished with value: 0.8425925925925926 and parameters: {'num_leaves': 211, 'learning_rate': 0.027998236001217452, 'feature_fraction': 0.8694387561577754, 'bagging_fraction': 0.7725624341733097, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,615] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 277, 'learning_rate': 0.20275579474656366, 'feature_fraction': 0.5761828585206791, 'bagging_fraction': 0.6190828395273713, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,658] Trial 8 finished with value: 0.8518518518518519 and parameters: {'num_leaves': 284, 'learning_rate': 0.16008656152582804, 'feature_fraction': 0.5223911536669429, 'bagging_fraction': 0.6136193169193479, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,682] Trial 9 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 204, 'learning_rate': 0.1666335770019891, 'feature_fraction': 0.8616168015055432, 'bagging_fraction': 0.7950678017859176, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,692] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 43, 'learning_rate': 0.2998674088372997, 'feature_fraction': 0.41564554235966417, 'bagging_fraction': 0.9808840115746787, 'bagging_freq': 5, 'min_child_samples': 80}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,725] Trial 11 finished with value: 0.6944444444444445 and parameters: {'num_leaves': 280, 'learning_rate': 0.2233079636776527, 'feature_fraction': 0.4912359048482344, 'bagging_fraction': 0.4292529580895678, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,849] Trial 12 finished with value: 0.8935185185185185 and parameters: {'num_leaves': 298, 'learning_rate': 0.09698009514585426, 'feature_fraction': 0.5104380993982455, 'bagging_fraction': 0.5325233982784795, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,954] Trial 13 finished with value: 0.8379629629629629 and parameters: {'num_leaves': 166, 'learning_rate': 0.08911691273247462, 'feature_fraction': 0.6911343801751023, 'bagging_fraction': 0.511873147700173, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:28,990] Trial 14 finished with value: 0.8240740740740741 and parameters: {'num_leaves': 298, 'learning_rate': 0.079070995630595, 'feature_fraction': 0.4933862922140941, 'bagging_fraction': 0.7521921924091785, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:29,002] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 174, 'learning_rate': 0.2197068338588916, 'feature_fraction': 0.7813588907012614, 'bagging_fraction': 0.8914933124713825, 'bagging_freq': 6, 'min_child_samples': 69}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:29,028] Trial 16 finished with value: 0.6898148148148148 and parameters: {'num_leaves': 250, 'learning_rate': 0.2678109955237552, 'feature_fraction': 0.6401031785807233, 'bagging_fraction': 0.5538687001017454, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:29,111] Trial 17 finished with value: 0.9027777777777777 and parameters: {'num_leaves': 196, 'learning_rate': 0.1418862161393577, 'feature_fraction': 0.45712585242895515, 'bagging_fraction': 0.40636916145556556, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:29,137] Trial 18 finished with value: 0.7037037037037036 and parameters: {'num_leaves': 186, 'learning_rate': 0.18655124615634439, 'feature_fraction': 0.4466710927096106, 'bagging_fraction': 0.8996400451833845, 'bagging_freq': 6, 'min_child_samples': 42}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:29,150] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 138, 'learning_rate': 0.1336630945691336, 'feature_fraction': 0.7787925040766361, 'bagging_fraction': 0.6896988189810507, 'bagging_freq': 6, 'min_child_samples': 67}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:29,208] Trial 20 finished with value: 0.9074074074074074 and parameters: {'num_leaves': 255, 'learning_rate': 0.25139145943097196, 'feature_fraction': 0.44771584893084443, 'bagging_fraction': 0.8312864653775174, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:29,265] Trial 21 finished with value: 0.8703703703703703 and parameters: {'num_leaves': 251, 'learning_rate': 0.2505561811041215, 'feature_fraction': 0.4542276678073659, 'bagging_fraction': 0.8486588619850733, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 5 with value: 0.9074074074074074.
[I 2025-09-17 13:16:29,374] Trial 22 finished with value: 0.9120370370370371 and parameters: {'num_leaves': 223, 'learning_rate': 0.2449233004145084, 'feature_fraction': 0.5481383463935142, 'bagging_fraction': 0.9161858385561785, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 22 with value: 0.9120370370370371.
[I 2025-09-17 13:16:29,415] Trial 23 finished with value: 0.9027777777777778 and parameters: {'num_leaves': 229, 'learning_rate': 0.25729175236476737, 'feature_fraction': 0.5654430080788482, 'bagging_fraction': 0.9457913686495407, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 22 with value: 0.9120370370370371.
[I 2025-09-17 13:16:29,490] Trial 24 finished with value: 0.9074074074074074 and parameters: {'num_leaves': 262, 'learning_rate': 0.28234265714444784, 'feature_fraction': 0.5338496615719521, 'bagging_fraction': 0.9210785180872645, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 22 with value: 0.9120370370370371.
[I 2025-09-17 13:16:29,525] Trial 25 finished with value: 0.8703703703703703 and parameters: {'num_leaves': 219, 'learning_rate': 0.23767323398148163, 'feature_fraction': 0.4052520063772034, 'bagging_fraction': 0.8266518396019984, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 22 with value: 0.9120370370370371.
[I 2025-09-17 13:16:29,547] Trial 26 finished with value: 0.7685185185185185 and parameters: {'num_leaves': 263, 'learning_rate': 0.18938507006471259, 'feature_fraction': 0.6433048638387739, 'bagging_fraction': 0.9470607258151497, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 22 with value: 0.9120370370370371.
[I 2025-09-17 13:16:29,605] Trial 27 finished with value: 0.861111111111111 and parameters: {'num_leaves': 14, 'learning_rate': 0.22571997971939425, 'feature_fraction': 0.5454055189318607, 'bagging_fraction': 0.8181537400409534, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 22 with value: 0.9120370370370371.
[I 2025-09-17 13:16:29,652] Trial 28 finished with value: 0.8981481481481481 and parameters: {'num_leaves': 150, 'learning_rate': 0.20222380920068952, 'feature_fraction': 0.4813480448507593, 'bagging_fraction': 0.7264108796134615, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 22 with value: 0.9120370370370371.
[I 2025-09-17 13:16:29,716] Trial 29 finished with value: 0.888888888888889 and parameters: {'num_leaves': 238, 'learning_rate': 0.2779482458591528, 'feature_fraction': 0.6155747649606971, 'bagging_fraction': 0.8721798181092633, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 22 with value: 0.9120370370370371.
[I 2025-09-17 13:16:29,805] Trial 30 finished with value: 0.9537037037037037 and parameters: {'num_leaves': 261, 'learning_rate': 0.24373373198324622, 'feature_fraction': 0.4625687387882936, 'bagging_fraction': 0.9365257605789271, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:29,897] Trial 31 finished with value: 0.9027777777777777 and parameters: {'num_leaves': 261, 'learning_rate': 0.24462696133703687, 'feature_fraction': 0.4461694627208752, 'bagging_fraction': 0.9475239619067173, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:29,937] Trial 32 finished with value: 0.8981481481481481 and parameters: {'num_leaves': 237, 'learning_rate': 0.2985390716107838, 'feature_fraction': 0.47354492617555366, 'bagging_fraction': 0.9941426393946003, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,024] Trial 33 finished with value: 0.875 and parameters: {'num_leaves': 221, 'learning_rate': 0.18084494398452322, 'feature_fraction': 0.54447741915846, 'bagging_fraction': 0.92253564141218, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,036] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 269, 'learning_rate': 0.2672176066318095, 'feature_fraction': 0.5880153034488964, 'bagging_fraction': 0.8519033540463248, 'bagging_freq': 3, 'min_child_samples': 91}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,060] Trial 35 finished with value: 0.6805555555555556 and parameters: {'num_leaves': 245, 'learning_rate': 0.2107287707332245, 'feature_fraction': 0.43249704020376006, 'bagging_fraction': 0.968185434486558, 'bagging_freq': 7, 'min_child_samples': 59}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,121] Trial 36 finished with value: 0.8842592592592593 and parameters: {'num_leaves': 192, 'learning_rate': 0.23648015429807154, 'feature_fraction': 0.4005996853363556, 'bagging_fraction': 0.890740911403057, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,173] Trial 37 finished with value: 0.8425925925925926 and parameters: {'num_leaves': 289, 'learning_rate': 0.06703963299362756, 'feature_fraction': 0.49632247821120995, 'bagging_fraction': 0.9985025430638861, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,280] Trial 38 finished with value: 0.8981481481481483 and parameters: {'num_leaves': 210, 'learning_rate': 0.11143941791334742, 'feature_fraction': 0.9850627963999634, 'bagging_fraction': 0.9204149005949986, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,315] Trial 39 finished with value: 0.8703703703703703 and parameters: {'num_leaves': 107, 'learning_rate': 0.26158791950915283, 'feature_fraction': 0.6191707218084957, 'bagging_fraction': 0.7924932819376506, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,343] Trial 40 finished with value: 0.8240740740740741 and parameters: {'num_leaves': 229, 'learning_rate': 0.04780921378677039, 'feature_fraction': 0.6857691863898225, 'bagging_fraction': 0.9554860490241153, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,409] Trial 41 finished with value: 0.9027777777777779 and parameters: {'num_leaves': 269, 'learning_rate': 0.2829578741150324, 'feature_fraction': 0.5308589216830815, 'bagging_fraction': 0.9296714392571056, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,484] Trial 42 finished with value: 0.8472222222222221 and parameters: {'num_leaves': 255, 'learning_rate': 0.28123652203339256, 'feature_fraction': 0.5645137863378555, 'bagging_fraction': 0.858442580692047, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,540] Trial 43 finished with value: 0.8796296296296297 and parameters: {'num_leaves': 276, 'learning_rate': 0.23498427146754897, 'feature_fraction': 0.5361105184671081, 'bagging_fraction': 0.9008581642909953, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,589] Trial 44 finished with value: 0.8888888888888888 and parameters: {'num_leaves': 74, 'learning_rate': 0.29047462123769574, 'feature_fraction': 0.509929872244388, 'bagging_fraction': 0.9213194105858062, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,675] Trial 45 finished with value: 0.9305555555555555 and parameters: {'num_leaves': 288, 'learning_rate': 0.27163401850292207, 'feature_fraction': 0.43006097858467496, 'bagging_fraction': 0.8171674493627608, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,757] Trial 46 finished with value: 0.9398148148148149 and parameters: {'num_leaves': 285, 'learning_rate': 0.20541123729423807, 'feature_fraction': 0.43867827489259287, 'bagging_fraction': 0.7663690035161439, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 30 with value: 0.9537037037037037.
[I 2025-09-17 13:16:30,918] Trial 47 finished with value: 0.962962962962963 and parameters: {'num_leaves': 288, 'learning_rate': 0.20516049654401616, 'feature_fraction': 0.42284901069002295, 'bagging_fraction': 0.7606355978353587, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 47 with value: 0.962962962962963.
[I 2025-09-17 13:16:31,058] Trial 48 finished with value: 0.861111111111111 and parameters: {'num_leaves': 288, 'learning_rate': 0.204541370956713, 'feature_fraction': 0.42749784095220705, 'bagging_fraction': 0.750799993375845, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 47 with value: 0.962962962962963.
[I 2025-09-17 13:16:31,155] Trial 49 finished with value: 0.8981481481481481 and parameters: {'num_leaves': 298, 'learning_rate': 0.15405213492898934, 'feature_fraction': 0.47302385421368964, 'bagging_fraction': 0.6573441284940099, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 47 with value: 0.962962962962963.
[I 2025-09-17 13:16:31,530] A new study created in memory with name: no-name-064966e1-bfd5-4d09-8165-fe7fcbd01a44
[I 2025-09-17 13:16:31,542] Trial 0 finished with value: 0.5714285714285714 and parameters: {'num_leaves': 274, 'learning_rate': 0.2831650698096345, 'feature_fraction': 0.839207812576113, 'bagging_fraction': 0.6257114177600094, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 0 with value: 0.5714285714285714.
[I 2025-09-17 13:16:31,580] Trial 1 finished with value: 0.9821428571428571 and parameters: {'num_leaves': 234, 'learning_rate': 0.2554983212072911, 'feature_fraction': 0.9457838998129613, 'bagging_fraction': 0.45251303561917794, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 1 with value: 0.9821428571428571.
[I 2025-09-17 13:16:31,602] Trial 2 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 84, 'learning_rate': 0.14437865021396318, 'feature_fraction': 0.4818202687343611, 'bagging_fraction': 0.7046262811920732, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 1 with value: 0.9821428571428571.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.568424
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.654936
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.484833
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.513128
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.493823
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.636077
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.656899
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.416337
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.468656
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.452196
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.542301
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.621683
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.400436
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.515093
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.504513
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.606311
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.381345
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.584493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.362026
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.470896
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.378546
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.435079
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.455047
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.453551
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.55196
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.465085
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.38952
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.439671
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.267971
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.389171
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.42778
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.466437
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.624878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.409237
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.493631
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.404969
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.448017
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.541647
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.385678
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.469701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.478186
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.414204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.37449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.349319
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.252751
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.451711
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.462353
Training model for P071... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.212351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.158027
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.195003
[I 2025-09-17 13:16:31,631] Trial 3 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 55, 'learning_rate': 0.21781231691717184, 'feature_fraction': 0.6968120613163005, 'bagging_fraction': 0.9205439062367985, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 1 with value: 0.9821428571428571.
[I 2025-09-17 13:16:31,642] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 43, 'learning_rate': 0.24373363957103883, 'feature_fraction': 0.5769532027008449, 'bagging_fraction': 0.8274193164150575, 'bagging_freq': 1, 'min_child_samples': 67}. Best is trial 1 with value: 0.9821428571428571.
[I 2025-09-17 13:16:31,663] Trial 5 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 251, 'learning_rate': 0.1538788451978128, 'feature_fraction': 0.48009307837781307, 'bagging_fraction': 0.6666969400740879, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 1 with value: 0.9821428571428571.
[I 2025-09-17 13:16:31,673] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 279, 'learning_rate': 0.021159245605976536, 'feature_fraction': 0.6457481910391097, 'bagging_fraction': 0.5964561360573423, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 1 with value: 0.9821428571428571.
[I 2025-09-17 13:16:31,681] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 257, 'learning_rate': 0.22277228542203292, 'feature_fraction': 0.8580265469625714, 'bagging_fraction': 0.8980320555126844, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 1 with value: 0.9821428571428571.
[I 2025-09-17 13:16:31,703] Trial 8 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 81, 'learning_rate': 0.2330033469445754, 'feature_fraction': 0.6666421269717557, 'bagging_fraction': 0.8993738923167542, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 8 with value: 0.9821428571428572.
[I 2025-09-17 13:16:31,724] Trial 9 finished with value: 0.6428571428571428 and parameters: {'num_leaves': 193, 'learning_rate': 0.064485745841524, 'feature_fraction': 0.8430451930798746, 'bagging_fraction': 0.7406167633816432, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 8 with value: 0.9821428571428572.
[I 2025-09-17 13:16:31,734] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 124, 'learning_rate': 0.09725704876639862, 'feature_fraction': 0.5880907163367837, 'bagging_fraction': 0.982292105494579, 'bagging_freq': 7, 'min_child_samples': 66}. Best is trial 8 with value: 0.9821428571428572.
[I 2025-09-17 13:16:31,790] Trial 11 finished with value: 1.0 and parameters: {'num_leaves': 182, 'learning_rate': 0.2652377575964578, 'feature_fraction': 0.9976691793842817, 'bagging_fraction': 0.46270964707154144, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:31,830] Trial 12 finished with value: 1.0 and parameters: {'num_leaves': 151, 'learning_rate': 0.19460248345501147, 'feature_fraction': 0.9893333458753775, 'bagging_fraction': 0.42097163004111743, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:31,883] Trial 13 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 171, 'learning_rate': 0.29996061210323083, 'feature_fraction': 0.9997616337259642, 'bagging_fraction': 0.4080605470817141, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:31,922] Trial 14 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 133, 'learning_rate': 0.18941575390920895, 'feature_fraction': 0.932150853241362, 'bagging_fraction': 0.5207595155761827, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:31,951] Trial 15 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 207, 'learning_rate': 0.18988438101900867, 'feature_fraction': 0.7790265600897195, 'bagging_fraction': 0.5027513981255974, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:31,979] Trial 16 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 151, 'learning_rate': 0.11912392727186578, 'feature_fraction': 0.9665613082862542, 'bagging_fraction': 0.5334258883285369, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:31,992] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 105, 'learning_rate': 0.1881221915933072, 'feature_fraction': 0.7612298559779375, 'bagging_fraction': 0.5818648106596602, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,063] Trial 18 finished with value: 1.0 and parameters: {'num_leaves': 185, 'learning_rate': 0.2792635227482742, 'feature_fraction': 0.9009278807685381, 'bagging_fraction': 0.4036157390908178, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,081] Trial 19 finished with value: 0.6428571428571428 and parameters: {'num_leaves': 15, 'learning_rate': 0.20247964325814188, 'feature_fraction': 0.772775864838373, 'bagging_fraction': 0.45747268598707463, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,097] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 213, 'learning_rate': 0.170117532237723, 'feature_fraction': 0.41387006908757434, 'bagging_fraction': 0.45606799446204954, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,134] Trial 21 finished with value: 0.5446428571428572 and parameters: {'num_leaves': 179, 'learning_rate': 0.2727801752801507, 'feature_fraction': 0.8921384117837918, 'bagging_fraction': 0.41502501955096016, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,172] Trial 22 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 155, 'learning_rate': 0.26396945942648065, 'feature_fraction': 0.9936479347252254, 'bagging_fraction': 0.4859527121807225, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,212] Trial 23 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 216, 'learning_rate': 0.2937881953352334, 'feature_fraction': 0.9123450154321561, 'bagging_fraction': 0.554068672074498, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,228] Trial 24 finished with value: 0.4464285714285714 and parameters: {'num_leaves': 179, 'learning_rate': 0.25462562988352755, 'feature_fraction': 0.9084365798698945, 'bagging_fraction': 0.40138096510567217, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,303] Trial 25 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 132, 'learning_rate': 0.2152398662823107, 'feature_fraction': 0.9992223449066708, 'bagging_fraction': 0.4773222137620059, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,346] Trial 26 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 157, 'learning_rate': 0.27408496490449424, 'feature_fraction': 0.8135048135098939, 'bagging_fraction': 0.764000511727676, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,360] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 111, 'learning_rate': 0.23805764977263189, 'feature_fraction': 0.8812594920164418, 'bagging_fraction': 0.43460738129424326, 'bagging_freq': 7, 'min_child_samples': 81}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,384] Trial 28 finished with value: 0.6785714285714286 and parameters: {'num_leaves': 233, 'learning_rate': 0.13256156703181465, 'feature_fraction': 0.9500356360882442, 'bagging_fraction': 0.5654955787756618, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,402] Trial 29 finished with value: 0.625 and parameters: {'num_leaves': 197, 'learning_rate': 0.2814335400821449, 'feature_fraction': 0.8170627367112452, 'bagging_fraction': 0.6483768958327439, 'bagging_freq': 2, 'min_child_samples': 44}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,452] Trial 30 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 148, 'learning_rate': 0.09821300376545648, 'feature_fraction': 0.9495002540937023, 'bagging_fraction': 0.6292795787496801, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,477] Trial 31 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 82, 'learning_rate': 0.23765229198219534, 'feature_fraction': 0.6963991975967783, 'bagging_fraction': 0.8427806416961319, 'bagging_freq': 7, 'min_child_samples': 47}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,510] Trial 32 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 74, 'learning_rate': 0.23022674712366886, 'feature_fraction': 0.6298437996543413, 'bagging_fraction': 0.5036811679577845, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,549] Trial 33 finished with value: 1.0 and parameters: {'num_leaves': 105, 'learning_rate': 0.25571006374671307, 'feature_fraction': 0.7468135444954345, 'bagging_fraction': 0.43396224928719906, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,583] Trial 34 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 295, 'learning_rate': 0.25602784793283123, 'feature_fraction': 0.745327052613064, 'bagging_fraction': 0.44283779311533544, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,626] Trial 35 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 108, 'learning_rate': 0.2877443244486664, 'feature_fraction': 0.8682436109837177, 'bagging_fraction': 0.400371515298565, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,654] Trial 36 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 170, 'learning_rate': 0.24882093204569095, 'feature_fraction': 0.970544464699774, 'bagging_fraction': 0.4803938825126922, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,695] Trial 37 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 192, 'learning_rate': 0.21083242717469663, 'feature_fraction': 0.9241404180538928, 'bagging_fraction': 0.43753918502725664, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,761] Trial 38 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 238, 'learning_rate': 0.16972042187065386, 'feature_fraction': 0.8240537626536669, 'bagging_fraction': 0.5346933877292104, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,784] Trial 39 finished with value: 0.6785714285714286 and parameters: {'num_leaves': 59, 'learning_rate': 0.2649099436726242, 'feature_fraction': 0.529020805034291, 'bagging_fraction': 0.6068832088217707, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,820] Trial 40 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 132, 'learning_rate': 0.2805611929911585, 'feature_fraction': 0.7354401696165802, 'bagging_fraction': 0.6906406472448228, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,875] Trial 41 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 94, 'learning_rate': 0.2277752044285313, 'feature_fraction': 0.6711677149130446, 'bagging_fraction': 0.9466041864282231, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,895] Trial 42 finished with value: 0.5 and parameters: {'num_leaves': 63, 'learning_rate': 0.24009375910204783, 'feature_fraction': 0.6268403538140793, 'bagging_fraction': 0.8505032356072049, 'bagging_freq': 7, 'min_child_samples': 63}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,911] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 93, 'learning_rate': 0.20177380428330097, 'feature_fraction': 0.5690717830817528, 'bagging_fraction': 0.7645673038779768, 'bagging_freq': 6, 'min_child_samples': 76}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,972] Trial 44 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 36, 'learning_rate': 0.2620275810921854, 'feature_fraction': 0.9557761212275715, 'bagging_fraction': 0.8951708234836571, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:32,985] Trial 45 finished with value: 0.3214285714285714 and parameters: {'num_leaves': 123, 'learning_rate': 0.248140372833793, 'feature_fraction': 0.701372612365363, 'bagging_fraction': 0.9996536862199742, 'bagging_freq': 6, 'min_child_samples': 59}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:33,002] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 43, 'learning_rate': 0.17336613723828423, 'feature_fraction': 0.601345520878495, 'bagging_fraction': 0.46506256185128264, 'bagging_freq': 7, 'min_child_samples': 98}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:33,020] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 144, 'learning_rate': 0.22197100234921846, 'feature_fraction': 0.8507286292470054, 'bagging_fraction': 0.4279960817856213, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:33,036] Trial 48 finished with value: 0.4375 and parameters: {'num_leaves': 167, 'learning_rate': 0.2998400013937844, 'feature_fraction': 0.9731840380155928, 'bagging_fraction': 0.5155991443134109, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:33,190] Trial 49 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 187, 'learning_rate': 0.031005798786277766, 'feature_fraction': 0.7106154504760025, 'bagging_fraction': 0.7353396213087324, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 11 with value: 1.0.
[I 2025-09-17 13:16:33,340] A new study created in memory with name: no-name-7e3deb89-e03b-4179-a91d-05e08d4b33ac
[I 2025-09-17 13:16:33,423] Trial 0 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 129, 'learning_rate': 0.12930819358664059, 'feature_fraction': 0.8679736926364092, 'bagging_fraction': 0.967092540563565, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 0 with value: 0.9464285714285715.
[I 2025-09-17 13:16:33,440] Trial 1 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 13, 'learning_rate': 0.055353381156644205, 'feature_fraction': 0.9478239753843523, 'bagging_fraction': 0.49776225009817937, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 0 with value: 0.9464285714285715.
[I 2025-09-17 13:16:33,510] Trial 2 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 12, 'learning_rate': 0.2651001062998619, 'feature_fraction': 0.48538719778623074, 'bagging_fraction': 0.9574720983834597, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,519] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 182, 'learning_rate': 0.1484993345768337, 'feature_fraction': 0.4595322185429598, 'bagging_fraction': 0.7800391666131743, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,598] Trial 4 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 93, 'learning_rate': 0.059190937474768494, 'feature_fraction': 0.5420711613479438, 'bagging_fraction': 0.8706352872388669, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,607] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.012762896584467385, 'feature_fraction': 0.7043402692448109, 'bagging_fraction': 0.7752357779329841, 'bagging_freq': 6, 'min_child_samples': 68}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,630] Trial 6 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 141, 'learning_rate': 0.13464401132801307, 'feature_fraction': 0.713745038475066, 'bagging_fraction': 0.646449801564096, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,641] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 145, 'learning_rate': 0.055544711611158426, 'feature_fraction': 0.706591655278297, 'bagging_fraction': 0.8083080801994269, 'bagging_freq': 3, 'min_child_samples': 71}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,650] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 192, 'learning_rate': 0.11994903416516754, 'feature_fraction': 0.8270388079418773, 'bagging_fraction': 0.5545818929723842, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,669] Trial 9 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 165, 'learning_rate': 0.1428098334123018, 'feature_fraction': 0.6276968154470725, 'bagging_fraction': 0.8712919446121766, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,688] Trial 10 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 276, 'learning_rate': 0.29050445850785434, 'feature_fraction': 0.406630043942844, 'bagging_fraction': 0.9891323608388873, 'bagging_freq': 7, 'min_child_samples': 49}. Best is trial 2 with value: 0.9821428571428572.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.161844
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.217655
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.103226
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.228203
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.0692222
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.144568
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.196116
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.175199
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.193033
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.170584
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.0284798
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.214274
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.29602
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.130444
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.128081
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.128279
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.114431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.200124
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.2449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.160817
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.17708
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.143726
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.119689
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.153258
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.16046
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.144948
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.167361
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.11321
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.213931
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.113035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.158765
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.143549
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.259006
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.244796
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.191833
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.143109
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.204511
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.0900281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.135802
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.154299
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.147772
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.153684
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:33,754] Trial 11 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 23, 'learning_rate': 0.2427327239381823, 'feature_fraction': 0.9910481008885812, 'bagging_fraction': 0.9941579339211876, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,830] Trial 12 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 14, 'learning_rate': 0.2659591519516339, 'feature_fraction': 0.5412556320981199, 'bagging_fraction': 0.9508680337791651, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,848] Trial 13 finished with value: 0.8660714285714286 and parameters: {'num_leaves': 54, 'learning_rate': 0.2210024097409336, 'feature_fraction': 0.989295592101868, 'bagging_fraction': 0.4046268593824949, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,870] Trial 14 finished with value: 0.875 and parameters: {'num_leaves': 49, 'learning_rate': 0.21626943623870556, 'feature_fraction': 0.8162701738872444, 'bagging_fraction': 0.8771187443999255, 'bagging_freq': 7, 'min_child_samples': 46}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,903] Trial 15 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 245, 'learning_rate': 0.21693665871283294, 'feature_fraction': 0.5381282410873132, 'bagging_fraction': 0.665517686624496, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:33,985] Trial 16 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 49, 'learning_rate': 0.2555041994355932, 'feature_fraction': 0.6320460864839811, 'bagging_fraction': 0.9996092229237871, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,000] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 90, 'learning_rate': 0.19709934219814085, 'feature_fraction': 0.9036077086410226, 'bagging_fraction': 0.910107879999303, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,014] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.29886407357476963, 'feature_fraction': 0.7571947027682803, 'bagging_fraction': 0.7192486350082755, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,034] Trial 19 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 218, 'learning_rate': 0.24600800511243506, 'feature_fraction': 0.5992716763146462, 'bagging_fraction': 0.9146351164757689, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,099] Trial 20 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 68, 'learning_rate': 0.17993115785357436, 'feature_fraction': 0.46575478375979035, 'bagging_fraction': 0.8264908838961645, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,165] Trial 21 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 42, 'learning_rate': 0.1839474102335195, 'feature_fraction': 0.46623124980330183, 'bagging_fraction': 0.8279093597668017, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,229] Trial 22 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 113, 'learning_rate': 0.1743119382053991, 'feature_fraction': 0.4036628434320169, 'bagging_fraction': 0.9248347212181088, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,262] Trial 23 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 70, 'learning_rate': 0.24445613815900152, 'feature_fraction': 0.48807019608319313, 'bagging_fraction': 0.7430379642327072, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,355] Trial 24 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 34, 'learning_rate': 0.27938019244582857, 'feature_fraction': 0.6011434491790367, 'bagging_fraction': 0.839565332159682, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,378] Trial 25 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 26, 'learning_rate': 0.23222511404865526, 'feature_fraction': 0.46711689629249453, 'bagging_fraction': 0.9997725731030715, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,427] Trial 26 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 68, 'learning_rate': 0.10319998256805668, 'feature_fraction': 0.5117026801103826, 'bagging_fraction': 0.9417538395573307, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,528] Trial 27 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 110, 'learning_rate': 0.16651377667301218, 'feature_fraction': 0.5668945560161527, 'bagging_fraction': 0.8870341762418141, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,562] Trial 28 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 68, 'learning_rate': 0.26952496473674353, 'feature_fraction': 0.7537293709437127, 'bagging_fraction': 0.9511882654768524, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,644] Trial 29 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 118, 'learning_rate': 0.19476154742581991, 'feature_fraction': 0.6551994182463319, 'bagging_fraction': 0.8431486952518753, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,675] Trial 30 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 30, 'learning_rate': 0.20601758289548644, 'feature_fraction': 0.8950720413463472, 'bagging_fraction': 0.792434298355551, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,705] Trial 31 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 72, 'learning_rate': 0.24500031417652107, 'feature_fraction': 0.5044653596581721, 'bagging_fraction': 0.7281424589924993, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,738] Trial 32 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 66, 'learning_rate': 0.2378077469288155, 'feature_fraction': 0.435496588851189, 'bagging_fraction': 0.6101496888813905, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,826] Trial 33 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 32, 'learning_rate': 0.26096928290316646, 'feature_fraction': 0.4959046878857774, 'bagging_fraction': 0.7434914488981686, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,867] Trial 34 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 11, 'learning_rate': 0.27597221533177624, 'feature_fraction': 0.5736008170851323, 'bagging_fraction': 0.7488610624483925, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,891] Trial 35 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 86, 'learning_rate': 0.23016898798587218, 'feature_fraction': 0.43472087587042374, 'bagging_fraction': 0.965097958042508, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,904] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 53, 'learning_rate': 0.0850523719580452, 'feature_fraction': 0.48840667665039905, 'bagging_fraction': 0.7662200208239683, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,916] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 101, 'learning_rate': 0.285473412133377, 'feature_fraction': 0.6657723196233077, 'bagging_fraction': 0.68688367703429, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:34,940] Trial 38 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 128, 'learning_rate': 0.15305179804194474, 'feature_fraction': 0.9983602836379909, 'bagging_fraction': 0.6120626397865279, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:16:35,021] Trial 39 finished with value: 1.0 and parameters: {'num_leaves': 25, 'learning_rate': 0.2507323725728281, 'feature_fraction': 0.9426685580057169, 'bagging_fraction': 0.8221965710876282, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,099] Trial 40 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 25, 'learning_rate': 0.013238466827521528, 'feature_fraction': 0.9547480235551531, 'bagging_fraction': 0.8985334098249848, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,178] Trial 41 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 76, 'learning_rate': 0.25133623994777243, 'feature_fraction': 0.9314652232763769, 'bagging_fraction': 0.7895668943849752, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,259] Trial 42 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 41, 'learning_rate': 0.2550637887177005, 'feature_fraction': 0.9437366747311821, 'bagging_fraction': 0.8078140372466295, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,343] Trial 43 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 21, 'learning_rate': 0.2058144099102132, 'feature_fraction': 0.8601288776984503, 'bagging_fraction': 0.8455358677816427, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,403] Trial 44 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 160, 'learning_rate': 0.2962582401791384, 'feature_fraction': 0.9647082805391703, 'bagging_fraction': 0.7803069416950204, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,444] Trial 45 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 82, 'learning_rate': 0.22836887728197977, 'feature_fraction': 0.9210736946822399, 'bagging_fraction': 0.864961805451172, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,545] Trial 46 finished with value: 1.0 and parameters: {'num_leaves': 60, 'learning_rate': 0.1263208774485626, 'feature_fraction': 0.8555354195415527, 'bagging_fraction': 0.8036639388493383, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,627] Trial 47 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 56, 'learning_rate': 0.12341075125591583, 'feature_fraction': 0.8413734724110951, 'bagging_fraction': 0.8103104508690891, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,779] Trial 48 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 100, 'learning_rate': 0.0996665857853134, 'feature_fraction': 0.8728858422945196, 'bagging_fraction': 0.8172494903699038, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,827] Trial 49 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 179, 'learning_rate': 0.13110472644029333, 'feature_fraction': 0.7696134387613396, 'bagging_fraction': 0.7017077813196302, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 39 with value: 1.0.
[I 2025-09-17 13:16:35,990] A new study created in memory with name: no-name-064b0a6b-90c9-4b31-a2eb-593ca958d26c
[I 2025-09-17 13:16:35,998] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.19860576688155188, 'feature_fraction': 0.572364139173686, 'bagging_fraction': 0.7073941134696518, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:36,027] Trial 1 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 254, 'learning_rate': 0.19997070655172544, 'feature_fraction': 0.5418740571972311, 'bagging_fraction': 0.5850906046240983, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,035] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 46, 'learning_rate': 0.2654717516847212, 'feature_fraction': 0.815700196880341, 'bagging_fraction': 0.6019559437208418, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,043] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 134, 'learning_rate': 0.07682852389697614, 'feature_fraction': 0.5405310004111772, 'bagging_fraction': 0.42542033356091824, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,051] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 117, 'learning_rate': 0.025897228205096746, 'feature_fraction': 0.8043868263625928, 'bagging_fraction': 0.47104096270995716, 'bagging_freq': 6, 'min_child_samples': 81}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,059] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 88, 'learning_rate': 0.2185560373298051, 'feature_fraction': 0.6353383457707457, 'bagging_fraction': 0.8768468852164744, 'bagging_freq': 4, 'min_child_samples': 65}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,066] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 56, 'learning_rate': 0.10454531147623075, 'feature_fraction': 0.7136702133218039, 'bagging_fraction': 0.9342774165623065, 'bagging_freq': 7, 'min_child_samples': 82}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,074] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 44, 'learning_rate': 0.19818477112462374, 'feature_fraction': 0.8077563659038205, 'bagging_fraction': 0.4310898820443656, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,083] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 216, 'learning_rate': 0.2748710078003809, 'feature_fraction': 0.6808106254430325, 'bagging_fraction': 0.4446992925549053, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,089] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.2469200387240241, 'feature_fraction': 0.9147102179841311, 'bagging_fraction': 0.5777104122746564, 'bagging_freq': 1, 'min_child_samples': 92}. Best is trial 1 with value: 0.7142857142857143.
[I 2025-09-17 13:16:36,220] Trial 10 finished with value: 1.0 and parameters: {'num_leaves': 299, 'learning_rate': 0.12926763663111746, 'feature_fraction': 0.4019980102700955, 'bagging_fraction': 0.7489307161695562, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,315] Trial 11 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 288, 'learning_rate': 0.1425421161123217, 'feature_fraction': 0.41387485635327537, 'bagging_fraction': 0.770460699519914, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,405] Trial 12 finished with value: 0.9196428571428571 and parameters: {'num_leaves': 288, 'learning_rate': 0.13509210354967147, 'feature_fraction': 0.4216453447335437, 'bagging_fraction': 0.7830507640110198, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,534] Trial 13 finished with value: 1.0 and parameters: {'num_leaves': 192, 'learning_rate': 0.14901280684173368, 'feature_fraction': 0.40247790299811137, 'bagging_fraction': 0.8044478418013254, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,583] Trial 14 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 192, 'learning_rate': 0.07665455573507038, 'feature_fraction': 0.45043083676163115, 'bagging_fraction': 0.8455590773717707, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,624] Trial 15 finished with value: 0.875 and parameters: {'num_leaves': 166, 'learning_rate': 0.1675747579159633, 'feature_fraction': 0.4946005641544826, 'bagging_fraction': 0.9653266582990543, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,639] Trial 16 finished with value: 0.5535714285714286 and parameters: {'num_leaves': 239, 'learning_rate': 0.10484869917112599, 'feature_fraction': 0.9894516451188009, 'bagging_fraction': 0.6804398334847469, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,720] Trial 17 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 247, 'learning_rate': 0.03102388770840883, 'feature_fraction': 0.6085490673937186, 'bagging_fraction': 0.7956983572221673, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,741] Trial 18 finished with value: 0.75 and parameters: {'num_leaves': 182, 'learning_rate': 0.16258390756092705, 'feature_fraction': 0.48785801663018924, 'bagging_fraction': 0.6689125606425472, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,800] Trial 19 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 140, 'learning_rate': 0.09962375425030609, 'feature_fraction': 0.4581819221354252, 'bagging_fraction': 0.8848814617946885, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,813] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 96, 'learning_rate': 0.12984142018533248, 'feature_fraction': 0.4025361771587532, 'bagging_fraction': 0.7171602572194844, 'bagging_freq': 7, 'min_child_samples': 51}. Best is trial 10 with value: 1.0.
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.116482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.172254
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.1909
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.140819
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.148152
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.162797
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.155417
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.129628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.131743
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.139535
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.109664
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.192572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.137417
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.155159
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.131051
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.129512
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.15624
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.148002
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.117951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.167517
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.117555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.118981
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.150617
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.139996
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.0719487
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.167296
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.0692499
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.138131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.108667
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.137171
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.160526
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.0403404
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.12229
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.0789421
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.140748
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.226497
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.0930111
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.174756
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.209164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.110873
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.185763
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.18143
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.244223
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.187611
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.191879
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.188189
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.245449
[I 2025-09-17 13:16:36,939] Trial 21 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 275, 'learning_rate': 0.14348139233856672, 'feature_fraction': 0.40949142860172694, 'bagging_fraction': 0.7804737723254364, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:36,997] Trial 22 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 270, 'learning_rate': 0.1720475696397952, 'feature_fraction': 0.5040139045428029, 'bagging_fraction': 0.8255552107513832, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,148] Trial 23 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 220, 'learning_rate': 0.05455280216285824, 'feature_fraction': 0.4687102956664757, 'bagging_fraction': 0.7462394565745725, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,183] Trial 24 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 221, 'learning_rate': 0.052564944661111404, 'feature_fraction': 0.4660441180778312, 'bagging_fraction': 0.723489337040885, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,229] Trial 25 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 166, 'learning_rate': 0.29965127523131374, 'feature_fraction': 0.5211919259252412, 'bagging_fraction': 0.6497103457032583, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,387] Trial 26 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 231, 'learning_rate': 0.010829102145210018, 'feature_fraction': 0.574652158796156, 'bagging_fraction': 0.7497299356899437, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,430] Trial 27 finished with value: 0.875 and parameters: {'num_leaves': 212, 'learning_rate': 0.06441721578460029, 'feature_fraction': 0.7205830130549903, 'bagging_fraction': 0.5299305548197177, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,463] Trial 28 finished with value: 0.6607142857142857 and parameters: {'num_leaves': 260, 'learning_rate': 0.11412373860807624, 'feature_fraction': 0.4464766866723011, 'bagging_fraction': 0.6349192636082908, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,527] Trial 29 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 18, 'learning_rate': 0.17942778921031013, 'feature_fraction': 0.5826606614042812, 'bagging_fraction': 0.9037584227335497, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,583] Trial 30 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 150, 'learning_rate': 0.08795876676246392, 'feature_fraction': 0.5420102606790143, 'bagging_fraction': 0.8378631382002777, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,678] Trial 31 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 277, 'learning_rate': 0.14875648986496842, 'feature_fraction': 0.40870676684085566, 'bagging_fraction': 0.7269967159621592, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,829] Trial 32 finished with value: 1.0 and parameters: {'num_leaves': 298, 'learning_rate': 0.12353801686824611, 'feature_fraction': 0.4005953265985906, 'bagging_fraction': 0.8038316313275495, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,889] Trial 33 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 296, 'learning_rate': 0.0501857653912203, 'feature_fraction': 0.4681978069488521, 'bagging_fraction': 0.8141771560073893, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:37,958] Trial 34 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 255, 'learning_rate': 0.12298407755198729, 'feature_fraction': 0.43584158079606344, 'bagging_fraction': 0.7504465444228721, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,077] Trial 35 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 299, 'learning_rate': 0.1904694026202202, 'feature_fraction': 0.5347187527077112, 'bagging_fraction': 0.8591821675381626, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,104] Trial 36 finished with value: 0.6071428571428572 and parameters: {'num_leaves': 178, 'learning_rate': 0.21845678825024437, 'feature_fraction': 0.4786995691936868, 'bagging_fraction': 0.6956006335310101, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,121] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 235, 'learning_rate': 0.21915154690279104, 'feature_fraction': 0.7559437712820479, 'bagging_fraction': 0.6135172646873166, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,134] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 261, 'learning_rate': 0.08517104825864452, 'feature_fraction': 0.43590499343974554, 'bagging_fraction': 0.9287512208083915, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,180] Trial 39 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 117, 'learning_rate': 0.11721459259166771, 'feature_fraction': 0.6166786849834538, 'bagging_fraction': 0.9898470691177955, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,195] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 204, 'learning_rate': 0.1581867747791211, 'feature_fraction': 0.659889343678188, 'bagging_fraction': 0.7569161360848362, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,273] Trial 41 finished with value: 1.0 and parameters: {'num_leaves': 300, 'learning_rate': 0.17815496756371146, 'feature_fraction': 0.538482144822929, 'bagging_fraction': 0.8617105244906982, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,346] Trial 42 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 278, 'learning_rate': 0.18624657220652213, 'feature_fraction': 0.5149523786776112, 'bagging_fraction': 0.8065460963846036, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,386] Trial 43 finished with value: 0.9642857142857142 and parameters: {'num_leaves': 289, 'learning_rate': 0.1575849774142777, 'feature_fraction': 0.5557112500274018, 'bagging_fraction': 0.8734493849996439, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,442] Trial 44 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 246, 'learning_rate': 0.20899880339199822, 'feature_fraction': 0.44045488541817834, 'bagging_fraction': 0.9053374612901736, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,523] Trial 45 finished with value: 1.0 and parameters: {'num_leaves': 226, 'learning_rate': 0.13766327791351446, 'feature_fraction': 0.49097654156801845, 'bagging_fraction': 0.8340170609524108, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,598] Trial 46 finished with value: 1.0 and parameters: {'num_leaves': 268, 'learning_rate': 0.13759189397405255, 'feature_fraction': 0.85235685670648, 'bagging_fraction': 0.8499619658615891, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,611] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 283, 'learning_rate': 0.13096659518194703, 'feature_fraction': 0.42711639704649706, 'bagging_fraction': 0.7977478180184104, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,690] Trial 48 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 188, 'learning_rate': 0.10857748893932724, 'feature_fraction': 0.5041458662032337, 'bagging_fraction': 0.9454446724422382, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:38,730] Trial 49 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 299, 'learning_rate': 0.24304902520155386, 'feature_fraction': 0.40173501311273535, 'bagging_fraction': 0.8323739621545314, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:16:39,083] A new study created in memory with name: no-name-f3da6095-1056-4467-8721-2156fd676b65
[I 2025-09-17 13:16:39,142] Trial 0 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 92, 'learning_rate': 0.228477164829018, 'feature_fraction': 0.8739326494003632, 'bagging_fraction': 0.9676431490147247, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,150] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.21804119029334312, 'feature_fraction': 0.8736545369425782, 'bagging_fraction': 0.4239197623560816, 'bagging_freq': 6, 'min_child_samples': 72}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,158] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 56, 'learning_rate': 0.16505301778246817, 'feature_fraction': 0.7767810667420914, 'bagging_fraction': 0.8140089200126682, 'bagging_freq': 2, 'min_child_samples': 79}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,165] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 111, 'learning_rate': 0.17803921775384818, 'feature_fraction': 0.5826758226651529, 'bagging_fraction': 0.5497354097432988, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,185] Trial 4 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 23, 'learning_rate': 0.17662931763254572, 'feature_fraction': 0.4894112686356398, 'bagging_fraction': 0.8975793996417065, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,193] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 244, 'learning_rate': 0.015630031564601243, 'feature_fraction': 0.8451612811688787, 'bagging_fraction': 0.52433547875995, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,212] Trial 6 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 51, 'learning_rate': 0.29741199144809627, 'feature_fraction': 0.48712697119833187, 'bagging_fraction': 0.8216489690986082, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,219] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 254, 'learning_rate': 0.15402002059613862, 'feature_fraction': 0.6407662534468322, 'bagging_fraction': 0.9576054056253699, 'bagging_freq': 3, 'min_child_samples': 80}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,232] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 36, 'learning_rate': 0.0579343933961977, 'feature_fraction': 0.9454775544217248, 'bagging_fraction': 0.43894572452498193, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,240] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 76, 'learning_rate': 0.1483696572969055, 'feature_fraction': 0.43285125849408534, 'bagging_fraction': 0.5866655352061818, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,310] Trial 10 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 162, 'learning_rate': 0.28523572658339186, 'feature_fraction': 0.7388312232497356, 'bagging_fraction': 0.7438064767131485, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,364] Trial 11 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 11, 'learning_rate': 0.23236011025287226, 'feature_fraction': 0.98919559412382, 'bagging_fraction': 0.9425384043224043, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 0 with value: 0.9285714285714286.
[I 2025-09-17 13:16:39,407] Trial 12 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 107, 'learning_rate': 0.09382342804151933, 'feature_fraction': 0.5482163229536944, 'bagging_fraction': 0.9915955747054258, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,448] Trial 13 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 107, 'learning_rate': 0.09227660899003569, 'feature_fraction': 0.6070931186749778, 'bagging_fraction': 0.9926328610365539, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,490] Trial 14 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 113, 'learning_rate': 0.10633622277177351, 'feature_fraction': 0.6493731388561947, 'bagging_fraction': 0.8651918808255361, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,527] Trial 15 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 140, 'learning_rate': 0.0988992743370033, 'feature_fraction': 0.6727552541839952, 'bagging_fraction': 0.8691016410644242, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,558] Trial 16 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 201, 'learning_rate': 0.0972050898903001, 'feature_fraction': 0.5374997148214097, 'bagging_fraction': 0.6953879234641713, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,581] Trial 17 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 295, 'learning_rate': 0.050179579810863115, 'feature_fraction': 0.7052172027602602, 'bagging_fraction': 0.6981480268877334, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,630] Trial 18 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 136, 'learning_rate': 0.1250327632391214, 'feature_fraction': 0.41472396788541405, 'bagging_fraction': 0.7594699376120028, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,652] Trial 19 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 177, 'learning_rate': 0.05679956607529525, 'feature_fraction': 0.5400751590214723, 'bagging_fraction': 0.8909254841742734, 'bagging_freq': 7, 'min_child_samples': 49}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,675] Trial 20 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 118, 'learning_rate': 0.12072535750953094, 'feature_fraction': 0.7857977231680855, 'bagging_fraction': 0.6443820348545337, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,696] Trial 21 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 265, 'learning_rate': 0.05004921944571368, 'feature_fraction': 0.6990772814628066, 'bagging_fraction': 0.6615629461142014, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,726] Trial 22 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 221, 'learning_rate': 0.011803633833827612, 'feature_fraction': 0.6418032419806128, 'bagging_fraction': 0.7975049041344954, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,798] Trial 23 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 278, 'learning_rate': 0.07478115882306202, 'feature_fraction': 0.7307869030240103, 'bagging_fraction': 0.9199227530047113, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,810] Trial 24 finished with value: 0.5 and parameters: {'num_leaves': 292, 'learning_rate': 0.04200804697194848, 'feature_fraction': 0.5786281163432948, 'bagging_fraction': 0.8431732666481002, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,825] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 75, 'learning_rate': 0.12366740195041884, 'feature_fraction': 0.6560380018963178, 'bagging_fraction': 0.7291891372148646, 'bagging_freq': 3, 'min_child_samples': 98}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,850] Trial 26 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 155, 'learning_rate': 0.07636669500466972, 'feature_fraction': 0.5302386810500888, 'bagging_fraction': 0.6231217774985514, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,902] Trial 27 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 225, 'learning_rate': 0.03359189680084469, 'feature_fraction': 0.7881427042274518, 'bagging_fraction': 0.9960880884138831, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:39,994] Trial 28 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 132, 'learning_rate': 0.07402883869699343, 'feature_fraction': 0.5983735420267757, 'bagging_fraction': 0.7786476221738298, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 12 with value: 0.9464285714285715.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.187867
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.182731
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.17899
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.170702
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.18307
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.20537
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.203041
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.203949
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.168794
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.177102
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.189186
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.110039
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.205376
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.175291
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.150896
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.219853
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.156602
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.159868
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.209498
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.164358
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.227969
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.143839
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.133461
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.169168
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.2057
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.182332
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.157533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.135409
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.214605
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.155947
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.146591
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.150921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.13141
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.127507
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.144786
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.169515
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.139305
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.159271
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.151939
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.200466
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.19201
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.127258
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.183609
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.147653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.126694
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:40,031] Trial 29 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 89, 'learning_rate': 0.11176900983090224, 'feature_fraction': 0.7069893651967941, 'bagging_fraction': 0.8605731225556639, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,167] Trial 30 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 90, 'learning_rate': 0.13893731058640635, 'feature_fraction': 0.4732411841767481, 'bagging_fraction': 0.8582041020219624, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,283] Trial 31 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 87, 'learning_rate': 0.14080890606115448, 'feature_fraction': 0.4742880897568543, 'bagging_fraction': 0.8626204016338164, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,320] Trial 32 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 94, 'learning_rate': 0.19895356328092884, 'feature_fraction': 0.4501409067469132, 'bagging_fraction': 0.9293682454989662, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,439] Trial 33 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 58, 'learning_rate': 0.1086563655301557, 'feature_fraction': 0.5164018021449934, 'bagging_fraction': 0.8919823614748549, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,500] Trial 34 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 98, 'learning_rate': 0.13614458690469608, 'feature_fraction': 0.5749714050220245, 'bagging_fraction': 0.8409852985727596, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,566] Trial 35 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 118, 'learning_rate': 0.16857350538052338, 'feature_fraction': 0.6302844821150617, 'bagging_fraction': 0.9681298051964726, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,597] Trial 36 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 70, 'learning_rate': 0.19828677668822875, 'feature_fraction': 0.8309862285241401, 'bagging_fraction': 0.8131306334989419, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,625] Trial 37 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 40, 'learning_rate': 0.08417151373900086, 'feature_fraction': 0.5596909827154206, 'bagging_fraction': 0.8988380741451533, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,637] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 152, 'learning_rate': 0.1184802143336047, 'feature_fraction': 0.5048743331574265, 'bagging_fraction': 0.7808835320330565, 'bagging_freq': 3, 'min_child_samples': 65}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,669] Trial 39 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 126, 'learning_rate': 0.10740413010695647, 'feature_fraction': 0.4555572304688176, 'bagging_fraction': 0.9715643890280625, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 29 with value: 0.9642857142857143.
[I 2025-09-17 13:16:40,783] Trial 40 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 104, 'learning_rate': 0.15808315145008528, 'feature_fraction': 0.6136397161247247, 'bagging_fraction': 0.8540097918108273, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:40,893] Trial 41 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 100, 'learning_rate': 0.1561025881002423, 'feature_fraction': 0.6166144923554345, 'bagging_fraction': 0.8506545553538264, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:40,999] Trial 42 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 88, 'learning_rate': 0.1604912018777554, 'feature_fraction': 0.6971536965023212, 'bagging_fraction': 0.9106058023960967, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:41,080] Trial 43 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 55, 'learning_rate': 0.19389525016867756, 'feature_fraction': 0.6286703066253071, 'bagging_fraction': 0.8325849802769831, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:41,131] Trial 44 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 103, 'learning_rate': 0.1779018867862915, 'feature_fraction': 0.6080284461142985, 'bagging_fraction': 0.9450506882118874, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:41,181] Trial 45 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 66, 'learning_rate': 0.22113047589032037, 'feature_fraction': 0.7499510024611523, 'bagging_fraction': 0.9417483215554446, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:41,267] Trial 46 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 41, 'learning_rate': 0.18113359979900168, 'feature_fraction': 0.6098600157048202, 'bagging_fraction': 0.8657519155991735, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:41,392] Trial 47 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 82, 'learning_rate': 0.15125775516686352, 'feature_fraction': 0.6754349704601761, 'bagging_fraction': 0.8184326753669493, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:41,511] Trial 48 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 82, 'learning_rate': 0.14697524040348642, 'feature_fraction': 0.7644042838937312, 'bagging_fraction': 0.8000343285461465, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:41,546] Trial 49 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 27, 'learning_rate': 0.13314591322424243, 'feature_fraction': 0.6735063641261748, 'bagging_fraction': 0.4700023394751855, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 40 with value: 0.9821428571428572.
[I 2025-09-17 13:16:41,807] A new study created in memory with name: no-name-cbbbe295-3522-4c36-b7e0-1d978627c324
[I 2025-09-17 13:16:41,816] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 152, 'learning_rate': 0.08627105660409767, 'feature_fraction': 0.6890537256086626, 'bagging_fraction': 0.7068118490544435, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,825] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 137, 'learning_rate': 0.19030644448284867, 'feature_fraction': 0.7629152291037506, 'bagging_fraction': 0.6463408795108552, 'bagging_freq': 2, 'min_child_samples': 97}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,839] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 30, 'learning_rate': 0.19429043151643735, 'feature_fraction': 0.6100410779224786, 'bagging_fraction': 0.5104060483449832, 'bagging_freq': 4, 'min_child_samples': 65}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,850] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 164, 'learning_rate': 0.2516468014505207, 'feature_fraction': 0.9712833582516643, 'bagging_fraction': 0.7966826659817761, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,860] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 272, 'learning_rate': 0.20937627200908396, 'feature_fraction': 0.4697297932215522, 'bagging_fraction': 0.5999875289819773, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,868] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 222, 'learning_rate': 0.05598971771909477, 'feature_fraction': 0.6239331655458954, 'bagging_fraction': 0.8801485213389353, 'bagging_freq': 6, 'min_child_samples': 93}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,876] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 62, 'learning_rate': 0.2559643035267078, 'feature_fraction': 0.834313421347436, 'bagging_fraction': 0.41707670572705846, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,891] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 195, 'learning_rate': 0.046448923681121454, 'feature_fraction': 0.4481749847773155, 'bagging_fraction': 0.9573862612503578, 'bagging_freq': 3, 'min_child_samples': 65}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,902] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 172, 'learning_rate': 0.14041545118649526, 'feature_fraction': 0.916171519346759, 'bagging_fraction': 0.6539189057443818, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:41,940] Trial 9 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 19, 'learning_rate': 0.2727492971664424, 'feature_fraction': 0.7891665802669856, 'bagging_fraction': 0.6484977098904199, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 9 with value: 0.9107142857142857.
[I 2025-09-17 13:16:41,986] Trial 10 finished with value: 0.9107142857142858 and parameters: {'num_leaves': 92, 'learning_rate': 0.299982432060793, 'feature_fraction': 0.8406379749432042, 'bagging_fraction': 0.7727672323930661, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 10 with value: 0.9107142857142858.
[I 2025-09-17 13:16:42,047] Trial 11 finished with value: 0.6607142857142857 and parameters: {'num_leaves': 92, 'learning_rate': 0.2905410956003185, 'feature_fraction': 0.837552290865517, 'bagging_fraction': 0.7845447473286747, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 10 with value: 0.9107142857142858.
[I 2025-09-17 13:16:42,098] Trial 12 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 17, 'learning_rate': 0.2949226869387503, 'feature_fraction': 0.8025347776192211, 'bagging_fraction': 0.7603802927561825, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:42,126] Trial 13 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 92, 'learning_rate': 0.2930910847376847, 'feature_fraction': 0.9012362819273305, 'bagging_fraction': 0.7639097030821018, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:42,159] Trial 14 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 81, 'learning_rate': 0.23009761272773382, 'feature_fraction': 0.6834836617244244, 'bagging_fraction': 0.8672703378870039, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:42,190] Trial 15 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 55, 'learning_rate': 0.23088758484428476, 'feature_fraction': 0.560858769793718, 'bagging_fraction': 0.901989216383871, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 12 with value: 0.9464285714285715.
[I 2025-09-17 13:16:42,211] Trial 16 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 10, 'learning_rate': 0.12962337168387844, 'feature_fraction': 0.7092467062814051, 'bagging_fraction': 0.8644343764004825, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,248] Trial 17 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 15, 'learning_rate': 0.13390827938850908, 'feature_fraction': 0.742323053988263, 'bagging_fraction': 0.9776620693102461, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,272] Trial 18 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 128, 'learning_rate': 0.10791080768636473, 'feature_fraction': 0.5278962198436578, 'bagging_fraction': 0.8396059694981284, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,324] Trial 19 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 47, 'learning_rate': 0.16700805914240505, 'feature_fraction': 0.6388617943488787, 'bagging_fraction': 0.7261094020479361, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,337] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 13, 'learning_rate': 0.09112993435491373, 'feature_fraction': 0.7342916457488533, 'bagging_fraction': 0.5432669304409132, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,373] Trial 21 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 77, 'learning_rate': 0.23761244613997284, 'feature_fraction': 0.6772133831727417, 'bagging_fraction': 0.9011614518490781, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,406] Trial 22 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 118, 'learning_rate': 0.16552077625707923, 'feature_fraction': 0.6874005885524394, 'bagging_fraction': 0.8396533888495666, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,432] Trial 23 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 42, 'learning_rate': 0.21571909315434806, 'feature_fraction': 0.79760803742406, 'bagging_fraction': 0.8485453899819578, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,485] Trial 24 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 68, 'learning_rate': 0.2700110720360852, 'feature_fraction': 0.5723527684379836, 'bagging_fraction': 0.9704841015569691, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,538] Trial 25 finished with value: 0.9732142857142857 and parameters: {'num_leaves': 40, 'learning_rate': 0.2708011696184323, 'feature_fraction': 0.5398935610707623, 'bagging_fraction': 0.9340905289820571, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,722] Trial 26 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 111, 'learning_rate': 0.02146360181552326, 'feature_fraction': 0.530571393074093, 'bagging_fraction': 0.945593870240446, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,779] Trial 27 finished with value: 0.9107142857142858 and parameters: {'num_leaves': 65, 'learning_rate': 0.26922381864511014, 'feature_fraction': 0.4083991121936787, 'bagging_fraction': 0.9382023174333071, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,821] Trial 28 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 35, 'learning_rate': 0.12967780115999653, 'feature_fraction': 0.564009180416977, 'bagging_fraction': 0.9963943282685113, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,872] Trial 29 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 292, 'learning_rate': 0.18297618510556554, 'feature_fraction': 0.4855978734689942, 'bagging_fraction': 0.9257874021158733, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,894] Trial 30 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 44, 'learning_rate': 0.11488771839295589, 'feature_fraction': 0.5878851586749098, 'bagging_fraction': 0.9862295250004437, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,916] Trial 31 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 44, 'learning_rate': 0.11335982146771453, 'feature_fraction': 0.5884531947193776, 'bagging_fraction': 0.985327122740945, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,939] Trial 32 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 67, 'learning_rate': 0.07338343618609305, 'feature_fraction': 0.6454470269431055, 'bagging_fraction': 0.9170583686681596, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,958] Trial 33 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 33, 'learning_rate': 0.15025396702719143, 'feature_fraction': 0.5227991674618465, 'bagging_fraction': 0.9932766506339056, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:42,972] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 141, 'learning_rate': 0.10449789706545302, 'feature_fraction': 0.5915833036372973, 'bagging_fraction': 0.9519278722347101, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,035] Trial 35 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 105, 'learning_rate': 0.1851300473387171, 'feature_fraction': 0.7207514607969587, 'bagging_fraction': 0.8205764069673541, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,064] Trial 36 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 30, 'learning_rate': 0.20763773931243723, 'feature_fraction': 0.653675968958771, 'bagging_fraction': 0.8968374288435471, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,079] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 234, 'learning_rate': 0.0768962706312677, 'feature_fraction': 0.4887617037262202, 'bagging_fraction': 0.8736404941559661, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 16 with value: 0.9821428571428572.
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.144719
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.124863
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.137208
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.128641
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.165716
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.138409
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.160971
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.129295
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.145277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.144628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.111271
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.110683
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.163257
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.131759
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.138241
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.13929
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.14681
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.109569
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.131537
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.138753
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.16483
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.187886
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.232098
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.160199
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.170199
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.168572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.180977
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.175314
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.158784
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.172112
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.131628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.168123
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.178918
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.194345
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.143592
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.145944
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.191148
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.15816
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.173039
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.14023
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.162845
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.154851
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.204695
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.172741
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.191021
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.185509
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:43,137] Trial 38 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 58, 'learning_rate': 0.2543919443835666, 'feature_fraction': 0.6057826995758504, 'bagging_fraction': 0.9518456590109667, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,164] Trial 39 finished with value: 0.875 and parameters: {'num_leaves': 11, 'learning_rate': 0.12243620413058694, 'feature_fraction': 0.43456349770901714, 'bagging_fraction': 0.8206993912268238, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,176] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 159, 'learning_rate': 0.2772726827769255, 'feature_fraction': 0.5654731105919211, 'bagging_fraction': 0.42563264856309213, 'bagging_freq': 2, 'min_child_samples': 71}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,206] Trial 41 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 44, 'learning_rate': 0.11245889230251116, 'feature_fraction': 0.582484219361923, 'bagging_fraction': 0.9752817697691235, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,231] Trial 42 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 28, 'learning_rate': 0.0938797903352544, 'feature_fraction': 0.6131896705766, 'bagging_fraction': 0.9949897575660486, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,256] Trial 43 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 77, 'learning_rate': 0.14712906450103364, 'feature_fraction': 0.5045290591988297, 'bagging_fraction': 0.9594650278443002, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,269] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 51, 'learning_rate': 0.06048268093351235, 'feature_fraction': 0.5470116045339851, 'bagging_fraction': 0.9223821359461329, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,290] Trial 45 finished with value: 0.9553571428571429 and parameters: {'num_leaves': 26, 'learning_rate': 0.1193225359862938, 'feature_fraction': 0.6279463948987561, 'bagging_fraction': 0.6910691266676046, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,333] Trial 46 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 194, 'learning_rate': 0.096543893712239, 'feature_fraction': 0.6624344430979026, 'bagging_fraction': 0.9721286218209125, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,346] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 72, 'learning_rate': 0.13724450626016818, 'feature_fraction': 0.4658343912789834, 'bagging_fraction': 0.8848540993651557, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,457] Trial 48 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 44, 'learning_rate': 0.17025092092371255, 'feature_fraction': 0.7720165298274643, 'bagging_fraction': 0.9249772109077317, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,502] Trial 49 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 94, 'learning_rate': 0.24223344958915752, 'feature_fraction': 0.5974925038548036, 'bagging_fraction': 0.864373737068971, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:16:43,696] A new study created in memory with name: no-name-b48936e0-e4a7-480b-b8de-d66f2a5daa09
[I 2025-09-17 13:16:43,778] Trial 0 finished with value: 0.7698412698412698 and parameters: {'num_leaves': 50, 'learning_rate': 0.24301538544920684, 'feature_fraction': 0.939607219760807, 'bagging_fraction': 0.8025246184617519, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 0 with value: 0.7698412698412698.
[I 2025-09-17 13:16:43,906] Trial 1 finished with value: 0.7738095238095237 and parameters: {'num_leaves': 162, 'learning_rate': 0.01900034334432389, 'feature_fraction': 0.9619721381633026, 'bagging_fraction': 0.975761696338478, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 1 with value: 0.7738095238095237.
[I 2025-09-17 13:16:43,919] Trial 2 finished with value: 0.49404761904761896 and parameters: {'num_leaves': 227, 'learning_rate': 0.15944919639617475, 'feature_fraction': 0.678341379143452, 'bagging_fraction': 0.4732767703886044, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 1 with value: 0.7738095238095237.
[I 2025-09-17 13:16:44,004] Trial 3 finished with value: 0.8373015873015872 and parameters: {'num_leaves': 66, 'learning_rate': 0.046878980873342226, 'feature_fraction': 0.9202156688229618, 'bagging_fraction': 0.6178861242118303, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,017] Trial 4 finished with value: 0.5059523809523809 and parameters: {'num_leaves': 133, 'learning_rate': 0.0477105178910335, 'feature_fraction': 0.4314895410460363, 'bagging_fraction': 0.8583280364186153, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,182] Trial 5 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 181, 'learning_rate': 0.015860166667917633, 'feature_fraction': 0.5067075656793628, 'bagging_fraction': 0.9526346364575988, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,194] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 211, 'learning_rate': 0.1801039036297532, 'feature_fraction': 0.5655879154242824, 'bagging_fraction': 0.5293608017482234, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,206] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 236, 'learning_rate': 0.0832192491202059, 'feature_fraction': 0.9462921568860532, 'bagging_fraction': 0.5065381810531996, 'bagging_freq': 3, 'min_child_samples': 82}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,219] Trial 8 finished with value: 0.48611111111111105 and parameters: {'num_leaves': 268, 'learning_rate': 0.10823846185262251, 'feature_fraction': 0.9512797872084806, 'bagging_fraction': 0.45758495551943623, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,242] Trial 9 finished with value: 0.5515873015873016 and parameters: {'num_leaves': 223, 'learning_rate': 0.1542384513994451, 'feature_fraction': 0.41230576100597827, 'bagging_fraction': 0.9396889894193714, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,254] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 25, 'learning_rate': 0.254456451562147, 'feature_fraction': 0.8063207098750798, 'bagging_fraction': 0.6439077630337843, 'bagging_freq': 1, 'min_child_samples': 92}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,270] Trial 11 finished with value: 0.3511904761904761 and parameters: {'num_leaves': 96, 'learning_rate': 0.017266769294570408, 'feature_fraction': 0.753955059725258, 'bagging_fraction': 0.6757212132753682, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,304] Trial 12 finished with value: 0.6666666666666666 and parameters: {'num_leaves': 93, 'learning_rate': 0.07593808041974784, 'feature_fraction': 0.5739512071623079, 'bagging_fraction': 0.7606862511887577, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,377] Trial 13 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 170, 'learning_rate': 0.05699973172777829, 'feature_fraction': 0.8241597025273413, 'bagging_fraction': 0.5678431821686398, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,390] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.12282381106622067, 'feature_fraction': 0.5542350893157268, 'bagging_fraction': 0.5861472144179771, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,433] Trial 15 finished with value: 0.75 and parameters: {'num_leaves': 111, 'learning_rate': 0.013544636784048193, 'feature_fraction': 0.6687720242361245, 'bagging_fraction': 0.7358921655782895, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,449] Trial 16 finished with value: 0.5119047619047619 and parameters: {'num_leaves': 50, 'learning_rate': 0.053504713984507964, 'feature_fraction': 0.854691648519061, 'bagging_fraction': 0.8834205082275142, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,471] Trial 17 finished with value: 0.5515873015873016 and parameters: {'num_leaves': 187, 'learning_rate': 0.20579225220300257, 'feature_fraction': 0.48899678489377696, 'bagging_fraction': 0.6291932855636233, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,483] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.11190340275729424, 'feature_fraction': 0.622934489935394, 'bagging_fraction': 0.8345434033796886, 'bagging_freq': 2, 'min_child_samples': 77}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,513] Trial 19 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 69, 'learning_rate': 0.08464565698795098, 'feature_fraction': 0.7550750414063445, 'bagging_fraction': 0.41699319227602005, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,532] Trial 20 finished with value: 0.4186507936507937 and parameters: {'num_leaves': 15, 'learning_rate': 0.037631288464396694, 'feature_fraction': 0.8792651374976019, 'bagging_fraction': 0.7441602855789301, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,604] Trial 21 finished with value: 0.7896825396825398 and parameters: {'num_leaves': 154, 'learning_rate': 0.01162507862552364, 'feature_fraction': 0.9894924225524436, 'bagging_fraction': 0.9992367162854999, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,675] Trial 22 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 197, 'learning_rate': 0.01140312341965987, 'feature_fraction': 0.8869350369469342, 'bagging_fraction': 0.9828630202412939, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,807] Trial 23 finished with value: 0.75 and parameters: {'num_leaves': 137, 'learning_rate': 0.043180299468896524, 'feature_fraction': 0.9971792641417212, 'bagging_fraction': 0.9325285424516296, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,831] Trial 24 finished with value: 0.6587301587301587 and parameters: {'num_leaves': 249, 'learning_rate': 0.07012578461962926, 'feature_fraction': 0.9951766605607388, 'bagging_fraction': 0.9131628041061893, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,873] Trial 25 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 185, 'learning_rate': 0.29550451937573174, 'feature_fraction': 0.904524947932565, 'bagging_fraction': 0.9935880012699496, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,888] Trial 26 finished with value: 0.31547619047619047 and parameters: {'num_leaves': 118, 'learning_rate': 0.03323620530727203, 'feature_fraction': 0.7368197790547724, 'bagging_fraction': 0.7915021451452895, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,942] Trial 27 finished with value: 0.6746031746031745 and parameters: {'num_leaves': 71, 'learning_rate': 0.09493066695145096, 'feature_fraction': 0.4756922103528167, 'bagging_fraction': 0.6822925670866459, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:44,976] Trial 28 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 153, 'learning_rate': 0.13665079489518137, 'feature_fraction': 0.8051425652309557, 'bagging_fraction': 0.8857653425978582, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,086] Trial 29 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 42, 'learning_rate': 0.06460537247484874, 'feature_fraction': 0.9236010266698115, 'bagging_fraction': 0.8217225509565729, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,125] Trial 30 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 82, 'learning_rate': 0.031987816771963634, 'feature_fraction': 0.6128716288408785, 'bagging_fraction': 0.950859965504451, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,202] Trial 31 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 40, 'learning_rate': 0.06304489488315133, 'feature_fraction': 0.9071152971935001, 'bagging_fraction': 0.8102479389240872, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,372] Trial 32 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 55, 'learning_rate': 0.03082655964078109, 'feature_fraction': 0.9282358703883492, 'bagging_fraction': 0.892545623577486, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,449] Trial 33 finished with value: 0.746031746031746 and parameters: {'num_leaves': 33, 'learning_rate': 0.01183648063701713, 'feature_fraction': 0.97361286632421, 'bagging_fraction': 0.9608831909961584, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,521] Trial 34 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 171, 'learning_rate': 0.05468564190710774, 'feature_fraction': 0.8369736800017303, 'bagging_fraction': 0.9998282797918417, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,570] Trial 35 finished with value: 0.7023809523809524 and parameters: {'num_leaves': 146, 'learning_rate': 0.09455189231247012, 'feature_fraction': 0.9336244377925939, 'bagging_fraction': 0.8523914654171553, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,608] Trial 36 finished with value: 0.6587301587301586 and parameters: {'num_leaves': 206, 'learning_rate': 0.029293342634992496, 'feature_fraction': 0.8648833859852277, 'bagging_fraction': 0.7131071306492364, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,667] Trial 37 finished with value: 0.753968253968254 and parameters: {'num_leaves': 118, 'learning_rate': 0.04634145439349391, 'feature_fraction': 0.7062011582156202, 'bagging_fraction': 0.914709351198824, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,714] Trial 38 finished with value: 0.6071428571428571 and parameters: {'num_leaves': 14, 'learning_rate': 0.19881354936585802, 'feature_fraction': 0.4918059707514794, 'bagging_fraction': 0.6084254975772505, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,794] Trial 39 finished with value: 0.6825396825396826 and parameters: {'num_leaves': 102, 'learning_rate': 0.07174849753437251, 'feature_fraction': 0.9738043657535346, 'bagging_fraction': 0.5506935141936835, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,812] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 60, 'learning_rate': 0.02571222415480802, 'feature_fraction': 0.916003695085865, 'bagging_fraction': 0.7846244201841878, 'bagging_freq': 4, 'min_child_samples': 98}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,892] Trial 41 finished with value: 0.746031746031746 and parameters: {'num_leaves': 36, 'learning_rate': 0.06589397785883747, 'feature_fraction': 0.9531058706682979, 'bagging_fraction': 0.8365706464049351, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:45,962] Trial 42 finished with value: 0.753968253968254 and parameters: {'num_leaves': 39, 'learning_rate': 0.05914551929536467, 'feature_fraction': 0.9049453501739887, 'bagging_fraction': 0.8223839727793739, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:46,107] Trial 43 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 85, 'learning_rate': 0.08974602579071814, 'feature_fraction': 0.9658809789499035, 'bagging_fraction': 0.8673304434677197, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:46,169] Trial 44 finished with value: 0.7063492063492064 and parameters: {'num_leaves': 80, 'learning_rate': 0.0859801909073797, 'feature_fraction': 0.9693930022595567, 'bagging_fraction': 0.9621867677286067, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:46,200] Trial 45 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 223, 'learning_rate': 0.1560787366555069, 'feature_fraction': 0.7940783989202276, 'bagging_fraction': 0.8622891013942825, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:46,217] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 123, 'learning_rate': 0.13800386738679893, 'feature_fraction': 0.9993395647468588, 'bagging_fraction': 0.9215733392562964, 'bagging_freq': 6, 'min_child_samples': 67}. Best is trial 3 with value: 0.8373015873015872.
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.132138
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.180837
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.156664
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.17592
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.152987
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.190121
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.16719
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.188421
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.164901
Training model for P094... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.563572
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.526861
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657267
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.476269
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.655263
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.5177
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.658076
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.65251
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.656989
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.613687
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.530555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.600221
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655355
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.651561
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.592074
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.658312
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.541954
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.555914
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.564009
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.607758
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.544491
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.658297
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.599244
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.533833
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.541509
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.610168
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.527058
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.578579
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.560679
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.572075
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.580615
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.626058
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.559514
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.642164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.608387
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.542289
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.558993
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.5045
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.586555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.571732
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.655533
[I 2025-09-17 13:16:46,259] Trial 47 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 88, 'learning_rate': 0.1025616739987116, 'feature_fraction': 0.9486167966766259, 'bagging_fraction': 0.49486812085118415, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:46,412] Trial 48 finished with value: 0.7023809523809524 and parameters: {'num_leaves': 174, 'learning_rate': 0.04590317723670492, 'feature_fraction': 0.5244114304060913, 'bagging_fraction': 0.9665510096253126, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:46,431] Trial 49 finished with value: 0.5079365079365079 and parameters: {'num_leaves': 104, 'learning_rate': 0.12482066319756796, 'feature_fraction': 0.40674071078591306, 'bagging_fraction': 0.645237419225729, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 3 with value: 0.8373015873015872.
[I 2025-09-17 13:16:47,181] A new study created in memory with name: no-name-17033e73-3318-4674-bcc4-6f566a258910
[I 2025-09-17 13:16:47,217] Trial 0 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 69, 'learning_rate': 0.03320177682242156, 'feature_fraction': 0.62388384812363, 'bagging_fraction': 0.5945404033745348, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 0 with value: 0.6904761904761905.
[I 2025-09-17 13:16:47,226] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 180, 'learning_rate': 0.11057428976370282, 'feature_fraction': 0.8680980566826978, 'bagging_fraction': 0.8452116199966556, 'bagging_freq': 5, 'min_child_samples': 91}. Best is trial 0 with value: 0.6904761904761905.
[I 2025-09-17 13:16:47,233] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 226, 'learning_rate': 0.08578666063025472, 'feature_fraction': 0.6006771128916131, 'bagging_fraction': 0.4011197492938925, 'bagging_freq': 5, 'min_child_samples': 91}. Best is trial 0 with value: 0.6904761904761905.
[I 2025-09-17 13:16:47,246] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 250, 'learning_rate': 0.20065524180990746, 'feature_fraction': 0.5699658293297849, 'bagging_fraction': 0.6241047799707158, 'bagging_freq': 2, 'min_child_samples': 89}. Best is trial 0 with value: 0.6904761904761905.
[I 2025-09-17 13:16:47,266] Trial 4 finished with value: 0.5952380952380952 and parameters: {'num_leaves': 74, 'learning_rate': 0.05598758248331291, 'feature_fraction': 0.4810915283348463, 'bagging_fraction': 0.579205157281444, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 0 with value: 0.6904761904761905.
[I 2025-09-17 13:16:47,305] Trial 5 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 265, 'learning_rate': 0.2453006130440936, 'feature_fraction': 0.5525523440723213, 'bagging_fraction': 0.8042765201854366, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 5 with value: 0.7698412698412699.
[I 2025-09-17 13:16:47,397] Trial 6 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 114, 'learning_rate': 0.21843010730021312, 'feature_fraction': 0.9066566469898242, 'bagging_fraction': 0.7835403983207525, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 6 with value: 0.8134920634920635.
[I 2025-09-17 13:16:47,436] Trial 7 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 130, 'learning_rate': 0.24675067505758772, 'feature_fraction': 0.9806545307749118, 'bagging_fraction': 0.6654406493697096, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 7 with value: 0.8214285714285714.
[I 2025-09-17 13:16:47,451] Trial 8 finished with value: 0.4166666666666667 and parameters: {'num_leaves': 117, 'learning_rate': 0.2470812372206367, 'feature_fraction': 0.5053752545351226, 'bagging_fraction': 0.9366415934019535, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial 7 with value: 0.8214285714285714.
[I 2025-09-17 13:16:47,481] Trial 9 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 25, 'learning_rate': 0.10976992400437974, 'feature_fraction': 0.8028517180810306, 'bagging_fraction': 0.40991152860096314, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 7 with value: 0.8214285714285714.
[I 2025-09-17 13:16:47,500] Trial 10 finished with value: 0.623015873015873 and parameters: {'num_leaves': 183, 'learning_rate': 0.28759005178353875, 'feature_fraction': 0.9630726362547236, 'bagging_fraction': 0.6901441449507779, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 7 with value: 0.8214285714285714.
[I 2025-09-17 13:16:47,587] Trial 11 finished with value: 0.9087301587301586 and parameters: {'num_leaves': 133, 'learning_rate': 0.1749781485461978, 'feature_fraction': 0.9825733605888022, 'bagging_fraction': 0.7784335113479298, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,611] Trial 12 finished with value: 0.6706349206349207 and parameters: {'num_leaves': 139, 'learning_rate': 0.16132734707172638, 'feature_fraction': 0.7388578669774908, 'bagging_fraction': 0.998107264108621, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,627] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 188, 'learning_rate': 0.1621515795810093, 'feature_fraction': 0.9867149964959224, 'bagging_fraction': 0.7400269916733309, 'bagging_freq': 7, 'min_child_samples': 63}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,650] Trial 14 finished with value: 0.6071428571428571 and parameters: {'num_leaves': 84, 'learning_rate': 0.29047112112957907, 'feature_fraction': 0.8444717669869757, 'bagging_fraction': 0.6788694865300176, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,739] Trial 15 finished with value: 0.8373015873015872 and parameters: {'num_leaves': 16, 'learning_rate': 0.1962561394490903, 'feature_fraction': 0.7538098538021833, 'bagging_fraction': 0.49238304264099, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,817] Trial 16 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 21, 'learning_rate': 0.1825290372054778, 'feature_fraction': 0.7169305111449769, 'bagging_fraction': 0.5130846932262638, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,832] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 56, 'learning_rate': 0.11751257194608883, 'feature_fraction': 0.7860118274683875, 'bagging_fraction': 0.8751803023368402, 'bagging_freq': 6, 'min_child_samples': 67}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,878] Trial 18 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 285, 'learning_rate': 0.14048948125584096, 'feature_fraction': 0.4263545002486301, 'bagging_fraction': 0.49752865822233944, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,889] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 218, 'learning_rate': 0.20994248966901405, 'feature_fraction': 0.6411410460424862, 'bagging_fraction': 0.47966843125638703, 'bagging_freq': 4, 'min_child_samples': 76}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,906] Trial 20 finished with value: 0.4583333333333333 and parameters: {'num_leaves': 13, 'learning_rate': 0.18272288480120813, 'feature_fraction': 0.8880282643002959, 'bagging_fraction': 0.742035937012663, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,951] Trial 21 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 141, 'learning_rate': 0.2462258645429706, 'feature_fraction': 0.9428349291649541, 'bagging_fraction': 0.6455989293071188, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:47,989] Trial 22 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 161, 'learning_rate': 0.23223175434022741, 'feature_fraction': 0.940059896088791, 'bagging_fraction': 0.533845400236785, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,008] Trial 23 finished with value: 0.630952380952381 and parameters: {'num_leaves': 97, 'learning_rate': 0.261059705575536, 'feature_fraction': 0.8152917341924861, 'bagging_fraction': 0.5643622971788006, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,083] Trial 24 finished with value: 0.861111111111111 and parameters: {'num_leaves': 47, 'learning_rate': 0.19138795629945365, 'feature_fraction': 0.9092102033446454, 'bagging_fraction': 0.6310460219216196, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,154] Trial 25 finished with value: 0.9007936507936509 and parameters: {'num_leaves': 50, 'learning_rate': 0.18535687831049463, 'feature_fraction': 0.7678781421623224, 'bagging_fraction': 0.725025899875626, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,170] Trial 26 finished with value: 0.3551587301587302 and parameters: {'num_leaves': 46, 'learning_rate': 0.1447694673261772, 'feature_fraction': 0.6627277162559623, 'bagging_fraction': 0.7428308303837967, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,234] Trial 27 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 41, 'learning_rate': 0.18147556935964299, 'feature_fraction': 0.9112111142148143, 'bagging_fraction': 0.8098720572923792, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,248] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 96, 'learning_rate': 0.1342564524093343, 'feature_fraction': 0.9998562005984312, 'bagging_fraction': 0.8855045302454925, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,281] Trial 29 finished with value: 0.6666666666666666 and parameters: {'num_leaves': 66, 'learning_rate': 0.030574357471298663, 'feature_fraction': 0.8387383646513796, 'bagging_fraction': 0.6119684178611466, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,300] Trial 30 finished with value: 0.5873015873015873 and parameters: {'num_leaves': 41, 'learning_rate': 0.16644411434900658, 'feature_fraction': 0.6888172811082084, 'bagging_fraction': 0.7361888905087239, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,347] Trial 31 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 39, 'learning_rate': 0.17976444160237354, 'feature_fraction': 0.9110925414908996, 'bagging_fraction': 0.7979120011618881, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,406] Trial 32 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 61, 'learning_rate': 0.22000672182136283, 'feature_fraction': 0.8695723911852067, 'bagging_fraction': 0.8326302949791952, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,435] Trial 33 finished with value: 0.6984126984126984 and parameters: {'num_leaves': 99, 'learning_rate': 0.19699894592863276, 'feature_fraction': 0.9240389750725839, 'bagging_fraction': 0.7174907811925777, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,464] Trial 34 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 77, 'learning_rate': 0.12364199629620101, 'feature_fraction': 0.7708357802754403, 'bagging_fraction': 0.7696561497759989, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,528] Trial 35 finished with value: 0.7658730158730159 and parameters: {'num_leaves': 43, 'learning_rate': 0.012784592126274169, 'feature_fraction': 0.851075277643678, 'bagging_fraction': 0.8707727936244063, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,616] Trial 36 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 164, 'learning_rate': 0.09776614784604995, 'feature_fraction': 0.8893383717124994, 'bagging_fraction': 0.8274970493171654, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,656] Trial 37 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 220, 'learning_rate': 0.08185987887484782, 'feature_fraction': 0.9599580220430723, 'bagging_fraction': 0.9265991510399634, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,774] Trial 38 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 81, 'learning_rate': 0.1734972834397407, 'feature_fraction': 0.8128366522792252, 'bagging_fraction': 0.6379693035790696, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,812] Trial 39 finished with value: 0.746031746031746 and parameters: {'num_leaves': 120, 'learning_rate': 0.1516311413572544, 'feature_fraction': 0.8316429158054142, 'bagging_fraction': 0.637567908236532, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,907] Trial 40 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 92, 'learning_rate': 0.21015302165704514, 'feature_fraction': 0.7185356506326077, 'bagging_fraction': 0.596728878530882, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 11 with value: 0.9087301587301586.
[I 2025-09-17 13:16:48,958] Trial 41 finished with value: 0.9325396825396826 and parameters: {'num_leaves': 33, 'learning_rate': 0.17371036701349435, 'feature_fraction': 0.8703356344812405, 'bagging_fraction': 0.7049797837832439, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,019] Trial 42 finished with value: 0.8809523809523809 and parameters: {'num_leaves': 30, 'learning_rate': 0.17242390435135754, 'feature_fraction': 0.8012150048261374, 'bagging_fraction': 0.701154481889009, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,098] Trial 43 finished with value: 0.9007936507936508 and parameters: {'num_leaves': 26, 'learning_rate': 0.16710274060511163, 'feature_fraction': 0.7818024672505601, 'bagging_fraction': 0.7043510438395773, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,128] Trial 44 finished with value: 0.7222222222222223 and parameters: {'num_leaves': 26, 'learning_rate': 0.1538126369437852, 'feature_fraction': 0.7675741422139287, 'bagging_fraction': 0.7059409480227374, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,196] Trial 45 finished with value: 0.873015873015873 and parameters: {'num_leaves': 27, 'learning_rate': 0.13462576987770258, 'feature_fraction': 0.7903101779957317, 'bagging_fraction': 0.7730523010729405, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,232] Trial 46 finished with value: 0.746031746031746 and parameters: {'num_leaves': 59, 'learning_rate': 0.22679548675801559, 'feature_fraction': 0.5914048219540351, 'bagging_fraction': 0.6683493276150326, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,278] Trial 47 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 32, 'learning_rate': 0.16180690042329304, 'feature_fraction': 0.7387357038215057, 'bagging_fraction': 0.7055742122085139, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,306] Trial 48 finished with value: 0.7063492063492064 and parameters: {'num_leaves': 10, 'learning_rate': 0.15950015912587923, 'feature_fraction': 0.7351286721691149, 'bagging_fraction': 0.7650988367613965, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,340] Trial 49 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 201, 'learning_rate': 0.2096839103954452, 'feature_fraction': 0.7071239407294642, 'bagging_fraction': 0.6811109548013182, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 41 with value: 0.9325396825396826.
[I 2025-09-17 13:16:49,657] A new study created in memory with name: no-name-1708e638-d8da-4302-bf21-f1cb1f1b85e4
[I 2025-09-17 13:16:49,668] Trial 0 finished with value: 0.3988095238095238 and parameters: {'num_leaves': 80, 'learning_rate': 0.10331273185700798, 'feature_fraction': 0.9589216634197129, 'bagging_fraction': 0.9597953338163644, 'bagging_freq': 7, 'min_child_samples': 57}. Best is trial 0 with value: 0.3988095238095238.
[I 2025-09-17 13:16:49,682] Trial 1 finished with value: 0.6309523809523809 and parameters: {'num_leaves': 73, 'learning_rate': 0.023481253965564296, 'feature_fraction': 0.8593856185074162, 'bagging_fraction': 0.9350808232804133, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 1 with value: 0.6309523809523809.
[I 2025-09-17 13:16:49,695] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 134, 'learning_rate': 0.2849177150591123, 'feature_fraction': 0.7269056862324261, 'bagging_fraction': 0.9393158702665787, 'bagging_freq': 6, 'min_child_samples': 66}. Best is trial 1 with value: 0.6309523809523809.
[I 2025-09-17 13:16:49,756] Trial 3 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 169, 'learning_rate': 0.04473688241394929, 'feature_fraction': 0.57709488458821, 'bagging_fraction': 0.486716979662323, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:49,782] Trial 4 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 75, 'learning_rate': 0.1811585742761581, 'feature_fraction': 0.9855869721606824, 'bagging_fraction': 0.9363785792413742, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:49,797] Trial 5 finished with value: 0.375 and parameters: {'num_leaves': 41, 'learning_rate': 0.04864773844567933, 'feature_fraction': 0.7222582404757812, 'bagging_fraction': 0.5047320624236791, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 3 with value: 0.8134920634920635.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.599195
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.581194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.650273
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.594656
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.647734
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.547699
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.499985
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.491498
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.658633
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.541431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.624595
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.426984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.617762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.633382
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.537847
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.530473
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.563052
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.660276
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.506414
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.537001
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.626158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.464417
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.396339
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.651387
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.486661
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.606204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.649363
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.54005
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.5026
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.59209
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.587121
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.55478
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.497545
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.553199
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.43965
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.587655
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.528833
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.461349
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.471307
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.397765
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.592472
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.446807
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.582447
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.460833
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.60746
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.59839
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.660666
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.654029
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.553757
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.551221
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659787
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:49,834] Trial 6 finished with value: 0.6071428571428572 and parameters: {'num_leaves': 244, 'learning_rate': 0.025586826621332746, 'feature_fraction': 0.6969221064190367, 'bagging_fraction': 0.45512226149220003, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:49,844] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 111, 'learning_rate': 0.19780302434173727, 'feature_fraction': 0.8212802051198487, 'bagging_fraction': 0.42905042617350564, 'bagging_freq': 5, 'min_child_samples': 88}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:49,869] Trial 8 finished with value: 0.6666666666666666 and parameters: {'num_leaves': 249, 'learning_rate': 0.216909850411025, 'feature_fraction': 0.9728822916823526, 'bagging_fraction': 0.9305636235957245, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:49,882] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 60, 'learning_rate': 0.11522839806649494, 'feature_fraction': 0.6149965454700159, 'bagging_fraction': 0.881343524116458, 'bagging_freq': 1, 'min_child_samples': 74}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:49,946] Trial 10 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 190, 'learning_rate': 0.0962623392136006, 'feature_fraction': 0.41889828050774525, 'bagging_fraction': 0.6014905890182554, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:49,973] Trial 11 finished with value: 0.5833333333333333 and parameters: {'num_leaves': 187, 'learning_rate': 0.18256709794066014, 'feature_fraction': 0.5155729595609737, 'bagging_fraction': 0.7967486579885321, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,047] Trial 12 finished with value: 0.6507936507936507 and parameters: {'num_leaves': 179, 'learning_rate': 0.24903810353305342, 'feature_fraction': 0.56530604179136, 'bagging_fraction': 0.6885939822134405, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,061] Trial 13 finished with value: 0.4761904761904762 and parameters: {'num_leaves': 127, 'learning_rate': 0.14981299679983207, 'feature_fraction': 0.42749596608216744, 'bagging_fraction': 0.6088830394047822, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,088] Trial 14 finished with value: 0.7599206349206349 and parameters: {'num_leaves': 11, 'learning_rate': 0.1475964351705979, 'feature_fraction': 0.8318150664450705, 'bagging_fraction': 0.7804169064526242, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,115] Trial 15 finished with value: 0.615079365079365 and parameters: {'num_leaves': 288, 'learning_rate': 0.06496825989319006, 'feature_fraction': 0.6375782873485059, 'bagging_fraction': 0.5442107816685723, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,147] Trial 16 finished with value: 0.6825396825396826 and parameters: {'num_leaves': 155, 'learning_rate': 0.23293844017636978, 'feature_fraction': 0.5231355417741804, 'bagging_fraction': 0.7193800750734527, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,243] Trial 17 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 102, 'learning_rate': 0.16920362925533017, 'feature_fraction': 0.929482133231883, 'bagging_fraction': 0.8436007537424208, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,260] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.1275639288885593, 'feature_fraction': 0.8922607998929586, 'bagging_fraction': 0.668449337026549, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,275] Trial 19 finished with value: 0.4107142857142857 and parameters: {'num_leaves': 20, 'learning_rate': 0.07344101165516681, 'feature_fraction': 0.7778432358600057, 'bagging_fraction': 0.7584181505882135, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,293] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 158, 'learning_rate': 0.28205433341882136, 'feature_fraction': 0.6518097143420967, 'bagging_fraction': 0.6159156593925337, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,326] Trial 21 finished with value: 0.7261904761904763 and parameters: {'num_leaves': 28, 'learning_rate': 0.13925374612650016, 'feature_fraction': 0.7843377352840171, 'bagging_fraction': 0.8390265969945333, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 3 with value: 0.8134920634920635.
[I 2025-09-17 13:16:50,355] Trial 22 finished with value: 0.8273809523809523 and parameters: {'num_leaves': 11, 'learning_rate': 0.1954321275047419, 'feature_fraction': 0.9991271270051351, 'bagging_fraction': 0.7474939166540971, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,372] Trial 23 finished with value: 0.37499999999999994 and parameters: {'num_leaves': 52, 'learning_rate': 0.19708210287394382, 'feature_fraction': 0.9921768935487872, 'bagging_fraction': 0.4028877505307017, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,403] Trial 24 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 85, 'learning_rate': 0.24660875148807548, 'feature_fraction': 0.9120445714692671, 'bagging_fraction': 0.4966561215857527, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,455] Trial 25 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 41, 'learning_rate': 0.2113290335449599, 'feature_fraction': 0.47571833088294174, 'bagging_fraction': 0.8787053752730849, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,470] Trial 26 finished with value: 0.6547619047619048 and parameters: {'num_leaves': 102, 'learning_rate': 0.17015853752841475, 'feature_fraction': 0.5862433234685169, 'bagging_fraction': 0.7392290822213659, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,508] Trial 27 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 149, 'learning_rate': 0.17117337145875938, 'feature_fraction': 0.999186671729677, 'bagging_fraction': 0.6531985467432058, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,524] Trial 28 finished with value: 0.37499999999999994 and parameters: {'num_leaves': 211, 'learning_rate': 0.2534516183353479, 'feature_fraction': 0.8811749720044504, 'bagging_fraction': 0.5543918496476634, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,541] Trial 29 finished with value: 0.5357142857142857 and parameters: {'num_leaves': 79, 'learning_rate': 0.09418242582730718, 'feature_fraction': 0.9498372698568708, 'bagging_fraction': 0.9927453757936983, 'bagging_freq': 7, 'min_child_samples': 66}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,578] Trial 30 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 62, 'learning_rate': 0.11579085833624912, 'feature_fraction': 0.6711825745770168, 'bagging_fraction': 0.8061103912968989, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,605] Trial 31 finished with value: 0.6349206349206349 and parameters: {'num_leaves': 92, 'learning_rate': 0.25812471249485236, 'feature_fraction': 0.9226217942884057, 'bagging_fraction': 0.4627682953456135, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,643] Trial 32 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 126, 'learning_rate': 0.2345586911246434, 'feature_fraction': 0.908276125842056, 'bagging_fraction': 0.497159627450952, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,672] Trial 33 finished with value: 0.7797619047619049 and parameters: {'num_leaves': 79, 'learning_rate': 0.27282516814305363, 'feature_fraction': 0.953402894719309, 'bagging_fraction': 0.5590645739133674, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,687] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 47, 'learning_rate': 0.2959765097747613, 'feature_fraction': 0.854771169296277, 'bagging_fraction': 0.512859894556157, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,757] Trial 35 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 35, 'learning_rate': 0.22366351159567358, 'feature_fraction': 0.9615530501196894, 'bagging_fraction': 0.9932542624905096, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,776] Trial 36 finished with value: 0.48809523809523814 and parameters: {'num_leaves': 139, 'learning_rate': 0.19156331323577486, 'feature_fraction': 0.7750724464773033, 'bagging_fraction': 0.466233544953549, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,794] Trial 37 finished with value: 0.369047619047619 and parameters: {'num_leaves': 172, 'learning_rate': 0.03792259418417674, 'feature_fraction': 0.7330486165121834, 'bagging_fraction': 0.8930372821291075, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,821] Trial 38 finished with value: 0.5992063492063492 and parameters: {'num_leaves': 116, 'learning_rate': 0.21661981554796625, 'feature_fraction': 0.9973663300977142, 'bagging_fraction': 0.40073582432026345, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,858] Trial 39 finished with value: 0.7281746031746031 and parameters: {'num_leaves': 70, 'learning_rate': 0.1627323222255108, 'feature_fraction': 0.8699315905792899, 'bagging_fraction': 0.6440578063274219, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,883] Trial 40 finished with value: 0.6388888888888888 and parameters: {'num_leaves': 93, 'learning_rate': 0.18434012858361298, 'feature_fraction': 0.934606088890303, 'bagging_fraction': 0.9381362705351692, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:50,946] Trial 41 finished with value: 0.746031746031746 and parameters: {'num_leaves': 31, 'learning_rate': 0.23177386040665315, 'feature_fraction': 0.9666072399743821, 'bagging_fraction': 0.9651070495073708, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,010] Trial 42 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 32, 'learning_rate': 0.20411373547159958, 'feature_fraction': 0.9588403734232126, 'bagging_fraction': 0.9923527193401291, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,038] Trial 43 finished with value: 0.7202380952380952 and parameters: {'num_leaves': 11, 'learning_rate': 0.2050600073891944, 'feature_fraction': 0.9093267052856024, 'bagging_fraction': 0.9149829721465286, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,133] Trial 44 finished with value: 0.7817460317460319 and parameters: {'num_leaves': 57, 'learning_rate': 0.18367758273020718, 'feature_fraction': 0.8357629496399416, 'bagging_fraction': 0.9594030461983414, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,164] Trial 45 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 22, 'learning_rate': 0.024806630424708803, 'feature_fraction': 0.97544955761009, 'bagging_fraction': 0.5188882507971498, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,184] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 68, 'learning_rate': 0.2060710631474854, 'feature_fraction': 0.9322701515787946, 'bagging_fraction': 0.5907390798429235, 'bagging_freq': 7, 'min_child_samples': 80}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,364] Trial 47 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 204, 'learning_rate': 0.01141321795260275, 'feature_fraction': 0.9782102565139958, 'bagging_fraction': 0.846941354770498, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,385] Trial 48 finished with value: 0.5555555555555556 and parameters: {'num_leaves': 238, 'learning_rate': 0.15848889268329802, 'feature_fraction': 0.8107482305989899, 'bagging_fraction': 0.44229172088160845, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,419] Trial 49 finished with value: 0.7043650793650793 and parameters: {'num_leaves': 46, 'learning_rate': 0.2456414630245496, 'feature_fraction': 0.5490772161995868, 'bagging_fraction': 0.4820806033018978, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 22 with value: 0.8273809523809523.
[I 2025-09-17 13:16:51,690] A new study created in memory with name: no-name-f391023e-bb63-4fe2-a6be-4e9cb3de211a
[I 2025-09-17 13:16:51,743] Trial 0 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 294, 'learning_rate': 0.12484554095577183, 'feature_fraction': 0.5543154602221092, 'bagging_fraction': 0.8518654174543059, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,774] Trial 1 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 116, 'learning_rate': 0.28185495911223024, 'feature_fraction': 0.9780092099192008, 'bagging_fraction': 0.5330233780895899, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,783] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 194, 'learning_rate': 0.24335878748410159, 'feature_fraction': 0.9918006284535665, 'bagging_fraction': 0.9689390617902687, 'bagging_freq': 4, 'min_child_samples': 76}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,798] Trial 3 finished with value: 0.4801587301587302 and parameters: {'num_leaves': 131, 'learning_rate': 0.266668415405719, 'feature_fraction': 0.9155470897304894, 'bagging_fraction': 0.6295592843507768, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,820] Trial 4 finished with value: 0.753968253968254 and parameters: {'num_leaves': 37, 'learning_rate': 0.26740156320455644, 'feature_fraction': 0.7873724749718474, 'bagging_fraction': 0.9178867111458061, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,850] Trial 5 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 96, 'learning_rate': 0.07273495198135727, 'feature_fraction': 0.873595219223782, 'bagging_fraction': 0.7941375444839573, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,861] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 63, 'learning_rate': 0.2865488125029209, 'feature_fraction': 0.9251088100586305, 'bagging_fraction': 0.45205880512158775, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,880] Trial 7 finished with value: 0.5079365079365079 and parameters: {'num_leaves': 30, 'learning_rate': 0.09302451451335514, 'feature_fraction': 0.6636222076119308, 'bagging_fraction': 0.4890236558042824, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,890] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 25, 'learning_rate': 0.05363114846223852, 'feature_fraction': 0.5814389537160192, 'bagging_fraction': 0.44196130433267933, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,902] Trial 9 finished with value: 0.619047619047619 and parameters: {'num_leaves': 293, 'learning_rate': 0.2610812610292964, 'feature_fraction': 0.44959915291766295, 'bagging_fraction': 0.8578915423581845, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:51,953] Trial 10 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 297, 'learning_rate': 0.17481708406786356, 'feature_fraction': 0.46332839445642965, 'bagging_fraction': 0.7160810957668544, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:52,040] Trial 11 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 287, 'learning_rate': 0.16103674218926428, 'feature_fraction': 0.43185683125245145, 'bagging_fraction': 0.7261946888661859, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:52,128] Trial 12 finished with value: 0.761904761904762 and parameters: {'num_leaves': 228, 'learning_rate': 0.14054838858601293, 'feature_fraction': 0.5549645054227751, 'bagging_fraction': 0.744723931885833, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:52,143] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.1734693746491899, 'feature_fraction': 0.40283467833232744, 'bagging_fraction': 0.64761982631925, 'bagging_freq': 3, 'min_child_samples': 99}. Best is trial 0 with value: 0.7857142857142857.
[I 2025-09-17 13:16:52,192] Trial 14 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 249, 'learning_rate': 0.12768534849010063, 'feature_fraction': 0.550441717091843, 'bagging_fraction': 0.8196535205903307, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 14 with value: 0.7896825396825397.
[I 2025-09-17 13:16:52,244] Trial 15 finished with value: 0.753968253968254 and parameters: {'num_leaves': 179, 'learning_rate': 0.01757082543393977, 'feature_fraction': 0.5709326969669183, 'bagging_fraction': 0.8315076733948022, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 14 with value: 0.7896825396825397.
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.627362
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.612554
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.570327
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.64062
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.634581
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.658042
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.575074
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.632754
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.596273
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.568762
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.658358
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.560994
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.54579
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.671473
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.513501
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.57033
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.64313
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.549917
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.676149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.653348
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.579919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.650016
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.548203
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.537094
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.531712
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.658774
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.638689
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.580667
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.640535
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.562349
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.526054
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.584815
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.538665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.607644
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.58033
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.646858
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.621998
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.535273
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.565141
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.626057
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.579312
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.605308
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.647487
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.638448
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.544423
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.543603
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.568717
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.528385
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.57786
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:52,259] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 246, 'learning_rate': 0.10336087152484259, 'feature_fraction': 0.6735306975375588, 'bagging_fraction': 0.8998272807259359, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial 14 with value: 0.7896825396825397.
[I 2025-09-17 13:16:52,298] Trial 17 finished with value: 0.75 and parameters: {'num_leaves': 230, 'learning_rate': 0.20885586901203737, 'feature_fraction': 0.5264022317018258, 'bagging_fraction': 0.9895697598920861, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 14 with value: 0.7896825396825397.
[I 2025-09-17 13:16:52,316] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 259, 'learning_rate': 0.12896250428900655, 'feature_fraction': 0.7522825934029869, 'bagging_fraction': 0.7889880502943768, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 14 with value: 0.7896825396825397.
[I 2025-09-17 13:16:52,348] Trial 19 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 194, 'learning_rate': 0.2185624811224663, 'feature_fraction': 0.5055627723844229, 'bagging_fraction': 0.6052426549705461, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 14 with value: 0.7896825396825397.
[I 2025-09-17 13:16:52,364] Trial 20 finished with value: 0.5634920634920635 and parameters: {'num_leaves': 269, 'learning_rate': 0.11626333685653983, 'feature_fraction': 0.6248381033735644, 'bagging_fraction': 0.9040503152259058, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 14 with value: 0.7896825396825397.
[I 2025-09-17 13:16:52,481] Trial 21 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 278, 'learning_rate': 0.16212380948428695, 'feature_fraction': 0.40965351545731354, 'bagging_fraction': 0.7560266047760911, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 14 with value: 0.7896825396825397.
[I 2025-09-17 13:16:52,525] Trial 22 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 217, 'learning_rate': 0.19362807982419478, 'feature_fraction': 0.48876710021625835, 'bagging_fraction': 0.6785794426653168, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 22 with value: 0.7936507936507936.
[I 2025-09-17 13:16:52,570] Trial 23 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 221, 'learning_rate': 0.19795286120961894, 'feature_fraction': 0.5025531273666561, 'bagging_fraction': 0.6753593859769604, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 22 with value: 0.7936507936507936.
[I 2025-09-17 13:16:52,604] Trial 24 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 203, 'learning_rate': 0.14222579216408354, 'feature_fraction': 0.598900418305822, 'bagging_fraction': 0.8388075126204648, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,630] Trial 25 finished with value: 0.748015873015873 and parameters: {'num_leaves': 167, 'learning_rate': 0.1878450264970235, 'feature_fraction': 0.6205334612200024, 'bagging_fraction': 0.8192875090617993, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,655] Trial 26 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 199, 'learning_rate': 0.23274312324362617, 'feature_fraction': 0.7199180758673426, 'bagging_fraction': 0.5703408910935363, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,680] Trial 27 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 142, 'learning_rate': 0.23856001025368218, 'feature_fraction': 0.7331953781913415, 'bagging_fraction': 0.5872498524148722, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,692] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.22911605182263003, 'feature_fraction': 0.8166933923420888, 'bagging_fraction': 0.535251885594787, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,704] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.1455625125053355, 'feature_fraction': 0.6217449188432868, 'bagging_fraction': 0.5668770041528448, 'bagging_freq': 6, 'min_child_samples': 77}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,731] Trial 30 finished with value: 0.628968253968254 and parameters: {'num_leaves': 211, 'learning_rate': 0.19211439870570599, 'feature_fraction': 0.6932182350437331, 'bagging_fraction': 0.49396779104654887, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,770] Trial 31 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 188, 'learning_rate': 0.12289000669547206, 'feature_fraction': 0.48730646257986343, 'bagging_fraction': 0.6612138954038439, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,804] Trial 32 finished with value: 0.761904761904762 and parameters: {'num_leaves': 243, 'learning_rate': 0.09432891045679571, 'feature_fraction': 0.6073507159218012, 'bagging_fraction': 0.8681468643514374, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,878] Trial 33 finished with value: 0.75 and parameters: {'num_leaves': 207, 'learning_rate': 0.21274583740629713, 'feature_fraction': 0.5280664084244898, 'bagging_fraction': 0.7709598368089604, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,923] Trial 34 finished with value: 0.75 and parameters: {'num_leaves': 177, 'learning_rate': 0.1485778285782399, 'feature_fraction': 0.6480389661698147, 'bagging_fraction': 0.9402964831285778, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,936] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 141, 'learning_rate': 0.24783721593879987, 'feature_fraction': 0.7136450462949324, 'bagging_fraction': 0.6837212981594561, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,971] Trial 36 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 258, 'learning_rate': 0.17828693222821457, 'feature_fraction': 0.5883482852832387, 'bagging_fraction': 0.6215035144862862, 'bagging_freq': 7, 'min_child_samples': 34}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:52,989] Trial 37 finished with value: 0.5575396825396826 and parameters: {'num_leaves': 111, 'learning_rate': 0.07445430312326495, 'feature_fraction': 0.8012686725052334, 'bagging_fraction': 0.5590949626376428, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,017] Trial 38 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 226, 'learning_rate': 0.29616089991091, 'feature_fraction': 0.5369913230626121, 'bagging_fraction': 0.7023406368069712, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,036] Trial 39 finished with value: 0.4920634920634921 and parameters: {'num_leaves': 196, 'learning_rate': 0.2678370882004941, 'feature_fraction': 0.47491986113754003, 'bagging_fraction': 0.4017215704861919, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,051] Trial 40 finished with value: 0.6071428571428572 and parameters: {'num_leaves': 173, 'learning_rate': 0.29990426344588744, 'feature_fraction': 0.7576618629604894, 'bagging_fraction': 0.7027559400718566, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,089] Trial 41 finished with value: 0.7738095238095237 and parameters: {'num_leaves': 233, 'learning_rate': 0.2859412549391189, 'feature_fraction': 0.5320884973166341, 'bagging_fraction': 0.8117535150809578, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,137] Trial 42 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 209, 'learning_rate': 0.2528674490169918, 'feature_fraction': 0.5430045273133018, 'bagging_fraction': 0.874492908187167, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,172] Trial 43 finished with value: 0.7559523809523809 and parameters: {'num_leaves': 220, 'learning_rate': 0.22819016980761908, 'feature_fraction': 0.5903110830087028, 'bagging_fraction': 0.9425176005459518, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,233] Trial 44 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 258, 'learning_rate': 0.1329055602910141, 'feature_fraction': 0.5599797550026984, 'bagging_fraction': 0.725179548753871, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,280] Trial 45 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 270, 'learning_rate': 0.27482207522743624, 'feature_fraction': 0.6507121089797718, 'bagging_fraction': 0.7348510363749181, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,327] Trial 46 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 277, 'learning_rate': 0.2729370940240489, 'feature_fraction': 0.6637329474514049, 'bagging_fraction': 0.7265530471574834, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,384] Trial 47 finished with value: 0.7757936507936508 and parameters: {'num_leaves': 300, 'learning_rate': 0.2565828227034681, 'feature_fraction': 0.654129568891625, 'bagging_fraction': 0.7225693882916903, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:16:53,452] Trial 48 finished with value: 0.8373015873015873 and parameters: {'num_leaves': 272, 'learning_rate': 0.27110425235236996, 'feature_fraction': 0.8483830463780744, 'bagging_fraction': 0.7435362063793035, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 48 with value: 0.8373015873015873.
[I 2025-09-17 13:16:53,503] Trial 49 finished with value: 0.7281746031746031 and parameters: {'num_leaves': 282, 'learning_rate': 0.27370021501457154, 'feature_fraction': 0.8543757444793089, 'bagging_fraction': 0.7456715509928429, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 48 with value: 0.8373015873015873.
[I 2025-09-17 13:16:53,748] A new study created in memory with name: no-name-3da30630-7d22-4fea-bba6-a86e128d37ac
[I 2025-09-17 13:16:53,800] Trial 0 finished with value: 0.6746031746031745 and parameters: {'num_leaves': 186, 'learning_rate': 0.10393823507520936, 'feature_fraction': 0.9195901323897073, 'bagging_fraction': 0.9020080554633567, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 0 with value: 0.6746031746031745.
[I 2025-09-17 13:16:53,886] Trial 1 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 228, 'learning_rate': 0.2712189517968156, 'feature_fraction': 0.8532176305801132, 'bagging_fraction': 0.8159896597559888, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 1 with value: 0.7182539682539683.
[I 2025-09-17 13:16:53,896] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 288, 'learning_rate': 0.02940979878959559, 'feature_fraction': 0.9187912665673431, 'bagging_fraction': 0.5246840889602264, 'bagging_freq': 6, 'min_child_samples': 83}. Best is trial 1 with value: 0.7182539682539683.
[I 2025-09-17 13:16:53,904] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 194, 'learning_rate': 0.029392450262699273, 'feature_fraction': 0.8392501569970098, 'bagging_fraction': 0.840532233063134, 'bagging_freq': 6, 'min_child_samples': 68}. Best is trial 1 with value: 0.7182539682539683.
[I 2025-09-17 13:16:53,911] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 19, 'learning_rate': 0.10600930491677514, 'feature_fraction': 0.7851687524469988, 'bagging_fraction': 0.8121621029332304, 'bagging_freq': 7, 'min_child_samples': 100}. Best is trial 1 with value: 0.7182539682539683.
[I 2025-09-17 13:16:53,944] Trial 5 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 17, 'learning_rate': 0.09417099657755992, 'feature_fraction': 0.6181522597081754, 'bagging_fraction': 0.8980978895845311, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 5 with value: 0.7420634920634921.
[I 2025-09-17 13:16:53,952] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 279, 'learning_rate': 0.040598463880981275, 'feature_fraction': 0.8783317075902028, 'bagging_fraction': 0.5526484785641008, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 5 with value: 0.7420634920634921.
[I 2025-09-17 13:16:53,959] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 61, 'learning_rate': 0.21740628722935335, 'feature_fraction': 0.7172137210856737, 'bagging_fraction': 0.5912638729268862, 'bagging_freq': 2, 'min_child_samples': 93}. Best is trial 5 with value: 0.7420634920634921.
[I 2025-09-17 13:16:53,967] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.010297341003840554, 'feature_fraction': 0.4435067556773071, 'bagging_fraction': 0.7307169364503807, 'bagging_freq': 5, 'min_child_samples': 77}. Best is trial 5 with value: 0.7420634920634921.
[I 2025-09-17 13:16:53,975] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 127, 'learning_rate': 0.29786892827976263, 'feature_fraction': 0.5172346649341764, 'bagging_fraction': 0.4223609625408875, 'bagging_freq': 2, 'min_child_samples': 37}. Best is trial 5 with value: 0.7420634920634921.
[I 2025-09-17 13:16:54,008] Trial 10 finished with value: 0.738095238095238 and parameters: {'num_leaves': 96, 'learning_rate': 0.1728604264157712, 'feature_fraction': 0.6284365869371752, 'bagging_fraction': 0.9961206685215095, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 5 with value: 0.7420634920634921.
[I 2025-09-17 13:16:54,038] Trial 11 finished with value: 0.753968253968254 and parameters: {'num_leaves': 97, 'learning_rate': 0.16687084410906922, 'feature_fraction': 0.5986613790300244, 'bagging_fraction': 0.9982740481600444, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 11 with value: 0.753968253968254.
[I 2025-09-17 13:16:54,083] Trial 12 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 20, 'learning_rate': 0.12874905888707794, 'feature_fraction': 0.5993167382826617, 'bagging_fraction': 0.9830887558859625, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 11 with value: 0.753968253968254.
[I 2025-09-17 13:16:54,133] Trial 13 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 77, 'learning_rate': 0.17415961990789622, 'feature_fraction': 0.5986781316077141, 'bagging_fraction': 0.9141488212591177, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 13 with value: 0.7579365079365079.
[I 2025-09-17 13:16:54,149] Trial 14 finished with value: 0.625 and parameters: {'num_leaves': 89, 'learning_rate': 0.1880560963476867, 'feature_fraction': 0.5293754781434286, 'bagging_fraction': 0.7063239579424881, 'bagging_freq': 1, 'min_child_samples': 50}. Best is trial 13 with value: 0.7579365079365079.
[I 2025-09-17 13:16:54,192] Trial 15 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 143, 'learning_rate': 0.2355764884416474, 'feature_fraction': 0.4004915936593543, 'bagging_fraction': 0.9256178734289263, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 15 with value: 0.7936507936507937.
[I 2025-09-17 13:16:54,260] Trial 16 finished with value: 0.7777777777777777 and parameters: {'num_leaves': 146, 'learning_rate': 0.22531680887075703, 'feature_fraction': 0.4236715782673468, 'bagging_fraction': 0.9034089082281866, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 15 with value: 0.7936507936507937.
[I 2025-09-17 13:16:54,388] Trial 17 finished with value: 0.876984126984127 and parameters: {'num_leaves': 144, 'learning_rate': 0.2304524280823223, 'feature_fraction': 0.4183972595111989, 'bagging_fraction': 0.7829328375817768, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,425] Trial 18 finished with value: 0.7658730158730159 and parameters: {'num_leaves': 160, 'learning_rate': 0.2449056694976545, 'feature_fraction': 0.5011738851267815, 'bagging_fraction': 0.7676822273809616, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,438] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 131, 'learning_rate': 0.252038856524371, 'feature_fraction': 0.4128847094442371, 'bagging_fraction': 0.632162382879507, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,485] Trial 20 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 243, 'learning_rate': 0.2076050170389233, 'feature_fraction': 0.4784868342791312, 'bagging_fraction': 0.6808812123207786, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,601] Trial 21 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 149, 'learning_rate': 0.21867211858204416, 'feature_fraction': 0.4012025644056539, 'bagging_fraction': 0.8656671151659224, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,721] Trial 22 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 172, 'learning_rate': 0.2790425895501587, 'feature_fraction': 0.4047881830348143, 'bagging_fraction': 0.8537731436888347, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,769] Trial 23 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 177, 'learning_rate': 0.2998236814700172, 'feature_fraction': 0.46529556018966267, 'bagging_fraction': 0.760407148714989, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,807] Trial 24 finished with value: 0.7380952380952381 and parameters: {'num_leaves': 117, 'learning_rate': 0.2693078513414411, 'feature_fraction': 0.9911016264886339, 'bagging_fraction': 0.9404873386114309, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,863] Trial 25 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 168, 'learning_rate': 0.2732628559855123, 'feature_fraction': 0.5395590249131366, 'bagging_fraction': 0.7985444437724614, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 17 with value: 0.876984126984127.
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.547056
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.584699
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.646991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.570326
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.539284
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.583062
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.5173
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.571035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.533057
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.568194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.636822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.575751
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.550953
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.580999
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.549832
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.593851
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.64577
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.563878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.642643
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.641754
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.540133
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.588717
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.565716
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.552836
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.528367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.527839
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.544643
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.529597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.560706
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.560338
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.554279
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.56034
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.587115
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.571902
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.562178
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.523705
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.637794
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.516261
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.531572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.408486
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.559691
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.551202
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.530974
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.508017
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.521667
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.547893
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.548256
[I 2025-09-17 13:16:54,891] Trial 26 finished with value: 0.6507936507936508 and parameters: {'num_leaves': 206, 'learning_rate': 0.24591983566279307, 'feature_fraction': 0.6864686766283269, 'bagging_fraction': 0.8574147114979628, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:54,985] Trial 27 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 113, 'learning_rate': 0.1957439939759839, 'feature_fraction': 0.4615459545384467, 'bagging_fraction': 0.6674996142990481, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,077] Trial 28 finished with value: 0.8015873015873015 and parameters: {'num_leaves': 58, 'learning_rate': 0.19893925970445003, 'feature_fraction': 0.5561542724789024, 'bagging_fraction': 0.6561697508097175, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,131] Trial 29 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 42, 'learning_rate': 0.14228221003290403, 'feature_fraction': 0.5586063199624882, 'bagging_fraction': 0.6656168241172506, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,175] Trial 30 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 54, 'learning_rate': 0.19511131389073388, 'feature_fraction': 0.4775998388726992, 'bagging_fraction': 0.6251339250889154, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,223] Trial 31 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 51, 'learning_rate': 0.19744505966015954, 'feature_fraction': 0.4650536073141883, 'bagging_fraction': 0.6074279797627358, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,271] Trial 32 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 114, 'learning_rate': 0.18997366953115805, 'feature_fraction': 0.4801067296908291, 'bagging_fraction': 0.6212093027826506, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,308] Trial 33 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 42, 'learning_rate': 0.15150554752158546, 'feature_fraction': 0.45131734342396357, 'bagging_fraction': 0.48629620534255613, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,346] Trial 34 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 71, 'learning_rate': 0.202789225270512, 'feature_fraction': 0.49827991984237996, 'bagging_fraction': 0.5727195314022271, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,426] Trial 35 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 44, 'learning_rate': 0.12421463664406057, 'feature_fraction': 0.44567098385625603, 'bagging_fraction': 0.5055786790789666, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,457] Trial 36 finished with value: 0.7202380952380953 and parameters: {'num_leaves': 109, 'learning_rate': 0.1877758080422546, 'feature_fraction': 0.564409881731368, 'bagging_fraction': 0.7208922893155881, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 17 with value: 0.876984126984127.
[I 2025-09-17 13:16:55,503] Trial 37 finished with value: 0.880952380952381 and parameters: {'num_leaves': 82, 'learning_rate': 0.22762284855944603, 'feature_fraction': 0.6938873090683284, 'bagging_fraction': 0.6152412775569465, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 37 with value: 0.880952380952381.
[I 2025-09-17 13:16:55,532] Trial 38 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 33, 'learning_rate': 0.22986852661384916, 'feature_fraction': 0.7980568207134431, 'bagging_fraction': 0.5395459066791095, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 37 with value: 0.880952380952381.
[I 2025-09-17 13:16:55,547] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 78, 'learning_rate': 0.21294189357676083, 'feature_fraction': 0.6807534433651327, 'bagging_fraction': 0.6197219110966955, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial 37 with value: 0.880952380952381.
[I 2025-09-17 13:16:55,589] Trial 40 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 61, 'learning_rate': 0.25467945404694897, 'feature_fraction': 0.7667980562140272, 'bagging_fraction': 0.5842313605610996, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 37 with value: 0.880952380952381.
[I 2025-09-17 13:16:55,629] Trial 41 finished with value: 0.8531746031746033 and parameters: {'num_leaves': 59, 'learning_rate': 0.2575704753086585, 'feature_fraction': 0.7325893050577555, 'bagging_fraction': 0.5916517460083061, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 37 with value: 0.880952380952381.
[I 2025-09-17 13:16:55,657] Trial 42 finished with value: 0.7817460317460316 and parameters: {'num_leaves': 15, 'learning_rate': 0.2621278385572439, 'feature_fraction': 0.7316545795700568, 'bagging_fraction': 0.4662194607859168, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 37 with value: 0.880952380952381.
[I 2025-09-17 13:16:55,702] Trial 43 finished with value: 0.9126984126984126 and parameters: {'num_leaves': 29, 'learning_rate': 0.2290907805001668, 'feature_fraction': 0.6421481743818571, 'bagging_fraction': 0.5981524190756017, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 43 with value: 0.9126984126984126.
[I 2025-09-17 13:16:55,715] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 29, 'learning_rate': 0.2842936036925526, 'feature_fraction': 0.7519231806975116, 'bagging_fraction': 0.5673072844336884, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 43 with value: 0.9126984126984126.
[I 2025-09-17 13:16:55,750] Trial 45 finished with value: 0.6746031746031745 and parameters: {'num_leaves': 11, 'learning_rate': 0.23772455384313815, 'feature_fraction': 0.6532400089618879, 'bagging_fraction': 0.5979637469690564, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 43 with value: 0.9126984126984126.
[I 2025-09-17 13:16:55,764] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 90, 'learning_rate': 0.2206678510702874, 'feature_fraction': 0.8144234483906937, 'bagging_fraction': 0.5269774125390132, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 43 with value: 0.9126984126984126.
[I 2025-09-17 13:16:55,811] Trial 47 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 245, 'learning_rate': 0.05699783498099911, 'feature_fraction': 0.8444521348385013, 'bagging_fraction': 0.694906015771549, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 43 with value: 0.9126984126984126.
[I 2025-09-17 13:16:55,847] Trial 48 finished with value: 0.6428571428571428 and parameters: {'num_leaves': 29, 'learning_rate': 0.17294363993280196, 'feature_fraction': 0.7117497272876869, 'bagging_fraction': 0.6478058442642564, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 43 with value: 0.9126984126984126.
[I 2025-09-17 13:16:55,865] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 72, 'learning_rate': 0.2593346313720248, 'feature_fraction': 0.8852539094686096, 'bagging_fraction': 0.7477550911452009, 'bagging_freq': 7, 'min_child_samples': 58}. Best is trial 43 with value: 0.9126984126984126.
[I 2025-09-17 13:16:56,136] A new study created in memory with name: no-name-f2a269fd-53fe-467b-a409-f1eebd3e5220
[I 2025-09-17 13:16:56,145] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 205, 'learning_rate': 0.053485171324423784, 'feature_fraction': 0.63576032661588, 'bagging_fraction': 0.8282740466266649, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:56,152] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 40, 'learning_rate': 0.03131981644013073, 'feature_fraction': 0.4131046843217716, 'bagging_fraction': 0.487194524905821, 'bagging_freq': 2, 'min_child_samples': 86}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:56,171] Trial 2 finished with value: 0.7476780185758514 and parameters: {'num_leaves': 56, 'learning_rate': 0.19711335527239637, 'feature_fraction': 0.8864000850416762, 'bagging_fraction': 0.7822052210690511, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,179] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 176, 'learning_rate': 0.14255703701004524, 'feature_fraction': 0.7942451413609506, 'bagging_fraction': 0.4926960447548081, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,187] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 221, 'learning_rate': 0.1778293930725563, 'feature_fraction': 0.7341344234253788, 'bagging_fraction': 0.7255426752027245, 'bagging_freq': 2, 'min_child_samples': 97}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,195] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 163, 'learning_rate': 0.2953598487913879, 'feature_fraction': 0.7517981592944813, 'bagging_fraction': 0.4555362788564311, 'bagging_freq': 1, 'min_child_samples': 72}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,217] Trial 6 finished with value: 0.7058823529411765 and parameters: {'num_leaves': 141, 'learning_rate': 0.010519569266011181, 'feature_fraction': 0.4209067928965743, 'bagging_fraction': 0.7718271007277084, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,225] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 167, 'learning_rate': 0.05006666298947432, 'feature_fraction': 0.7892015887549233, 'bagging_fraction': 0.5262013393660837, 'bagging_freq': 6, 'min_child_samples': 86}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,240] Trial 8 finished with value: 0.7058823529411764 and parameters: {'num_leaves': 173, 'learning_rate': 0.24045507923884757, 'feature_fraction': 0.8256703963767125, 'bagging_fraction': 0.6311552632686594, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,248] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.0473741232402782, 'feature_fraction': 0.7461633891123978, 'bagging_fraction': 0.48294213390359636, 'bagging_freq': 6, 'min_child_samples': 66}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,305] Trial 10 finished with value: 0.7244582043343653 and parameters: {'num_leaves': 10, 'learning_rate': 0.15738503527180472, 'feature_fraction': 0.9991921613324235, 'bagging_fraction': 0.9946186155214727, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,362] Trial 11 finished with value: 0.7105263157894737 and parameters: {'num_leaves': 10, 'learning_rate': 0.15183216409658604, 'feature_fraction': 0.9852827926049484, 'bagging_fraction': 0.9530702632517664, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,426] Trial 12 finished with value: 0.6965944272445821 and parameters: {'num_leaves': 82, 'learning_rate': 0.20697959643584396, 'feature_fraction': 0.9978136753496274, 'bagging_fraction': 0.9957219453612967, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,447] Trial 13 finished with value: 0.7151702786377709 and parameters: {'num_leaves': 92, 'learning_rate': 0.11304510233221139, 'feature_fraction': 0.8989407105246068, 'bagging_fraction': 0.8643360405132956, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,471] Trial 14 finished with value: 0.6687306501547987 and parameters: {'num_leaves': 287, 'learning_rate': 0.23393187651437342, 'feature_fraction': 0.9006117514674783, 'bagging_fraction': 0.6438432598224111, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,511] Trial 15 finished with value: 0.739938080495356 and parameters: {'num_leaves': 63, 'learning_rate': 0.09439745438024015, 'feature_fraction': 0.5754437577431567, 'bagging_fraction': 0.9107207437955008, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,544] Trial 16 finished with value: 0.7352941176470588 and parameters: {'num_leaves': 105, 'learning_rate': 0.09506127597384961, 'feature_fraction': 0.5694632474201378, 'bagging_fraction': 0.9016668041375727, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,574] Trial 17 finished with value: 0.739938080495356 and parameters: {'num_leaves': 59, 'learning_rate': 0.08809236257677211, 'feature_fraction': 0.5265243272017579, 'bagging_fraction': 0.7947150892936339, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 2 with value: 0.7476780185758514.
[I 2025-09-17 13:16:56,605] Trial 18 finished with value: 0.7554179566563468 and parameters: {'num_leaves': 49, 'learning_rate': 0.29324989951937763, 'feature_fraction': 0.6367312332826675, 'bagging_fraction': 0.9116292550897984, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 18 with value: 0.7554179566563468.
[I 2025-09-17 13:16:56,627] Trial 19 finished with value: 0.7492260061919505 and parameters: {'num_leaves': 123, 'learning_rate': 0.2994628533030944, 'feature_fraction': 0.6657516502597373, 'bagging_fraction': 0.6881622332716343, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 18 with value: 0.7554179566563468.
[I 2025-09-17 13:16:56,639] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 124, 'learning_rate': 0.29965509027537196, 'feature_fraction': 0.6654613968331351, 'bagging_fraction': 0.5862838876185137, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 18 with value: 0.7554179566563468.
[I 2025-09-17 13:16:56,654] Trial 21 finished with value: 0.695046439628483 and parameters: {'num_leaves': 45, 'learning_rate': 0.26596288271897356, 'feature_fraction': 0.6472029019309884, 'bagging_fraction': 0.7101505665300349, 'bagging_freq': 4, 'min_child_samples': 43}. Best is trial 18 with value: 0.7554179566563468.
[I 2025-09-17 13:16:56,685] Trial 22 finished with value: 0.7770897832817338 and parameters: {'num_leaves': 112, 'learning_rate': 0.2674644788022671, 'feature_fraction': 0.6871697261753231, 'bagging_fraction': 0.7565570029466675, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,712] Trial 23 finished with value: 0.7306501547987616 and parameters: {'num_leaves': 117, 'learning_rate': 0.26578865360885856, 'feature_fraction': 0.694794782175894, 'bagging_fraction': 0.6636452240048502, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,731] Trial 24 finished with value: 0.6780185758513932 and parameters: {'num_leaves': 137, 'learning_rate': 0.27293456096318547, 'feature_fraction': 0.5913778472814288, 'bagging_fraction': 0.7378473712057059, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,759] Trial 25 finished with value: 0.7337461300309597 and parameters: {'num_leaves': 83, 'learning_rate': 0.24528101084859355, 'feature_fraction': 0.608387317030923, 'bagging_fraction': 0.5747092901552129, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,776] Trial 26 finished with value: 0.7337461300309598 and parameters: {'num_leaves': 103, 'learning_rate': 0.2855350275532623, 'feature_fraction': 0.49705404846908585, 'bagging_fraction': 0.8536290028471364, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,808] Trial 27 finished with value: 0.6857585139318886 and parameters: {'num_leaves': 30, 'learning_rate': 0.2240884757373029, 'feature_fraction': 0.694328895426279, 'bagging_fraction': 0.6780320098723198, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,830] Trial 28 finished with value: 0.6857585139318885 and parameters: {'num_leaves': 270, 'learning_rate': 0.26003503980509163, 'feature_fraction': 0.5087370375342031, 'bagging_fraction': 0.9144586956407397, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,887] Trial 29 finished with value: 0.7616099071207431 and parameters: {'num_leaves': 235, 'learning_rate': 0.28067341505424753, 'feature_fraction': 0.6236819981682943, 'bagging_fraction': 0.40165731619208694, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,969] Trial 30 finished with value: 0.7089783281733746 and parameters: {'num_leaves': 217, 'learning_rate': 0.21475400739803602, 'feature_fraction': 0.61490124696914, 'bagging_fraction': 0.8173270435936333, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:56,996] Trial 31 finished with value: 0.7213622291021673 and parameters: {'num_leaves': 248, 'learning_rate': 0.2791743749281668, 'feature_fraction': 0.6548475074305768, 'bagging_fraction': 0.41519983752818795, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 22 with value: 0.7770897832817338.
[I 2025-09-17 13:16:57,058] Trial 32 finished with value: 0.78328173374613 and parameters: {'num_leaves': 131, 'learning_rate': 0.2517848173031591, 'feature_fraction': 0.54711972410928, 'bagging_fraction': 0.4002055581930114, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,106] Trial 33 finished with value: 0.6873065015479877 and parameters: {'num_leaves': 194, 'learning_rate': 0.2505839815495916, 'feature_fraction': 0.4722539998131574, 'bagging_fraction': 0.4116682497627795, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,177] Trial 34 finished with value: 0.6904024767801857 and parameters: {'num_leaves': 253, 'learning_rate': 0.1978215920159373, 'feature_fraction': 0.5525572768921416, 'bagging_fraction': 0.4450889823248221, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 32 with value: 0.78328173374613.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.60117
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.510622
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.506132
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.502084
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.515478
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.511234
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.544016
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.579176
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.552923
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.530314
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.584884
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.423688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.527089
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.468983
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.463719
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.513952
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.383217
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.589132
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.561505
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.59399
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655482
Training model for P105... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.606617
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.634463
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.621065
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.622416
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.629824
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.643124
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.616555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.644953
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.602977
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.610951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.613908
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.571836
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.603399
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.61386
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.580716
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.612088
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.649651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.607143
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.605175
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.637986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.617525
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.59463
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.61677
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.619727
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.58945
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.627259
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.644938
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:57,204] Trial 35 finished with value: 0.7693498452012384 and parameters: {'num_leaves': 142, 'learning_rate': 0.2818991387770179, 'feature_fraction': 0.6284433230828513, 'bagging_fraction': 0.5330287218975654, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,261] Trial 36 finished with value: 0.7616099071207431 and parameters: {'num_leaves': 146, 'learning_rate': 0.18076672816213157, 'feature_fraction': 0.46523861015794743, 'bagging_fraction': 0.520533532427702, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,286] Trial 37 finished with value: 0.7445820433436532 and parameters: {'num_leaves': 152, 'learning_rate': 0.25433639999036717, 'feature_fraction': 0.7307040638007041, 'bagging_fraction': 0.44938255399499116, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,315] Trial 38 finished with value: 0.7569659442724458 and parameters: {'num_leaves': 187, 'learning_rate': 0.2269670991943021, 'feature_fraction': 0.5461390451564111, 'bagging_fraction': 0.5679476798787475, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,328] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 228, 'learning_rate': 0.2744096402862204, 'feature_fraction': 0.61944055430447, 'bagging_fraction': 0.5206405614279987, 'bagging_freq': 2, 'min_child_samples': 62}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,343] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.24518563857619657, 'feature_fraction': 0.4004542119670817, 'bagging_fraction': 0.40336981079025824, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,380] Trial 41 finished with value: 0.7229102167182663 and parameters: {'num_leaves': 143, 'learning_rate': 0.18762399311581351, 'feature_fraction': 0.4485241963699949, 'bagging_fraction': 0.5060195840309608, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,448] Trial 42 finished with value: 0.6749226006191951 and parameters: {'num_leaves': 180, 'learning_rate': 0.2834986600199537, 'feature_fraction': 0.5301951468293091, 'bagging_fraction': 0.4607389588096024, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,492] Trial 43 finished with value: 0.78328173374613 and parameters: {'num_leaves': 149, 'learning_rate': 0.17892169452711368, 'feature_fraction': 0.4751566156403935, 'bagging_fraction': 0.6119859326314905, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,526] Trial 44 finished with value: 0.718266253869969 and parameters: {'num_leaves': 131, 'learning_rate': 0.12391050027579248, 'feature_fraction': 0.4413761845209919, 'bagging_fraction': 0.6155352337620862, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,559] Trial 45 finished with value: 0.7151702786377709 and parameters: {'num_leaves': 106, 'learning_rate': 0.1695822489409786, 'feature_fraction': 0.48659748190254576, 'bagging_fraction': 0.48005062226625234, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,597] Trial 46 finished with value: 0.7213622291021671 and parameters: {'num_leaves': 164, 'learning_rate': 0.2161380945614576, 'feature_fraction': 0.718865621360262, 'bagging_fraction': 0.5548267110306406, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,611] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 208, 'learning_rate': 0.23361515382580833, 'feature_fraction': 0.7662088598018529, 'bagging_fraction': 0.604039687258545, 'bagging_freq': 2, 'min_child_samples': 82}. Best is trial 32 with value: 0.78328173374613.
[I 2025-09-17 13:16:57,675] Trial 48 finished with value: 0.7910216718266254 and parameters: {'num_leaves': 114, 'learning_rate': 0.25957717321771867, 'feature_fraction': 0.5908309493702163, 'bagging_fraction': 0.7696610368548469, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 48 with value: 0.7910216718266254.
[I 2025-09-17 13:16:57,690] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.2592945054585331, 'feature_fraction': 0.8360358769507185, 'bagging_fraction': 0.754169266257224, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 48 with value: 0.7910216718266254.
[I 2025-09-17 13:16:57,993] A new study created in memory with name: no-name-069fbe59-fffa-4a69-bbd3-8baabad73730
[I 2025-09-17 13:16:58,001] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 120, 'learning_rate': 0.25252699015783453, 'feature_fraction': 0.9535327942327039, 'bagging_fraction': 0.5356776029105829, 'bagging_freq': 2, 'min_child_samples': 71}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:58,010] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 75, 'learning_rate': 0.09284163801822656, 'feature_fraction': 0.9428776541788917, 'bagging_fraction': 0.7436612892516706, 'bagging_freq': 4, 'min_child_samples': 90}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:58,020] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 254, 'learning_rate': 0.27678987044578574, 'feature_fraction': 0.6032891719370929, 'bagging_fraction': 0.4676948837281205, 'bagging_freq': 7, 'min_child_samples': 69}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:58,041] Trial 3 finished with value: 0.7198142414860681 and parameters: {'num_leaves': 154, 'learning_rate': 0.14723403141103802, 'feature_fraction': 0.8356573847196329, 'bagging_fraction': 0.6899912491721588, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 3 with value: 0.7198142414860681.
[I 2025-09-17 13:16:58,050] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 85, 'learning_rate': 0.14398362018008662, 'feature_fraction': 0.9136088970491397, 'bagging_fraction': 0.5181048701856467, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 3 with value: 0.7198142414860681.
[I 2025-09-17 13:16:58,058] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.2738733813814159, 'feature_fraction': 0.5509512085208335, 'bagging_fraction': 0.7880243570092519, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 3 with value: 0.7198142414860681.
[I 2025-09-17 13:16:58,074] Trial 6 finished with value: 0.7321981424148607 and parameters: {'num_leaves': 238, 'learning_rate': 0.14266748798939957, 'feature_fraction': 0.7453585782581189, 'bagging_fraction': 0.6156684367306886, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 6 with value: 0.7321981424148607.
[I 2025-09-17 13:16:58,144] Trial 7 finished with value: 0.7291021671826625 and parameters: {'num_leaves': 137, 'learning_rate': 0.2345660204072249, 'feature_fraction': 0.7818068450959863, 'bagging_fraction': 0.9067315642325208, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 6 with value: 0.7321981424148607.
[I 2025-09-17 13:16:58,160] Trial 8 finished with value: 0.7306501547987616 and parameters: {'num_leaves': 83, 'learning_rate': 0.06528897502811648, 'feature_fraction': 0.6834336220712558, 'bagging_fraction': 0.5080534281205584, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 6 with value: 0.7321981424148607.
[I 2025-09-17 13:16:58,182] Trial 9 finished with value: 0.7291021671826625 and parameters: {'num_leaves': 131, 'learning_rate': 0.02621177743226248, 'feature_fraction': 0.9189201337964964, 'bagging_fraction': 0.4807458189212832, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 6 with value: 0.7321981424148607.
[I 2025-09-17 13:16:58,196] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 297, 'learning_rate': 0.19214376228715124, 'feature_fraction': 0.4107561735850097, 'bagging_fraction': 0.6532232342827083, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 6 with value: 0.7321981424148607.
[I 2025-09-17 13:16:58,219] Trial 11 finished with value: 0.7770897832817337 and parameters: {'num_leaves': 16, 'learning_rate': 0.07573530686677779, 'feature_fraction': 0.6724444270663992, 'bagging_fraction': 0.6021133892169463, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,239] Trial 12 finished with value: 0.7089783281733747 and parameters: {'num_leaves': 13, 'learning_rate': 0.1064620740594892, 'feature_fraction': 0.7227872514859122, 'bagging_fraction': 0.5918391905350036, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,254] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 219, 'learning_rate': 0.035951015460374304, 'feature_fraction': 0.637782641695183, 'bagging_fraction': 0.6194592739724686, 'bagging_freq': 3, 'min_child_samples': 54}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,313] Trial 14 finished with value: 0.7461300309597524 and parameters: {'num_leaves': 209, 'learning_rate': 0.2010443365069327, 'feature_fraction': 0.5032616778889438, 'bagging_fraction': 0.4106926266206202, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,378] Trial 15 finished with value: 0.6470588235294118 and parameters: {'num_leaves': 189, 'learning_rate': 0.19888980507812104, 'feature_fraction': 0.4691183884935272, 'bagging_fraction': 0.4239856899922146, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,407] Trial 16 finished with value: 0.6904024767801857 and parameters: {'num_leaves': 11, 'learning_rate': 0.19213153775257702, 'feature_fraction': 0.5134284969168043, 'bagging_fraction': 0.4024994948911331, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,443] Trial 17 finished with value: 0.7693498452012384 and parameters: {'num_leaves': 200, 'learning_rate': 0.09652115532622906, 'feature_fraction': 0.5971737210656429, 'bagging_fraction': 0.8578271760710385, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,475] Trial 18 finished with value: 0.718266253869969 and parameters: {'num_leaves': 55, 'learning_rate': 0.10085342794250671, 'feature_fraction': 0.6114936787563281, 'bagging_fraction': 0.9999178915339441, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,498] Trial 19 finished with value: 0.7027863777089783 and parameters: {'num_leaves': 286, 'learning_rate': 0.054203931501598704, 'feature_fraction': 0.8239250062047252, 'bagging_fraction': 0.849837541756354, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,532] Trial 20 finished with value: 0.7662538699690402 and parameters: {'num_leaves': 182, 'learning_rate': 0.07706551101956391, 'feature_fraction': 0.6793910350054084, 'bagging_fraction': 0.8232726602335336, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,570] Trial 21 finished with value: 0.7012383900928792 and parameters: {'num_leaves': 174, 'learning_rate': 0.07817782155756088, 'feature_fraction': 0.668748270191987, 'bagging_fraction': 0.8804511713411594, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,598] Trial 22 finished with value: 0.695046439628483 and parameters: {'num_leaves': 196, 'learning_rate': 0.12147702290845092, 'feature_fraction': 0.591834627498882, 'bagging_fraction': 0.7862686577776186, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,646] Trial 23 finished with value: 0.7306501547987615 and parameters: {'num_leaves': 264, 'learning_rate': 0.04973546899553698, 'feature_fraction': 0.6629548427044439, 'bagging_fraction': 0.9506038687769518, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,669] Trial 24 finished with value: 0.6594427244582044 and parameters: {'num_leaves': 220, 'learning_rate': 0.07681615520131713, 'feature_fraction': 0.559677706346449, 'bagging_fraction': 0.8381779223815902, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,698] Trial 25 finished with value: 0.7089783281733746 and parameters: {'num_leaves': 111, 'learning_rate': 0.01786198809461792, 'feature_fraction': 0.7607265066523143, 'bagging_fraction': 0.7414104747915045, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,738] Trial 26 finished with value: 0.7662538699690403 and parameters: {'num_leaves': 51, 'learning_rate': 0.12441596903471894, 'feature_fraction': 0.7130282389572511, 'bagging_fraction': 0.8056435680640152, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,776] Trial 27 finished with value: 0.7337461300309597 and parameters: {'num_leaves': 36, 'learning_rate': 0.1678643278708174, 'feature_fraction': 0.8211435536836468, 'bagging_fraction': 0.71481526737664, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,789] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 42, 'learning_rate': 0.11951381883648018, 'feature_fraction': 0.7829198347044372, 'bagging_fraction': 0.9347488796507959, 'bagging_freq': 6, 'min_child_samples': 99}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,810] Trial 29 finished with value: 0.7430340557275542 and parameters: {'num_leaves': 102, 'learning_rate': 0.16834707085279674, 'feature_fraction': 0.7039840845854821, 'bagging_fraction': 0.6647545491647644, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,832] Trial 30 finished with value: 0.7244582043343654 and parameters: {'num_leaves': 60, 'learning_rate': 0.13037874938668365, 'feature_fraction': 0.8770796781049229, 'bagging_fraction': 0.5666073877015628, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,876] Trial 31 finished with value: 0.7089783281733746 and parameters: {'num_leaves': 28, 'learning_rate': 0.08569714198722125, 'feature_fraction': 0.7123680519313218, 'bagging_fraction': 0.8085118065521465, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,911] Trial 32 finished with value: 0.739938080495356 and parameters: {'num_leaves': 183, 'learning_rate': 0.10261419030042457, 'feature_fraction': 0.6484840670213152, 'bagging_fraction': 0.7633571324020999, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,929] Trial 33 finished with value: 0.6888544891640866 and parameters: {'num_leaves': 150, 'learning_rate': 0.0651112782836042, 'feature_fraction': 0.6197716985272228, 'bagging_fraction': 0.8365921422157023, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,954] Trial 34 finished with value: 0.7631578947368421 and parameters: {'num_leaves': 63, 'learning_rate': 0.10885315537368807, 'feature_fraction': 0.573347161049325, 'bagging_fraction': 0.884427384671986, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:58,985] Trial 35 finished with value: 0.6811145510835913 and parameters: {'num_leaves': 241, 'learning_rate': 0.04041347479220133, 'feature_fraction': 0.733539540465149, 'bagging_fraction': 0.7228254190049472, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,034] Trial 36 finished with value: 0.741486068111455 and parameters: {'num_leaves': 160, 'learning_rate': 0.09025448561880703, 'feature_fraction': 0.679885604386373, 'bagging_fraction': 0.8104817492153648, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,056] Trial 37 finished with value: 0.7430340557275542 and parameters: {'num_leaves': 103, 'learning_rate': 0.13354009847122922, 'feature_fraction': 0.5293311666859853, 'bagging_fraction': 0.6714826214380946, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,068] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 203, 'learning_rate': 0.16127443815216677, 'feature_fraction': 0.6408960124736814, 'bagging_fraction': 0.8699106934547812, 'bagging_freq': 4, 'min_child_samples': 79}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,096] Trial 39 finished with value: 0.6981424148606811 and parameters: {'num_leaves': 170, 'learning_rate': 0.0685604271961846, 'feature_fraction': 0.7819501799014031, 'bagging_fraction': 0.7662135691567402, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,117] Trial 40 finished with value: 0.7383900928792569 and parameters: {'num_leaves': 130, 'learning_rate': 0.11770976120537273, 'feature_fraction': 0.6032240700974647, 'bagging_fraction': 0.9191607024620317, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,144] Trial 41 finished with value: 0.7708978328173375 and parameters: {'num_leaves': 68, 'learning_rate': 0.29746663092166115, 'feature_fraction': 0.557386458470343, 'bagging_fraction': 0.8914948463819274, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,174] Trial 42 finished with value: 0.6919504643962848 and parameters: {'num_leaves': 80, 'learning_rate': 0.22996521579578103, 'feature_fraction': 0.4654824211896898, 'bagging_fraction': 0.9657279931816177, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,192] Trial 43 finished with value: 0.6981424148606812 and parameters: {'num_leaves': 24, 'learning_rate': 0.2724876528546684, 'feature_fraction': 0.5782404477253703, 'bagging_fraction': 0.8572567610704913, 'bagging_freq': 6, 'min_child_samples': 46}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,217] Trial 44 finished with value: 0.6857585139318886 and parameters: {'num_leaves': 46, 'learning_rate': 0.2580155400225609, 'feature_fraction': 0.6945353903326809, 'bagging_fraction': 0.8139815197177263, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 11 with value: 0.7770897832817337.
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.568021
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.616899
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.605035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.574172
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.619087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.640356
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.57497
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.604346
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.625271
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.621421
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.575696
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.610091
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.611461
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.615247
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.607694
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.615155
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.59715
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.631586
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.5933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.65502
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.632244
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.596509
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.615013
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.614301
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.603833
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.61005
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.628032
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.605785
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.66656
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.614958
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.595375
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.612058
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.595562
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.609555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.620373
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.606264
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.643919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.607905
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.618017
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.618156
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.599301
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.633227
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.604726
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.586654
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.621228
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.617777
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.634335
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:16:59,235] Trial 45 finished with value: 0.6981424148606812 and parameters: {'num_leaves': 73, 'learning_rate': 0.2978536679349294, 'feature_fraction': 0.4756248792019924, 'bagging_fraction': 0.7730471267302808, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 11 with value: 0.7770897832817337.
[I 2025-09-17 13:16:59,287] Trial 46 finished with value: 0.7770897832817338 and parameters: {'num_leaves': 144, 'learning_rate': 0.1468825391702417, 'feature_fraction': 0.5470191888886448, 'bagging_fraction': 0.9048414653662942, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 46 with value: 0.7770897832817338.
[I 2025-09-17 13:16:59,345] Trial 47 finished with value: 0.7647058823529411 and parameters: {'num_leaves': 92, 'learning_rate': 0.15138803759762962, 'feature_fraction': 0.9960844021963351, 'bagging_fraction': 0.9064309666556005, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 46 with value: 0.7770897832817338.
[I 2025-09-17 13:16:59,381] Trial 48 finished with value: 0.7461300309597523 and parameters: {'num_leaves': 24, 'learning_rate': 0.18177959322289003, 'feature_fraction': 0.5466480732395145, 'bagging_fraction': 0.9055155341662731, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 46 with value: 0.7770897832817338.
[I 2025-09-17 13:16:59,436] Trial 49 finished with value: 0.7739938080495357 and parameters: {'num_leaves': 71, 'learning_rate': 0.2087856698710786, 'feature_fraction': 0.4309237014956596, 'bagging_fraction': 0.9771469144439333, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 46 with value: 0.7770897832817338.
[I 2025-09-17 13:16:59,926] A new study created in memory with name: no-name-561ba196-1d05-4cca-81db-166ac03c9d86
[I 2025-09-17 13:16:59,939] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 269, 'learning_rate': 0.11948649421410766, 'feature_fraction': 0.44568456396670497, 'bagging_fraction': 0.9174462707059382, 'bagging_freq': 4, 'min_child_samples': 88}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:59,951] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 24, 'learning_rate': 0.2631226866334546, 'feature_fraction': 0.4821351356968937, 'bagging_fraction': 0.5857003240482817, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:16:59,959] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 124, 'learning_rate': 0.02536561448290208, 'feature_fraction': 0.8224816435653965, 'bagging_fraction': 0.5520772182593885, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:00,022] Trial 3 finished with value: 0.875 and parameters: {'num_leaves': 146, 'learning_rate': 0.0851845903751053, 'feature_fraction': 0.7263826692385775, 'bagging_fraction': 0.6579905581284347, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,030] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 288, 'learning_rate': 0.09765788322935717, 'feature_fraction': 0.5931206512836215, 'bagging_fraction': 0.6384607649646094, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,042] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.23620975809635827, 'feature_fraction': 0.9177270132585906, 'bagging_fraction': 0.4903755375595086, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,054] Trial 6 finished with value: 0.4953125 and parameters: {'num_leaves': 104, 'learning_rate': 0.14370582557588207, 'feature_fraction': 0.8851613669301167, 'bagging_fraction': 0.8590108090345473, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,062] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 116, 'learning_rate': 0.09452641255932248, 'feature_fraction': 0.9125013997845571, 'bagging_fraction': 0.5226650618944504, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,083] Trial 8 finished with value: 0.7250000000000001 and parameters: {'num_leaves': 293, 'learning_rate': 0.06184198067088108, 'feature_fraction': 0.7590915371406379, 'bagging_fraction': 0.8676239938643734, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,150] Trial 9 finished with value: 0.784375 and parameters: {'num_leaves': 224, 'learning_rate': 0.03723200425868045, 'feature_fraction': 0.7364856528824588, 'bagging_fraction': 0.47132175670434884, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,208] Trial 10 finished with value: 0.875 and parameters: {'num_leaves': 25, 'learning_rate': 0.19220261333969724, 'feature_fraction': 0.6740803672215551, 'bagging_fraction': 0.748084615259738, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,269] Trial 11 finished with value: 0.7906249999999999 and parameters: {'num_leaves': 25, 'learning_rate': 0.19758315166772492, 'feature_fraction': 0.6243864199939406, 'bagging_fraction': 0.7401773149020506, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,296] Trial 12 finished with value: 0.7406250000000001 and parameters: {'num_leaves': 79, 'learning_rate': 0.17795270418147038, 'feature_fraction': 0.6382122451744897, 'bagging_fraction': 0.7596105834919576, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,320] Trial 13 finished with value: 0.7203124999999999 and parameters: {'num_leaves': 160, 'learning_rate': 0.21260840810859838, 'feature_fraction': 0.5307524030549042, 'bagging_fraction': 0.6826319660265696, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,348] Trial 14 finished with value: 0.7921874999999999 and parameters: {'num_leaves': 173, 'learning_rate': 0.29809102826020406, 'feature_fraction': 0.6667898602264756, 'bagging_fraction': 0.9918584994880026, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,390] Trial 15 finished with value: 0.78125 and parameters: {'num_leaves': 60, 'learning_rate': 0.15541360675272506, 'feature_fraction': 0.7868027558688292, 'bagging_fraction': 0.7924187943503885, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,425] Trial 16 finished with value: 0.7515624999999999 and parameters: {'num_leaves': 205, 'learning_rate': 0.07534366395098052, 'feature_fraction': 0.6978567279764234, 'bagging_fraction': 0.6529939746406601, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,468] Trial 17 finished with value: 0.7906249999999999 and parameters: {'num_leaves': 58, 'learning_rate': 0.1322386613299582, 'feature_fraction': 0.8390346808554193, 'bagging_fraction': 0.6188185942636729, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,486] Trial 18 finished with value: 0.753125 and parameters: {'num_leaves': 15, 'learning_rate': 0.17244536457144502, 'feature_fraction': 0.57135246007928, 'bagging_fraction': 0.7180222527862207, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,568] Trial 19 finished with value: 0.825 and parameters: {'num_leaves': 145, 'learning_rate': 0.2259745555919782, 'feature_fraction': 0.9733814638631102, 'bagging_fraction': 0.789044109534531, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,607] Trial 20 finished with value: 0.784375 and parameters: {'num_leaves': 178, 'learning_rate': 0.11146820097385994, 'feature_fraction': 0.722916890885243, 'bagging_fraction': 0.81324761634759, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,651] Trial 21 finished with value: 0.853125 and parameters: {'num_leaves': 137, 'learning_rate': 0.23725311263521875, 'feature_fraction': 0.951121526994728, 'bagging_fraction': 0.4046138056424616, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,713] Trial 22 finished with value: 0.825 and parameters: {'num_leaves': 85, 'learning_rate': 0.26082631108215054, 'feature_fraction': 0.9961179058965478, 'bagging_fraction': 0.4614997391124685, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,747] Trial 23 finished with value: 0.8125 and parameters: {'num_leaves': 137, 'learning_rate': 0.25224112326014997, 'feature_fraction': 0.40576225933003185, 'bagging_fraction': 0.40142211009363044, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,791] Trial 24 finished with value: 0.784375 and parameters: {'num_leaves': 242, 'learning_rate': 0.19329027449906322, 'feature_fraction': 0.8312868076535227, 'bagging_fraction': 0.6959914927677674, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,813] Trial 25 finished with value: 0.728125 and parameters: {'num_leaves': 199, 'learning_rate': 0.28919829209059533, 'feature_fraction': 0.678201896881953, 'bagging_fraction': 0.4270315057956158, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,893] Trial 26 finished with value: 0.7421875 and parameters: {'num_leaves': 48, 'learning_rate': 0.15986383371873322, 'feature_fraction': 0.5424999927460556, 'bagging_fraction': 0.5763845778633275, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,911] Trial 27 finished with value: 0.7531249999999999 and parameters: {'num_leaves': 94, 'learning_rate': 0.2079451066485813, 'feature_fraction': 0.7788186722450108, 'bagging_fraction': 0.9360233204943759, 'bagging_freq': 7, 'min_child_samples': 47}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,939] Trial 28 finished with value: 0.7531249999999999 and parameters: {'num_leaves': 165, 'learning_rate': 0.05303287306966062, 'feature_fraction': 0.9490252575157536, 'bagging_fraction': 0.8374120993999772, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,951] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 254, 'learning_rate': 0.128418390057465, 'feature_fraction': 0.8715184857359314, 'bagging_fraction': 0.9034012213448592, 'bagging_freq': 5, 'min_child_samples': 77}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:00,963] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.2311619030861394, 'feature_fraction': 0.6347196049780104, 'bagging_fraction': 0.677537961339931, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,008] Trial 31 finished with value: 0.828125 and parameters: {'num_leaves': 135, 'learning_rate': 0.22581024188596044, 'feature_fraction': 0.9796726002613079, 'bagging_fraction': 0.7497353917214151, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,053] Trial 32 finished with value: 0.8374999999999999 and parameters: {'num_leaves': 133, 'learning_rate': 0.24930057835455013, 'feature_fraction': 0.9481963559231205, 'bagging_fraction': 0.7542518435942399, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,085] Trial 33 finished with value: 0.79375 and parameters: {'num_leaves': 122, 'learning_rate': 0.27763996476448155, 'feature_fraction': 0.93643793652141, 'bagging_fraction': 0.5962589536161103, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,128] Trial 34 finished with value: 0.821875 and parameters: {'num_leaves': 149, 'learning_rate': 0.26973223345172265, 'feature_fraction': 0.870685778760145, 'bagging_fraction': 0.7669044076159326, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,144] Trial 35 finished with value: 0.3625 and parameters: {'num_leaves': 115, 'learning_rate': 0.24512601802388598, 'feature_fraction': 0.472606872960906, 'bagging_fraction': 0.7192279164309489, 'bagging_freq': 7, 'min_child_samples': 55}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,161] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 75, 'learning_rate': 0.18983849292577257, 'feature_fraction': 0.9003998230735698, 'bagging_fraction': 0.5377166078377538, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,205] Trial 37 finished with value: 0.784375 and parameters: {'num_leaves': 37, 'learning_rate': 0.21095681568129998, 'feature_fraction': 0.8062411727404262, 'bagging_fraction': 0.6457251116995069, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,262] Trial 38 finished with value: 0.84375 and parameters: {'num_leaves': 100, 'learning_rate': 0.24654718157545263, 'feature_fraction': 0.9467301331050938, 'bagging_fraction': 0.8880914895020673, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,323] Trial 39 finished with value: 0.834375 and parameters: {'num_leaves': 102, 'learning_rate': 0.017942013609534388, 'feature_fraction': 0.7391169418987599, 'bagging_fraction': 0.9696092935232925, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 3 with value: 0.875.
[I 2025-09-17 13:17:01,390] Trial 40 finished with value: 0.8750000000000001 and parameters: {'num_leaves': 67, 'learning_rate': 0.08716651136350685, 'feature_fraction': 0.8477591615891917, 'bagging_fraction': 0.8987631764667862, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:01,480] Trial 41 finished with value: 0.859375 and parameters: {'num_leaves': 39, 'learning_rate': 0.08249629927023824, 'feature_fraction': 0.8727625789857122, 'bagging_fraction': 0.8875319464768546, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:01,583] Trial 42 finished with value: 0.8500000000000001 and parameters: {'num_leaves': 13, 'learning_rate': 0.08825237569924464, 'feature_fraction': 0.8529170574548801, 'bagging_fraction': 0.930317003158786, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:01,651] Trial 43 finished with value: 0.796875 and parameters: {'num_leaves': 34, 'learning_rate': 0.11280418565678924, 'feature_fraction': 0.805978740020438, 'bagging_fraction': 0.8483504613610074, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:01,716] Trial 44 finished with value: 0.84375 and parameters: {'num_leaves': 63, 'learning_rate': 0.04389797119836284, 'feature_fraction': 0.7624459886549594, 'bagging_fraction': 0.8776528138008992, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:01,885] Trial 45 finished with value: 0.853125 and parameters: {'num_leaves': 42, 'learning_rate': 0.06891180199986537, 'feature_fraction': 0.8935134116071464, 'bagging_fraction': 0.9608627860689652, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:01,932] Trial 46 finished with value: 0.76875 and parameters: {'num_leaves': 26, 'learning_rate': 0.08667407687066873, 'feature_fraction': 0.7146246044539867, 'bagging_fraction': 0.8246180982913212, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:01,960] Trial 47 finished with value: 0.734375 and parameters: {'num_leaves': 75, 'learning_rate': 0.10103427635610926, 'feature_fraction': 0.6608862007191388, 'bagging_fraction': 0.49537229488133233, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:01,992] Trial 48 finished with value: 0.7406250000000001 and parameters: {'num_leaves': 55, 'learning_rate': 0.14194821770325988, 'feature_fraction': 0.8563546212501828, 'bagging_fraction': 0.5623027306825149, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:02,049] Trial 49 finished with value: 0.834375 and parameters: {'num_leaves': 69, 'learning_rate': 0.08063901221909268, 'feature_fraction': 0.6011547403326228, 'bagging_fraction': 0.604700716681373, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 40 with value: 0.8750000000000001.
[I 2025-09-17 13:17:02,560] A new study created in memory with name: no-name-66ef2e56-3b76-4ec6-84ab-a4221efa9f98
[I 2025-09-17 13:17:02,586] Trial 0 finished with value: 0.734375 and parameters: {'num_leaves': 102, 'learning_rate': 0.20937087869613408, 'feature_fraction': 0.5404195068383505, 'bagging_fraction': 0.5173231675325143, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 0 with value: 0.734375.
[I 2025-09-17 13:17:02,600] Trial 1 finished with value: 0.7140625 and parameters: {'num_leaves': 247, 'learning_rate': 0.20316649764199615, 'feature_fraction': 0.6816052711608194, 'bagging_fraction': 0.9172558228152272, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 0 with value: 0.734375.
[I 2025-09-17 13:17:02,623] Trial 2 finished with value: 0.740625 and parameters: {'num_leaves': 127, 'learning_rate': 0.2689780126389891, 'feature_fraction': 0.4802401504971439, 'bagging_fraction': 0.4940607391467449, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,631] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 81, 'learning_rate': 0.27513935732052297, 'feature_fraction': 0.4196254703413538, 'bagging_fraction': 0.7332031922448551, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,639] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 19, 'learning_rate': 0.12821418765043066, 'feature_fraction': 0.7467599211032689, 'bagging_fraction': 0.6601439933148252, 'bagging_freq': 2, 'min_child_samples': 72}. Best is trial 2 with value: 0.740625.
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.617078
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.588781
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.625753
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.6092
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.576583
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.454499
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.671636
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.596496
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.533542
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.438333
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.530638
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.573044
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.59109
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.519531
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.538004
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.585655
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.527459
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.574022
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.484389
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.538575
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.47947
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.528197
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.495861
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.557305
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.573101
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.598132
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.571998
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.578357
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.459624
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.487798
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.54567
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.501761
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.504806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.458024
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.499571
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.47278
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.490226
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.483184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.526318
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.485124
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.487352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.539196
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.597508
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.603597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.528367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.585789
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.623779
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.60843
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:02,645] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 148, 'learning_rate': 0.20031113111874504, 'feature_fraction': 0.6530280876319478, 'bagging_fraction': 0.8201180899552971, 'bagging_freq': 1, 'min_child_samples': 94}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,653] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.19155572176932634, 'feature_fraction': 0.5523647500716811, 'bagging_fraction': 0.6479799082280272, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,686] Trial 7 finished with value: 0.7109375 and parameters: {'num_leaves': 11, 'learning_rate': 0.05051893587229632, 'feature_fraction': 0.6769267848761916, 'bagging_fraction': 0.6802181931366029, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,697] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 202, 'learning_rate': 0.26005414558228546, 'feature_fraction': 0.4576980033841064, 'bagging_fraction': 0.5088173271360011, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,715] Trial 9 finished with value: 0.7359375 and parameters: {'num_leaves': 205, 'learning_rate': 0.05050618985882998, 'feature_fraction': 0.8644858770127934, 'bagging_fraction': 0.6331262822669874, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,777] Trial 10 finished with value: 0.690625 and parameters: {'num_leaves': 298, 'learning_rate': 0.2991415690910847, 'feature_fraction': 0.8910892530351335, 'bagging_fraction': 0.43794617010596876, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,791] Trial 11 finished with value: 0.45000000000000007 and parameters: {'num_leaves': 141, 'learning_rate': 0.04089498388706937, 'feature_fraction': 0.9525829816354815, 'bagging_fraction': 0.5572266169019858, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,815] Trial 12 finished with value: 0.696875 and parameters: {'num_leaves': 223, 'learning_rate': 0.10709809488722784, 'feature_fraction': 0.8337405420688645, 'bagging_fraction': 0.585975909550242, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,833] Trial 13 finished with value: 0.48437500000000006 and parameters: {'num_leaves': 105, 'learning_rate': 0.0825238511110653, 'feature_fraction': 0.7827638413853399, 'bagging_fraction': 0.40060198743374525, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,850] Trial 14 finished with value: 0.475 and parameters: {'num_leaves': 263, 'learning_rate': 0.15980680237820546, 'feature_fraction': 0.9607400931187113, 'bagging_fraction': 0.7765007494739069, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,962] Trial 15 finished with value: 0.7375 and parameters: {'num_leaves': 177, 'learning_rate': 0.017964452450717212, 'feature_fraction': 0.5834070851689811, 'bagging_fraction': 0.5960216583760747, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:02,998] Trial 16 finished with value: 0.7296874999999999 and parameters: {'num_leaves': 64, 'learning_rate': 0.2281667469449822, 'feature_fraction': 0.5728331875832089, 'bagging_fraction': 0.46574942034402284, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:03,026] Trial 17 finished with value: 0.6859375 and parameters: {'num_leaves': 170, 'learning_rate': 0.15581914719181178, 'feature_fraction': 0.4751592630184856, 'bagging_fraction': 0.5824902657711227, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:03,176] Trial 18 finished with value: 0.709375 and parameters: {'num_leaves': 128, 'learning_rate': 0.01694399374808141, 'feature_fraction': 0.6190284507722851, 'bagging_fraction': 0.8801221473125462, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:03,193] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 45, 'learning_rate': 0.09039695415631238, 'feature_fraction': 0.5149665938486966, 'bagging_fraction': 0.5018134259914896, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 2 with value: 0.740625.
[I 2025-09-17 13:17:03,221] Trial 20 finished with value: 0.7562500000000001 and parameters: {'num_leaves': 165, 'learning_rate': 0.24960364245378575, 'feature_fraction': 0.40004879169002117, 'bagging_fraction': 0.7283363302528743, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 20 with value: 0.7562500000000001.
[I 2025-09-17 13:17:03,259] Trial 21 finished with value: 0.7000000000000001 and parameters: {'num_leaves': 175, 'learning_rate': 0.24667515977387905, 'feature_fraction': 0.41235279587826956, 'bagging_fraction': 0.9919890651998948, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 20 with value: 0.7562500000000001.
[I 2025-09-17 13:17:03,303] Trial 22 finished with value: 0.7171875 and parameters: {'num_leaves': 113, 'learning_rate': 0.27304347410871727, 'feature_fraction': 0.4763139143355356, 'bagging_fraction': 0.7249318627323678, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 20 with value: 0.7562500000000001.
[I 2025-09-17 13:17:03,327] Trial 23 finished with value: 0.7046875 and parameters: {'num_leaves': 156, 'learning_rate': 0.29698926054019414, 'feature_fraction': 0.6070361383491563, 'bagging_fraction': 0.610570878154478, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 20 with value: 0.7562500000000001.
[I 2025-09-17 13:17:03,371] Trial 24 finished with value: 0.709375 and parameters: {'num_leaves': 225, 'learning_rate': 0.24410737371996555, 'feature_fraction': 0.5028209212662862, 'bagging_fraction': 0.7831591991831287, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 20 with value: 0.7562500000000001.
[I 2025-09-17 13:17:03,389] Trial 25 finished with value: 0.6265625 and parameters: {'num_leaves': 129, 'learning_rate': 0.17326250976394597, 'feature_fraction': 0.4107821826056741, 'bagging_fraction': 0.5392536248861629, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 20 with value: 0.7562500000000001.
[I 2025-09-17 13:17:03,437] Trial 26 finished with value: 0.759375 and parameters: {'num_leaves': 163, 'learning_rate': 0.13451062872030028, 'feature_fraction': 0.5905015660892101, 'bagging_fraction': 0.7056909757860936, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 26 with value: 0.759375.
[I 2025-09-17 13:17:03,479] Trial 27 finished with value: 0.6875 and parameters: {'num_leaves': 87, 'learning_rate': 0.12876133363176, 'feature_fraction': 0.45438336085907, 'bagging_fraction': 0.7056039472549004, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 26 with value: 0.759375.
[I 2025-09-17 13:17:03,498] Trial 28 finished with value: 0.709375 and parameters: {'num_leaves': 158, 'learning_rate': 0.13333643741527218, 'feature_fraction': 0.5197573981394588, 'bagging_fraction': 0.8251284698966572, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 26 with value: 0.759375.
[I 2025-09-17 13:17:03,528] Trial 29 finished with value: 0.6734375 and parameters: {'num_leaves': 126, 'learning_rate': 0.2167427197311745, 'feature_fraction': 0.5423010896249288, 'bagging_fraction': 0.7634780926199067, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 26 with value: 0.759375.
[I 2025-09-17 13:17:03,552] Trial 30 finished with value: 0.725 and parameters: {'num_leaves': 196, 'learning_rate': 0.17397127695076506, 'feature_fraction': 0.6412197862872118, 'bagging_fraction': 0.8491592462343862, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 26 with value: 0.759375.
[I 2025-09-17 13:17:03,614] Trial 31 finished with value: 0.7281249999999999 and parameters: {'num_leaves': 174, 'learning_rate': 0.01292320542589229, 'feature_fraction': 0.604745369530643, 'bagging_fraction': 0.6868123015768886, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 26 with value: 0.759375.
[I 2025-09-17 13:17:03,686] Trial 32 finished with value: 0.734375 and parameters: {'num_leaves': 214, 'learning_rate': 0.2341092031243161, 'feature_fraction': 0.595815341632486, 'bagging_fraction': 0.610604954969872, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 26 with value: 0.759375.
[I 2025-09-17 13:17:03,714] Trial 33 finished with value: 0.74375 and parameters: {'num_leaves': 183, 'learning_rate': 0.27312922530647493, 'feature_fraction': 0.7243484068717086, 'bagging_fraction': 0.46721473630885574, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 26 with value: 0.759375.
[I 2025-09-17 13:17:03,732] Trial 34 finished with value: 0.7625 and parameters: {'num_leaves': 242, 'learning_rate': 0.2783118823105898, 'feature_fraction': 0.7053777031769983, 'bagging_fraction': 0.44185911254332466, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,750] Trial 35 finished with value: 0.7515625 and parameters: {'num_leaves': 258, 'learning_rate': 0.28856471092660413, 'feature_fraction': 0.7265530207220985, 'bagging_fraction': 0.40043038381391166, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,777] Trial 36 finished with value: 0.7546875 and parameters: {'num_leaves': 252, 'learning_rate': 0.28312141558675286, 'feature_fraction': 0.7831382957794569, 'bagging_fraction': 0.7452992396347161, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,799] Trial 37 finished with value: 0.7140625 and parameters: {'num_leaves': 282, 'learning_rate': 0.262321917193489, 'feature_fraction': 0.7673261172167389, 'bagging_fraction': 0.7515184010514752, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,814] Trial 38 finished with value: 0.45000000000000007 and parameters: {'num_leaves': 241, 'learning_rate': 0.21474272807221856, 'feature_fraction': 0.803936964541125, 'bagging_fraction': 0.8074438940753887, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,836] Trial 39 finished with value: 0.746875 and parameters: {'num_leaves': 241, 'learning_rate': 0.19142548857495698, 'feature_fraction': 0.6992507009863341, 'bagging_fraction': 0.7152507282311187, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,852] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 274, 'learning_rate': 0.2505692633104279, 'feature_fraction': 0.6855294588645212, 'bagging_fraction': 0.6672420627206049, 'bagging_freq': 6, 'min_child_samples': 71}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,880] Trial 41 finished with value: 0.7234375 and parameters: {'num_leaves': 256, 'learning_rate': 0.2864751470837896, 'feature_fraction': 0.7331447132278173, 'bagging_fraction': 0.40344278655437477, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,901] Trial 42 finished with value: 0.7609375 and parameters: {'num_leaves': 288, 'learning_rate': 0.2875326804648412, 'feature_fraction': 0.8144880098951714, 'bagging_fraction': 0.45091572139602837, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,920] Trial 43 finished with value: 0.6859375 and parameters: {'num_leaves': 299, 'learning_rate': 0.2856106536995885, 'feature_fraction': 0.8967421475273682, 'bagging_fraction': 0.4453029689936809, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,938] Trial 44 finished with value: 0.45000000000000007 and parameters: {'num_leaves': 283, 'learning_rate': 0.2590817525316291, 'feature_fraction': 0.8227464252544475, 'bagging_fraction': 0.6310247674965447, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,969] Trial 45 finished with value: 0.740625 and parameters: {'num_leaves': 236, 'learning_rate': 0.27735688271907233, 'feature_fraction': 0.7609068129508086, 'bagging_fraction': 0.7405063005794039, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 34 with value: 0.7625.
[I 2025-09-17 13:17:03,992] Trial 46 finished with value: 0.771875 and parameters: {'num_leaves': 269, 'learning_rate': 0.2347429211479589, 'feature_fraction': 0.8669588301409136, 'bagging_fraction': 0.5504142059523248, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 46 with value: 0.771875.
[I 2025-09-17 13:17:04,012] Trial 47 finished with value: 0.7140625 and parameters: {'num_leaves': 278, 'learning_rate': 0.2298109430360859, 'feature_fraction': 0.8728811202002653, 'bagging_fraction': 0.5330828407579751, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 46 with value: 0.771875.
[I 2025-09-17 13:17:04,031] Trial 48 finished with value: 0.7328125 and parameters: {'num_leaves': 267, 'learning_rate': 0.200629801333387, 'feature_fraction': 0.9334816018676491, 'bagging_fraction': 0.48146169603893063, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 46 with value: 0.771875.
[I 2025-09-17 13:17:04,065] Trial 49 finished with value: 0.7375 and parameters: {'num_leaves': 294, 'learning_rate': 0.1078674106202319, 'feature_fraction': 0.8439472140818784, 'bagging_fraction': 0.4482327153551526, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 46 with value: 0.771875.
[I 2025-09-17 13:17:04,266] A new study created in memory with name: no-name-469092af-2886-4ce2-9e7f-3df9fd857719
[I 2025-09-17 13:17:04,276] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 49, 'learning_rate': 0.02749862037823554, 'feature_fraction': 0.6799393517219906, 'bagging_fraction': 0.8335680558961216, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:04,283] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 194, 'learning_rate': 0.21316541439155717, 'feature_fraction': 0.8356186995272721, 'bagging_fraction': 0.6891353202687949, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:04,301] Trial 2 finished with value: 0.69375 and parameters: {'num_leaves': 109, 'learning_rate': 0.022409369997948493, 'feature_fraction': 0.985129026815497, 'bagging_fraction': 0.9402134496473854, 'bagging_freq': 6, 'min_child_samples': 60}. Best is trial 2 with value: 0.69375.
[I 2025-09-17 13:17:04,319] Trial 3 finished with value: 0.7359375 and parameters: {'num_leaves': 42, 'learning_rate': 0.21958832270108133, 'feature_fraction': 0.7404851885935884, 'bagging_fraction': 0.6632390021175654, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,333] Trial 4 finished with value: 0.6734375000000001 and parameters: {'num_leaves': 162, 'learning_rate': 0.15644236451493737, 'feature_fraction': 0.8173058565105992, 'bagging_fraction': 0.4634017423234805, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,350] Trial 5 finished with value: 0.6640625 and parameters: {'num_leaves': 238, 'learning_rate': 0.1575291415378347, 'feature_fraction': 0.5203649539019503, 'bagging_fraction': 0.472506767948894, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,363] Trial 6 finished with value: 0.69375 and parameters: {'num_leaves': 99, 'learning_rate': 0.22193778461640676, 'feature_fraction': 0.999206736707929, 'bagging_fraction': 0.9109266985987179, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,389] Trial 7 finished with value: 0.659375 and parameters: {'num_leaves': 173, 'learning_rate': 0.015382079575537003, 'feature_fraction': 0.7764564153716009, 'bagging_fraction': 0.6372936152040596, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,417] Trial 8 finished with value: 0.5421875 and parameters: {'num_leaves': 37, 'learning_rate': 0.23406231614400375, 'feature_fraction': 0.6508175874770984, 'bagging_fraction': 0.43473131714433977, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,427] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 219, 'learning_rate': 0.13082035882024234, 'feature_fraction': 0.5468507716659772, 'bagging_fraction': 0.8314099246709998, 'bagging_freq': 4, 'min_child_samples': 74}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,441] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 101, 'learning_rate': 0.285920551654616, 'feature_fraction': 0.4279715551339353, 'bagging_fraction': 0.6211918714498761, 'bagging_freq': 2, 'min_child_samples': 97}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,456] Trial 11 finished with value: 0.6656250000000001 and parameters: {'num_leaves': 92, 'learning_rate': 0.09872417210561704, 'feature_fraction': 0.9000305991203695, 'bagging_fraction': 0.9890886482118126, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,470] Trial 12 finished with value: 0.69375 and parameters: {'num_leaves': 13, 'learning_rate': 0.07418296918564607, 'feature_fraction': 0.9954422004361138, 'bagging_fraction': 0.7829714310383126, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 3 with value: 0.7359375.
[I 2025-09-17 13:17:04,537] Trial 13 finished with value: 0.75625 and parameters: {'num_leaves': 127, 'learning_rate': 0.2780918440515994, 'feature_fraction': 0.9050606570252522, 'bagging_fraction': 0.5939052716341712, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 13 with value: 0.75625.
[I 2025-09-17 13:17:04,612] Trial 14 finished with value: 0.7062499999999999 and parameters: {'num_leaves': 277, 'learning_rate': 0.29226825273767254, 'feature_fraction': 0.7360507558327948, 'bagging_fraction': 0.5697414168342106, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 13 with value: 0.75625.
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.62738
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.623859
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.634922
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.623005
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.684686
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.623834
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.603146
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.635085
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.643779
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.595994
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.638125
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.62308
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.620386
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.623479
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.638669
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.579752
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.65374
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.631562
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.640909
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.621264
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.632735
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.628657
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.581825
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.590164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.592835
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.600578
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.610819
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.697482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.584968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.591483
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.607187
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.606855
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.697004
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.595621
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.569958
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.575858
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.61419
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.597774
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.613567
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.607173
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.610637
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.638326
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.615416
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.621557
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.676849
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.617122
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.624409
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.602069
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.666433
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:04,639] Trial 15 finished with value: 0.7281249999999999 and parameters: {'num_leaves': 134, 'learning_rate': 0.25571039169614423, 'feature_fraction': 0.8907130207530677, 'bagging_fraction': 0.5364368892875587, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 13 with value: 0.75625.
[I 2025-09-17 13:17:04,657] Trial 16 finished with value: 0.6734375 and parameters: {'num_leaves': 64, 'learning_rate': 0.19120908868000527, 'feature_fraction': 0.6079631077552056, 'bagging_fraction': 0.726896131618696, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 13 with value: 0.75625.
[I 2025-09-17 13:17:04,721] Trial 17 finished with value: 0.7015625 and parameters: {'num_leaves': 137, 'learning_rate': 0.2550826114163479, 'feature_fraction': 0.9033095184863864, 'bagging_fraction': 0.5492541906335141, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 13 with value: 0.75625.
[I 2025-09-17 13:17:04,748] Trial 18 finished with value: 0.6609375 and parameters: {'num_leaves': 74, 'learning_rate': 0.19435666435540258, 'feature_fraction': 0.7449848473371279, 'bagging_fraction': 0.6961182249593421, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 13 with value: 0.75625.
[I 2025-09-17 13:17:04,764] Trial 19 finished with value: 0.7500000000000001 and parameters: {'num_leaves': 10, 'learning_rate': 0.2644525820445518, 'feature_fraction': 0.8419426480991732, 'bagging_fraction': 0.6233579263866363, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 13 with value: 0.75625.
[I 2025-09-17 13:17:04,776] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.27980260928112766, 'feature_fraction': 0.8402497951817244, 'bagging_fraction': 0.7518810901657115, 'bagging_freq': 6, 'min_child_samples': 79}. Best is trial 13 with value: 0.75625.
[I 2025-09-17 13:17:04,792] Trial 21 finished with value: 0.796875 and parameters: {'num_leaves': 23, 'learning_rate': 0.25469791747000203, 'feature_fraction': 0.925749860277126, 'bagging_fraction': 0.622721575453409, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:04,811] Trial 22 finished with value: 0.5 and parameters: {'num_leaves': 14, 'learning_rate': 0.25783316204751083, 'feature_fraction': 0.9369010559558179, 'bagging_fraction': 0.6036722432595333, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:04,832] Trial 23 finished with value: 0.6468750000000001 and parameters: {'num_leaves': 10, 'learning_rate': 0.26119885982788427, 'feature_fraction': 0.9238914971401526, 'bagging_fraction': 0.511835189604129, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:04,844] Trial 24 finished with value: 0.5 and parameters: {'num_leaves': 71, 'learning_rate': 0.29998053107944, 'feature_fraction': 0.85442353158425, 'bagging_fraction': 0.5869730645501208, 'bagging_freq': 6, 'min_child_samples': 87}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:04,856] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 131, 'learning_rate': 0.19047684442959267, 'feature_fraction': 0.7982677062389479, 'bagging_fraction': 0.5046436114070101, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:04,873] Trial 26 finished with value: 0.715625 and parameters: {'num_leaves': 29, 'learning_rate': 0.24388098300836153, 'feature_fraction': 0.9502067416661304, 'bagging_fraction': 0.660895679178588, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:04,892] Trial 27 finished with value: 0.725 and parameters: {'num_leaves': 53, 'learning_rate': 0.2687782999784166, 'feature_fraction': 0.8676016232285516, 'bagging_fraction': 0.6070977000505738, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:04,926] Trial 28 finished with value: 0.784375 and parameters: {'num_leaves': 85, 'learning_rate': 0.1753559590784023, 'feature_fraction': 0.941196677798124, 'bagging_fraction': 0.7285178271477921, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:04,966] Trial 29 finished with value: 0.68125 and parameters: {'num_leaves': 122, 'learning_rate': 0.13322163023126143, 'feature_fraction': 0.9534409418709225, 'bagging_fraction': 0.8001428284906641, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,015] Trial 30 finished with value: 0.690625 and parameters: {'num_leaves': 88, 'learning_rate': 0.05090174311763522, 'feature_fraction': 0.6782833230863482, 'bagging_fraction': 0.7318037841205352, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,039] Trial 31 finished with value: 0.6906249999999999 and parameters: {'num_leaves': 54, 'learning_rate': 0.2348028777813626, 'feature_fraction': 0.8750966516703883, 'bagging_fraction': 0.6446009032076195, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,053] Trial 32 finished with value: 0.5 and parameters: {'num_leaves': 33, 'learning_rate': 0.20727224230417615, 'feature_fraction': 0.9548214656119948, 'bagging_fraction': 0.6827422302017426, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,071] Trial 33 finished with value: 0.6656250000000001 and parameters: {'num_leaves': 180, 'learning_rate': 0.17184111713600064, 'feature_fraction': 0.7949036990209204, 'bagging_fraction': 0.5740117113870328, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,084] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 77, 'learning_rate': 0.27661424341574226, 'feature_fraction': 0.9132116975375165, 'bagging_fraction': 0.7129171984615312, 'bagging_freq': 1, 'min_child_samples': 63}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,103] Trial 35 finished with value: 0.6984375 and parameters: {'num_leaves': 156, 'learning_rate': 0.11848313780836042, 'feature_fraction': 0.8473734755660003, 'bagging_fraction': 0.7812054778963645, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,163] Trial 36 finished with value: 0.7046875000000001 and parameters: {'num_leaves': 23, 'learning_rate': 0.23585398717620454, 'feature_fraction': 0.9706262796861778, 'bagging_fraction': 0.8769397617702495, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,187] Trial 37 finished with value: 0.6906249999999999 and parameters: {'num_leaves': 110, 'learning_rate': 0.205702800788568, 'feature_fraction': 0.8299598977295544, 'bagging_fraction': 0.6697856005539037, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,206] Trial 38 finished with value: 0.6499999999999999 and parameters: {'num_leaves': 46, 'learning_rate': 0.1754984201125736, 'feature_fraction': 0.9259295024206138, 'bagging_fraction': 0.6340693112989173, 'bagging_freq': 7, 'min_child_samples': 47}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,238] Trial 39 finished with value: 0.746875 and parameters: {'num_leaves': 197, 'learning_rate': 0.272237298851092, 'feature_fraction': 0.7575817019665709, 'bagging_fraction': 0.7560080694099226, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,258] Trial 40 finished with value: 0.7015625 and parameters: {'num_leaves': 120, 'learning_rate': 0.2186628162768972, 'feature_fraction': 0.812451051492385, 'bagging_fraction': 0.47561318285701826, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,290] Trial 41 finished with value: 0.70625 and parameters: {'num_leaves': 210, 'learning_rate': 0.2456519959334151, 'feature_fraction': 0.767469669343105, 'bagging_fraction': 0.7624642841537699, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,324] Trial 42 finished with value: 0.7875000000000001 and parameters: {'num_leaves': 192, 'learning_rate': 0.26793081928615853, 'feature_fraction': 0.8788018398516624, 'bagging_fraction': 0.8450895110540358, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,353] Trial 43 finished with value: 0.7640625 and parameters: {'num_leaves': 246, 'learning_rate': 0.29834446926242086, 'feature_fraction': 0.8781137477408522, 'bagging_fraction': 0.8577999895002757, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,379] Trial 44 finished with value: 0.7296874999999999 and parameters: {'num_leaves': 234, 'learning_rate': 0.2952360701021902, 'feature_fraction': 0.9761974657680759, 'bagging_fraction': 0.8932722584349545, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,399] Trial 45 finished with value: 0.7 and parameters: {'num_leaves': 254, 'learning_rate': 0.2868055217439224, 'feature_fraction': 0.8857700676575363, 'bagging_fraction': 0.8290261908485096, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,454] Trial 46 finished with value: 0.5921875 and parameters: {'num_leaves': 185, 'learning_rate': 0.2803016679285539, 'feature_fraction': 0.4257192249839031, 'bagging_fraction': 0.9586697852734226, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,526] Trial 47 finished with value: 0.6984375 and parameters: {'num_leaves': 251, 'learning_rate': 0.22581196328489306, 'feature_fraction': 0.8764069078963448, 'bagging_fraction': 0.8607595820623543, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,549] Trial 48 finished with value: 0.69375 and parameters: {'num_leaves': 165, 'learning_rate': 0.24843601531563703, 'feature_fraction': 0.9815867733883894, 'bagging_fraction': 0.9190900911630278, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,585] Trial 49 finished with value: 0.6765625000000001 and parameters: {'num_leaves': 216, 'learning_rate': 0.2988342595414973, 'feature_fraction': 0.7017700681016157, 'bagging_fraction': 0.8155759801848093, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 21 with value: 0.796875.
[I 2025-09-17 13:17:05,727] A new study created in memory with name: no-name-586c6cb3-b4fd-4768-8b9c-b3422b4336d3
[I 2025-09-17 13:17:05,740] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 47, 'learning_rate': 0.16588731086686923, 'feature_fraction': 0.608327053298105, 'bagging_fraction': 0.7048100539094486, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:05,768] Trial 1 finished with value: 0.8791666666666665 and parameters: {'num_leaves': 251, 'learning_rate': 0.08816355793397912, 'feature_fraction': 0.9464334341453534, 'bagging_fraction': 0.4268507827173353, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 1 with value: 0.8791666666666665.
[I 2025-09-17 13:17:05,778] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 150, 'learning_rate': 0.04765486950208257, 'feature_fraction': 0.836542516847258, 'bagging_fraction': 0.5071940599734178, 'bagging_freq': 1, 'min_child_samples': 53}. Best is trial 1 with value: 0.8791666666666665.
[I 2025-09-17 13:17:05,833] Trial 3 finished with value: 0.9375 and parameters: {'num_leaves': 140, 'learning_rate': 0.04569263388700287, 'feature_fraction': 0.42924833954819097, 'bagging_fraction': 0.6418183683494796, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 3 with value: 0.9375.
[I 2025-09-17 13:17:05,852] Trial 4 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 294, 'learning_rate': 0.0645711768800064, 'feature_fraction': 0.8850103581489123, 'bagging_fraction': 0.9806296780301434, 'bagging_freq': 6, 'min_child_samples': 60}. Best is trial 3 with value: 0.9375.
[I 2025-09-17 13:17:05,892] Trial 5 finished with value: 0.95 and parameters: {'num_leaves': 43, 'learning_rate': 0.0925630094180602, 'feature_fraction': 0.9625068956161014, 'bagging_fraction': 0.7932337228842536, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 5 with value: 0.95.
[I 2025-09-17 13:17:05,906] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 274, 'learning_rate': 0.1752661567215289, 'feature_fraction': 0.6471512805791537, 'bagging_fraction': 0.7260762627112405, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial 5 with value: 0.95.
[I 2025-09-17 13:17:05,915] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 85, 'learning_rate': 0.29324649928085955, 'feature_fraction': 0.8728733153475676, 'bagging_fraction': 0.44340664427229054, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 5 with value: 0.95.
[I 2025-09-17 13:17:05,928] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 274, 'learning_rate': 0.1727329135284413, 'feature_fraction': 0.579438656687365, 'bagging_fraction': 0.49013111396240633, 'bagging_freq': 7, 'min_child_samples': 47}. Best is trial 5 with value: 0.95.
[I 2025-09-17 13:17:05,942] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.13531858901712818, 'feature_fraction': 0.5169241189050349, 'bagging_fraction': 0.7286823765304362, 'bagging_freq': 7, 'min_child_samples': 60}. Best is trial 5 with value: 0.95.
[I 2025-09-17 13:17:06,035] Trial 10 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 18, 'learning_rate': 0.2511115193116391, 'feature_fraction': 0.7408434027929716, 'bagging_fraction': 0.9366614815523153, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 5 with value: 0.95.
[I 2025-09-17 13:17:06,099] Trial 11 finished with value: 0.9375 and parameters: {'num_leaves': 10, 'learning_rate': 0.27679907200397325, 'feature_fraction': 0.7619698402212501, 'bagging_fraction': 0.9266976253971779, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 5 with value: 0.95.
[I 2025-09-17 13:17:06,127] Trial 12 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 80, 'learning_rate': 0.23703964318554346, 'feature_fraction': 0.9767554711363824, 'bagging_fraction': 0.8600648354647414, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,157] Trial 13 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 91, 'learning_rate': 0.21748959763473427, 'feature_fraction': 0.9998796866758338, 'bagging_fraction': 0.8378008158225428, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,190] Trial 14 finished with value: 0.95 and parameters: {'num_leaves': 100, 'learning_rate': 0.23205413641388753, 'feature_fraction': 0.9925152938155898, 'bagging_fraction': 0.8493732904262881, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,216] Trial 15 finished with value: 0.9291666666666667 and parameters: {'num_leaves': 90, 'learning_rate': 0.21785033739876988, 'feature_fraction': 0.8037961375093958, 'bagging_fraction': 0.8533767392509534, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,240] Trial 16 finished with value: 0.8791666666666667 and parameters: {'num_leaves': 121, 'learning_rate': 0.1997642292724044, 'feature_fraction': 0.9014676773929712, 'bagging_fraction': 0.6028024031863619, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,259] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 193, 'learning_rate': 0.258174602300313, 'feature_fraction': 0.9893039128055584, 'bagging_fraction': 0.833337778701329, 'bagging_freq': 4, 'min_child_samples': 81}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,272] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 63, 'learning_rate': 0.011794864424426899, 'feature_fraction': 0.9222567571140252, 'bagging_fraction': 0.786309363729118, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,298] Trial 19 finished with value: 0.9125000000000001 and parameters: {'num_leaves': 191, 'learning_rate': 0.1376270981665283, 'feature_fraction': 0.7142481986421156, 'bagging_fraction': 0.9055728310247924, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,341] Trial 20 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 112, 'learning_rate': 0.1983149164356689, 'feature_fraction': 0.7956638988084168, 'bagging_fraction': 0.9839149125763779, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,398] Trial 21 finished with value: 0.9500000000000001 and parameters: {'num_leaves': 54, 'learning_rate': 0.11660626815112, 'feature_fraction': 0.9975975667119608, 'bagging_fraction': 0.7907999592208953, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 12 with value: 0.9541666666666666.
[I 2025-09-17 13:17:06,437] Trial 22 finished with value: 0.9708333333333332 and parameters: {'num_leaves': 75, 'learning_rate': 0.12426350229147479, 'feature_fraction': 0.9450099064381318, 'bagging_fraction': 0.7833279820154511, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 22 with value: 0.9708333333333332.
[I 2025-09-17 13:17:06,458] Trial 23 finished with value: 0.925 and parameters: {'num_leaves': 72, 'learning_rate': 0.22159586624737312, 'feature_fraction': 0.8548965177302477, 'bagging_fraction': 0.653039019408494, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 22 with value: 0.9708333333333332.
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.614393
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.623124
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.628793
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.63189
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.612702
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.614544
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.673219
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.603714
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.609357
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.570737
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.642278
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.635697
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.632261
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.619943
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.614317
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.619321
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.637637
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.668365
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.599217
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.619024
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.611954
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.564653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.582573
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.59949
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.617255
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.684077
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.62219
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.613082
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.631987
Training model for P124... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.363521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.291587
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.433959
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.260968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.28898
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.296304
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.260983
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.243562
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.27138
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.341079
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.386934
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.36029
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.270657
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.268245
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.19856
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.317759
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:06,478] Trial 24 finished with value: 0.9083333333333333 and parameters: {'num_leaves': 123, 'learning_rate': 0.19278203519963327, 'feature_fraction': 0.9295176192206571, 'bagging_fraction': 0.9031433226154696, 'bagging_freq': 6, 'min_child_samples': 42}. Best is trial 22 with value: 0.9708333333333332.
[I 2025-09-17 13:17:06,515] Trial 25 finished with value: 0.9916666666666666 and parameters: {'num_leaves': 30, 'learning_rate': 0.24808399439078385, 'feature_fraction': 0.9434288703735718, 'bagging_fraction': 0.7724906555258552, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,546] Trial 26 finished with value: 0.9791666666666667 and parameters: {'num_leaves': 30, 'learning_rate': 0.29948463952327214, 'feature_fraction': 0.8089199662836037, 'bagging_fraction': 0.7561394468642834, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,580] Trial 27 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 28, 'learning_rate': 0.2939623866949935, 'feature_fraction': 0.8190357871030097, 'bagging_fraction': 0.758945998449218, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,610] Trial 28 finished with value: 0.9375 and parameters: {'num_leaves': 30, 'learning_rate': 0.298991916851449, 'feature_fraction': 0.6673196578172723, 'bagging_fraction': 0.5948320278896507, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,627] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 41, 'learning_rate': 0.27264078870734976, 'feature_fraction': 0.8236731032209691, 'bagging_fraction': 0.682346594908137, 'bagging_freq': 2, 'min_child_samples': 74}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,680] Trial 30 finished with value: 0.9375 and parameters: {'num_leaves': 33, 'learning_rate': 0.279658967690441, 'feature_fraction': 0.7707965784895653, 'bagging_fraction': 0.744053398484163, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,723] Trial 31 finished with value: 0.9625 and parameters: {'num_leaves': 56, 'learning_rate': 0.2595250125941215, 'feature_fraction': 0.8988985519048923, 'bagging_fraction': 0.7669287270990014, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,754] Trial 32 finished with value: 0.9375 and parameters: {'num_leaves': 24, 'learning_rate': 0.2970809208428793, 'feature_fraction': 0.851448916750692, 'bagging_fraction': 0.6942725585563118, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,774] Trial 33 finished with value: 0.9208333333333333 and parameters: {'num_leaves': 14, 'learning_rate': 0.15231904570665572, 'feature_fraction': 0.9329991650251634, 'bagging_fraction': 0.7572107691771108, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,827] Trial 34 finished with value: 0.9208333333333333 and parameters: {'num_leaves': 61, 'learning_rate': 0.10034874927470175, 'feature_fraction': 0.8178914481820763, 'bagging_fraction': 0.8083464521567374, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,849] Trial 35 finished with value: 0.8458333333333333 and parameters: {'num_leaves': 42, 'learning_rate': 0.2794180207868625, 'feature_fraction': 0.7054189713446264, 'bagging_fraction': 0.6715638022639471, 'bagging_freq': 1, 'min_child_samples': 43}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,883] Trial 36 finished with value: 0.9500000000000001 and parameters: {'num_leaves': 226, 'learning_rate': 0.24832296589332148, 'feature_fraction': 0.8825539438713658, 'bagging_fraction': 0.6176893868652881, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:06,930] Trial 37 finished with value: 0.8833333333333334 and parameters: {'num_leaves': 33, 'learning_rate': 0.2710000781078479, 'feature_fraction': 0.7704449556703873, 'bagging_fraction': 0.7168927223729596, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,000] Trial 38 finished with value: 0.95 and parameters: {'num_leaves': 161, 'learning_rate': 0.07776506560871697, 'feature_fraction': 0.4030186038255686, 'bagging_fraction': 0.8180483071189085, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,014] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 46, 'learning_rate': 0.10640807518085331, 'feature_fraction': 0.9514811298752386, 'bagging_fraction': 0.5563977919501929, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,038] Trial 40 finished with value: 0.8791666666666667 and parameters: {'num_leaves': 67, 'learning_rate': 0.11991140158889395, 'feature_fraction': 0.853377017519717, 'bagging_fraction': 0.8791401869572372, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,068] Trial 41 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 51, 'learning_rate': 0.25991456877058483, 'feature_fraction': 0.9187921699329874, 'bagging_fraction': 0.7618615057774286, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,103] Trial 42 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 24, 'learning_rate': 0.28810698431747633, 'feature_fraction': 0.9165457277249582, 'bagging_fraction': 0.7669320865603466, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,134] Trial 43 finished with value: 0.9708333333333334 and parameters: {'num_leaves': 26, 'learning_rate': 0.2890117658335658, 'feature_fraction': 0.8987587754229699, 'bagging_fraction': 0.7422739721822349, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,166] Trial 44 finished with value: 0.9208333333333333 and parameters: {'num_leaves': 13, 'learning_rate': 0.28484337078488275, 'feature_fraction': 0.9025278636032492, 'bagging_fraction': 0.7171984674638656, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,229] Trial 45 finished with value: 0.9249999999999999 and parameters: {'num_leaves': 48, 'learning_rate': 0.26492198783810383, 'feature_fraction': 0.8691220865741132, 'bagging_fraction': 0.7349509424158777, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,250] Trial 46 finished with value: 0.9041666666666667 and parameters: {'num_leaves': 10, 'learning_rate': 0.24323711634937836, 'feature_fraction': 0.966896413974547, 'bagging_fraction': 0.6985254217651612, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,289] Trial 47 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 22, 'learning_rate': 0.28889606393236483, 'feature_fraction': 0.9107649016849758, 'bagging_fraction': 0.6421011634229012, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,390] Trial 48 finished with value: 0.925 and parameters: {'num_leaves': 33, 'learning_rate': 0.230262257216259, 'feature_fraction': 0.9597485381858799, 'bagging_fraction': 0.8127225428322238, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,427] Trial 49 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 49, 'learning_rate': 0.2539712141983032, 'feature_fraction': 0.5721167298011203, 'bagging_fraction': 0.7715925023047029, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 25 with value: 0.9916666666666666.
[I 2025-09-17 13:17:07,576] A new study created in memory with name: no-name-7339807f-88d0-445a-9c4f-3ab18b2df7bc
[I 2025-09-17 13:17:07,586] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 151, 'learning_rate': 0.23030627355187838, 'feature_fraction': 0.6209421346488306, 'bagging_fraction': 0.7423375022501322, 'bagging_freq': 3, 'min_child_samples': 71}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:07,600] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 284, 'learning_rate': 0.2689312422414061, 'feature_fraction': 0.6578037384742279, 'bagging_fraction': 0.5206509052088415, 'bagging_freq': 6, 'min_child_samples': 54}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:07,608] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 221, 'learning_rate': 0.2665421342385918, 'feature_fraction': 0.685217123087029, 'bagging_fraction': 0.6035118227829284, 'bagging_freq': 7, 'min_child_samples': 78}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:07,638] Trial 3 finished with value: 0.9375 and parameters: {'num_leaves': 289, 'learning_rate': 0.16763810446668695, 'feature_fraction': 0.4636870315619688, 'bagging_fraction': 0.5891402807703067, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 3 with value: 0.9375.
[I 2025-09-17 13:17:07,653] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 108, 'learning_rate': 0.058640590416624144, 'feature_fraction': 0.6141783238922893, 'bagging_fraction': 0.720556780539281, 'bagging_freq': 2, 'min_child_samples': 67}. Best is trial 3 with value: 0.9375.
[I 2025-09-17 13:17:07,659] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 120, 'learning_rate': 0.25934063141457364, 'feature_fraction': 0.5066317914950552, 'bagging_fraction': 0.9506926055860372, 'bagging_freq': 1, 'min_child_samples': 71}. Best is trial 3 with value: 0.9375.
[I 2025-09-17 13:17:07,689] Trial 6 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 100, 'learning_rate': 0.10105386543674404, 'feature_fraction': 0.40461815055002825, 'bagging_fraction': 0.5824504311772751, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 6 with value: 0.9416666666666667.
[I 2025-09-17 13:17:07,709] Trial 7 finished with value: 0.9583333333333334 and parameters: {'num_leaves': 216, 'learning_rate': 0.17221171896613213, 'feature_fraction': 0.7837301354140627, 'bagging_fraction': 0.8135283303522094, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 7 with value: 0.9583333333333334.
[I 2025-09-17 13:17:07,731] Trial 8 finished with value: 0.9875 and parameters: {'num_leaves': 106, 'learning_rate': 0.2396973981540326, 'feature_fraction': 0.5580629300986841, 'bagging_fraction': 0.8673501674073354, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 8 with value: 0.9875.
[I 2025-09-17 13:17:07,743] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 82, 'learning_rate': 0.17132440693630296, 'feature_fraction': 0.9295582317943126, 'bagging_fraction': 0.577998854420239, 'bagging_freq': 2, 'min_child_samples': 88}. Best is trial 8 with value: 0.9875.
[I 2025-09-17 13:17:07,798] Trial 10 finished with value: 1.0 and parameters: {'num_leaves': 19, 'learning_rate': 0.20882268354972344, 'feature_fraction': 0.8634841871106745, 'bagging_fraction': 0.9993644365593801, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:07,855] Trial 11 finished with value: 0.9875 and parameters: {'num_leaves': 17, 'learning_rate': 0.2103181765853538, 'feature_fraction': 0.8807541745387808, 'bagging_fraction': 0.9944374418020988, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:07,926] Trial 12 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 13, 'learning_rate': 0.2979251537634707, 'feature_fraction': 0.8111514692981232, 'bagging_fraction': 0.8842746780994905, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,004] Trial 13 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 19, 'learning_rate': 0.2967275654674395, 'feature_fraction': 0.7954198015113598, 'bagging_fraction': 0.8984934339710519, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,055] Trial 14 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 58, 'learning_rate': 0.12330344159718834, 'feature_fraction': 0.8065413287598089, 'bagging_fraction': 0.4192976856346702, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,094] Trial 15 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 53, 'learning_rate': 0.2985816022652286, 'feature_fraction': 0.9626506025533077, 'bagging_fraction': 0.8147280437748506, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,120] Trial 16 finished with value: 0.9 and parameters: {'num_leaves': 10, 'learning_rate': 0.20427570604392398, 'feature_fraction': 0.8530369156198393, 'bagging_fraction': 0.9924736348640713, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,146] Trial 17 finished with value: 0.8999999999999999 and parameters: {'num_leaves': 56, 'learning_rate': 0.031190630008438566, 'feature_fraction': 0.7317556939392398, 'bagging_fraction': 0.9218162286799125, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,188] Trial 18 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 157, 'learning_rate': 0.1151260260770016, 'feature_fraction': 0.9948402380568491, 'bagging_fraction': 0.792440318436355, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,288] Trial 19 finished with value: 0.9625 and parameters: {'num_leaves': 41, 'learning_rate': 0.21862864803554163, 'feature_fraction': 0.8825434748454701, 'bagging_fraction': 0.8770259940981439, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,311] Trial 20 finished with value: 0.8916666666666667 and parameters: {'num_leaves': 156, 'learning_rate': 0.19198073996703893, 'feature_fraction': 0.7497165020722992, 'bagging_fraction': 0.6568483746977406, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,360] Trial 21 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 182, 'learning_rate': 0.127513955644394, 'feature_fraction': 0.9854615984526377, 'bagging_fraction': 0.8177910430326752, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,406] Trial 22 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 140, 'learning_rate': 0.07628201384705961, 'feature_fraction': 0.9225126491957583, 'bagging_fraction': 0.7768352087025644, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,479] Trial 23 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 195, 'learning_rate': 0.13831739817508598, 'feature_fraction': 0.9973696110681458, 'bagging_fraction': 0.947893724675786, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,508] Trial 24 finished with value: 0.9624999999999999 and parameters: {'num_leaves': 76, 'learning_rate': 0.09187451459726777, 'feature_fraction': 0.8290163092774964, 'bagging_fraction': 0.8472190279079268, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,555] Trial 25 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 37, 'learning_rate': 0.1500501873309805, 'feature_fraction': 0.9140758669574178, 'bagging_fraction': 0.6746916540143096, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,586] Trial 26 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 259, 'learning_rate': 0.01983958045996101, 'feature_fraction': 0.8678052603655975, 'bagging_fraction': 0.9335969685809686, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,722] Trial 27 finished with value: 0.9708333333333332 and parameters: {'num_leaves': 171, 'learning_rate': 0.10911970685820095, 'feature_fraction': 0.7512589282041697, 'bagging_fraction': 0.7509730278842806, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,776] Trial 28 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 129, 'learning_rate': 0.05393513745028203, 'feature_fraction': 0.958945739686548, 'bagging_fraction': 0.9782160221945494, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,792] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 81, 'learning_rate': 0.1928364147961058, 'feature_fraction': 0.8366531761589399, 'bagging_fraction': 0.7701526893966395, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,813] Trial 30 finished with value: 0.9458333333333334 and parameters: {'num_leaves': 159, 'learning_rate': 0.24131399314985985, 'feature_fraction': 0.9245683787158269, 'bagging_fraction': 0.8977332843619172, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,856] Trial 31 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 188, 'learning_rate': 0.1344933770051476, 'feature_fraction': 0.9992678960575689, 'bagging_fraction': 0.830160339417687, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 10 with value: 1.0.
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.387104
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.184017
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.207414
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.219995
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.300014
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.280851
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.234275
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.273532
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.379893
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.303225
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.417142
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.290776
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.314668
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.270122
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.385733
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.197544
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.189878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.226344
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.279027
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.3139
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.349121
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.256611
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.308016
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.286218
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.29164
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.282806
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.250665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.154813
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.133325
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.125968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.0756378
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.181627
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.169426
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.223163
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.372012
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.400867
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.141706
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.179697
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.389982
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.138393
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.153798
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.183783
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.239612
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.162176
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.310249
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.178552
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.172912
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.288242
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.126325
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:08,935] Trial 32 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 233, 'learning_rate': 0.11807772045787088, 'feature_fraction': 0.9606963668538692, 'bagging_fraction': 0.7904746209128142, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,948] Trial 33 finished with value: 0.5 and parameters: {'num_leaves': 184, 'learning_rate': 0.08756372495562459, 'feature_fraction': 0.8898749884280275, 'bagging_fraction': 0.699271603327095, 'bagging_freq': 3, 'min_child_samples': 98}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:08,992] Trial 34 finished with value: 0.9875 and parameters: {'num_leaves': 208, 'learning_rate': 0.16234627690978679, 'feature_fraction': 0.650070980844103, 'bagging_fraction': 0.8477518928329059, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,032] Trial 35 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 236, 'learning_rate': 0.28327942696170694, 'feature_fraction': 0.9755189747640622, 'bagging_fraction': 0.9031489067425642, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,086] Trial 36 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 170, 'learning_rate': 0.25756272187098983, 'feature_fraction': 0.9387593257969165, 'bagging_fraction': 0.7361950643208779, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,146] Trial 37 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 143, 'learning_rate': 0.14355346869132374, 'feature_fraction': 0.6761661884203336, 'bagging_fraction': 0.953462944453101, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,189] Trial 38 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 30, 'learning_rate': 0.0679067921767238, 'feature_fraction': 0.7135916932487668, 'bagging_fraction': 0.8017265009015246, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,216] Trial 39 finished with value: 0.9541666666666667 and parameters: {'num_leaves': 123, 'learning_rate': 0.1271494381005301, 'feature_fraction': 0.9010770558714218, 'bagging_fraction': 0.8612640735840602, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,226] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 201, 'learning_rate': 0.2759813194643116, 'feature_fraction': 0.7728923937672525, 'bagging_fraction': 0.6215020815724783, 'bagging_freq': 1, 'min_child_samples': 59}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,270] Trial 41 finished with value: 1.0 and parameters: {'num_leaves': 188, 'learning_rate': 0.18363614029114378, 'feature_fraction': 0.9963222209401926, 'bagging_fraction': 0.8354647435694287, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,322] Trial 42 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 179, 'learning_rate': 0.19311957616378486, 'feature_fraction': 0.9950923777765195, 'bagging_fraction': 0.7562305205077042, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,352] Trial 43 finished with value: 0.9916666666666666 and parameters: {'num_leaves': 248, 'learning_rate': 0.17700251496603417, 'feature_fraction': 0.9469789909949539, 'bagging_fraction': 0.8289710785805126, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,400] Trial 44 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 215, 'learning_rate': 0.2333511282683724, 'feature_fraction': 0.8218943915218331, 'bagging_fraction': 0.7206577865763089, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,530] Trial 45 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 98, 'learning_rate': 0.1596868498629987, 'feature_fraction': 0.9718212869307512, 'bagging_fraction': 0.8821527058335409, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,562] Trial 46 finished with value: 0.9166666666666667 and parameters: {'num_leaves': 166, 'learning_rate': 0.25086885167030626, 'feature_fraction': 0.5743040246343818, 'bagging_fraction': 0.4536255930626608, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,574] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.17868868244726868, 'feature_fraction': 0.8479615743739781, 'bagging_fraction': 0.9182161326813945, 'bagging_freq': 6, 'min_child_samples': 78}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,655] Trial 48 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 140, 'learning_rate': 0.2202959493867524, 'feature_fraction': 0.9021667371217571, 'bagging_fraction': 0.8028954854970693, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,727] Trial 49 finished with value: 0.9875 and parameters: {'num_leaves': 67, 'learning_rate': 0.10930280048749674, 'feature_fraction': 0.8640764984754121, 'bagging_fraction': 0.9673950168581348, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 10 with value: 1.0.
[I 2025-09-17 13:17:09,977] A new study created in memory with name: no-name-62af38e6-c673-4fdd-b386-2527f3ed0304
[I 2025-09-17 13:17:09,999] Trial 0 finished with value: 0.9083333333333332 and parameters: {'num_leaves': 73, 'learning_rate': 0.11673814719880511, 'feature_fraction': 0.9413631462015812, 'bagging_fraction': 0.9730656266283341, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 0 with value: 0.9083333333333332.
[I 2025-09-17 13:17:10,008] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.09730246276225937, 'feature_fraction': 0.7377587786050281, 'bagging_fraction': 0.6739881804531467, 'bagging_freq': 2, 'min_child_samples': 56}. Best is trial 0 with value: 0.9083333333333332.
[I 2025-09-17 13:17:10,036] Trial 2 finished with value: 0.9291666666666667 and parameters: {'num_leaves': 113, 'learning_rate': 0.013945159623691857, 'feature_fraction': 0.5952858047979721, 'bagging_fraction': 0.7540384706904104, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 2 with value: 0.9291666666666667.
[I 2025-09-17 13:17:10,045] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 52, 'learning_rate': 0.061248842130705854, 'feature_fraction': 0.4609792849487653, 'bagging_fraction': 0.8301748060816085, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 2 with value: 0.9291666666666667.
[I 2025-09-17 13:17:10,059] Trial 4 finished with value: 0.7229166666666667 and parameters: {'num_leaves': 203, 'learning_rate': 0.03622182203201399, 'feature_fraction': 0.7637400876945992, 'bagging_fraction': 0.5751139895291888, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 2 with value: 0.9291666666666667.
[I 2025-09-17 13:17:10,069] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 288, 'learning_rate': 0.06230781642590409, 'feature_fraction': 0.7768056962764784, 'bagging_fraction': 0.4495332569495273, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 2 with value: 0.9291666666666667.
[I 2025-09-17 13:17:10,088] Trial 6 finished with value: 0.8958333333333334 and parameters: {'num_leaves': 125, 'learning_rate': 0.10257285910558431, 'feature_fraction': 0.5560128800603568, 'bagging_fraction': 0.6393975795856625, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 2 with value: 0.9291666666666667.
[I 2025-09-17 13:17:10,096] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 231, 'learning_rate': 0.1282910248317017, 'feature_fraction': 0.5367966232215179, 'bagging_fraction': 0.42598231317831353, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 2 with value: 0.9291666666666667.
[I 2025-09-17 13:17:10,106] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.16415539901079415, 'feature_fraction': 0.6981336382763246, 'bagging_fraction': 0.625433053220456, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 2 with value: 0.9291666666666667.
[I 2025-09-17 13:17:10,115] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 172, 'learning_rate': 0.25580179890873816, 'feature_fraction': 0.4173908251147965, 'bagging_fraction': 0.6979638812172546, 'bagging_freq': 4, 'min_child_samples': 87}. Best is trial 2 with value: 0.9291666666666667.
[I 2025-09-17 13:17:10,201] Trial 10 finished with value: 0.9583333333333333 and parameters: {'num_leaves': 16, 'learning_rate': 0.21252815731928507, 'feature_fraction': 0.6177603741379488, 'bagging_fraction': 0.8391937306782995, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 10 with value: 0.9583333333333333.
[I 2025-09-17 13:17:10,278] Trial 11 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 12, 'learning_rate': 0.20735553674203389, 'feature_fraction': 0.6459442021694827, 'bagging_fraction': 0.8265817242493061, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 10 with value: 0.9583333333333333.
[I 2025-09-17 13:17:10,360] Trial 12 finished with value: 0.9625 and parameters: {'num_leaves': 87, 'learning_rate': 0.29548272130219827, 'feature_fraction': 0.6004847811746254, 'bagging_fraction': 0.8197463284025788, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 12 with value: 0.9625.
[I 2025-09-17 13:17:10,437] Trial 13 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 17, 'learning_rate': 0.2922748245260459, 'feature_fraction': 0.865117379320443, 'bagging_fraction': 0.9572798883942741, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 12 with value: 0.9625.
[I 2025-09-17 13:17:10,474] Trial 14 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 72, 'learning_rate': 0.2234980712512407, 'feature_fraction': 0.49598873729350235, 'bagging_fraction': 0.8717982022046951, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 14 with value: 0.9666666666666667.
[I 2025-09-17 13:17:10,513] Trial 15 finished with value: 0.9499999999999998 and parameters: {'num_leaves': 81, 'learning_rate': 0.29811307129125386, 'feature_fraction': 0.49059511442290266, 'bagging_fraction': 0.9170432677949576, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 14 with value: 0.9666666666666667.
[I 2025-09-17 13:17:10,558] Trial 16 finished with value: 0.9166666666666667 and parameters: {'num_leaves': 91, 'learning_rate': 0.24409791881525678, 'feature_fraction': 0.41161850287521584, 'bagging_fraction': 0.7680724689730064, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 14 with value: 0.9666666666666667.
[I 2025-09-17 13:17:10,625] Trial 17 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 51, 'learning_rate': 0.1846031657707843, 'feature_fraction': 0.5212094145612386, 'bagging_fraction': 0.8975707337689371, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 14 with value: 0.9666666666666667.
[I 2025-09-17 13:17:10,638] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 158, 'learning_rate': 0.2588157041495093, 'feature_fraction': 0.6577070114147958, 'bagging_fraction': 0.7656128119337315, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 14 with value: 0.9666666666666667.
[I 2025-09-17 13:17:10,671] Trial 19 finished with value: 0.9125000000000001 and parameters: {'num_leaves': 53, 'learning_rate': 0.22995476853433017, 'feature_fraction': 0.5691058840778682, 'bagging_fraction': 0.887141209130041, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 14 with value: 0.9666666666666667.
[I 2025-09-17 13:17:10,719] Trial 20 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 101, 'learning_rate': 0.2728289066796124, 'feature_fraction': 0.8386138334745, 'bagging_fraction': 0.5192492543964866, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 14 with value: 0.9666666666666667.
[I 2025-09-17 13:17:10,810] Trial 21 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 40, 'learning_rate': 0.21275337906785027, 'feature_fraction': 0.6090395382434685, 'bagging_fraction': 0.8288685377628496, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:10,840] Trial 22 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 43, 'learning_rate': 0.18610872626977393, 'feature_fraction': 0.46034491410391254, 'bagging_fraction': 0.7993854363411036, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:10,902] Trial 23 finished with value: 0.9333333333333332 and parameters: {'num_leaves': 74, 'learning_rate': 0.22309323266439657, 'feature_fraction': 0.6781765226897765, 'bagging_fraction': 0.8908864591138099, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:10,981] Trial 24 finished with value: 0.95 and parameters: {'num_leaves': 36, 'learning_rate': 0.15893271730565353, 'feature_fraction': 0.6070348161020412, 'bagging_fraction': 0.9933627871439704, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,028] Trial 25 finished with value: 0.925 and parameters: {'num_leaves': 128, 'learning_rate': 0.27798283820670966, 'feature_fraction': 0.4880278773507159, 'bagging_fraction': 0.723482610953786, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,070] Trial 26 finished with value: 0.9583333333333334 and parameters: {'num_leaves': 68, 'learning_rate': 0.18529512838139672, 'feature_fraction': 0.580820004472633, 'bagging_fraction': 0.8616658499451836, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,096] Trial 27 finished with value: 0.8791666666666667 and parameters: {'num_leaves': 99, 'learning_rate': 0.23909306255354698, 'feature_fraction': 0.5186448424132084, 'bagging_fraction': 0.9297380061226316, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,120] Trial 28 finished with value: 0.8708333333333333 and parameters: {'num_leaves': 28, 'learning_rate': 0.21202767831559588, 'feature_fraction': 0.6413360201051798, 'bagging_fraction': 0.7928086813664523, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,133] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 68, 'learning_rate': 0.1320472060845922, 'feature_fraction': 0.9384003335674685, 'bagging_fraction': 0.962464234080504, 'bagging_freq': 3, 'min_child_samples': 65}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,179] Trial 30 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 148, 'learning_rate': 0.2716096071609906, 'feature_fraction': 0.7254128462410891, 'bagging_fraction': 0.7245035277494861, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,225] Trial 31 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 71, 'learning_rate': 0.18759634506643966, 'feature_fraction': 0.5759811686293501, 'bagging_fraction': 0.8569995355337565, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,333] Trial 32 finished with value: 0.9208333333333334 and parameters: {'num_leaves': 66, 'learning_rate': 0.19668598890787126, 'feature_fraction': 0.6271259332862512, 'bagging_fraction': 0.8658741753981938, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,368] Trial 33 finished with value: 0.9125000000000001 and parameters: {'num_leaves': 108, 'learning_rate': 0.17071062735514897, 'feature_fraction': 0.5820787824225568, 'bagging_fraction': 0.8041137250951115, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,425] Trial 34 finished with value: 0.925 and parameters: {'num_leaves': 87, 'learning_rate': 0.14234853415031234, 'feature_fraction': 0.45030798637431435, 'bagging_fraction': 0.9439883902575821, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,484] Trial 35 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 31, 'learning_rate': 0.2273757964073515, 'feature_fraction': 0.49460329290201555, 'bagging_fraction': 0.8668018798451866, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,510] Trial 36 finished with value: 0.8999999999999999 and parameters: {'num_leaves': 58, 'learning_rate': 0.1473490204092398, 'feature_fraction': 0.5379283230993597, 'bagging_fraction': 0.7354731095382545, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,548] Trial 37 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 117, 'learning_rate': 0.1754953772533834, 'feature_fraction': 0.5933706568348971, 'bagging_fraction': 0.8243315230119838, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,564] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 148, 'learning_rate': 0.24869840990196906, 'feature_fraction': 0.6774684601960739, 'bagging_fraction': 0.6694367660446181, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,600] Trial 39 finished with value: 0.8916666666666667 and parameters: {'num_leaves': 295, 'learning_rate': 0.10767017985854646, 'feature_fraction': 0.7214478435585662, 'bagging_fraction': 0.9157359003821731, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,620] Trial 40 finished with value: 0.9083333333333333 and parameters: {'num_leaves': 252, 'learning_rate': 0.20330659925249758, 'feature_fraction': 0.7662666033567882, 'bagging_fraction': 0.9912392467002102, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 21 with value: 0.9750000000000001.
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.131567
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.135833
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.11473
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.182287
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.145797
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.186674
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.278847
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.102163
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.194389
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.133429
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.180988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.209348
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.318489
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.184762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.151736
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.391118
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.406942
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.640621
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.397952
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.291391
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.295293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.245823
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.281209
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.278797
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.265674
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.295014
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.279474
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.319845
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.274371
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.196347
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.300449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.283696
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.231796
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.310632
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.248363
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.329633
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.406539
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.274355
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.273087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.279856
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.328815
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.287246
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.234774
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.380824
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.304344
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.327626
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.404073
[I 2025-09-17 13:17:11,704] Trial 41 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 26, 'learning_rate': 0.21541214673792639, 'feature_fraction': 0.6206990456017918, 'bagging_fraction': 0.8537383551008803, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,814] Trial 42 finished with value: 0.9166666666666667 and parameters: {'num_leaves': 42, 'learning_rate': 0.07200659789954802, 'feature_fraction': 0.5517695508447578, 'bagging_fraction': 0.8436718343678317, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,873] Trial 43 finished with value: 0.9416666666666668 and parameters: {'num_leaves': 27, 'learning_rate': 0.2198102148194343, 'feature_fraction': 0.6091516166913243, 'bagging_fraction': 0.7871740290610175, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:11,975] Trial 44 finished with value: 0.9291666666666667 and parameters: {'num_leaves': 61, 'learning_rate': 0.19766953399858572, 'feature_fraction': 0.6703083695360929, 'bagging_fraction': 0.8213512115647998, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:12,022] Trial 45 finished with value: 0.9125 and parameters: {'num_leaves': 85, 'learning_rate': 0.2609685452766769, 'feature_fraction': 0.6962246828683536, 'bagging_fraction': 0.8915608695374958, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:12,061] Trial 46 finished with value: 0.9208333333333334 and parameters: {'num_leaves': 19, 'learning_rate': 0.28545080660078426, 'feature_fraction': 0.5557044314897474, 'bagging_fraction': 0.8690748696294199, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:12,118] Trial 47 finished with value: 0.8875 and parameters: {'num_leaves': 45, 'learning_rate': 0.2369000091475866, 'feature_fraction': 0.6302083611118205, 'bagging_fraction': 0.7494518147472685, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:12,242] Trial 48 finished with value: 0.95 and parameters: {'num_leaves': 179, 'learning_rate': 0.17547885722029924, 'feature_fraction': 0.4394312963647643, 'bagging_fraction': 0.7758559323516093, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:12,281] Trial 49 finished with value: 0.9708333333333334 and parameters: {'num_leaves': 11, 'learning_rate': 0.20735286258538976, 'feature_fraction': 0.5081330753044704, 'bagging_fraction': 0.6919043553952233, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 21 with value: 0.9750000000000001.
[I 2025-09-17 13:17:12,559] A new study created in memory with name: no-name-a431b020-3995-4b8a-a1a6-a9afd7ef010f
[I 2025-09-17 13:17:12,567] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 231, 'learning_rate': 0.2568590547546916, 'feature_fraction': 0.8789450346046092, 'bagging_fraction': 0.5719207302180833, 'bagging_freq': 7, 'min_child_samples': 67}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:12,605] Trial 1 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 212, 'learning_rate': 0.1795644780864829, 'feature_fraction': 0.6630605300735412, 'bagging_fraction': 0.9765164345979102, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,628] Trial 2 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 37, 'learning_rate': 0.1068485566053702, 'feature_fraction': 0.7370227727405436, 'bagging_fraction': 0.5745661151014303, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,652] Trial 3 finished with value: 0.9291666666666666 and parameters: {'num_leaves': 80, 'learning_rate': 0.044294987597650486, 'feature_fraction': 0.5901392823289386, 'bagging_fraction': 0.667086890143672, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,672] Trial 4 finished with value: 0.9666666666666666 and parameters: {'num_leaves': 12, 'learning_rate': 0.2835898964728885, 'feature_fraction': 0.5626273924838389, 'bagging_fraction': 0.9581845274801444, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,678] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 63, 'learning_rate': 0.28795932478816416, 'feature_fraction': 0.8439467269476101, 'bagging_fraction': 0.688122968223733, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,700] Trial 6 finished with value: 0.8916666666666667 and parameters: {'num_leaves': 12, 'learning_rate': 0.04605661057520816, 'feature_fraction': 0.6123689008844384, 'bagging_fraction': 0.8494134738059249, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,713] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 150, 'learning_rate': 0.2825935347031922, 'feature_fraction': 0.4229431326663675, 'bagging_fraction': 0.8191409221138064, 'bagging_freq': 3, 'min_child_samples': 89}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,746] Trial 8 finished with value: 0.9208333333333334 and parameters: {'num_leaves': 56, 'learning_rate': 0.04258093525667701, 'feature_fraction': 0.7697026687626982, 'bagging_fraction': 0.45065566367682286, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,754] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 283, 'learning_rate': 0.2529282200298403, 'feature_fraction': 0.5887084676614022, 'bagging_fraction': 0.4793817130685236, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,858] Trial 10 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 192, 'learning_rate': 0.19102934406195302, 'feature_fraction': 0.9789075385238233, 'bagging_fraction': 0.9911100707157852, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:17:12,981] Trial 11 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 186, 'learning_rate': 0.18021413547508433, 'feature_fraction': 0.9701307360168128, 'bagging_fraction': 0.974129875515615, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,058] Trial 12 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 142, 'learning_rate': 0.17641784746236405, 'feature_fraction': 0.9997515465554364, 'bagging_fraction': 0.8624419112969924, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,082] Trial 13 finished with value: 0.8791666666666667 and parameters: {'num_leaves': 128, 'learning_rate': 0.13242881503057793, 'feature_fraction': 0.9995769986182232, 'bagging_fraction': 0.849027028403324, 'bagging_freq': 6, 'min_child_samples': 48}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,182] Trial 14 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 114, 'learning_rate': 0.20391543268753815, 'feature_fraction': 0.8990963853376324, 'bagging_fraction': 0.8960909016412317, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,196] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 192, 'learning_rate': 0.12306006856309679, 'feature_fraction': 0.9313255589277121, 'bagging_fraction': 0.7574564660037141, 'bagging_freq': 6, 'min_child_samples': 62}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,241] Trial 16 finished with value: 0.9625 and parameters: {'num_leaves': 260, 'learning_rate': 0.2306578152012764, 'feature_fraction': 0.8530359309229198, 'bagging_fraction': 0.90623023787643, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,267] Trial 17 finished with value: 0.9041666666666666 and parameters: {'num_leaves': 170, 'learning_rate': 0.1600732623078176, 'feature_fraction': 0.8036328250004869, 'bagging_fraction': 0.7634060931169577, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,331] Trial 18 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 102, 'learning_rate': 0.10185205649523296, 'feature_fraction': 0.9434876661309646, 'bagging_fraction': 0.9183191615392307, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,344] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 147, 'learning_rate': 0.21851371788320956, 'feature_fraction': 0.49082315104615026, 'bagging_fraction': 0.8004135033689042, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,369] Trial 20 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 243, 'learning_rate': 0.1623495312617742, 'feature_fraction': 0.9458985063084127, 'bagging_fraction': 0.9180070905250419, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,435] Trial 21 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 97, 'learning_rate': 0.08521326152546406, 'feature_fraction': 0.939451563859168, 'bagging_fraction': 0.9343118978787696, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,639] Trial 22 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 121, 'learning_rate': 0.08836928121701669, 'feature_fraction': 0.9975002885504439, 'bagging_fraction': 0.8823799735131967, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,667] Trial 23 finished with value: 0.9041666666666666 and parameters: {'num_leaves': 174, 'learning_rate': 0.13521331526879932, 'feature_fraction': 0.9043644426491352, 'bagging_fraction': 0.9762074727957855, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,722] Trial 24 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 137, 'learning_rate': 0.08202633646850818, 'feature_fraction': 0.8215772100945833, 'bagging_fraction': 0.7648290836736646, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,747] Trial 25 finished with value: 0.9458333333333332 and parameters: {'num_leaves': 146, 'learning_rate': 0.07438683360988452, 'feature_fraction': 0.8054447584789179, 'bagging_fraction': 0.7196933467245762, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,802] Trial 26 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 207, 'learning_rate': 0.014577834473966905, 'feature_fraction': 0.7128979502754628, 'bagging_fraction': 0.6296005006159477, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,823] Trial 27 finished with value: 0.9208333333333334 and parameters: {'num_leaves': 172, 'learning_rate': 0.17656047065234673, 'feature_fraction': 0.8272422741117776, 'bagging_fraction': 0.7850214184438283, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,862] Trial 28 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 133, 'learning_rate': 0.15295126908186846, 'feature_fraction': 0.7659158686946584, 'bagging_fraction': 0.8426736737148184, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,941] Trial 29 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 231, 'learning_rate': 0.23571019080067923, 'feature_fraction': 0.8961544332950349, 'bagging_fraction': 0.7308196055705425, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:13,953] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 92, 'learning_rate': 0.20160284830946204, 'feature_fraction': 0.8617777003553698, 'bagging_fraction': 0.6331492711439184, 'bagging_freq': 5, 'min_child_samples': 76}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:14,029] Trial 31 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 105, 'learning_rate': 0.06748572459517119, 'feature_fraction': 0.9536709972965682, 'bagging_fraction': 0.9382806526230044, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 11 with value: 0.9958333333333333.
[I 2025-09-17 13:17:14,084] Trial 32 finished with value: 1.0 and parameters: {'num_leaves': 161, 'learning_rate': 0.11858363415496248, 'feature_fraction': 0.9601339572503269, 'bagging_fraction': 0.8718751767396788, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,118] Trial 33 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 190, 'learning_rate': 0.12258403267283516, 'feature_fraction': 0.9716678462125062, 'bagging_fraction': 0.8734596877596601, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,159] Trial 34 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 160, 'learning_rate': 0.1428754680937233, 'feature_fraction': 0.670943482818507, 'bagging_fraction': 0.8221119296784042, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,195] Trial 35 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 211, 'learning_rate': 0.10775974888377524, 'feature_fraction': 0.9127644879582539, 'bagging_fraction': 0.9971784197595113, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,223] Trial 36 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 132, 'learning_rate': 0.17589522663601553, 'feature_fraction': 0.8904771263041327, 'bagging_fraction': 0.9568789612582337, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,290] Trial 37 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 81, 'learning_rate': 0.11016726270828342, 'feature_fraction': 0.9734318910059859, 'bagging_fraction': 0.8703101555476997, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,374] Trial 38 finished with value: 0.9708333333333332 and parameters: {'num_leaves': 75, 'learning_rate': 0.1107754577636335, 'feature_fraction': 0.9730892131655755, 'bagging_fraction': 0.8689615789946373, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,399] Trial 39 finished with value: 0.95 and parameters: {'num_leaves': 26, 'learning_rate': 0.16783504021218965, 'feature_fraction': 0.8739734847772652, 'bagging_fraction': 0.5287450982923059, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,422] Trial 40 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 55, 'learning_rate': 0.1465350085854853, 'feature_fraction': 0.920502345852308, 'bagging_fraction': 0.960118907887191, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,492] Trial 41 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 160, 'learning_rate': 0.06730843291350576, 'feature_fraction': 0.9634816322765948, 'bagging_fraction': 0.8017681412118174, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,532] Trial 42 finished with value: 0.9708333333333332 and parameters: {'num_leaves': 79, 'learning_rate': 0.09155422718918868, 'feature_fraction': 0.9980855943086965, 'bagging_fraction': 0.8338632969264772, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,583] Trial 43 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 184, 'learning_rate': 0.11955479413514275, 'feature_fraction': 0.82422105101979, 'bagging_fraction': 0.7623293449190538, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,607] Trial 44 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 141, 'learning_rate': 0.19428817272154203, 'feature_fraction': 0.7781190040605164, 'bagging_fraction': 0.8643956509692451, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,689] Trial 45 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 222, 'learning_rate': 0.0486033006445734, 'feature_fraction': 0.9292325440168924, 'bagging_fraction': 0.7064421607656877, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,769] Trial 46 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 222, 'learning_rate': 0.011508366892472303, 'feature_fraction': 0.9770462547488081, 'bagging_fraction': 0.6816930324656576, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,882] Trial 47 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 241, 'learning_rate': 0.03604440300438777, 'feature_fraction': 0.9246226578445689, 'bagging_fraction': 0.5580992761451349, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,895] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 203, 'learning_rate': 0.058108577870059165, 'feature_fraction': 0.8741737713436083, 'bagging_fraction': 0.8966481594091129, 'bagging_freq': 6, 'min_child_samples': 99}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:14,910] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 181, 'learning_rate': 0.18760058345101552, 'feature_fraction': 0.5149670805932132, 'bagging_fraction': 0.621347056443901, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 32 with value: 1.0.
[I 2025-09-17 13:17:15,187] A new study created in memory with name: no-name-031dd8b6-aa87-4f4b-9385-413616bdaa65
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.184868
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.266801
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.26015
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.300956
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.323382
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.282148
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.306385
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.248234
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.300256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.225103
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.354446
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.33715
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.23114
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.391527
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.302129
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.180307
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.11934
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.215555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.402013
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.226837
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.233644
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.334281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.183852
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.235528
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.187431
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.215067
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.347216
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.180308
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.260978
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.290977
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.322882
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.208458
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.165794
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.182161
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.177492
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.220764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.230268
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.20536
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.212234
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.192132
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.231897
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.256953
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.224813
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.189802
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.227465
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.197429
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.228673
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.155168
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.2976
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.245153
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.661598
[I 2025-09-17 13:17:15,200] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.028032278687346507, 'feature_fraction': 0.7918208615761048, 'bagging_fraction': 0.5852377572091454, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:15,212] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 249, 'learning_rate': 0.15719395674551437, 'feature_fraction': 0.5069296436656425, 'bagging_fraction': 0.6347362479028783, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:15,232] Trial 2 finished with value: 0.8875000000000001 and parameters: {'num_leaves': 54, 'learning_rate': 0.033860600934516615, 'feature_fraction': 0.8704105212530884, 'bagging_fraction': 0.49391644223008224, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 2 with value: 0.8875000000000001.
[I 2025-09-17 13:17:15,285] Trial 3 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 295, 'learning_rate': 0.1265255114017591, 'feature_fraction': 0.9752184239053021, 'bagging_fraction': 0.850077735028548, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 3 with value: 0.9708333333333333.
[I 2025-09-17 13:17:15,293] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 277, 'learning_rate': 0.18465743536459414, 'feature_fraction': 0.4156793884623454, 'bagging_fraction': 0.7838813707526195, 'bagging_freq': 5, 'min_child_samples': 91}. Best is trial 3 with value: 0.9708333333333333.
[I 2025-09-17 13:17:15,302] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 22, 'learning_rate': 0.22615329193276057, 'feature_fraction': 0.8868929123420517, 'bagging_fraction': 0.4778797587896927, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 3 with value: 0.9708333333333333.
[I 2025-09-17 13:17:15,319] Trial 6 finished with value: 0.9500000000000001 and parameters: {'num_leaves': 240, 'learning_rate': 0.22047769280613824, 'feature_fraction': 0.7243955973299847, 'bagging_fraction': 0.9460428401164122, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 3 with value: 0.9708333333333333.
[I 2025-09-17 13:17:15,327] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 74, 'learning_rate': 0.24388723866250664, 'feature_fraction': 0.8743219084486333, 'bagging_fraction': 0.487055226344946, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 3 with value: 0.9708333333333333.
[I 2025-09-17 13:17:15,387] Trial 8 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 85, 'learning_rate': 0.22669009304065127, 'feature_fraction': 0.6699396334382535, 'bagging_fraction': 0.8701993581040119, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,429] Trial 9 finished with value: 0.9291666666666666 and parameters: {'num_leaves': 232, 'learning_rate': 0.18424388667600972, 'feature_fraction': 0.6135539692759049, 'bagging_fraction': 0.6870563819272592, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,437] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 117, 'learning_rate': 0.2848102056154712, 'feature_fraction': 0.6050625936978854, 'bagging_fraction': 0.989660577125796, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,581] Trial 11 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 136, 'learning_rate': 0.08795921714260556, 'feature_fraction': 0.6661265397103757, 'bagging_fraction': 0.8230038425203361, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,723] Trial 12 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 146, 'learning_rate': 0.0971314458991201, 'feature_fraction': 0.6593619895743451, 'bagging_fraction': 0.8330615994741922, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,759] Trial 13 finished with value: 0.9374999999999999 and parameters: {'num_leaves': 124, 'learning_rate': 0.08157304677040073, 'feature_fraction': 0.5352778498038604, 'bagging_fraction': 0.8969038881174289, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,824] Trial 14 finished with value: 0.9625 and parameters: {'num_leaves': 177, 'learning_rate': 0.2940260521624388, 'feature_fraction': 0.718076076497761, 'bagging_fraction': 0.7525392850544929, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,838] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 90, 'learning_rate': 0.0809989905989031, 'feature_fraction': 0.7644220074434623, 'bagging_fraction': 0.8975277388079733, 'bagging_freq': 4, 'min_child_samples': 67}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,871] Trial 16 finished with value: 0.9249999999999999 and parameters: {'num_leaves': 18, 'learning_rate': 0.12853016148194327, 'feature_fraction': 0.555923592665015, 'bagging_fraction': 0.7499685770193686, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,883] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 102, 'learning_rate': 0.1792295982761346, 'feature_fraction': 0.664519053133391, 'bagging_fraction': 0.824277614877219, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,928] Trial 18 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 153, 'learning_rate': 0.2563946090859728, 'feature_fraction': 0.48218948577047216, 'bagging_fraction': 0.6968085354733596, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,958] Trial 19 finished with value: 0.925 and parameters: {'num_leaves': 54, 'learning_rate': 0.06757299214979204, 'feature_fraction': 0.7815921896369407, 'bagging_fraction': 0.9045571711898827, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:15,980] Trial 20 finished with value: 0.9125 and parameters: {'num_leaves': 185, 'learning_rate': 0.12123965559635373, 'feature_fraction': 0.601929051496701, 'bagging_fraction': 0.9888948457541706, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,111] Trial 21 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 145, 'learning_rate': 0.10477354617457933, 'feature_fraction': 0.6752155840532245, 'bagging_fraction': 0.8070900864102536, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,276] Trial 22 finished with value: 0.9583333333333334 and parameters: {'num_leaves': 133, 'learning_rate': 0.10597375120387946, 'feature_fraction': 0.6574546362561318, 'bagging_fraction': 0.7887020399262683, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,313] Trial 23 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 166, 'learning_rate': 0.05176813707812325, 'feature_fraction': 0.6863090111092095, 'bagging_fraction': 0.8620027376276141, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,367] Trial 24 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 210, 'learning_rate': 0.15528496175415707, 'feature_fraction': 0.7410639350871551, 'bagging_fraction': 0.7442129934219972, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,421] Trial 25 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 84, 'learning_rate': 0.015065738766659231, 'feature_fraction': 0.578070558593435, 'bagging_fraction': 0.931626661757252, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,442] Trial 26 finished with value: 0.9208333333333334 and parameters: {'num_leaves': 114, 'learning_rate': 0.14517327995106583, 'feature_fraction': 0.8277766905997948, 'bagging_fraction': 0.6499320008530703, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,558] Trial 27 finished with value: 0.975 and parameters: {'num_leaves': 56, 'learning_rate': 0.20548581265832813, 'feature_fraction': 0.6271181140269444, 'bagging_fraction': 0.8040158449314244, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,586] Trial 28 finished with value: 0.9 and parameters: {'num_leaves': 148, 'learning_rate': 0.05725962012811651, 'feature_fraction': 0.6903201591110043, 'bagging_fraction': 0.8705740877002376, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,643] Trial 29 finished with value: 0.9625 and parameters: {'num_leaves': 194, 'learning_rate': 0.10208086867961746, 'feature_fraction': 0.8121764997051407, 'bagging_fraction': 0.5654353324378643, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,655] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 136, 'learning_rate': 0.263739233025305, 'feature_fraction': 0.4476047315740356, 'bagging_fraction': 0.41274207452021444, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,821] Trial 31 finished with value: 0.9791666666666667 and parameters: {'num_leaves': 163, 'learning_rate': 0.09651924203080335, 'feature_fraction': 0.6501290577824227, 'bagging_fraction': 0.8209726289941823, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,865] Trial 32 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 211, 'learning_rate': 0.09090133064327785, 'feature_fraction': 0.6408241927829448, 'bagging_fraction': 0.7720800433629604, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,948] Trial 33 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 170, 'learning_rate': 0.11444509165511349, 'feature_fraction': 0.6915152061402017, 'bagging_fraction': 0.82091992930315, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:16,974] Trial 34 finished with value: 0.9125 and parameters: {'num_leaves': 161, 'learning_rate': 0.041914876434526585, 'feature_fraction': 0.7464873336478394, 'bagging_fraction': 0.7196505385523039, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,064] Trial 35 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 104, 'learning_rate': 0.14328271825828726, 'feature_fraction': 0.5176212853010238, 'bagging_fraction': 0.9410720847499356, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,137] Trial 36 finished with value: 0.9708333333333332 and parameters: {'num_leaves': 103, 'learning_rate': 0.15104297804985323, 'feature_fraction': 0.4991230708496228, 'bagging_fraction': 0.951174515586247, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,154] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 67, 'learning_rate': 0.13653381493237823, 'feature_fraction': 0.40649852114039553, 'bagging_fraction': 0.928261159015599, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,197] Trial 38 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 50, 'learning_rate': 0.16723855894132195, 'feature_fraction': 0.9215586660646513, 'bagging_fraction': 0.8674348056368731, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,260] Trial 39 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 98, 'learning_rate': 0.20356620062269717, 'feature_fraction': 0.5382962311903022, 'bagging_fraction': 0.9690082107690924, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,350] Trial 40 finished with value: 0.9583333333333334 and parameters: {'num_leaves': 36, 'learning_rate': 0.07286885254636756, 'feature_fraction': 0.45933506271634017, 'bagging_fraction': 0.9080792171114441, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,451] Trial 41 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 133, 'learning_rate': 0.11527390677637411, 'feature_fraction': 0.5936269952074923, 'bagging_fraction': 0.8480635954887685, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,637] Trial 42 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 112, 'learning_rate': 0.1373575978067306, 'feature_fraction': 0.5695490994703715, 'bagging_fraction': 0.8052153255317682, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,707] Trial 43 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 77, 'learning_rate': 0.09015853383604897, 'feature_fraction': 0.7130314287373045, 'bagging_fraction': 0.8773541901018231, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,739] Trial 44 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 78, 'learning_rate': 0.17309697814960334, 'feature_fraction': 0.7163242930079229, 'bagging_fraction': 0.8793052180809459, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,785] Trial 45 finished with value: 0.9583333333333334 and parameters: {'num_leaves': 67, 'learning_rate': 0.19655308075144984, 'feature_fraction': 0.8382869112031446, 'bagging_fraction': 0.9658972736549828, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,837] Trial 46 finished with value: 0.9624999999999999 and parameters: {'num_leaves': 116, 'learning_rate': 0.23483377659816937, 'feature_fraction': 0.7716509092059537, 'bagging_fraction': 0.923833965281254, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,871] Trial 47 finished with value: 0.9208333333333334 and parameters: {'num_leaves': 88, 'learning_rate': 0.08846141877887186, 'feature_fraction': 0.6740948316914002, 'bagging_fraction': 0.8436120552709083, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,885] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 32, 'learning_rate': 0.0681518050313002, 'feature_fraction': 0.7101129648200045, 'bagging_fraction': 0.8825975717186857, 'bagging_freq': 6, 'min_child_samples': 98}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:17,980] Trial 49 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 285, 'learning_rate': 0.027684928384026725, 'feature_fraction': 0.7461520921987663, 'bagging_fraction': 0.7806422491686016, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 8 with value: 0.9833333333333334.
[I 2025-09-17 13:17:18,156] A new study created in memory with name: no-name-460c4734-822e-434b-ba9f-1edc4cb956b0
[I 2025-09-17 13:17:18,169] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 118, 'learning_rate': 0.1816318799692721, 'feature_fraction': 0.5060069847524543, 'bagging_fraction': 0.5679239734936397, 'bagging_freq': 7, 'min_child_samples': 53}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:18,177] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.0794500872763771, 'feature_fraction': 0.7313545473355174, 'bagging_fraction': 0.45566765145799243, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:18,185] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 242, 'learning_rate': 0.20628095098675675, 'feature_fraction': 0.9611177468911488, 'bagging_fraction': 0.7810991443094969, 'bagging_freq': 3, 'min_child_samples': 96}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:18,191] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 234, 'learning_rate': 0.17197172136080482, 'feature_fraction': 0.8326770050452371, 'bagging_fraction': 0.5574483614862007, 'bagging_freq': 1, 'min_child_samples': 45}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:18,199] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 44, 'learning_rate': 0.24876372426990595, 'feature_fraction': 0.7903202551088396, 'bagging_fraction': 0.4692706385488847, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:18,207] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 71, 'learning_rate': 0.027411122929170945, 'feature_fraction': 0.42988060239146386, 'bagging_fraction': 0.5376941567234045, 'bagging_freq': 7, 'min_child_samples': 72}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:18,338] Trial 6 finished with value: 0.7969924812030076 and parameters: {'num_leaves': 17, 'learning_rate': 0.08225848367130727, 'feature_fraction': 0.5867131935823178, 'bagging_fraction': 0.8223150599906477, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 6 with value: 0.7969924812030076.
[I 2025-09-17 13:17:18,346] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 272, 'learning_rate': 0.16270791421877667, 'feature_fraction': 0.46648654547944146, 'bagging_fraction': 0.5244306279000808, 'bagging_freq': 5, 'min_child_samples': 73}. Best is trial 6 with value: 0.7969924812030076.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.406108
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.192982
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.277132
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.136652
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.253105
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.167575
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.183616
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.265843
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.193806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.28093
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.259799
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.284246
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.370125
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.185583
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.231073
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.243086
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.205082
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.298124
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.275739
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.18905
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.363623
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.22881
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.197175
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.217011
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.199844
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.298967
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.168228
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.192297
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.165184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.175238
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.20392
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.183868
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.202242
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.177443
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.218845
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.236713
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.198011
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.308921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.225746
Training model for P133... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.490928
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
[I 2025-09-17 13:17:18,373] Trial 8 finished with value: 0.6203007518796994 and parameters: {'num_leaves': 214, 'learning_rate': 0.17694960521226946, 'feature_fraction': 0.4499162615013038, 'bagging_fraction': 0.4785817334891624, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 6 with value: 0.7969924812030076.
[I 2025-09-17 13:17:18,381] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.23844845577830331, 'feature_fraction': 0.5974612614915894, 'bagging_fraction': 0.5879223570251906, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 6 with value: 0.7969924812030076.
[I 2025-09-17 13:17:18,477] Trial 10 finished with value: 0.8045112781954887 and parameters: {'num_leaves': 159, 'learning_rate': 0.09456447048162979, 'feature_fraction': 0.616017164890815, 'bagging_fraction': 0.9978604174710061, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 10 with value: 0.8045112781954887.
[I 2025-09-17 13:17:18,633] Trial 11 finished with value: 0.8195488721804511 and parameters: {'num_leaves': 160, 'learning_rate': 0.09681521200626002, 'feature_fraction': 0.6105751388286527, 'bagging_fraction': 0.9581741615630411, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:18,666] Trial 12 finished with value: 0.6654135338345866 and parameters: {'num_leaves': 167, 'learning_rate': 0.10531232302899693, 'feature_fraction': 0.6220561949417543, 'bagging_fraction': 0.9734643268698826, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:18,772] Trial 13 finished with value: 0.81203007518797 and parameters: {'num_leaves': 147, 'learning_rate': 0.10973946889896997, 'feature_fraction': 0.6812005498807739, 'bagging_fraction': 0.9688196491973341, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:18,810] Trial 14 finished with value: 0.6278195488721805 and parameters: {'num_leaves': 110, 'learning_rate': 0.04544910322784455, 'feature_fraction': 0.7146903428216255, 'bagging_fraction': 0.8824224669357997, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:18,861] Trial 15 finished with value: 0.7406015037593985 and parameters: {'num_leaves': 194, 'learning_rate': 0.12502283704878173, 'feature_fraction': 0.8764023545607077, 'bagging_fraction': 0.9129803118903435, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:18,886] Trial 16 finished with value: 0.7293233082706767 and parameters: {'num_leaves': 118, 'learning_rate': 0.12867476454093874, 'feature_fraction': 0.535742744325075, 'bagging_fraction': 0.6911926640360333, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:18,938] Trial 17 finished with value: 0.736842105263158 and parameters: {'num_leaves': 180, 'learning_rate': 0.057308374930549306, 'feature_fraction': 0.66836275615141, 'bagging_fraction': 0.7107508878515565, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:18,952] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 82, 'learning_rate': 0.29880323497234773, 'feature_fraction': 0.7604448898597116, 'bagging_fraction': 0.9022039727458417, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:18,985] Trial 19 finished with value: 0.6992481203007519 and parameters: {'num_leaves': 147, 'learning_rate': 0.13798853200665223, 'feature_fraction': 0.6781250383743537, 'bagging_fraction': 0.8231608183168025, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:19,106] Trial 20 finished with value: 0.8007518796992481 and parameters: {'num_leaves': 134, 'learning_rate': 0.06596213301009157, 'feature_fraction': 0.5564146786705277, 'bagging_fraction': 0.9412197883986486, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:19,207] Trial 21 finished with value: 0.7669172932330828 and parameters: {'num_leaves': 164, 'learning_rate': 0.01083271835268064, 'feature_fraction': 0.6352257299283601, 'bagging_fraction': 0.9950865505765275, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:17:19,346] Trial 22 finished with value: 0.8458646616541353 and parameters: {'num_leaves': 203, 'learning_rate': 0.10526937782339978, 'feature_fraction': 0.6519967767943564, 'bagging_fraction': 0.991687749865202, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,401] Trial 23 finished with value: 0.736842105263158 and parameters: {'num_leaves': 211, 'learning_rate': 0.12432588193689918, 'feature_fraction': 0.6794558257401683, 'bagging_fraction': 0.8559322078093361, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,442] Trial 24 finished with value: 0.7706766917293234 and parameters: {'num_leaves': 186, 'learning_rate': 0.10598540549067734, 'feature_fraction': 0.7774007148222805, 'bagging_fraction': 0.9458027461393831, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,463] Trial 25 finished with value: 0.5902255639097744 and parameters: {'num_leaves': 93, 'learning_rate': 0.04429477778664026, 'feature_fraction': 0.5170142865286299, 'bagging_fraction': 0.722368346922535, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,514] Trial 26 finished with value: 0.7857142857142858 and parameters: {'num_leaves': 141, 'learning_rate': 0.14712949480513332, 'feature_fraction': 0.6593685289893338, 'bagging_fraction': 0.9436624980907877, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,621] Trial 27 finished with value: 0.7744360902255639 and parameters: {'num_leaves': 222, 'learning_rate': 0.1046374908784043, 'feature_fraction': 0.7255155728748024, 'bagging_fraction': 0.6320420903395048, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,636] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.07945720459872221, 'feature_fraction': 0.5643816060898693, 'bagging_fraction': 0.7676531475521002, 'bagging_freq': 1, 'min_child_samples': 87}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,672] Trial 29 finished with value: 0.7218045112781956 and parameters: {'num_leaves': 125, 'learning_rate': 0.21741880538093586, 'feature_fraction': 0.4936096868350287, 'bagging_fraction': 0.8651797662833688, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,692] Trial 30 finished with value: 0.6165413533834587 and parameters: {'num_leaves': 100, 'learning_rate': 0.19408894624703, 'feature_fraction': 0.8367745460422672, 'bagging_fraction': 0.924394364415168, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,752] Trial 31 finished with value: 0.7255639097744362 and parameters: {'num_leaves': 163, 'learning_rate': 0.09513550148374196, 'feature_fraction': 0.6274061005747525, 'bagging_fraction': 0.9799738072143206, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,865] Trial 32 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 172, 'learning_rate': 0.09043362456792393, 'feature_fraction': 0.5896033357549023, 'bagging_fraction': 0.9981145957343669, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,921] Trial 33 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 252, 'learning_rate': 0.11700516397003462, 'feature_fraction': 0.7085228352550045, 'bagging_fraction': 0.9605414041110747, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:19,990] Trial 34 finished with value: 0.755639097744361 and parameters: {'num_leaves': 139, 'learning_rate': 0.15176104380126337, 'feature_fraction': 0.6372614067789094, 'bagging_fraction': 0.8978926480104584, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:20,023] Trial 35 finished with value: 0.6466165413533835 and parameters: {'num_leaves': 197, 'learning_rate': 0.06840263965673642, 'feature_fraction': 0.9971761692576524, 'bagging_fraction': 0.8260280958092845, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:20,063] Trial 36 finished with value: 0.793233082706767 and parameters: {'num_leaves': 154, 'learning_rate': 0.1389255389032817, 'feature_fraction': 0.7382833212289737, 'bagging_fraction': 0.9736392491801923, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 22 with value: 0.8458646616541353.
[I 2025-09-17 13:17:20,197] Trial 37 finished with value: 0.849624060150376 and parameters: {'num_leaves': 234, 'learning_rate': 0.11048326453783555, 'feature_fraction': 0.6101071774025013, 'bagging_fraction': 0.7703467329012279, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,222] Trial 38 finished with value: 0.7255639097744361 and parameters: {'num_leaves': 255, 'learning_rate': 0.16072490767801398, 'feature_fraction': 0.8173352451082216, 'bagging_fraction': 0.7752422174124832, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,247] Trial 39 finished with value: 0.6541353383458647 and parameters: {'num_leaves': 232, 'learning_rate': 0.11207119819736769, 'feature_fraction': 0.5686129734947619, 'bagging_fraction': 0.6611723063455097, 'bagging_freq': 1, 'min_child_samples': 36}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,268] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 261, 'learning_rate': 0.07889606797929055, 'feature_fraction': 0.40712403576772405, 'bagging_fraction': 0.4318246442812901, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,397] Trial 41 finished with value: 0.7744360902255639 and parameters: {'num_leaves': 234, 'learning_rate': 0.09275651832372316, 'feature_fraction': 0.6045110319979228, 'bagging_fraction': 0.9350717103265744, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,550] Trial 42 finished with value: 0.7744360902255639 and parameters: {'num_leaves': 208, 'learning_rate': 0.0508592443755828, 'feature_fraction': 0.6606242976902491, 'bagging_fraction': 0.8504713184779862, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,621] Trial 43 finished with value: 0.7330827067669173 and parameters: {'num_leaves': 54, 'learning_rate': 0.028909386895738395, 'feature_fraction': 0.6884223745396513, 'bagging_fraction': 0.9628504087819909, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,693] Trial 44 finished with value: 0.8045112781954887 and parameters: {'num_leaves': 180, 'learning_rate': 0.0710827550283202, 'feature_fraction': 0.607908793274536, 'bagging_fraction': 0.7406735129064563, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,756] Trial 45 finished with value: 0.7669172932330827 and parameters: {'num_leaves': 277, 'learning_rate': 0.09708421152736232, 'feature_fraction': 0.531431407917668, 'bagging_fraction': 0.99863351695917, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,810] Trial 46 finished with value: 0.7518796992481203 and parameters: {'num_leaves': 155, 'learning_rate': 0.1359816308600193, 'feature_fraction': 0.4941822933768859, 'bagging_fraction': 0.8966231720037544, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,889] Trial 47 finished with value: 0.830827067669173 and parameters: {'num_leaves': 292, 'learning_rate': 0.11756366364258129, 'feature_fraction': 0.753495989160044, 'bagging_fraction': 0.8033794929059938, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,902] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.18602050682732327, 'feature_fraction': 0.8916589677516601, 'bagging_fraction': 0.7908076815735706, 'bagging_freq': 3, 'min_child_samples': 85}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:20,957] Trial 49 finished with value: 0.7969924812030076 and parameters: {'num_leaves': 288, 'learning_rate': 0.1692683511239968, 'feature_fraction': 0.7433734079262391, 'bagging_fraction': 0.7984410487385093, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 37 with value: 0.849624060150376.
[I 2025-09-17 13:17:21,504] A new study created in memory with name: no-name-a20b5530-b3af-4a34-a182-e39a9ac21e5f
[I 2025-09-17 13:17:21,526] Trial 0 finished with value: 0.7819548872180451 and parameters: {'num_leaves': 262, 'learning_rate': 0.17310200861431216, 'feature_fraction': 0.9471413719759565, 'bagging_fraction': 0.4455302147013779, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 0 with value: 0.7819548872180451.
[I 2025-09-17 13:17:21,547] Trial 1 finished with value: 0.7669172932330827 and parameters: {'num_leaves': 148, 'learning_rate': 0.24951938210552863, 'feature_fraction': 0.7295007579420336, 'bagging_fraction': 0.5687812446663119, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 0 with value: 0.7819548872180451.
[I 2025-09-17 13:17:21,602] Trial 2 finished with value: 0.8834586466165414 and parameters: {'num_leaves': 185, 'learning_rate': 0.29535115270488443, 'feature_fraction': 0.7271709205375037, 'bagging_fraction': 0.652415302399886, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,611] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 101, 'learning_rate': 0.28943733338475064, 'feature_fraction': 0.8562026892807953, 'bagging_fraction': 0.7995541326562854, 'bagging_freq': 7, 'min_child_samples': 60}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,621] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 78, 'learning_rate': 0.18000133927377354, 'feature_fraction': 0.8876295555231273, 'bagging_fraction': 0.6293700809165341, 'bagging_freq': 4, 'min_child_samples': 55}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,662] Trial 5 finished with value: 0.8796992481203008 and parameters: {'num_leaves': 180, 'learning_rate': 0.24265360450221188, 'feature_fraction': 0.6824101047067097, 'bagging_fraction': 0.7478552400255294, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,670] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 55, 'learning_rate': 0.268022441124686, 'feature_fraction': 0.7249318325023726, 'bagging_fraction': 0.6357125713911536, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,680] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 148, 'learning_rate': 0.061518264372646056, 'feature_fraction': 0.7886031143121457, 'bagging_fraction': 0.7741733666879884, 'bagging_freq': 2, 'min_child_samples': 77}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,689] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 272, 'learning_rate': 0.08875984750549104, 'feature_fraction': 0.8483094369491448, 'bagging_fraction': 0.45666945076561455, 'bagging_freq': 5, 'min_child_samples': 76}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,693] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 164, 'learning_rate': 0.03421064229784983, 'feature_fraction': 0.8980010073498943, 'bagging_fraction': 0.9840741871069543, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,866] Trial 10 finished with value: 0.8609022556390978 and parameters: {'num_leaves': 218, 'learning_rate': 0.12860403467662035, 'feature_fraction': 0.5384700903934703, 'bagging_fraction': 0.9048206234745962, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,951] Trial 11 finished with value: 0.8082706766917294 and parameters: {'num_leaves': 204, 'learning_rate': 0.23585250408272893, 'feature_fraction': 0.5809723450738076, 'bagging_fraction': 0.7673529891957068, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:21,976] Trial 12 finished with value: 0.755639097744361 and parameters: {'num_leaves': 13, 'learning_rate': 0.223370352943276, 'feature_fraction': 0.6515522417548406, 'bagging_fraction': 0.7094965470221981, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,000] Trial 13 finished with value: 0.6729323308270677 and parameters: {'num_leaves': 202, 'learning_rate': 0.29490926712412535, 'feature_fraction': 0.47720053299491283, 'bagging_fraction': 0.5395182658322715, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,044] Trial 14 finished with value: 0.8082706766917294 and parameters: {'num_leaves': 239, 'learning_rate': 0.21163616835953547, 'feature_fraction': 0.6020820046849988, 'bagging_fraction': 0.834057739118363, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,067] Trial 15 finished with value: 0.7781954887218046 and parameters: {'num_leaves': 118, 'learning_rate': 0.13486778229591007, 'feature_fraction': 0.6609241188471656, 'bagging_fraction': 0.6818614311519774, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 2 with value: 0.8834586466165414.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.623243
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.503991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.49852
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.619576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.480025
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.630107
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.535466
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.561044
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.554875
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.589933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.534603
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.548987
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.465709
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.567526
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.577158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.651965
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.504219
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.49239
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.580032
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.638787
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.569367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.504024
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.593693
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.585784
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.619551
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.517103
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.454363
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.58645
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.618023
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.522082
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.505496
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.554908
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.513983
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.523404
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.562963
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.473927
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.509221
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.528968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.570084
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.450735
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.466006
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.46475
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.516333
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.586361
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.569489
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.516815
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.570906
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.515649
[I 2025-09-17 13:17:22,121] Trial 16 finished with value: 0.8082706766917293 and parameters: {'num_leaves': 296, 'learning_rate': 0.2009929392497389, 'feature_fraction': 0.4312984817932124, 'bagging_fraction': 0.8898731793685615, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,137] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 175, 'learning_rate': 0.2628592676867766, 'feature_fraction': 0.7736132902788755, 'bagging_fraction': 0.5252732530347696, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,220] Trial 18 finished with value: 0.8308270676691729 and parameters: {'num_leaves': 116, 'learning_rate': 0.29354858386631993, 'feature_fraction': 0.9836039887882881, 'bagging_fraction': 0.7083050211196456, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,250] Trial 19 finished with value: 0.7293233082706767 and parameters: {'num_leaves': 183, 'learning_rate': 0.24091926192123897, 'feature_fraction': 0.6621238565377774, 'bagging_fraction': 0.6460943720952608, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,277] Trial 20 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 231, 'learning_rate': 0.1912410594491164, 'feature_fraction': 0.7891632522920441, 'bagging_fraction': 0.5839366835082149, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,357] Trial 21 finished with value: 0.81203007518797 and parameters: {'num_leaves': 220, 'learning_rate': 0.13287663815079714, 'feature_fraction': 0.5295253773523096, 'bagging_fraction': 0.9677027031714404, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,432] Trial 22 finished with value: 0.8045112781954887 and parameters: {'num_leaves': 197, 'learning_rate': 0.10539019112998341, 'feature_fraction': 0.5459975755540556, 'bagging_fraction': 0.9117252974605894, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,542] Trial 23 finished with value: 0.7819548872180452 and parameters: {'num_leaves': 250, 'learning_rate': 0.15521300608836971, 'feature_fraction': 0.6154239642388664, 'bagging_fraction': 0.8684526904969779, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,579] Trial 24 finished with value: 0.7969924812030076 and parameters: {'num_leaves': 149, 'learning_rate': 0.27002631551949163, 'feature_fraction': 0.4964529293658657, 'bagging_fraction': 0.7425854044002196, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,619] Trial 25 finished with value: 0.774436090225564 and parameters: {'num_leaves': 181, 'learning_rate': 0.10813069007714651, 'feature_fraction': 0.7079189390705829, 'bagging_fraction': 0.9372345215469607, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,668] Trial 26 finished with value: 0.7706766917293233 and parameters: {'num_leaves': 219, 'learning_rate': 0.15665095924462563, 'feature_fraction': 0.45176396180920686, 'bagging_fraction': 0.8324220666581686, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,691] Trial 27 finished with value: 0.7669172932330827 and parameters: {'num_leaves': 131, 'learning_rate': 0.12640588631217523, 'feature_fraction': 0.5423867326806306, 'bagging_fraction': 0.8280015561741547, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,716] Trial 28 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 288, 'learning_rate': 0.05193356682064376, 'feature_fraction': 0.743588426593989, 'bagging_fraction': 0.6602304603938003, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,730] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 214, 'learning_rate': 0.011157105366499859, 'feature_fraction': 0.6341670028343483, 'bagging_fraction': 0.4934294851872538, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,762] Trial 30 finished with value: 0.7406015037593985 and parameters: {'num_leaves': 254, 'learning_rate': 0.17104448458408236, 'feature_fraction': 0.575622872521573, 'bagging_fraction': 0.42584665299354046, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,851] Trial 31 finished with value: 0.8458646616541353 and parameters: {'num_leaves': 109, 'learning_rate': 0.2959481588825453, 'feature_fraction': 0.9803182001258488, 'bagging_fraction': 0.7294887672964738, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,897] Trial 32 finished with value: 0.7593984962406014 and parameters: {'num_leaves': 84, 'learning_rate': 0.2765344857544452, 'feature_fraction': 0.9533362749894833, 'bagging_fraction': 0.7320347854260018, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 2 with value: 0.8834586466165414.
[I 2025-09-17 13:17:22,999] Trial 33 finished with value: 0.8872180451127819 and parameters: {'num_leaves': 166, 'learning_rate': 0.2992500661608874, 'feature_fraction': 0.40882438856586345, 'bagging_fraction': 0.5996720412619082, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,034] Trial 34 finished with value: 0.7857142857142858 and parameters: {'num_leaves': 133, 'learning_rate': 0.25232574985786527, 'feature_fraction': 0.4293014043806746, 'bagging_fraction': 0.6016125251671604, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,079] Trial 35 finished with value: 0.8308270676691729 and parameters: {'num_leaves': 162, 'learning_rate': 0.27844418312909314, 'feature_fraction': 0.40162450846072906, 'bagging_fraction': 0.60694632110747, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,116] Trial 36 finished with value: 0.8270676691729323 and parameters: {'num_leaves': 186, 'learning_rate': 0.25428208174996053, 'feature_fraction': 0.6895770175265188, 'bagging_fraction': 0.563422371179735, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,147] Trial 37 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 167, 'learning_rate': 0.22577013335267843, 'feature_fraction': 0.8333695471143721, 'bagging_fraction': 0.6808694937278345, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,163] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.28200799317405645, 'feature_fraction': 0.5002375265695149, 'bagging_fraction': 0.47990041693427266, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,241] Trial 39 finished with value: 0.8270676691729323 and parameters: {'num_leaves': 196, 'learning_rate': 0.07463151297152207, 'feature_fraction': 0.754495257743041, 'bagging_fraction': 0.780851383999422, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,273] Trial 40 finished with value: 0.8308270676691729 and parameters: {'num_leaves': 229, 'learning_rate': 0.18043295533406384, 'feature_fraction': 0.9004843034278317, 'bagging_fraction': 0.6144934640090663, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,345] Trial 41 finished with value: 0.7669172932330828 and parameters: {'num_leaves': 89, 'learning_rate': 0.29950986882921, 'feature_fraction': 0.813292182733927, 'bagging_fraction': 0.7295570798520745, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,446] Trial 42 finished with value: 0.8383458646616541 and parameters: {'num_leaves': 105, 'learning_rate': 0.26205042691858516, 'feature_fraction': 0.8734295177162515, 'bagging_fraction': 0.6679950399131429, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,492] Trial 43 finished with value: 0.8007518796992482 and parameters: {'num_leaves': 151, 'learning_rate': 0.2849379391586867, 'feature_fraction': 0.9197585365259809, 'bagging_fraction': 0.7988864313139503, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,506] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 29, 'learning_rate': 0.24012800698939948, 'feature_fraction': 0.5877903572388165, 'bagging_fraction': 0.6362833794753794, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,518] Trial 45 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.28990771058200565, 'feature_fraction': 0.683423868450348, 'bagging_fraction': 0.5580116523029955, 'bagging_freq': 2, 'min_child_samples': 89}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,567] Trial 46 finished with value: 0.793233082706767 and parameters: {'num_leaves': 66, 'learning_rate': 0.29993471598259336, 'feature_fraction': 0.9987462147800912, 'bagging_fraction': 0.752560884989147, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,604] Trial 47 finished with value: 0.6654135338345866 and parameters: {'num_leaves': 171, 'learning_rate': 0.22633445319481701, 'feature_fraction': 0.4612128942748836, 'bagging_fraction': 0.7057570935358416, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,719] Trial 48 finished with value: 0.830827067669173 and parameters: {'num_leaves': 274, 'learning_rate': 0.21014605796460178, 'feature_fraction': 0.5190394125250472, 'bagging_fraction': 0.8654669708780381, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:23,760] Trial 49 finished with value: 0.8157894736842105 and parameters: {'num_leaves': 123, 'learning_rate': 0.26772936368641875, 'feature_fraction': 0.7282833797393762, 'bagging_fraction': 0.8075293786504277, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 33 with value: 0.8872180451127819.
[I 2025-09-17 13:17:24,062] A new study created in memory with name: no-name-e4c6cb22-7fe8-404d-b8e3-b78db82c1e0c
[I 2025-09-17 13:17:24,072] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 239, 'learning_rate': 0.10127022737430441, 'feature_fraction': 0.4236240139873141, 'bagging_fraction': 0.5018882104079907, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:24,107] Trial 1 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 139, 'learning_rate': 0.2947472325985566, 'feature_fraction': 0.7013441220681853, 'bagging_fraction': 0.8238506475470366, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 1 with value: 0.8421052631578947.
[I 2025-09-17 13:17:24,125] Trial 2 finished with value: 0.8007518796992481 and parameters: {'num_leaves': 57, 'learning_rate': 0.20497872745444404, 'feature_fraction': 0.49621210894216594, 'bagging_fraction': 0.9951509078984895, 'bagging_freq': 5, 'min_child_samples': 62}. Best is trial 1 with value: 0.8421052631578947.
[I 2025-09-17 13:17:24,165] Trial 3 finished with value: 0.9097744360902256 and parameters: {'num_leaves': 250, 'learning_rate': 0.13647241709258653, 'feature_fraction': 0.7307140550422737, 'bagging_fraction': 0.9849360810412964, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,191] Trial 4 finished with value: 0.8195488721804511 and parameters: {'num_leaves': 247, 'learning_rate': 0.21636134102603158, 'feature_fraction': 0.9861385434977368, 'bagging_fraction': 0.5439801313346048, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,199] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 34, 'learning_rate': 0.096129374526354, 'feature_fraction': 0.8804482592229546, 'bagging_fraction': 0.6502688119170372, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,223] Trial 6 finished with value: 0.868421052631579 and parameters: {'num_leaves': 137, 'learning_rate': 0.11144112614851245, 'feature_fraction': 0.8041094158697397, 'bagging_fraction': 0.4937429094251621, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,243] Trial 7 finished with value: 0.8609022556390977 and parameters: {'num_leaves': 242, 'learning_rate': 0.18756840131884983, 'feature_fraction': 0.8952075406785145, 'bagging_fraction': 0.7741634968759563, 'bagging_freq': 7, 'min_child_samples': 46}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,265] Trial 8 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 202, 'learning_rate': 0.12775598560000917, 'feature_fraction': 0.7820393328799937, 'bagging_fraction': 0.5424745906272079, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,301] Trial 9 finished with value: 0.8721804511278195 and parameters: {'num_leaves': 139, 'learning_rate': 0.13902265337878628, 'feature_fraction': 0.8984969875202935, 'bagging_fraction': 0.4231192500739981, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,309] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.015585994587778429, 'feature_fraction': 0.5758835840117913, 'bagging_fraction': 0.9649867776789323, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,366] Trial 11 finished with value: 0.8233082706766918 and parameters: {'num_leaves': 88, 'learning_rate': 0.04573418461247959, 'feature_fraction': 0.6531205228095137, 'bagging_fraction': 0.40177452652382906, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,497] Trial 12 finished with value: 0.9022556390977444 and parameters: {'num_leaves': 179, 'learning_rate': 0.15958591025129762, 'feature_fraction': 0.97732292384537, 'bagging_fraction': 0.8646403761255163, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 3 with value: 0.9097744360902256.
[I 2025-09-17 13:17:24,625] Trial 13 finished with value: 0.943609022556391 and parameters: {'num_leaves': 183, 'learning_rate': 0.16468817152325257, 'feature_fraction': 0.9936613348919177, 'bagging_fraction': 0.8919804617696262, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 13 with value: 0.943609022556391.
[I 2025-09-17 13:17:24,656] Trial 14 finished with value: 0.8270676691729324 and parameters: {'num_leaves': 288, 'learning_rate': 0.2667722131427359, 'feature_fraction': 0.6975924384771477, 'bagging_fraction': 0.9135547169251534, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 13 with value: 0.943609022556391.
[I 2025-09-17 13:17:24,717] Trial 15 finished with value: 0.8872180451127819 and parameters: {'num_leaves': 198, 'learning_rate': 0.0717389145082926, 'feature_fraction': 0.7906918585670832, 'bagging_fraction': 0.7139989695360733, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 13 with value: 0.943609022556391.
[I 2025-09-17 13:17:24,748] Trial 16 finished with value: 0.868421052631579 and parameters: {'num_leaves': 96, 'learning_rate': 0.17118588578813845, 'feature_fraction': 0.5722811744737488, 'bagging_fraction': 0.9201521251696098, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 13 with value: 0.943609022556391.
[I 2025-09-17 13:17:24,854] Trial 17 finished with value: 0.9323308270676691 and parameters: {'num_leaves': 266, 'learning_rate': 0.23989605066009895, 'feature_fraction': 0.627943415586127, 'bagging_fraction': 0.8291687858897819, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 13 with value: 0.943609022556391.
[I 2025-09-17 13:17:24,871] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 177, 'learning_rate': 0.23431735432861692, 'feature_fraction': 0.5850226049693114, 'bagging_fraction': 0.7630292720706919, 'bagging_freq': 2, 'min_child_samples': 74}. Best is trial 13 with value: 0.943609022556391.
[I 2025-09-17 13:17:24,984] Trial 19 finished with value: 0.9285714285714285 and parameters: {'num_leaves': 215, 'learning_rate': 0.2566262098407418, 'feature_fraction': 0.625558215763184, 'bagging_fraction': 0.6838871829134112, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 13 with value: 0.943609022556391.
[I 2025-09-17 13:17:24,996] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 275, 'learning_rate': 0.29777686915676693, 'feature_fraction': 0.4975634274404599, 'bagging_fraction': 0.8433446435296331, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 13 with value: 0.943609022556391.
[I 2025-09-17 13:17:25,112] Trial 21 finished with value: 0.962406015037594 and parameters: {'num_leaves': 215, 'learning_rate': 0.24802760021102713, 'feature_fraction': 0.6249278370948491, 'bagging_fraction': 0.664650044830875, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,166] Trial 22 finished with value: 0.887218045112782 and parameters: {'num_leaves': 215, 'learning_rate': 0.2433274098627434, 'feature_fraction': 0.5274206109673072, 'bagging_fraction': 0.612887405009339, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,222] Trial 23 finished with value: 0.924812030075188 and parameters: {'num_leaves': 271, 'learning_rate': 0.2120712193495306, 'feature_fraction': 0.6417807034510362, 'bagging_fraction': 0.7578285092762553, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,364] Trial 24 finished with value: 0.9548872180451128 and parameters: {'num_leaves': 167, 'learning_rate': 0.2736556091430485, 'feature_fraction': 0.43809619675203454, 'bagging_fraction': 0.9058944587562624, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,415] Trial 25 finished with value: 0.887218045112782 and parameters: {'num_leaves': 169, 'learning_rate': 0.2737226980471205, 'feature_fraction': 0.407185762874322, 'bagging_fraction': 0.8955431461614592, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 21 with value: 0.962406015037594.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.509969
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.614545
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.591011
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.527602
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.512055
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.550776
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.534617
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.57719
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.555518
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.586143
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.614035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.595961
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.491935
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.58614
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.450641
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.582419
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.475485
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.5557
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.561076
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.502721
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.519365
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.580267
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.501309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.530584
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.539524
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.600672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.499212
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.513406
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.470339
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.531893
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.397313
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.51479
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.476313
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.48967
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.531087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.436951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.506927
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.376747
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.343265
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.511518
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.414996
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.439803
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.338495
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.333208
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.324649
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.435414
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.368841
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.286971
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.433222
[I 2025-09-17 13:17:25,434] Trial 26 finished with value: 0.7406015037593985 and parameters: {'num_leaves': 121, 'learning_rate': 0.18689121858717458, 'feature_fraction': 0.4617173631440362, 'bagging_fraction': 0.6042084971814197, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,495] Trial 27 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 156, 'learning_rate': 0.2776942792725206, 'feature_fraction': 0.8515263302515775, 'bagging_fraction': 0.7121101638610603, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,537] Trial 28 finished with value: 0.8609022556390977 and parameters: {'num_leaves': 195, 'learning_rate': 0.22477701354315516, 'feature_fraction': 0.7346289832651238, 'bagging_fraction': 0.8010936770748387, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,549] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 227, 'learning_rate': 0.1902647649948118, 'feature_fraction': 0.9387023370086119, 'bagging_fraction': 0.944829752504228, 'bagging_freq': 1, 'min_child_samples': 79}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,626] Trial 30 finished with value: 0.906015037593985 and parameters: {'num_leaves': 113, 'learning_rate': 0.2512630711006159, 'feature_fraction': 0.4499009349821479, 'bagging_fraction': 0.8766704746014251, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,742] Trial 31 finished with value: 0.9398496240601505 and parameters: {'num_leaves': 266, 'learning_rate': 0.2389405868173952, 'feature_fraction': 0.5409547509333801, 'bagging_fraction': 0.8129850827734622, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,807] Trial 32 finished with value: 0.8759398496240601 and parameters: {'num_leaves': 227, 'learning_rate': 0.2843777696441603, 'feature_fraction': 0.5299277298296681, 'bagging_fraction': 0.7997758190409924, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:25,895] Trial 33 finished with value: 0.9022556390977443 and parameters: {'num_leaves': 182, 'learning_rate': 0.2604051968849897, 'feature_fraction': 0.44953179336453386, 'bagging_fraction': 0.9298483752099065, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,020] Trial 34 finished with value: 0.906015037593985 and parameters: {'num_leaves': 157, 'learning_rate': 0.22890699834145534, 'feature_fraction': 0.5396417396125852, 'bagging_fraction': 0.8613356589415829, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,088] Trial 35 finished with value: 0.868421052631579 and parameters: {'num_leaves': 258, 'learning_rate': 0.20320357432753472, 'feature_fraction': 0.488875692454822, 'bagging_fraction': 0.9966885073897832, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,137] Trial 36 finished with value: 0.7969924812030075 and parameters: {'num_leaves': 231, 'learning_rate': 0.29839603398524794, 'feature_fraction': 0.6770988471216683, 'bagging_fraction': 0.648907169149631, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,172] Trial 37 finished with value: 0.8195488721804511 and parameters: {'num_leaves': 210, 'learning_rate': 0.20331982954167838, 'feature_fraction': 0.6012987139294176, 'bagging_fraction': 0.7290994158574957, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,190] Trial 38 finished with value: 0.7330827067669173 and parameters: {'num_leaves': 14, 'learning_rate': 0.285038899592803, 'feature_fraction': 0.7363105904971199, 'bagging_fraction': 0.8027134788384273, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,236] Trial 39 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 250, 'learning_rate': 0.17039786511979624, 'feature_fraction': 0.429999174238436, 'bagging_fraction': 0.6722856851276792, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,258] Trial 40 finished with value: 0.7819548872180452 and parameters: {'num_leaves': 190, 'learning_rate': 0.09001489670519294, 'feature_fraction': 0.5548385391701123, 'bagging_fraction': 0.7428422817099826, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,348] Trial 41 finished with value: 0.9360902255639098 and parameters: {'num_leaves': 276, 'learning_rate': 0.24057006293351937, 'feature_fraction': 0.6119877982823766, 'bagging_fraction': 0.8294265053341385, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,407] Trial 42 finished with value: 0.8984962406015038 and parameters: {'num_leaves': 283, 'learning_rate': 0.24515475927555938, 'feature_fraction': 0.6116459476757689, 'bagging_fraction': 0.9616943247041397, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,451] Trial 43 finished with value: 0.8909774436090225 and parameters: {'num_leaves': 297, 'learning_rate': 0.21989991714800253, 'feature_fraction': 0.6822681198008766, 'bagging_fraction': 0.8373193587554363, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,546] Trial 44 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 237, 'learning_rate': 0.2688012650432942, 'feature_fraction': 0.5030449577296876, 'bagging_fraction': 0.8981537848161074, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,587] Trial 45 finished with value: 0.8646616541353382 and parameters: {'num_leaves': 141, 'learning_rate': 0.12265074922755297, 'feature_fraction': 0.6712179985794147, 'bagging_fraction': 0.7829157554375218, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,747] Trial 46 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 257, 'learning_rate': 0.15147035157036798, 'feature_fraction': 0.7121746444155991, 'bagging_fraction': 0.8797310434229196, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,792] Trial 47 finished with value: 0.8721804511278196 and parameters: {'num_leaves': 166, 'learning_rate': 0.22988132845411174, 'feature_fraction': 0.7590851686810595, 'bagging_fraction': 0.5940507769301137, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,866] Trial 48 finished with value: 0.9097744360902256 and parameters: {'num_leaves': 64, 'learning_rate': 0.2580374657923037, 'feature_fraction': 0.8197364977396209, 'bagging_fraction': 0.8535358136337067, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:26,883] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 243, 'learning_rate': 0.19396741040323345, 'feature_fraction': 0.5668052924271817, 'bagging_fraction': 0.8179860338233446, 'bagging_freq': 4, 'min_child_samples': 67}. Best is trial 21 with value: 0.962406015037594.
[I 2025-09-17 13:17:27,152] A new study created in memory with name: no-name-d405605c-a1ae-4a86-862c-24604405c59a
[I 2025-09-17 13:17:27,162] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 152, 'learning_rate': 0.07707349516998906, 'feature_fraction': 0.8948126985008291, 'bagging_fraction': 0.4528672655896599, 'bagging_freq': 7, 'min_child_samples': 47}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:27,171] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 268, 'learning_rate': 0.21500408624226938, 'feature_fraction': 0.4406059032080881, 'bagging_fraction': 0.44735380918210155, 'bagging_freq': 3, 'min_child_samples': 95}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:27,220] Trial 2 finished with value: 0.6842105263157895 and parameters: {'num_leaves': 78, 'learning_rate': 0.11809098765188782, 'feature_fraction': 0.8408935720517436, 'bagging_fraction': 0.7697195107342398, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 2 with value: 0.6842105263157895.
[I 2025-09-17 13:17:27,231] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 218, 'learning_rate': 0.23222611137915122, 'feature_fraction': 0.8116845670591484, 'bagging_fraction': 0.4032982141716332, 'bagging_freq': 6, 'min_child_samples': 94}. Best is trial 2 with value: 0.6842105263157895.
[I 2025-09-17 13:17:27,243] Trial 4 finished with value: 0.6259398496240601 and parameters: {'num_leaves': 212, 'learning_rate': 0.20584645427151607, 'feature_fraction': 0.5779655470030013, 'bagging_fraction': 0.8070563467923844, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 2 with value: 0.6842105263157895.
[I 2025-09-17 13:17:27,251] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.25942193936330193, 'feature_fraction': 0.9785306330864944, 'bagging_fraction': 0.4990653123556931, 'bagging_freq': 6, 'min_child_samples': 68}. Best is trial 2 with value: 0.6842105263157895.
[I 2025-09-17 13:17:27,294] Trial 6 finished with value: 0.6578947368421053 and parameters: {'num_leaves': 165, 'learning_rate': 0.027401720293159577, 'feature_fraction': 0.5326516193093239, 'bagging_fraction': 0.6329109454408129, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 2 with value: 0.6842105263157895.
[I 2025-09-17 13:17:27,308] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 238, 'learning_rate': 0.19658807113378804, 'feature_fraction': 0.5369701251523454, 'bagging_fraction': 0.8293404118916057, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 2 with value: 0.6842105263157895.
[I 2025-09-17 13:17:27,315] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 48, 'learning_rate': 0.28788997738066485, 'feature_fraction': 0.9055852243725467, 'bagging_fraction': 0.691797913636007, 'bagging_freq': 1, 'min_child_samples': 67}. Best is trial 2 with value: 0.6842105263157895.
[I 2025-09-17 13:17:27,356] Trial 9 finished with value: 0.6578947368421053 and parameters: {'num_leaves': 75, 'learning_rate': 0.28893691090745205, 'feature_fraction': 0.7887920332879683, 'bagging_fraction': 0.8991200219500457, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 2 with value: 0.6842105263157895.
[I 2025-09-17 13:17:27,383] Trial 10 finished with value: 0.7105263157894737 and parameters: {'num_leaves': 113, 'learning_rate': 0.12061442853483086, 'feature_fraction': 0.6811745596103459, 'bagging_fraction': 0.9458956769271212, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,414] Trial 11 finished with value: 0.6766917293233083 and parameters: {'num_leaves': 108, 'learning_rate': 0.12590045434896843, 'feature_fraction': 0.687615076783905, 'bagging_fraction': 0.9973235476883756, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,482] Trial 12 finished with value: 0.6090225563909775 and parameters: {'num_leaves': 111, 'learning_rate': 0.13136542769356244, 'feature_fraction': 0.6848751692425248, 'bagging_fraction': 0.9882423012761629, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,502] Trial 13 finished with value: 0.6466165413533834 and parameters: {'num_leaves': 27, 'learning_rate': 0.0747111740038019, 'feature_fraction': 0.7821991266964586, 'bagging_fraction': 0.7799366232037255, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,519] Trial 14 finished with value: 0.5507518796992481 and parameters: {'num_leaves': 110, 'learning_rate': 0.09150152534836664, 'feature_fraction': 0.6265161725515417, 'bagging_fraction': 0.6097096564111699, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,550] Trial 15 finished with value: 0.6635338345864662 and parameters: {'num_leaves': 72, 'learning_rate': 0.16637013618738355, 'feature_fraction': 0.7374742307773084, 'bagging_fraction': 0.8989956977246233, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,566] Trial 16 finished with value: 0.5733082706766917 and parameters: {'num_leaves': 12, 'learning_rate': 0.04039498366554527, 'feature_fraction': 0.857403403037567, 'bagging_fraction': 0.7329250467091029, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,665] Trial 17 finished with value: 0.650375939849624 and parameters: {'num_leaves': 130, 'learning_rate': 0.15208077551910837, 'feature_fraction': 0.9531043806859923, 'bagging_fraction': 0.8973939986997455, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,690] Trial 18 finished with value: 0.5845864661654135 and parameters: {'num_leaves': 71, 'learning_rate': 0.1071892826830945, 'feature_fraction': 0.6431761344247011, 'bagging_fraction': 0.5690397559251315, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,702] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 140, 'learning_rate': 0.16921456759825793, 'feature_fraction': 0.7394683976009663, 'bagging_fraction': 0.7123368198238781, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,715] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 92, 'learning_rate': 0.05428587522519515, 'feature_fraction': 0.4110316726506395, 'bagging_fraction': 0.9413803409944461, 'bagging_freq': 3, 'min_child_samples': 77}. Best is trial 10 with value: 0.7105263157894737.
[I 2025-09-17 13:17:27,742] Trial 21 finished with value: 0.7518796992481203 and parameters: {'num_leaves': 111, 'learning_rate': 0.12026451513208408, 'feature_fraction': 0.6887122182327512, 'bagging_fraction': 0.9534604394691396, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,766] Trial 22 finished with value: 0.6390977443609023 and parameters: {'num_leaves': 55, 'learning_rate': 0.11996791031875007, 'feature_fraction': 0.6283971811280875, 'bagging_fraction': 0.856567614202329, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,785] Trial 23 finished with value: 0.612781954887218 and parameters: {'num_leaves': 300, 'learning_rate': 0.14452641825068793, 'feature_fraction': 0.7417488885577737, 'bagging_fraction': 0.942028048507271, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,833] Trial 24 finished with value: 0.6203007518796992 and parameters: {'num_leaves': 171, 'learning_rate': 0.09697375775954482, 'feature_fraction': 0.8425766835283548, 'bagging_fraction': 0.772202310151596, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,856] Trial 25 finished with value: 0.6954887218045113 and parameters: {'num_leaves': 132, 'learning_rate': 0.1771777630679326, 'feature_fraction': 0.5760045465261177, 'bagging_fraction': 0.8643667638127498, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,878] Trial 26 finished with value: 0.5281954887218046 and parameters: {'num_leaves': 126, 'learning_rate': 0.1857474563296161, 'feature_fraction': 0.4842075760606165, 'bagging_fraction': 0.9474315164035434, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,904] Trial 27 finished with value: 0.6954887218045113 and parameters: {'num_leaves': 191, 'learning_rate': 0.1815505388331301, 'feature_fraction': 0.5541606289809046, 'bagging_fraction': 0.8626702217282767, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,919] Trial 28 finished with value: 0.5488721804511278 and parameters: {'num_leaves': 150, 'learning_rate': 0.24524565834858142, 'feature_fraction': 0.6140443842399219, 'bagging_fraction': 0.9632153154199558, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,938] Trial 29 finished with value: 0.5977443609022558 and parameters: {'num_leaves': 96, 'learning_rate': 0.07574600019641455, 'feature_fraction': 0.671016653075613, 'bagging_fraction': 0.87333398819842, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,967] Trial 30 finished with value: 0.7236842105263158 and parameters: {'num_leaves': 148, 'learning_rate': 0.14942040337976076, 'feature_fraction': 0.5007327708490704, 'bagging_fraction': 0.8210529974810992, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:27,994] Trial 31 finished with value: 0.6917293233082706 and parameters: {'num_leaves': 145, 'learning_rate': 0.15512418051808052, 'feature_fraction': 0.4962794840999299, 'bagging_fraction': 0.9185197962600568, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,028] Trial 32 finished with value: 0.618421052631579 and parameters: {'num_leaves': 134, 'learning_rate': 0.14043976381523873, 'feature_fraction': 0.582166371819097, 'bagging_fraction': 0.82871721174908, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,049] Trial 33 finished with value: 0.6447368421052632 and parameters: {'num_leaves': 163, 'learning_rate': 0.22176405630590604, 'feature_fraction': 0.4780589389980504, 'bagging_fraction': 0.9737818673323497, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,096] Trial 34 finished with value: 0.6766917293233082 and parameters: {'num_leaves': 116, 'learning_rate': 0.17101282952660463, 'feature_fraction': 0.4493352203812311, 'bagging_fraction': 0.8306719786375029, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 21 with value: 0.7518796992481203.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.601413
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.454358
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.46139
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.386253
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.318079
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.430096
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.403136
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.38982
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.454821
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.55282
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.491493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.615194
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.489728
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.550912
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.322766
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.39063
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.432333
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.334349
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.447825
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.360871
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.449272
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.357108
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.614934
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.665598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.613131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.635667
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.600319
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.611088
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.651824
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.652966
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.679855
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.592209
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.671762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.64282
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.668512
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.591054
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.653087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.656619
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.623036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.607134
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.678167
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.60729
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.675809
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.649075
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.611136
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.599412
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.623309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.666005
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.605919
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:28,127] Trial 35 finished with value: 0.631578947368421 and parameters: {'num_leaves': 188, 'learning_rate': 0.10704423693916623, 'feature_fraction': 0.5898174306563333, 'bagging_fraction': 0.9226234604940011, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,161] Trial 36 finished with value: 0.7105263157894737 and parameters: {'num_leaves': 94, 'learning_rate': 0.2003254867084957, 'feature_fraction': 0.6659226391972566, 'bagging_fraction': 0.8563802723430525, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,176] Trial 37 finished with value: 0.5733082706766917 and parameters: {'num_leaves': 91, 'learning_rate': 0.20637804576752805, 'feature_fraction': 0.7106150344786524, 'bagging_fraction': 0.8011625927522287, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,193] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 52, 'learning_rate': 0.0644384695387512, 'feature_fraction': 0.7787873611541895, 'bagging_fraction': 0.7325883440285178, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,207] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 218, 'learning_rate': 0.19335132840614863, 'feature_fraction': 0.67134188854368, 'bagging_fraction': 0.6668826232029297, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,245] Trial 40 finished with value: 0.6447368421052632 and parameters: {'num_leaves': 174, 'learning_rate': 0.23496139510577352, 'feature_fraction': 0.5169196689181733, 'bagging_fraction': 0.8000048524124147, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,267] Trial 41 finished with value: 0.6616541353383458 and parameters: {'num_leaves': 97, 'learning_rate': 0.1365975473244869, 'feature_fraction': 0.6486122254611018, 'bagging_fraction': 0.8717322542052038, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,301] Trial 42 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 123, 'learning_rate': 0.11463640831577507, 'feature_fraction': 0.5640202559139493, 'bagging_fraction': 0.8458870424754757, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,341] Trial 43 finished with value: 0.6992481203007519 and parameters: {'num_leaves': 150, 'learning_rate': 0.1097502904804775, 'feature_fraction': 0.7165891158141986, 'bagging_fraction': 0.9216470267400481, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,407] Trial 44 finished with value: 0.6466165413533834 and parameters: {'num_leaves': 122, 'learning_rate': 0.09451230368336012, 'feature_fraction': 0.4499872734557041, 'bagging_fraction': 0.8274498307003014, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,456] Trial 45 finished with value: 0.6466165413533835 and parameters: {'num_leaves': 82, 'learning_rate': 0.12576676164810585, 'feature_fraction': 0.5536186629635526, 'bagging_fraction': 0.9979558257966124, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,476] Trial 46 finished with value: 0.5789473684210527 and parameters: {'num_leaves': 200, 'learning_rate': 0.15544547244381843, 'feature_fraction': 0.6111397789791395, 'bagging_fraction': 0.7572638743162157, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,499] Trial 47 finished with value: 0.6221804511278195 and parameters: {'num_leaves': 105, 'learning_rate': 0.11938062409968923, 'feature_fraction': 0.7613635591650698, 'bagging_fraction': 0.8969330777526031, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,561] Trial 48 finished with value: 0.6917293233082706 and parameters: {'num_leaves': 157, 'learning_rate': 0.08675624475983688, 'feature_fraction': 0.40058072445853865, 'bagging_fraction': 0.9677141716502875, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,584] Trial 49 finished with value: 0.4605263157894737 and parameters: {'num_leaves': 233, 'learning_rate': 0.2556925514592631, 'feature_fraction': 0.8131096506802291, 'bagging_fraction': 0.45067218313195867, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 21 with value: 0.7518796992481203.
[I 2025-09-17 13:17:28,971] A new study created in memory with name: no-name-03ef7058-9142-4dff-95a1-c09126a163f8
[I 2025-09-17 13:17:28,980] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 88, 'learning_rate': 0.11843874824628804, 'feature_fraction': 0.9635769139104624, 'bagging_fraction': 0.535434791948842, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:28,989] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 149, 'learning_rate': 0.08079043914766212, 'feature_fraction': 0.5631300403527003, 'bagging_fraction': 0.6648356038598693, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:29,009] Trial 2 finished with value: 0.7888888888888889 and parameters: {'num_leaves': 221, 'learning_rate': 0.06984829611208426, 'feature_fraction': 0.9468947401160921, 'bagging_fraction': 0.573642459731528, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 2 with value: 0.7888888888888889.
[I 2025-09-17 13:17:29,021] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.05790624334986703, 'feature_fraction': 0.4206485643445601, 'bagging_fraction': 0.7101565849798843, 'bagging_freq': 7, 'min_child_samples': 90}. Best is trial 2 with value: 0.7888888888888889.
[I 2025-09-17 13:17:29,052] Trial 4 finished with value: 0.8148148148148148 and parameters: {'num_leaves': 213, 'learning_rate': 0.11757860924088304, 'feature_fraction': 0.5202630473074304, 'bagging_fraction': 0.5367138093623075, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 4 with value: 0.8148148148148148.
[I 2025-09-17 13:17:29,123] Trial 5 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 67, 'learning_rate': 0.16464624384842086, 'feature_fraction': 0.5927205476506004, 'bagging_fraction': 0.4884802958547538, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,154] Trial 6 finished with value: 0.7962962962962963 and parameters: {'num_leaves': 131, 'learning_rate': 0.2406465090098592, 'feature_fraction': 0.7450898760748372, 'bagging_fraction': 0.9743068695083333, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,174] Trial 7 finished with value: 0.8296296296296297 and parameters: {'num_leaves': 193, 'learning_rate': 0.2943867490291174, 'feature_fraction': 0.8648489440981106, 'bagging_fraction': 0.967510334926971, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,194] Trial 8 finished with value: 0.7962962962962963 and parameters: {'num_leaves': 89, 'learning_rate': 0.2168346004350857, 'feature_fraction': 0.717764848439461, 'bagging_fraction': 0.4597872627829284, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,202] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.07147877822686609, 'feature_fraction': 0.99959789559474, 'bagging_fraction': 0.7608993901840725, 'bagging_freq': 6, 'min_child_samples': 85}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,263] Trial 10 finished with value: 0.7518518518518519 and parameters: {'num_leaves': 10, 'learning_rate': 0.17573636447290317, 'feature_fraction': 0.6042466340290916, 'bagging_fraction': 0.40468709088331567, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,271] Trial 11 finished with value: 0.5 and parameters: {'num_leaves': 20, 'learning_rate': 0.2923197442046541, 'feature_fraction': 0.8379729153401246, 'bagging_fraction': 0.9862029672513567, 'bagging_freq': 1, 'min_child_samples': 66}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,291] Trial 12 finished with value: 0.7703703703703704 and parameters: {'num_leaves': 266, 'learning_rate': 0.2999302017978098, 'feature_fraction': 0.831519296359048, 'bagging_fraction': 0.8380455560075435, 'bagging_freq': 1, 'min_child_samples': 55}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,413] Trial 13 finished with value: 0.8185185185185185 and parameters: {'num_leaves': 67, 'learning_rate': 0.19297366450401238, 'feature_fraction': 0.6579854260929239, 'bagging_fraction': 0.8980192111644625, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,458] Trial 14 finished with value: 0.8185185185185185 and parameters: {'num_leaves': 129, 'learning_rate': 0.021936158036552134, 'feature_fraction': 0.8272698511135369, 'bagging_fraction': 0.8289567303024405, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,478] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 174, 'learning_rate': 0.24961603145530653, 'feature_fraction': 0.47555844162135585, 'bagging_fraction': 0.6348312109817051, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,502] Trial 16 finished with value: 0.825925925925926 and parameters: {'num_leaves': 52, 'learning_rate': 0.14248036608383283, 'feature_fraction': 0.6498807345112906, 'bagging_fraction': 0.7481606427914587, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,534] Trial 17 finished with value: 0.737037037037037 and parameters: {'num_leaves': 250, 'learning_rate': 0.2579148744640263, 'feature_fraction': 0.7574314821129345, 'bagging_fraction': 0.5988281088429654, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,548] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 106, 'learning_rate': 0.20246047596035147, 'feature_fraction': 0.8920116999203759, 'bagging_fraction': 0.4901297520671989, 'bagging_freq': 2, 'min_child_samples': 69}. Best is trial 5 with value: 0.8333333333333334.
[I 2025-09-17 13:17:29,571] Trial 19 finished with value: 0.8407407407407408 and parameters: {'num_leaves': 198, 'learning_rate': 0.17492681796376763, 'feature_fraction': 0.7813063124931654, 'bagging_fraction': 0.8900525731389449, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 19 with value: 0.8407407407407408.
[I 2025-09-17 13:17:29,583] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 46, 'learning_rate': 0.16046753033111277, 'feature_fraction': 0.6537768452940282, 'bagging_fraction': 0.8937103154880942, 'bagging_freq': 6, 'min_child_samples': 72}. Best is trial 19 with value: 0.8407407407407408.
[I 2025-09-17 13:17:29,605] Trial 21 finished with value: 0.788888888888889 and parameters: {'num_leaves': 198, 'learning_rate': 0.1326185518419701, 'feature_fraction': 0.792163144529957, 'bagging_fraction': 0.9406892264791912, 'bagging_freq': 7, 'min_child_samples': 46}. Best is trial 19 with value: 0.8407407407407408.
[I 2025-09-17 13:17:29,639] Trial 22 finished with value: 0.8518518518518519 and parameters: {'num_leaves': 169, 'learning_rate': 0.17266269701581974, 'feature_fraction': 0.8840235978638014, 'bagging_fraction': 0.8482155661096913, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,670] Trial 23 finished with value: 0.8148148148148149 and parameters: {'num_leaves': 237, 'learning_rate': 0.17135010603253173, 'feature_fraction': 0.8978115599748239, 'bagging_fraction': 0.8182655532405412, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,687] Trial 24 finished with value: 0.5 and parameters: {'num_leaves': 156, 'learning_rate': 0.1036418843298186, 'feature_fraction': 0.7835892593566683, 'bagging_fraction': 0.8780155404298908, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,745] Trial 25 finished with value: 0.788888888888889 and parameters: {'num_leaves': 166, 'learning_rate': 0.22255026119640914, 'feature_fraction': 0.6878083102504996, 'bagging_fraction': 0.761011308666177, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,770] Trial 26 finished with value: 0.8074074074074075 and parameters: {'num_leaves': 121, 'learning_rate': 0.18195529078382536, 'feature_fraction': 0.5825900816486566, 'bagging_fraction': 0.7848107392854027, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,800] Trial 27 finished with value: 0.8222222222222222 and parameters: {'num_leaves': 148, 'learning_rate': 0.15561729952820708, 'feature_fraction': 0.9198549375209816, 'bagging_fraction': 0.6897549531618093, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,821] Trial 28 finished with value: 0.812962962962963 and parameters: {'num_leaves': 219, 'learning_rate': 0.20778505360178087, 'feature_fraction': 0.7137311028414319, 'bagging_fraction': 0.9255291888205539, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,844] Trial 29 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 95, 'learning_rate': 0.13106462848975547, 'feature_fraction': 0.5325925761051743, 'bagging_fraction': 0.8595684647944443, 'bagging_freq': 7, 'min_child_samples': 45}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,858] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 269, 'learning_rate': 0.10925905269121869, 'feature_fraction': 0.9758202563878602, 'bagging_fraction': 0.7164674303798735, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,882] Trial 31 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 88, 'learning_rate': 0.1370294893601843, 'feature_fraction': 0.5055116164778541, 'bagging_fraction': 0.8535392336458827, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,907] Trial 32 finished with value: 0.7962962962962963 and parameters: {'num_leaves': 106, 'learning_rate': 0.09644730896677328, 'feature_fraction': 0.557213754219784, 'bagging_fraction': 0.802751212694906, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,930] Trial 33 finished with value: 0.825925925925926 and parameters: {'num_leaves': 64, 'learning_rate': 0.14950478397770867, 'feature_fraction': 0.6088386822318522, 'bagging_fraction': 0.8640512882995004, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:29,997] Trial 34 finished with value: 0.7703703703703704 and parameters: {'num_leaves': 39, 'learning_rate': 0.13018157634198702, 'feature_fraction': 0.40528049485852957, 'bagging_fraction': 0.9237276290999029, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,019] Trial 35 finished with value: 0.7518518518518518 and parameters: {'num_leaves': 86, 'learning_rate': 0.19224254872642002, 'feature_fraction': 0.45504801017290214, 'bagging_fraction': 0.6210755806163697, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,033] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 146, 'learning_rate': 0.16050233272692246, 'feature_fraction': 0.5125316076489049, 'bagging_fraction': 0.5365661430445123, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,064] Trial 37 finished with value: 0.8222222222222223 and parameters: {'num_leaves': 184, 'learning_rate': 0.09017760896884275, 'feature_fraction': 0.5689506063637597, 'bagging_fraction': 0.6577594396359201, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,082] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.04709277955184599, 'feature_fraction': 0.5384320269041888, 'bagging_fraction': 0.41281483139366454, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,115] Trial 39 finished with value: 0.7703703703703704 and parameters: {'num_leaves': 101, 'learning_rate': 0.23005622621752436, 'feature_fraction': 0.618777736023805, 'bagging_fraction': 0.9535596500020801, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,149] Trial 40 finished with value: 0.8296296296296297 and parameters: {'num_leaves': 135, 'learning_rate': 0.11942704089736124, 'feature_fraction': 0.4596431780846052, 'bagging_fraction': 0.9958508585819501, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,175] Trial 41 finished with value: 0.788888888888889 and parameters: {'num_leaves': 87, 'learning_rate': 0.13091915046242533, 'feature_fraction': 0.49114444837101595, 'bagging_fraction': 0.848253972340489, 'bagging_freq': 7, 'min_child_samples': 51}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,202] Trial 42 finished with value: 0.8037037037037037 and parameters: {'num_leaves': 70, 'learning_rate': 0.17548379540938122, 'feature_fraction': 0.5139651676205296, 'bagging_fraction': 0.9065404546524373, 'bagging_freq': 7, 'min_child_samples': 53}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,227] Trial 43 finished with value: 0.8222222222222223 and parameters: {'num_leaves': 33, 'learning_rate': 0.14265786825241622, 'feature_fraction': 0.4394882768888443, 'bagging_fraction': 0.7957288464438993, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 22 with value: 0.8518518518518519.
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.612886
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.564213
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.67867
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.618801
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.649201
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.593641
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.60185
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.61154
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.605109
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.673718
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.65584
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.607234
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.70704
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.551865
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.514173
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.513514
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.521537
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.521571
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.55033
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.579764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.543395
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.528979
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.542077
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.532475
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.548325
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.53124
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.548492
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.506949
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.508713
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.519355
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.530509
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.514191
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.528316
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.531567
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.513481
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.532182
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.527484
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.53187
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.570402
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.525327
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.545747
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.52441
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.532168
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.547089
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.51981
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:30,250] Trial 44 finished with value: 0.701851851851852 and parameters: {'num_leaves': 174, 'learning_rate': 0.16505063873122178, 'feature_fraction': 0.5291095098441333, 'bagging_fraction': 0.8721143584696038, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,278] Trial 45 finished with value: 0.825925925925926 and parameters: {'num_leaves': 79, 'learning_rate': 0.18868891188965134, 'feature_fraction': 0.8628540466466529, 'bagging_fraction': 0.8523136223356599, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,305] Trial 46 finished with value: 0.8296296296296297 and parameters: {'num_leaves': 116, 'learning_rate': 0.11834474581757017, 'feature_fraction': 0.6791626403836133, 'bagging_fraction': 0.5657733564741649, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,341] Trial 47 finished with value: 0.762962962962963 and parameters: {'num_leaves': 59, 'learning_rate': 0.20204687776918, 'feature_fraction': 0.7470737742038884, 'bagging_fraction': 0.7263506120325722, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,373] Trial 48 finished with value: 0.8 and parameters: {'num_leaves': 208, 'learning_rate': 0.07863452019532137, 'feature_fraction': 0.9383507278098578, 'bagging_fraction': 0.8204769829225849, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,388] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 233, 'learning_rate': 0.1424500993816815, 'feature_fraction': 0.80112887378693, 'bagging_fraction': 0.5079215274408505, 'bagging_freq': 7, 'min_child_samples': 58}. Best is trial 22 with value: 0.8518518518518519.
[I 2025-09-17 13:17:30,673] A new study created in memory with name: no-name-cf502433-41d4-4879-b07a-c224747319df
[I 2025-09-17 13:17:30,681] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 143, 'learning_rate': 0.23763063686912975, 'feature_fraction': 0.6701836792188174, 'bagging_fraction': 0.40696132748669267, 'bagging_freq': 7, 'min_child_samples': 73}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:30,796] Trial 1 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 123, 'learning_rate': 0.016849305492552424, 'feature_fraction': 0.9930364626716063, 'bagging_fraction': 0.79812029374544, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 1 with value: 0.9333333333333333.
[I 2025-09-17 13:17:30,824] Trial 2 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 133, 'learning_rate': 0.22704377619375232, 'feature_fraction': 0.8912853232817706, 'bagging_fraction': 0.6863195891707716, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 2 with value: 0.9411764705882353.
[I 2025-09-17 13:17:30,841] Trial 3 finished with value: 0.9098039215686275 and parameters: {'num_leaves': 46, 'learning_rate': 0.21921340571665135, 'feature_fraction': 0.7738695380361937, 'bagging_fraction': 0.8028067396711449, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 2 with value: 0.9411764705882353.
[I 2025-09-17 13:17:30,849] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 241, 'learning_rate': 0.021553457926856867, 'feature_fraction': 0.493697715262989, 'bagging_fraction': 0.8910656585578978, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 2 with value: 0.9411764705882353.
[I 2025-09-17 13:17:30,872] Trial 5 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 233, 'learning_rate': 0.12702406482423706, 'feature_fraction': 0.7191609746328858, 'bagging_fraction': 0.973106343489357, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 2 with value: 0.9411764705882353.
[I 2025-09-17 13:17:30,925] Trial 6 finished with value: 0.9686274509803922 and parameters: {'num_leaves': 30, 'learning_rate': 0.0988486350462, 'feature_fraction': 0.950789175810598, 'bagging_fraction': 0.41221582572742793, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:30,943] Trial 7 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 120, 'learning_rate': 0.1341478190279703, 'feature_fraction': 0.6635399848102201, 'bagging_fraction': 0.6371726926119898, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:30,951] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 174, 'learning_rate': 0.06975348495521172, 'feature_fraction': 0.6240459668685374, 'bagging_fraction': 0.6424003367824678, 'bagging_freq': 2, 'min_child_samples': 90}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:30,970] Trial 9 finished with value: 0.8431372549019608 and parameters: {'num_leaves': 108, 'learning_rate': 0.2598567782425193, 'feature_fraction': 0.5896879913582064, 'bagging_fraction': 0.8379987998559553, 'bagging_freq': 3, 'min_child_samples': 51}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:31,060] Trial 10 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 16, 'learning_rate': 0.08667251281845686, 'feature_fraction': 0.9956044181457615, 'bagging_fraction': 0.40330192963539346, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:31,140] Trial 11 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 15, 'learning_rate': 0.08763508681471767, 'feature_fraction': 0.9815187311700961, 'bagging_fraction': 0.42532873400020477, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:31,171] Trial 12 finished with value: 0.9490196078431372 and parameters: {'num_leaves': 60, 'learning_rate': 0.17484359284592008, 'feature_fraction': 0.8462941431181983, 'bagging_fraction': 0.5293252280135217, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:31,207] Trial 13 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 14, 'learning_rate': 0.08432085186314398, 'feature_fraction': 0.9002888051144577, 'bagging_fraction': 0.5149003119102089, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:31,299] Trial 14 finished with value: 0.9686274509803922 and parameters: {'num_leaves': 81, 'learning_rate': 0.16734207693915393, 'feature_fraction': 0.8142236281199496, 'bagging_fraction': 0.5085096347352904, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:31,322] Trial 15 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 77, 'learning_rate': 0.18486423859940526, 'feature_fraction': 0.8006926162022919, 'bagging_fraction': 0.5246707566240006, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 6 with value: 0.9686274509803922.
[I 2025-09-17 13:17:31,357] Trial 16 finished with value: 0.9725490196078431 and parameters: {'num_leaves': 298, 'learning_rate': 0.29059297773380477, 'feature_fraction': 0.9107042502100663, 'bagging_fraction': 0.5804124903478943, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 16 with value: 0.9725490196078431.
[I 2025-09-17 13:17:31,389] Trial 17 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 295, 'learning_rate': 0.2663553785966717, 'feature_fraction': 0.9244210189214825, 'bagging_fraction': 0.5808748475392835, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 17 with value: 0.9921568627450981.
[I 2025-09-17 13:17:31,403] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 294, 'learning_rate': 0.2932125724736754, 'feature_fraction': 0.4077875430282179, 'bagging_fraction': 0.5984430525518964, 'bagging_freq': 7, 'min_child_samples': 66}. Best is trial 17 with value: 0.9921568627450981.
[I 2025-09-17 13:17:31,435] Trial 19 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 287, 'learning_rate': 0.2910207445372157, 'feature_fraction': 0.8825224858941124, 'bagging_fraction': 0.7238954235119672, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 17 with value: 0.9921568627450981.
[I 2025-09-17 13:17:31,457] Trial 20 finished with value: 0.9490196078431373 and parameters: {'num_leaves': 237, 'learning_rate': 0.259840203302789, 'feature_fraction': 0.7425057794504428, 'bagging_fraction': 0.7298622501402715, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 17 with value: 0.9921568627450981.
[I 2025-09-17 13:17:31,501] Trial 21 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 195, 'learning_rate': 0.20132910887876887, 'feature_fraction': 0.9385014398641115, 'bagging_fraction': 0.5785775538442853, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 17 with value: 0.9921568627450981.
[I 2025-09-17 13:17:31,536] Trial 22 finished with value: 0.996078431372549 and parameters: {'num_leaves': 264, 'learning_rate': 0.267243815658811, 'feature_fraction': 0.9350870831910103, 'bagging_fraction': 0.4663524912661457, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 22 with value: 0.996078431372549.
[I 2025-09-17 13:17:31,569] Trial 23 finished with value: 1.0 and parameters: {'num_leaves': 265, 'learning_rate': 0.2630597677578569, 'feature_fraction': 0.8498353448189048, 'bagging_fraction': 0.47919447146121297, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,594] Trial 24 finished with value: 0.9137254901960784 and parameters: {'num_leaves': 265, 'learning_rate': 0.2640208940317085, 'feature_fraction': 0.8448001651971906, 'bagging_fraction': 0.469659549237984, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,606] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 209, 'learning_rate': 0.2534027182470161, 'feature_fraction': 0.8490307971029798, 'bagging_fraction': 0.47138897999493223, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,645] Trial 26 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 269, 'learning_rate': 0.20750205214115078, 'feature_fraction': 0.9326841728803503, 'bagging_fraction': 0.4687018612870961, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,665] Trial 27 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 263, 'learning_rate': 0.2774906894742668, 'feature_fraction': 0.7669894723426524, 'bagging_fraction': 0.5521720680171782, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,677] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 215, 'learning_rate': 0.24472470404491065, 'feature_fraction': 0.8691526262868148, 'bagging_fraction': 0.6310031729722966, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,702] Trial 29 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 163, 'learning_rate': 0.2352266140312816, 'feature_fraction': 0.9544013794732672, 'bagging_fraction': 0.4671018428122988, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,725] Trial 30 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 280, 'learning_rate': 0.2742730490350486, 'feature_fraction': 0.8098939636866593, 'bagging_fraction': 0.6743426187200467, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,761] Trial 31 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 261, 'learning_rate': 0.2092723817118843, 'feature_fraction': 0.9315466198562133, 'bagging_fraction': 0.44767925654440893, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,810] Trial 32 finished with value: 0.9490196078431372 and parameters: {'num_leaves': 251, 'learning_rate': 0.199303898533961, 'feature_fraction': 0.9596058652949355, 'bagging_fraction': 0.4945422339539691, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,847] Trial 33 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 272, 'learning_rate': 0.23433271508920858, 'feature_fraction': 0.9136698866640294, 'bagging_fraction': 0.5518046548717775, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,875] Trial 34 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 222, 'learning_rate': 0.21644461100316154, 'feature_fraction': 0.9936523564638061, 'bagging_fraction': 0.4402852893802434, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,920] Trial 35 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 191, 'learning_rate': 0.2728378572195113, 'feature_fraction': 0.8920195858852438, 'bagging_fraction': 0.48826634338209396, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,933] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 248, 'learning_rate': 0.22524364288080337, 'feature_fraction': 0.8680277871946165, 'bagging_fraction': 0.548557742226981, 'bagging_freq': 6, 'min_child_samples': 79}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,946] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 276, 'learning_rate': 0.24719128913800562, 'feature_fraction': 0.9671280696327079, 'bagging_fraction': 0.5963043741450611, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:31,995] Trial 38 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 231, 'learning_rate': 0.29764426939831196, 'feature_fraction': 0.825240356569952, 'bagging_fraction': 0.437509394678802, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,034] Trial 39 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 252, 'learning_rate': 0.14692907271683453, 'feature_fraction': 0.7799900976568195, 'bagging_fraction': 0.9700592071031786, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,047] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.1899090822844282, 'feature_fraction': 0.7002749607919017, 'bagging_fraction': 0.4065848498464704, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,096] Trial 41 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 230, 'learning_rate': 0.2968913390310985, 'feature_fraction': 0.8317163847349427, 'bagging_fraction': 0.4465422877679563, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,128] Trial 42 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 282, 'learning_rate': 0.2750812417791856, 'feature_fraction': 0.920268981060258, 'bagging_fraction': 0.48219635295640273, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,175] Trial 43 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 143, 'learning_rate': 0.28242398959406423, 'feature_fraction': 0.8720847835514267, 'bagging_fraction': 0.4346169875755067, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,209] Trial 44 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 242, 'learning_rate': 0.2992543156619651, 'feature_fraction': 0.9214970956881557, 'bagging_fraction': 0.4611872944699874, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,265] Trial 45 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 199, 'learning_rate': 0.26214553892229303, 'feature_fraction': 0.5449379924807258, 'bagging_fraction': 0.507080767419481, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,292] Trial 46 finished with value: 0.9686274509803922 and parameters: {'num_leaves': 261, 'learning_rate': 0.23951891597506433, 'feature_fraction': 0.7408897456244559, 'bagging_fraction': 0.4058424904481793, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,382] Trial 47 finished with value: 0.9411764705882354 and parameters: {'num_leaves': 181, 'learning_rate': 0.03846054152067292, 'feature_fraction': 0.6641223935571887, 'bagging_fraction': 0.5489060783675999, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,415] Trial 48 finished with value: 0.9725490196078431 and parameters: {'num_leaves': 225, 'learning_rate': 0.22589560187880095, 'feature_fraction': 0.9659124574221366, 'bagging_fraction': 0.7868841967842505, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,458] Trial 49 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 284, 'learning_rate': 0.25224690577625936, 'feature_fraction': 0.819123954036614, 'bagging_fraction': 0.5311342427614353, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 23 with value: 1.0.
[I 2025-09-17 13:17:32,632] A new study created in memory with name: no-name-9a0bfed8-0433-4404-bba1-20487f5cbc15
[I 2025-09-17 13:17:32,640] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 223, 'learning_rate': 0.24115553787790583, 'feature_fraction': 0.8172049142785832, 'bagging_fraction': 0.7621403921548469, 'bagging_freq': 6, 'min_child_samples': 83}. Best is trial 0 with value: 0.5.
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.642464
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.524648
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.529671
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.545231
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.539101
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.689533
Training model for P135... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.343212
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.278768
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.43116
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.339989
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.20238
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.399972
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.474079
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.210045
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.197403
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.263445
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.271613
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.20874
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.292063
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.19024
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.188747
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.2444
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.28231
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.239759
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.152192
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.140235
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.319535
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.147504
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.386645
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.26045
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.271906
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.172544
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.20768
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.244056
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.290855
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.248724
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.136501
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.254949
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.216015
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.204185
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.231493
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.266091
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.241187
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.218155
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.282986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.235647
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.20868
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:32,648] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.27021327476597695, 'feature_fraction': 0.6161302950546128, 'bagging_fraction': 0.7975986530376955, 'bagging_freq': 4, 'min_child_samples': 65}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:32,676] Trial 2 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 232, 'learning_rate': 0.14919689769476827, 'feature_fraction': 0.9737450210964264, 'bagging_fraction': 0.7959148325069916, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 2 with value: 0.9333333333333333.
[I 2025-09-17 13:17:32,697] Trial 3 finished with value: 0.8705882352941177 and parameters: {'num_leaves': 109, 'learning_rate': 0.01897143185606617, 'feature_fraction': 0.5585288671746177, 'bagging_fraction': 0.7500392033451795, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 2 with value: 0.9333333333333333.
[I 2025-09-17 13:17:32,718] Trial 4 finished with value: 0.8980392156862745 and parameters: {'num_leaves': 37, 'learning_rate': 0.013999095149171244, 'feature_fraction': 0.530609104241824, 'bagging_fraction': 0.6491589206262112, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 2 with value: 0.9333333333333333.
[I 2025-09-17 13:17:32,788] Trial 5 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 56, 'learning_rate': 0.2251417965962235, 'feature_fraction': 0.7251945268123439, 'bagging_fraction': 0.754854282042491, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:32,807] Trial 6 finished with value: 0.9450980392156864 and parameters: {'num_leaves': 279, 'learning_rate': 0.20544527385201072, 'feature_fraction': 0.9272024980577761, 'bagging_fraction': 0.8351664424710962, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:32,814] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.208577773352322, 'feature_fraction': 0.998444552317676, 'bagging_fraction': 0.851640485423647, 'bagging_freq': 6, 'min_child_samples': 65}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:32,822] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 62, 'learning_rate': 0.2719325855418724, 'feature_fraction': 0.638130024086949, 'bagging_fraction': 0.857859927818484, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:32,857] Trial 9 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 257, 'learning_rate': 0.1656536106008225, 'feature_fraction': 0.7954581702322405, 'bagging_fraction': 0.7084306732687851, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:32,929] Trial 10 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 129, 'learning_rate': 0.09756715092676513, 'feature_fraction': 0.7513893708399615, 'bagging_fraction': 0.5120074618153085, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:32,953] Trial 11 finished with value: 0.8745098039215686 and parameters: {'num_leaves': 300, 'learning_rate': 0.2027628702259981, 'feature_fraction': 0.8897655564962387, 'bagging_fraction': 0.9688162073385334, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,047] Trial 12 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 172, 'learning_rate': 0.13575839724518546, 'feature_fraction': 0.42657967538190705, 'bagging_fraction': 0.5644695165186033, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,063] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 95, 'learning_rate': 0.2986058232257335, 'feature_fraction': 0.8864936852702959, 'bagging_fraction': 0.4101902980899938, 'bagging_freq': 7, 'min_child_samples': 47}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,087] Trial 14 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 22, 'learning_rate': 0.2011163364761614, 'feature_fraction': 0.6983816393977947, 'bagging_fraction': 0.9481898976594746, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,152] Trial 15 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 150, 'learning_rate': 0.09832931531938838, 'feature_fraction': 0.9114501488807527, 'bagging_fraction': 0.8841165782120075, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,167] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.2235326571615315, 'feature_fraction': 0.7434469139361987, 'bagging_fraction': 0.649998611557893, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,202] Trial 17 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 76, 'learning_rate': 0.17841268042495884, 'feature_fraction': 0.8326458491819027, 'bagging_fraction': 0.9043705384221552, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,213] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 177, 'learning_rate': 0.2444628119721231, 'feature_fraction': 0.44826405576166684, 'bagging_fraction': 0.6563044057913844, 'bagging_freq': 7, 'min_child_samples': 98}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,252] Trial 19 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 265, 'learning_rate': 0.1172673473771425, 'feature_fraction': 0.6827136932135405, 'bagging_fraction': 0.5810934016712543, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,275] Trial 20 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 54, 'learning_rate': 0.0759655967446789, 'feature_fraction': 0.9417908202785562, 'bagging_fraction': 0.8179764930744647, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,303] Trial 21 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 257, 'learning_rate': 0.1498580011750508, 'feature_fraction': 0.9959298349783782, 'bagging_fraction': 0.7263343077766722, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,394] Trial 22 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 240, 'learning_rate': 0.1844549471487576, 'feature_fraction': 0.949063947217479, 'bagging_fraction': 0.7974407305258763, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,505] Trial 23 finished with value: 0.9176470588235295 and parameters: {'num_leaves': 268, 'learning_rate': 0.18553608312746334, 'feature_fraction': 0.8553805145802608, 'bagging_fraction': 0.9156218580893769, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,559] Trial 24 finished with value: 0.9607843137254903 and parameters: {'num_leaves': 192, 'learning_rate': 0.23265220408642498, 'feature_fraction': 0.7640212967583861, 'bagging_fraction': 0.8285763735793397, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,622] Trial 25 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 199, 'learning_rate': 0.24309697095374294, 'feature_fraction': 0.7455860880001722, 'bagging_fraction': 0.994450776027027, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,692] Trial 26 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 142, 'learning_rate': 0.22720712456331346, 'feature_fraction': 0.7754478860937836, 'bagging_fraction': 0.7608412764533179, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,712] Trial 27 finished with value: 0.9137254901960785 and parameters: {'num_leaves': 189, 'learning_rate': 0.2690288667633691, 'feature_fraction': 0.6560868429770395, 'bagging_fraction': 0.688749740263428, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,754] Trial 28 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 236, 'learning_rate': 0.29327844537461656, 'feature_fraction': 0.5830017601286064, 'bagging_fraction': 0.6007806471111246, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,851] Trial 29 finished with value: 0.9490196078431373 and parameters: {'num_leaves': 217, 'learning_rate': 0.25191155208022276, 'feature_fraction': 0.8411970395071486, 'bagging_fraction': 0.776505095044954, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,875] Trial 30 finished with value: 0.9058823529411765 and parameters: {'num_leaves': 124, 'learning_rate': 0.17531795289752103, 'feature_fraction': 0.7211021840322943, 'bagging_fraction': 0.7362222017401254, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 5 with value: 0.9647058823529412.
[I 2025-09-17 13:17:33,988] Trial 31 finished with value: 0.9686274509803922 and parameters: {'num_leaves': 219, 'learning_rate': 0.25392603212147985, 'feature_fraction': 0.833454286464931, 'bagging_fraction': 0.7912566443531528, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,024] Trial 32 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 163, 'learning_rate': 0.22490037699537743, 'feature_fraction': 0.8035181939582648, 'bagging_fraction': 0.801169703022015, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,135] Trial 33 finished with value: 0.9058823529411766 and parameters: {'num_leaves': 239, 'learning_rate': 0.2632935354833869, 'feature_fraction': 0.8660752981691849, 'bagging_fraction': 0.8616830341130022, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,197] Trial 34 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 213, 'learning_rate': 0.2838755944854578, 'feature_fraction': 0.9554392213741513, 'bagging_fraction': 0.7783993255898924, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,227] Trial 35 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 242, 'learning_rate': 0.18982533091612602, 'feature_fraction': 0.784628079911586, 'bagging_fraction': 0.8095741543564137, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,261] Trial 36 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 187, 'learning_rate': 0.23002790670939396, 'feature_fraction': 0.8209742037151602, 'bagging_fraction': 0.6777179933238147, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,273] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.25907254820601555, 'feature_fraction': 0.6764072914992455, 'bagging_fraction': 0.7535609713694633, 'bagging_freq': 7, 'min_child_samples': 87}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,302] Trial 38 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 202, 'learning_rate': 0.2224540067120803, 'feature_fraction': 0.7178548614975272, 'bagging_fraction': 0.8379428053748508, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,332] Trial 39 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 226, 'learning_rate': 0.1612105581507866, 'feature_fraction': 0.9136022679088703, 'bagging_fraction': 0.8817549052209467, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,388] Trial 40 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 15, 'learning_rate': 0.21259692653658063, 'feature_fraction': 0.76718469457186, 'bagging_fraction': 0.7165612910348792, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 31 with value: 0.9686274509803922.
[I 2025-09-17 13:17:34,460] Trial 41 finished with value: 0.9764705882352941 and parameters: {'num_leaves': 10, 'learning_rate': 0.21205352304361513, 'feature_fraction': 0.7655810075177473, 'bagging_fraction': 0.7214673616852039, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 41 with value: 0.9764705882352941.
[I 2025-09-17 13:17:34,518] Trial 42 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 14, 'learning_rate': 0.2359687950321553, 'feature_fraction': 0.7727365099399133, 'bagging_fraction': 0.721137466603936, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 41 with value: 0.9764705882352941.
[I 2025-09-17 13:17:34,551] Trial 43 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 18, 'learning_rate': 0.21527149313406585, 'feature_fraction': 0.6126346107751499, 'bagging_fraction': 0.6972695298500575, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 41 with value: 0.9764705882352941.
[I 2025-09-17 13:17:34,620] Trial 44 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 37, 'learning_rate': 0.28293828654935155, 'feature_fraction': 0.8032587255305925, 'bagging_fraction': 0.7207719065036812, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 44 with value: 0.9882352941176471.
[I 2025-09-17 13:17:34,632] Trial 45 finished with value: 0.5 and parameters: {'num_leaves': 34, 'learning_rate': 0.2827234210999955, 'feature_fraction': 0.8099691281994184, 'bagging_fraction': 0.6145122712524412, 'bagging_freq': 7, 'min_child_samples': 67}. Best is trial 44 with value: 0.9882352941176471.
[I 2025-09-17 13:17:34,677] Trial 46 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 46, 'learning_rate': 0.03083401235051582, 'feature_fraction': 0.7195772899659418, 'bagging_fraction': 0.6689383298030132, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 44 with value: 0.9882352941176471.
[I 2025-09-17 13:17:34,748] Trial 47 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 73, 'learning_rate': 0.2763096567162592, 'feature_fraction': 0.871242597371501, 'bagging_fraction': 0.6277149351200276, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 44 with value: 0.9882352941176471.
[I 2025-09-17 13:17:34,782] Trial 48 finished with value: 0.9450980392156862 and parameters: {'num_leaves': 33, 'learning_rate': 0.25238200114006687, 'feature_fraction': 0.7401187591780432, 'bagging_fraction': 0.7109457126444343, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 44 with value: 0.9882352941176471.
[I 2025-09-17 13:17:34,795] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 88, 'learning_rate': 0.19951044716729385, 'feature_fraction': 0.7936364682576842, 'bagging_fraction': 0.7384920435045589, 'bagging_freq': 1, 'min_child_samples': 78}. Best is trial 44 with value: 0.9882352941176471.
[I 2025-09-17 13:17:34,973] A new study created in memory with name: no-name-1ebeb1ab-1809-4c14-8018-2702d5ca50dc
[I 2025-09-17 13:17:35,002] Trial 0 finished with value: 0.9176470588235295 and parameters: {'num_leaves': 180, 'learning_rate': 0.15079330521381976, 'feature_fraction': 0.9529233415626833, 'bagging_fraction': 0.5082566594907748, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,011] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 153, 'learning_rate': 0.053437061939216005, 'feature_fraction': 0.491551464224911, 'bagging_fraction': 0.6085068881033275, 'bagging_freq': 7, 'min_child_samples': 66}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,019] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 114, 'learning_rate': 0.1866247696339264, 'feature_fraction': 0.7146851524749456, 'bagging_fraction': 0.5523257031001473, 'bagging_freq': 6, 'min_child_samples': 82}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,029] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 240, 'learning_rate': 0.24572685270707054, 'feature_fraction': 0.4838225538914992, 'bagging_fraction': 0.9482350794047146, 'bagging_freq': 3, 'min_child_samples': 82}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,038] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.27947518217638095, 'feature_fraction': 0.4904651096629873, 'bagging_fraction': 0.9474599190514071, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,047] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 121, 'learning_rate': 0.08600690038298324, 'feature_fraction': 0.5980603010376196, 'bagging_fraction': 0.6678983259373557, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,140] Trial 6 finished with value: 0.8862745098039216 and parameters: {'num_leaves': 188, 'learning_rate': 0.11557509926998809, 'feature_fraction': 0.4192854810636981, 'bagging_fraction': 0.7699623555953515, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,165] Trial 7 finished with value: 0.8549019607843137 and parameters: {'num_leaves': 233, 'learning_rate': 0.06837639127639895, 'feature_fraction': 0.7891091934107746, 'bagging_fraction': 0.4548229406072696, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,185] Trial 8 finished with value: 0.8392156862745098 and parameters: {'num_leaves': 268, 'learning_rate': 0.2118876975424684, 'feature_fraction': 0.9404805357149161, 'bagging_fraction': 0.6835031749590335, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,195] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 227, 'learning_rate': 0.2666973039215827, 'feature_fraction': 0.5844361925102166, 'bagging_fraction': 0.8723385336734835, 'bagging_freq': 3, 'min_child_samples': 82}. Best is trial 0 with value: 0.9176470588235295.
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.279149
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.491087
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.509183
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.235694
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.282687
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.263639
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.309773
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.418281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.298621
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.309305
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.278111
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.288025
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.308743
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.50716
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.292154
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.276588
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.318611
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.220617
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.252944
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.298064
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.362577
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.288255
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.268961
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.400334
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.21428
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.260124
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.354621
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.289099
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.336621
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.274688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.269754
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.291156
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.204394
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.219246
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.246782
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.307573
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.164877
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.369197
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.206204
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.283474
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.34765
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.41436
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.469648
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.490189
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:35,287] Trial 10 finished with value: 0.9058823529411764 and parameters: {'num_leaves': 17, 'learning_rate': 0.12155793780365276, 'feature_fraction': 0.9838208457658216, 'bagging_fraction': 0.41262854022364337, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 0 with value: 0.9176470588235295.
[I 2025-09-17 13:17:35,351] Trial 11 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 55, 'learning_rate': 0.14188547317873565, 'feature_fraction': 0.9967188768476805, 'bagging_fraction': 0.40129399741561317, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,377] Trial 12 finished with value: 0.9117647058823529 and parameters: {'num_leaves': 49, 'learning_rate': 0.010154057011405454, 'feature_fraction': 0.8717521996850333, 'bagging_fraction': 0.5031408798294731, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,405] Trial 13 finished with value: 0.8588235294117648 and parameters: {'num_leaves': 79, 'learning_rate': 0.16067406726851374, 'feature_fraction': 0.8621383619849486, 'bagging_fraction': 0.4065867038813564, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,419] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.15594071344699273, 'feature_fraction': 0.9875682347372003, 'bagging_fraction': 0.5381957835576225, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,457] Trial 15 finished with value: 0.9215686274509804 and parameters: {'num_leaves': 178, 'learning_rate': 0.20950927965229132, 'feature_fraction': 0.8790365153910271, 'bagging_fraction': 0.47421174138724637, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,469] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.2080789855630615, 'feature_fraction': 0.8666419217233644, 'bagging_fraction': 0.7695716388873212, 'bagging_freq': 4, 'min_child_samples': 98}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,510] Trial 17 finished with value: 0.8823529411764706 and parameters: {'num_leaves': 10, 'learning_rate': 0.23406876402404625, 'feature_fraction': 0.7808516843333427, 'bagging_fraction': 0.6058384321180321, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,524] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 164, 'learning_rate': 0.18514458927030522, 'feature_fraction': 0.9094085041165615, 'bagging_fraction': 0.44145576816938387, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,549] Trial 19 finished with value: 0.6078431372549019 and parameters: {'num_leaves': 130, 'learning_rate': 0.11469780960719636, 'feature_fraction': 0.8200891166689296, 'bagging_fraction': 0.4806221525365401, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,561] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 209, 'learning_rate': 0.29863790759183245, 'feature_fraction': 0.7137583805966343, 'bagging_fraction': 0.5804675648095373, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,595] Trial 21 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 183, 'learning_rate': 0.13627755856060542, 'feature_fraction': 0.9385774215980649, 'bagging_fraction': 0.5043551195339825, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 11 with value: 0.9372549019607843.
[I 2025-09-17 13:17:35,636] Trial 22 finished with value: 0.9490196078431372 and parameters: {'num_leaves': 202, 'learning_rate': 0.13559051253314747, 'feature_fraction': 0.904979825512686, 'bagging_fraction': 0.4706112870021348, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:35,690] Trial 23 finished with value: 0.9215686274509803 and parameters: {'num_leaves': 210, 'learning_rate': 0.1314133408490638, 'feature_fraction': 0.9518578311758491, 'bagging_fraction': 0.4220878249160548, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:35,724] Trial 24 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 141, 'learning_rate': 0.08738099912428246, 'feature_fraction': 0.9965569734265275, 'bagging_fraction': 0.6459599058393073, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:35,766] Trial 25 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 47, 'learning_rate': 0.09022585239634709, 'feature_fraction': 0.9992383417527158, 'bagging_fraction': 0.7292180540602244, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:35,795] Trial 26 finished with value: 0.9176470588235295 and parameters: {'num_leaves': 140, 'learning_rate': 0.04200152947954902, 'feature_fraction': 0.9126908368905566, 'bagging_fraction': 0.6322016342393927, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:35,916] Trial 27 finished with value: 0.8941176470588236 and parameters: {'num_leaves': 84, 'learning_rate': 0.10173542847394251, 'feature_fraction': 0.8182752473395734, 'bagging_fraction': 0.836266108922047, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:35,939] Trial 28 finished with value: 0.8941176470588236 and parameters: {'num_leaves': 100, 'learning_rate': 0.17634967102633625, 'feature_fraction': 0.6445469982486685, 'bagging_fraction': 0.5501115321089896, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:35,983] Trial 29 finished with value: 0.9215686274509804 and parameters: {'num_leaves': 48, 'learning_rate': 0.14820463233240247, 'feature_fraction': 0.9184587656789892, 'bagging_fraction': 0.643259370099339, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:35,995] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 67, 'learning_rate': 0.0733864538138709, 'feature_fraction': 0.9669253680852717, 'bagging_fraction': 0.5115370290355801, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,037] Trial 31 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 35, 'learning_rate': 0.09811337531685141, 'feature_fraction': 0.9950130848245357, 'bagging_fraction': 0.7241453696430914, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,106] Trial 32 finished with value: 0.9058823529411765 and parameters: {'num_leaves': 59, 'learning_rate': 0.03916721486821717, 'feature_fraction': 0.9976341912451082, 'bagging_fraction': 0.7368390250797925, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,121] Trial 33 finished with value: 0.5686274509803922 and parameters: {'num_leaves': 157, 'learning_rate': 0.10056732898892473, 'feature_fraction': 0.9557818039224601, 'bagging_fraction': 0.8213535754548927, 'bagging_freq': 1, 'min_child_samples': 56}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,167] Trial 34 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 34, 'learning_rate': 0.06463193247363716, 'feature_fraction': 0.8992828500641581, 'bagging_fraction': 0.7126429773319654, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,201] Trial 35 finished with value: 0.8980392156862744 and parameters: {'num_leaves': 30, 'learning_rate': 0.1393735943976855, 'feature_fraction': 0.9599208079080312, 'bagging_fraction': 0.575974581692799, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,274] Trial 36 finished with value: 0.8901960784313725 and parameters: {'num_leaves': 99, 'learning_rate': 0.10037573970315294, 'feature_fraction': 0.8408071269089519, 'bagging_fraction': 0.9004728175461854, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,285] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.08586281772315958, 'feature_fraction': 0.9292400227449746, 'bagging_fraction': 0.6565294399571915, 'bagging_freq': 1, 'min_child_samples': 67}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,318] Trial 38 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 255, 'learning_rate': 0.16139649075690063, 'feature_fraction': 0.6579825491663064, 'bagging_fraction': 0.9882930440519461, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,406] Trial 39 finished with value: 0.8823529411764706 and parameters: {'num_leaves': 260, 'learning_rate': 0.16449710561839676, 'feature_fraction': 0.6518479435157293, 'bagging_fraction': 0.9747636329072487, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,454] Trial 40 finished with value: 0.9215686274509804 and parameters: {'num_leaves': 291, 'learning_rate': 0.17468328815429593, 'feature_fraction': 0.7399568947546546, 'bagging_fraction': 0.9994971085112663, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,497] Trial 41 finished with value: 0.9176470588235295 and parameters: {'num_leaves': 277, 'learning_rate': 0.1236232571582371, 'feature_fraction': 0.5569436730229727, 'bagging_fraction': 0.9210566018638573, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,527] Trial 42 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 224, 'learning_rate': 0.1464124045831633, 'feature_fraction': 0.6721585540881538, 'bagging_fraction': 0.8113467906509074, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,542] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 251, 'learning_rate': 0.10941707461196497, 'feature_fraction': 0.7442740291484932, 'bagging_fraction': 0.44421397514671707, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,564] Trial 44 finished with value: 0.7411764705882353 and parameters: {'num_leaves': 110, 'learning_rate': 0.1262560319883481, 'feature_fraction': 0.5309642310696432, 'bagging_fraction': 0.7769902156211965, 'bagging_freq': 2, 'min_child_samples': 50}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,599] Trial 45 finished with value: 0.9450980392156864 and parameters: {'num_leaves': 27, 'learning_rate': 0.19688430229097612, 'feature_fraction': 0.6192523391977743, 'bagging_fraction': 0.8637275808387255, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,635] Trial 46 finished with value: 0.9019607843137255 and parameters: {'num_leaves': 27, 'learning_rate': 0.1971912687651402, 'feature_fraction': 0.623454654049001, 'bagging_fraction': 0.8977405068223026, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,671] Trial 47 finished with value: 0.9019607843137255 and parameters: {'num_leaves': 69, 'learning_rate': 0.2346037194890487, 'feature_fraction': 0.6881265653540678, 'bagging_fraction': 0.8648220567390309, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,764] Trial 48 finished with value: 0.9058823529411765 and parameters: {'num_leaves': 25, 'learning_rate': 0.16713264889934537, 'feature_fraction': 0.5921345449105434, 'bagging_fraction': 0.9431037619576277, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:36,834] Trial 49 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 39, 'learning_rate': 0.18690390854614777, 'feature_fraction': 0.46268921884191483, 'bagging_fraction': 0.6842713992441436, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 22 with value: 0.9490196078431372.
[I 2025-09-17 13:17:37,186] A new study created in memory with name: no-name-27678559-b400-47bf-9010-bb013799f96b
[I 2025-09-17 13:17:37,210] Trial 0 finished with value: 0.9098039215686274 and parameters: {'num_leaves': 274, 'learning_rate': 0.044667566679949255, 'feature_fraction': 0.775527141926855, 'bagging_fraction': 0.8307996115042784, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 0 with value: 0.9098039215686274.
[I 2025-09-17 13:17:37,214] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 183, 'learning_rate': 0.23263564537981465, 'feature_fraction': 0.4643155996595517, 'bagging_fraction': 0.989477454675503, 'bagging_freq': 1, 'min_child_samples': 89}. Best is trial 0 with value: 0.9098039215686274.
[I 2025-09-17 13:17:37,292] Trial 2 finished with value: 0.9686274509803922 and parameters: {'num_leaves': 87, 'learning_rate': 0.1860794573072732, 'feature_fraction': 0.826062135573323, 'bagging_fraction': 0.8365296456543366, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 2 with value: 0.9686274509803922.
[I 2025-09-17 13:17:37,315] Trial 3 finished with value: 0.9529411764705882 and parameters: {'num_leaves': 267, 'learning_rate': 0.06465829444886875, 'feature_fraction': 0.716632528912853, 'bagging_fraction': 0.7573804297333211, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 2 with value: 0.9686274509803922.
[I 2025-09-17 13:17:37,354] Trial 4 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 202, 'learning_rate': 0.03401604956763957, 'feature_fraction': 0.562185674548866, 'bagging_fraction': 0.5504479518754066, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 4 with value: 0.9764705882352942.
[I 2025-09-17 13:17:37,379] Trial 5 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 44, 'learning_rate': 0.07908543589981035, 'feature_fraction': 0.7264132053905075, 'bagging_fraction': 0.4016685012300006, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,388] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 13, 'learning_rate': 0.25745091608277526, 'feature_fraction': 0.4799164912111683, 'bagging_fraction': 0.6711818033415312, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,552] Trial 7 finished with value: 0.9647058823529413 and parameters: {'num_leaves': 97, 'learning_rate': 0.0982482415322091, 'feature_fraction': 0.8411155063970266, 'bagging_fraction': 0.9312039782610669, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,571] Trial 8 finished with value: 0.803921568627451 and parameters: {'num_leaves': 192, 'learning_rate': 0.11514558643129462, 'feature_fraction': 0.4215233288480269, 'bagging_fraction': 0.4499573556373341, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,580] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 105, 'learning_rate': 0.22655818606142375, 'feature_fraction': 0.8964172824096582, 'bagging_fraction': 0.7570822633905665, 'bagging_freq': 4, 'min_child_samples': 68}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,593] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 12, 'learning_rate': 0.1534268819476777, 'feature_fraction': 0.9743264155677122, 'bagging_fraction': 0.4096017639461503, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,623] Trial 11 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 223, 'learning_rate': 0.020823056549963713, 'feature_fraction': 0.6065926688948429, 'bagging_fraction': 0.5535826853612902, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,648] Trial 12 finished with value: 0.9431372549019608 and parameters: {'num_leaves': 145, 'learning_rate': 0.012480104347609808, 'feature_fraction': 0.5961743209584214, 'bagging_fraction': 0.5593359769406279, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,675] Trial 13 finished with value: 0.9725490196078431 and parameters: {'num_leaves': 62, 'learning_rate': 0.08505264111432372, 'feature_fraction': 0.5946640642258822, 'bagging_fraction': 0.5262983633339586, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,687] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 147, 'learning_rate': 0.1410115301156195, 'feature_fraction': 0.6740271838339248, 'bagging_fraction': 0.48530604534364097, 'bagging_freq': 6, 'min_child_samples': 58}. Best is trial 5 with value: 0.9803921568627452.
[I 2025-09-17 13:17:37,734] Trial 15 finished with value: 1.0 and parameters: {'num_leaves': 229, 'learning_rate': 0.056341873673727866, 'feature_fraction': 0.5232750469317838, 'bagging_fraction': 0.6100329403805319, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:37,747] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 243, 'learning_rate': 0.29564382247291787, 'feature_fraction': 0.7152255478531111, 'bagging_fraction': 0.6470657211809886, 'bagging_freq': 3, 'min_child_samples': 69}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:37,772] Trial 17 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 294, 'learning_rate': 0.07105859249102485, 'feature_fraction': 0.5098673889444097, 'bagging_fraction': 0.6424235827132587, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 15 with value: 1.0.
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.397919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.358005
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.530652
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.41872
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.354431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.423707
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.654369
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.370796
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.311262
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.352823
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.378404
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.334255
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.416669
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.403246
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.438716
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.341983
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.317609
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.385761
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.685897
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.344576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.385197
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.397336
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.330622
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.433161
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.342316
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.350981
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.319294
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.597482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.284149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.370501
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.343164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.407786
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.391781
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.431495
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.215742
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.366742
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.356617
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.285067
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.213047
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.528441
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.430844
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.503144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.305882
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.224861
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.368975
[I 2025-09-17 13:17:37,786] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 57, 'learning_rate': 0.12325562715677067, 'feature_fraction': 0.6538277554458921, 'bagging_fraction': 0.6079956593020828, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:37,822] Trial 19 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 163, 'learning_rate': 0.18973404685955558, 'feature_fraction': 0.7590042471927533, 'bagging_fraction': 0.4036672283064797, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:37,894] Trial 20 finished with value: 1.0 and parameters: {'num_leaves': 160, 'learning_rate': 0.19081020215821307, 'feature_fraction': 0.5278974158244556, 'bagging_fraction': 0.7197502749159442, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:37,960] Trial 21 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 168, 'learning_rate': 0.18317752915690697, 'feature_fraction': 0.4056344282664285, 'bagging_fraction': 0.7246624325968637, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:37,990] Trial 22 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 140, 'learning_rate': 0.18545720300814503, 'feature_fraction': 0.51670339403003, 'bagging_fraction': 0.7848739657470083, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,046] Trial 23 finished with value: 0.9764705882352941 and parameters: {'num_leaves': 122, 'learning_rate': 0.21367607010957695, 'feature_fraction': 0.5534036271393297, 'bagging_fraction': 0.6886876068250903, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,164] Trial 24 finished with value: 0.9686274509803923 and parameters: {'num_leaves': 217, 'learning_rate': 0.16622654863842407, 'feature_fraction': 0.7847995701282147, 'bagging_fraction': 0.6045607449325612, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,191] Trial 25 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 166, 'learning_rate': 0.204836592625511, 'feature_fraction': 0.6400573808824424, 'bagging_fraction': 0.4713432531419588, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,266] Trial 26 finished with value: 1.0 and parameters: {'num_leaves': 246, 'learning_rate': 0.2522186532011493, 'feature_fraction': 0.45756103209371474, 'bagging_fraction': 0.8567596180400292, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,290] Trial 27 finished with value: 0.9490196078431372 and parameters: {'num_leaves': 244, 'learning_rate': 0.26067226749778627, 'feature_fraction': 0.43825778637579194, 'bagging_fraction': 0.8881903441728158, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,362] Trial 28 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 230, 'learning_rate': 0.28653965198085085, 'feature_fraction': 0.5172579748868703, 'bagging_fraction': 0.8178332068067736, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,388] Trial 29 finished with value: 0.9098039215686274 and parameters: {'num_leaves': 262, 'learning_rate': 0.24842135844580535, 'feature_fraction': 0.4610653943011471, 'bagging_fraction': 0.8417969812939542, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,428] Trial 30 finished with value: 0.996078431372549 and parameters: {'num_leaves': 290, 'learning_rate': 0.2717428089543455, 'feature_fraction': 0.5524563470327629, 'bagging_fraction': 0.9093433681203268, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,472] Trial 31 finished with value: 1.0 and parameters: {'num_leaves': 284, 'learning_rate': 0.27656941379022665, 'feature_fraction': 0.5555447542187076, 'bagging_fraction': 0.9127691502419262, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,556] Trial 32 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 277, 'learning_rate': 0.24119953859900897, 'feature_fraction': 0.4880553951589738, 'bagging_fraction': 0.9732011452152391, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,620] Trial 33 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 262, 'learning_rate': 0.2796787369534691, 'feature_fraction': 0.44427207985123784, 'bagging_fraction': 0.8711591285184663, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,657] Trial 34 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 249, 'learning_rate': 0.22212531816987358, 'feature_fraction': 0.5310786415135351, 'bagging_fraction': 0.9605977767525075, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,693] Trial 35 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 198, 'learning_rate': 0.29759310123445226, 'feature_fraction': 0.6240145165483525, 'bagging_fraction': 0.7254601318302747, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,758] Trial 36 finished with value: 1.0 and parameters: {'num_leaves': 212, 'learning_rate': 0.04824128980454319, 'feature_fraction': 0.5737338795528073, 'bagging_fraction': 0.8025570246142825, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,843] Trial 37 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 280, 'learning_rate': 0.2693023363402722, 'feature_fraction': 0.48131386522408176, 'bagging_fraction': 0.7526785181647777, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,955] Trial 38 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 178, 'learning_rate': 0.2470368527943198, 'feature_fraction': 0.6727976046621099, 'bagging_fraction': 0.9956226597741393, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:38,987] Trial 39 finished with value: 0.996078431372549 and parameters: {'num_leaves': 238, 'learning_rate': 0.20144312066756503, 'feature_fraction': 0.46325153615470765, 'bagging_fraction': 0.9487678216905087, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,043] Trial 40 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 260, 'learning_rate': 0.23811933066947527, 'feature_fraction': 0.4047355661572337, 'bagging_fraction': 0.843691501715934, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,102] Trial 41 finished with value: 0.996078431372549 and parameters: {'num_leaves': 212, 'learning_rate': 0.05991080435632039, 'feature_fraction': 0.5755580464501414, 'bagging_fraction': 0.7968210325136929, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,207] Trial 42 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 185, 'learning_rate': 0.035824359019843044, 'feature_fraction': 0.5466615660559496, 'bagging_fraction': 0.8613820189069723, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,244] Trial 43 finished with value: 0.996078431372549 and parameters: {'num_leaves': 212, 'learning_rate': 0.056448888974284905, 'feature_fraction': 0.49964357256799896, 'bagging_fraction': 0.9244418226168069, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,302] Trial 44 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 228, 'learning_rate': 0.09852691397383972, 'feature_fraction': 0.5672753833075602, 'bagging_fraction': 0.793949066977543, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,340] Trial 45 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 198, 'learning_rate': 0.12815641430877844, 'feature_fraction': 0.5885160882305818, 'bagging_fraction': 0.8183756822659553, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,351] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 253, 'learning_rate': 0.05027804099199541, 'feature_fraction': 0.6203989179959006, 'bagging_fraction': 0.889192064191853, 'bagging_freq': 1, 'min_child_samples': 71}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,455] Trial 47 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 282, 'learning_rate': 0.10039752042051493, 'feature_fraction': 0.5384707138734093, 'bagging_fraction': 0.726182525969646, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,468] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.035551000106331436, 'feature_fraction': 0.46237531881532173, 'bagging_fraction': 0.5964463903346052, 'bagging_freq': 3, 'min_child_samples': 86}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:39,503] Trial 49 finished with value: 0.996078431372549 and parameters: {'num_leaves': 126, 'learning_rate': 0.14968645186423205, 'feature_fraction': 0.5072332107742077, 'bagging_fraction': 0.652543231249106, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:17:40,004] A new study created in memory with name: no-name-9d5c91fa-960f-447d-8e6e-9389fac2212f
[I 2025-09-17 13:17:40,012] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.2855919070894398, 'feature_fraction': 0.9517061859468874, 'bagging_fraction': 0.481454487852868, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:40,020] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 267, 'learning_rate': 0.14601685315172697, 'feature_fraction': 0.9317930006504057, 'bagging_fraction': 0.4191431505696438, 'bagging_freq': 5, 'min_child_samples': 74}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:40,027] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 257, 'learning_rate': 0.1830011580151236, 'feature_fraction': 0.7632963068976821, 'bagging_fraction': 0.8745509707640873, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:40,035] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 101, 'learning_rate': 0.08763707323631563, 'feature_fraction': 0.5943165628162266, 'bagging_fraction': 0.9207571485938886, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:40,042] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 18, 'learning_rate': 0.09193381839605261, 'feature_fraction': 0.6433394534972033, 'bagging_fraction': 0.6464122309129603, 'bagging_freq': 4, 'min_child_samples': 89}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:40,091] Trial 5 finished with value: 0.9686274509803923 and parameters: {'num_leaves': 171, 'learning_rate': 0.021046954082134757, 'feature_fraction': 0.8103706887174862, 'bagging_fraction': 0.5333984305741571, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 5 with value: 0.9686274509803923.
[I 2025-09-17 13:17:40,145] Trial 6 finished with value: 0.9607843137254903 and parameters: {'num_leaves': 252, 'learning_rate': 0.17714805025601307, 'feature_fraction': 0.5324440866539819, 'bagging_fraction': 0.7167169085835078, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 5 with value: 0.9686274509803923.
[I 2025-09-17 13:17:40,153] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 262, 'learning_rate': 0.2386272349650996, 'feature_fraction': 0.7017277271521973, 'bagging_fraction': 0.4343666921715571, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 5 with value: 0.9686274509803923.
[I 2025-09-17 13:17:40,212] Trial 8 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 296, 'learning_rate': 0.23780053473182566, 'feature_fraction': 0.869929731073445, 'bagging_fraction': 0.653721895157749, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,221] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.038107885834819964, 'feature_fraction': 0.4958574169991419, 'bagging_fraction': 0.4310371551249871, 'bagging_freq': 4, 'min_child_samples': 88}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,244] Trial 10 finished with value: 0.9686274509803922 and parameters: {'num_leaves': 192, 'learning_rate': 0.29319482923928186, 'feature_fraction': 0.8692462212755778, 'bagging_fraction': 0.7465532105537502, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,339] Trial 11 finished with value: 0.9686274509803923 and parameters: {'num_leaves': 188, 'learning_rate': 0.029970579154996346, 'feature_fraction': 0.8035255014947276, 'bagging_fraction': 0.5833256754055081, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,367] Trial 12 finished with value: 0.9647058823529413 and parameters: {'num_leaves': 69, 'learning_rate': 0.22927279511503762, 'feature_fraction': 0.7983149779454256, 'bagging_fraction': 0.5416231916112189, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,398] Trial 13 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 201, 'learning_rate': 0.11326385264387322, 'feature_fraction': 0.9889030879155251, 'bagging_fraction': 0.8080394560093003, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,493] Trial 14 finished with value: 0.9686274509803923 and parameters: {'num_leaves': 147, 'learning_rate': 0.22069608592854592, 'feature_fraction': 0.8472612764197976, 'bagging_fraction': 0.6125062129135666, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,510] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 225, 'learning_rate': 0.05508652194662905, 'feature_fraction': 0.7288124319291427, 'bagging_fraction': 0.5293024846107041, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,562] Trial 16 finished with value: 0.9490196078431373 and parameters: {'num_leaves': 64, 'learning_rate': 0.1362882130751157, 'feature_fraction': 0.41588057112742266, 'bagging_fraction': 0.6407979890924569, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,575] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 294, 'learning_rate': 0.012675544779398354, 'feature_fraction': 0.8901423240865532, 'bagging_fraction': 0.794613060133143, 'bagging_freq': 2, 'min_child_samples': 100}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,610] Trial 18 finished with value: 0.9764705882352941 and parameters: {'num_leaves': 167, 'learning_rate': 0.2635888290991146, 'feature_fraction': 0.6515298913733676, 'bagging_fraction': 0.6911975134066243, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,658] Trial 19 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 117, 'learning_rate': 0.25936366996420496, 'feature_fraction': 0.6584116681429429, 'bagging_fraction': 0.975948946387506, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,683] Trial 20 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 117, 'learning_rate': 0.19906605090117796, 'feature_fraction': 0.6460845089392924, 'bagging_fraction': 0.9857722408767453, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,721] Trial 21 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 82, 'learning_rate': 0.26222095518507843, 'feature_fraction': 0.5975389261979321, 'bagging_fraction': 0.6807049707004439, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,764] Trial 22 finished with value: 0.9686274509803923 and parameters: {'num_leaves': 41, 'learning_rate': 0.25418688608143325, 'feature_fraction': 0.668975862585618, 'bagging_fraction': 0.7762365259733432, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,789] Trial 23 finished with value: 0.9450980392156862 and parameters: {'num_leaves': 223, 'learning_rate': 0.27121756174014133, 'feature_fraction': 0.5736882232989686, 'bagging_fraction': 0.8537083636108731, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 8 with value: 0.9803921568627452.
[I 2025-09-17 13:17:40,833] Trial 24 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 153, 'learning_rate': 0.2092558479742213, 'feature_fraction': 0.7310817597281647, 'bagging_fraction': 0.6821863872985019, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 8 with value: 0.9803921568627452.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.202724
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.0914799
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.161299
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.192346
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.2056
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.238462
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.312117
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.121169
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.305901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.177438
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.383107
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.168157
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.140541
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.160572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.154436
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.182213
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.172623
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.210566
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.14608
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.261762
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.166709
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.168952
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.183756
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.200778
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.234174
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.174538
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.194921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.190581
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.202705
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.380954
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.301485
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.20647
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.302582
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.30888
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.288789
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.333568
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.24322
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.280652
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.251765
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.194452
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.306954
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.264118
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.208024
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.306295
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.219691
[I 2025-09-17 13:17:40,919] Trial 25 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 141, 'learning_rate': 0.2125796630964803, 'feature_fraction': 0.7430414735545542, 'bagging_fraction': 0.9988493523531041, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:40,952] Trial 26 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 100, 'learning_rate': 0.24109542269478224, 'feature_fraction': 0.7443807376967131, 'bagging_fraction': 0.9757550481723536, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:40,976] Trial 27 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 138, 'learning_rate': 0.1755264328504036, 'feature_fraction': 0.9110650869327266, 'bagging_fraction': 0.9327540104781367, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,056] Trial 28 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 120, 'learning_rate': 0.20759592946320662, 'feature_fraction': 0.8509843029844202, 'bagging_fraction': 0.9325281614825713, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,083] Trial 29 finished with value: 0.9019607843137255 and parameters: {'num_leaves': 91, 'learning_rate': 0.2940605392882669, 'feature_fraction': 0.9739040030447116, 'bagging_fraction': 0.8684843080542083, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,137] Trial 30 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 293, 'learning_rate': 0.27170023182879877, 'feature_fraction': 0.6939192356346695, 'bagging_fraction': 0.9735657045423616, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,244] Trial 31 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 125, 'learning_rate': 0.20044315466958512, 'feature_fraction': 0.8354105749055005, 'bagging_fraction': 0.9394998162549327, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,307] Trial 32 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 109, 'learning_rate': 0.15489440544163222, 'feature_fraction': 0.9382474562084948, 'bagging_fraction': 0.9044018476886382, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,438] Trial 33 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 171, 'learning_rate': 0.2185604991451761, 'feature_fraction': 0.7777089413679537, 'bagging_fraction': 0.8403628115152169, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,448] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 120, 'learning_rate': 0.19129360545943838, 'feature_fraction': 0.8747215329515985, 'bagging_fraction': 0.9936440094748762, 'bagging_freq': 7, 'min_child_samples': 68}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,514] Trial 35 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 65, 'learning_rate': 0.24598824942411518, 'feature_fraction': 0.7736595755657678, 'bagging_fraction': 0.8975975509765912, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,560] Trial 36 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 44, 'learning_rate': 0.27958653531478406, 'feature_fraction': 0.8335896341512833, 'bagging_fraction': 0.9514861518693402, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,601] Trial 37 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 10, 'learning_rate': 0.2770311164147902, 'feature_fraction': 0.9054137918841301, 'bagging_fraction': 0.9979193155165674, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,631] Trial 38 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 38, 'learning_rate': 0.2841378147570668, 'feature_fraction': 0.6992853304106258, 'bagging_fraction': 0.9483095028696055, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,654] Trial 39 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 38, 'learning_rate': 0.23171560243637634, 'feature_fraction': 0.8190547485028344, 'bagging_fraction': 0.8924604460785418, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,708] Trial 40 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 225, 'learning_rate': 0.2552839017684388, 'feature_fraction': 0.6077116130005232, 'bagging_fraction': 0.8250440051565293, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,791] Trial 41 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 142, 'learning_rate': 0.2142162577325729, 'feature_fraction': 0.8468444416835263, 'bagging_fraction': 0.951247946134574, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,877] Trial 42 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 85, 'learning_rate': 0.16962979204219364, 'feature_fraction': 0.9474038567371585, 'bagging_fraction': 0.916938800787116, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,906] Trial 43 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 157, 'learning_rate': 0.24778709814271738, 'feature_fraction': 0.7583162702356678, 'bagging_fraction': 0.7517831003687103, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,925] Trial 44 finished with value: 0.8058823529411765 and parameters: {'num_leaves': 244, 'learning_rate': 0.29578852268155953, 'feature_fraction': 0.789956609726404, 'bagging_fraction': 0.9535354085332685, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:41,984] Trial 45 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 184, 'learning_rate': 0.2377476643549845, 'feature_fraction': 0.8607300452174901, 'bagging_fraction': 0.8816865781311174, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 25 with value: 0.9882352941176471.
[I 2025-09-17 13:17:42,043] Trial 46 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 205, 'learning_rate': 0.23037064658685005, 'feature_fraction': 0.8159047981495932, 'bagging_fraction': 0.9649516241029158, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 46 with value: 0.9921568627450981.
[I 2025-09-17 13:17:42,085] Trial 47 finished with value: 0.9686274509803923 and parameters: {'num_leaves': 278, 'learning_rate': 0.2296494985240691, 'feature_fraction': 0.8155848439821398, 'bagging_fraction': 0.5886457594303397, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 46 with value: 0.9921568627450981.
[I 2025-09-17 13:17:42,099] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.23728061526911692, 'feature_fraction': 0.8972544607184998, 'bagging_fraction': 0.8727567729674497, 'bagging_freq': 3, 'min_child_samples': 76}. Best is trial 46 with value: 0.9921568627450981.
[I 2025-09-17 13:17:42,139] Trial 49 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 190, 'learning_rate': 0.13023724502563883, 'feature_fraction': 0.919081264666793, 'bagging_fraction': 0.6580674264132469, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 46 with value: 0.9921568627450981.
[I 2025-09-17 13:17:42,480] A new study created in memory with name: no-name-121eb9ad-2502-4a10-8fe4-b5b4c2631073
[I 2025-09-17 13:17:42,491] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 72, 'learning_rate': 0.011915158722234804, 'feature_fraction': 0.8560084111345027, 'bagging_fraction': 0.7700962128489313, 'bagging_freq': 6, 'min_child_samples': 58}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:42,511] Trial 1 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 252, 'learning_rate': 0.2747129774347513, 'feature_fraction': 0.9710495565416327, 'bagging_fraction': 0.6446359049238843, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 1 with value: 0.7619047619047619.
[I 2025-09-17 13:17:42,518] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 255, 'learning_rate': 0.1391504538638682, 'feature_fraction': 0.5214090812327826, 'bagging_fraction': 0.5125558378813893, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 1 with value: 0.7619047619047619.
[I 2025-09-17 13:17:42,529] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 102, 'learning_rate': 0.2585612840316922, 'feature_fraction': 0.8537701102148478, 'bagging_fraction': 0.5421448462399462, 'bagging_freq': 7, 'min_child_samples': 49}. Best is trial 1 with value: 0.7619047619047619.
[I 2025-09-17 13:17:42,545] Trial 4 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 25, 'learning_rate': 0.10431128537325411, 'feature_fraction': 0.9671691177747577, 'bagging_fraction': 0.41619367286847253, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 1 with value: 0.7619047619047619.
[I 2025-09-17 13:17:42,559] Trial 5 finished with value: 0.7996031746031745 and parameters: {'num_leaves': 266, 'learning_rate': 0.273461942310006, 'feature_fraction': 0.7600156861692062, 'bagging_fraction': 0.8463372793771695, 'bagging_freq': 5, 'min_child_samples': 51}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,574] Trial 6 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 30, 'learning_rate': 0.28554377382970275, 'feature_fraction': 0.9083939376965969, 'bagging_fraction': 0.5383098256725093, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,606] Trial 7 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 93, 'learning_rate': 0.26273971323747036, 'feature_fraction': 0.4414838021598646, 'bagging_fraction': 0.4062666631209217, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,637] Trial 8 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 82, 'learning_rate': 0.17530915864560515, 'feature_fraction': 0.6423311667117626, 'bagging_fraction': 0.8716701147847747, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,668] Trial 9 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 155, 'learning_rate': 0.04392911365870068, 'feature_fraction': 0.5355232152033402, 'bagging_fraction': 0.5319780382235894, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,677] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 296, 'learning_rate': 0.21155820856284235, 'feature_fraction': 0.7374819993411982, 'bagging_fraction': 0.9756791812933376, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,693] Trial 11 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 232, 'learning_rate': 0.21455935755532418, 'feature_fraction': 0.7126994808727436, 'bagging_fraction': 0.7031371844319085, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,776] Trial 12 finished with value: 0.6686507936507936 and parameters: {'num_leaves': 211, 'learning_rate': 0.29043525191170994, 'feature_fraction': 0.9838250660091317, 'bagging_fraction': 0.7985117856535731, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,787] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.22464054283303586, 'feature_fraction': 0.7919870309517497, 'bagging_fraction': 0.6545698311104063, 'bagging_freq': 5, 'min_child_samples': 76}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,813] Trial 14 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 187, 'learning_rate': 0.17748668775081378, 'feature_fraction': 0.6484657342589681, 'bagging_fraction': 0.9167368172002553, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,824] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 259, 'learning_rate': 0.2478192605725494, 'feature_fraction': 0.8019271014490277, 'bagging_fraction': 0.6617070952816001, 'bagging_freq': 5, 'min_child_samples': 69}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,835] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 158, 'learning_rate': 0.1045505453213749, 'feature_fraction': 0.9126120302055921, 'bagging_fraction': 0.8051650474362312, 'bagging_freq': 1, 'min_child_samples': 60}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,848] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 267, 'learning_rate': 0.2968205755607014, 'feature_fraction': 0.6261525374845389, 'bagging_fraction': 0.7384340699725014, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,869] Trial 18 finished with value: 0.6527777777777778 and parameters: {'num_leaves': 201, 'learning_rate': 0.2393611725938981, 'feature_fraction': 0.7736445023447265, 'bagging_fraction': 0.6203899628835682, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,928] Trial 19 finished with value: 0.6150793650793651 and parameters: {'num_leaves': 162, 'learning_rate': 0.1891445847513809, 'feature_fraction': 0.9211057150253011, 'bagging_fraction': 0.8623776080117787, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,956] Trial 20 finished with value: 0.75 and parameters: {'num_leaves': 232, 'learning_rate': 0.11737800430509931, 'feature_fraction': 0.5615903720893936, 'bagging_fraction': 0.9999188191196757, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,974] Trial 21 finished with value: 0.7341269841269843 and parameters: {'num_leaves': 193, 'learning_rate': 0.1816217755073481, 'feature_fraction': 0.6527920560538248, 'bagging_fraction': 0.9220518153075997, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:42,986] Trial 22 finished with value: 0.4920634920634921 and parameters: {'num_leaves': 182, 'learning_rate': 0.15817579233941484, 'feature_fraction': 0.5874833376345535, 'bagging_fraction': 0.8689530232961266, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:43,010] Trial 23 finished with value: 0.75 and parameters: {'num_leaves': 128, 'learning_rate': 0.06691328912906595, 'feature_fraction': 0.46636014371441514, 'bagging_fraction': 0.9250628437843502, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 5 with value: 0.7996031746031745.
[I 2025-09-17 13:17:43,029] Trial 24 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 234, 'learning_rate': 0.2769484378053948, 'feature_fraction': 0.6860458205791022, 'bagging_fraction': 0.5921963245534613, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 24 with value: 0.8134920634920635.
[I 2025-09-17 13:17:43,056] Trial 25 finished with value: 0.8154761904761905 and parameters: {'num_leaves': 233, 'learning_rate': 0.27288180488767133, 'feature_fraction': 0.6969769976473609, 'bagging_fraction': 0.5936433166152271, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,088] Trial 26 finished with value: 0.8095238095238094 and parameters: {'num_leaves': 227, 'learning_rate': 0.23545650947023775, 'feature_fraction': 0.705025791469482, 'bagging_fraction': 0.6038721869349158, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,117] Trial 27 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 225, 'learning_rate': 0.2350301138359323, 'feature_fraction': 0.6952013510256678, 'bagging_fraction': 0.5892753340708006, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,147] Trial 28 finished with value: 0.75 and parameters: {'num_leaves': 218, 'learning_rate': 0.2000516610146571, 'feature_fraction': 0.6914815195252769, 'bagging_fraction': 0.4688973836957907, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,174] Trial 29 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 285, 'learning_rate': 0.2530859086710816, 'feature_fraction': 0.8361756155977313, 'bagging_fraction': 0.5856917298583579, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,191] Trial 30 finished with value: 0.7321428571428572 and parameters: {'num_leaves': 132, 'learning_rate': 0.2986208179981625, 'feature_fraction': 0.6042101511287151, 'bagging_fraction': 0.4764960738655363, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,204] Trial 31 finished with value: 0.5 and parameters: {'num_leaves': 277, 'learning_rate': 0.2716606746197651, 'feature_fraction': 0.7495025516653966, 'bagging_fraction': 0.7273323295184274, 'bagging_freq': 6, 'min_child_samples': 54}. Best is trial 25 with value: 0.8154761904761905.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.168633
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.249292
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.380957
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.178546
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.427978
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.197718
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.180608
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.199513
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.24565
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.239434
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.214545
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.177498
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.227404
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.331957
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.201321
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.21126
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.234769
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.242975
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.544666
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.168194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.171669
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.224559
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.271959

2. Training models on reduced 49-feature dataset (user-wise normalized)...
Training model for P024... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.605008
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.59827
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.579767
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.59815
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.617331
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.595785
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.615388
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.574725
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.625195
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.588743
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.637456
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.67821
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.594493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.59751
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.596183
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.577081
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.562538
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.54369
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.613256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.585251
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.611219
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.600095
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:43,227] Trial 32 finished with value: 0.748015873015873 and parameters: {'num_leaves': 241, 'learning_rate': 0.2736217836765312, 'feature_fraction': 0.6800347562850536, 'bagging_fraction': 0.5981771059597485, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,265] Trial 33 finished with value: 0.7837301587301587 and parameters: {'num_leaves': 247, 'learning_rate': 0.2336804576726629, 'feature_fraction': 0.7486093909231879, 'bagging_fraction': 0.6810077051634591, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,282] Trial 34 finished with value: 0.7202380952380952 and parameters: {'num_leaves': 266, 'learning_rate': 0.27706459243488774, 'feature_fraction': 0.8211527481806236, 'bagging_fraction': 0.5620859427379631, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,294] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 210, 'learning_rate': 0.25808246402659196, 'feature_fraction': 0.7096523906876088, 'bagging_fraction': 0.49810548852966946, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,320] Trial 36 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 173, 'learning_rate': 0.27898977175855566, 'feature_fraction': 0.7761497610853804, 'bagging_fraction': 0.6231916325854455, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,330] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 248, 'learning_rate': 0.2600967816106762, 'feature_fraction': 0.6664958613606385, 'bagging_fraction': 0.6335447680666523, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,356] Trial 38 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 280, 'learning_rate': 0.21874231380681425, 'feature_fraction': 0.8685981484528179, 'bagging_fraction': 0.5618906408675703, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,367] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 46, 'learning_rate': 0.24380603208184715, 'feature_fraction': 0.7227820491895199, 'bagging_fraction': 0.4467479176073502, 'bagging_freq': 6, 'min_child_samples': 66}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,390] Trial 40 finished with value: 0.6706349206349207 and parameters: {'num_leaves': 128, 'learning_rate': 0.26716639253701757, 'feature_fraction': 0.6079681926372336, 'bagging_fraction': 0.5189102740872735, 'bagging_freq': 7, 'min_child_samples': 34}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,426] Trial 41 finished with value: 0.8035714285714285 and parameters: {'num_leaves': 249, 'learning_rate': 0.23273282832785272, 'feature_fraction': 0.7600947785462134, 'bagging_fraction': 0.6721703139591297, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,464] Trial 42 finished with value: 0.7063492063492064 and parameters: {'num_leaves': 239, 'learning_rate': 0.20482124342828928, 'feature_fraction': 0.7657569553786167, 'bagging_fraction': 0.6962258012050996, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,490] Trial 43 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 265, 'learning_rate': 0.28305749116220613, 'feature_fraction': 0.7284139119261617, 'bagging_fraction': 0.7802670218364316, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,579] Trial 44 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 221, 'learning_rate': 0.01230463166443943, 'feature_fraction': 0.8089766025521842, 'bagging_fraction': 0.7387498632011879, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,606] Trial 45 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 204, 'learning_rate': 0.22824330983429642, 'feature_fraction': 0.677771687294437, 'bagging_fraction': 0.6631295700055283, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,633] Trial 46 finished with value: 0.7757936507936508 and parameters: {'num_leaves': 290, 'learning_rate': 0.2484361602852454, 'feature_fraction': 0.8455475653638302, 'bagging_fraction': 0.5572155844870952, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,654] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 252, 'learning_rate': 0.28961857990897577, 'feature_fraction': 0.7475142174126715, 'bagging_fraction': 0.5980784079165773, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,761] Trial 48 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 233, 'learning_rate': 0.25859648285554854, 'feature_fraction': 0.7117018781130322, 'bagging_fraction': 0.8353133064916659, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:43,821] Trial 49 finished with value: 0.6825396825396826 and parameters: {'num_leaves': 229, 'learning_rate': 0.19316365249592743, 'feature_fraction': 0.6196948102798339, 'bagging_fraction': 0.8215778663904749, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 25 with value: 0.8154761904761905.
[I 2025-09-17 13:17:44,039] A new study created in memory with name: no-name-09cab40b-da4b-4395-bffe-c17b5ef87ac4
[I 2025-09-17 13:17:44,048] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 50, 'learning_rate': 0.1567216185009068, 'feature_fraction': 0.8849956994677246, 'bagging_fraction': 0.6603325133517295, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:44,075] Trial 1 finished with value: 0.75 and parameters: {'num_leaves': 33, 'learning_rate': 0.29857033508393427, 'feature_fraction': 0.9057253786715036, 'bagging_fraction': 0.6988466068410084, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 1 with value: 0.75.
[I 2025-09-17 13:17:44,082] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.24736254065185392, 'feature_fraction': 0.706874283224465, 'bagging_fraction': 0.4083885345176601, 'bagging_freq': 6, 'min_child_samples': 80}. Best is trial 1 with value: 0.75.
[I 2025-09-17 13:17:44,098] Trial 3 finished with value: 0.5714285714285714 and parameters: {'num_leaves': 184, 'learning_rate': 0.01872959129743519, 'feature_fraction': 0.7415312102471172, 'bagging_fraction': 0.7119261625182842, 'bagging_freq': 7, 'min_child_samples': 46}. Best is trial 1 with value: 0.75.
[I 2025-09-17 13:17:44,122] Trial 4 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 192, 'learning_rate': 0.058757523319134, 'feature_fraction': 0.9400735373363895, 'bagging_fraction': 0.7944326870749454, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,130] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 163, 'learning_rate': 0.04912061836125104, 'feature_fraction': 0.7436083778343932, 'bagging_fraction': 0.5626559164406358, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,170] Trial 6 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 24, 'learning_rate': 0.06939160131868485, 'feature_fraction': 0.5866049850916827, 'bagging_fraction': 0.5036691945416192, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,185] Trial 7 finished with value: 0.7083333333333334 and parameters: {'num_leaves': 90, 'learning_rate': 0.288698491110938, 'feature_fraction': 0.510546775636157, 'bagging_fraction': 0.6998118640851794, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,218] Trial 8 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 269, 'learning_rate': 0.13171498970362586, 'feature_fraction': 0.40167375056214616, 'bagging_fraction': 0.5621364435534754, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,226] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 122, 'learning_rate': 0.1299820591594254, 'feature_fraction': 0.6714723884980711, 'bagging_fraction': 0.8599311066956801, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,249] Trial 10 finished with value: 0.75 and parameters: {'num_leaves': 233, 'learning_rate': 0.19087370714791496, 'feature_fraction': 0.9758941903012577, 'bagging_fraction': 0.9610707789639519, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,281] Trial 11 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 290, 'learning_rate': 0.10818670657657908, 'feature_fraction': 0.4072413762189125, 'bagging_fraction': 0.8246789112456079, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,365] Trial 12 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 237, 'learning_rate': 0.07841902812761181, 'feature_fraction': 0.852869253459608, 'bagging_fraction': 0.5540601564695046, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 4 with value: 0.8412698412698413.
[I 2025-09-17 13:17:44,391] Trial 13 finished with value: 0.8531746031746031 and parameters: {'num_leaves': 295, 'learning_rate': 0.1762378558709466, 'feature_fraction': 0.4257796182178685, 'bagging_fraction': 0.8374136497223001, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,403] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.2018718022848558, 'feature_fraction': 0.5348599277874478, 'bagging_fraction': 0.8288490056146834, 'bagging_freq': 5, 'min_child_samples': 62}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,424] Trial 15 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 300, 'learning_rate': 0.18859963786107956, 'feature_fraction': 0.8136549552253661, 'bagging_fraction': 0.9876602237413752, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,436] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.2270176939088934, 'feature_fraction': 0.9912622568887572, 'bagging_fraction': 0.9058464647961009, 'bagging_freq': 6, 'min_child_samples': 65}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,479] Trial 17 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 132, 'learning_rate': 0.09789440583034996, 'feature_fraction': 0.6281005699668977, 'bagging_fraction': 0.765373752055584, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,501] Trial 18 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 205, 'learning_rate': 0.017620778584810065, 'feature_fraction': 0.4653776675441041, 'bagging_fraction': 0.7755196262641681, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,520] Trial 19 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 271, 'learning_rate': 0.14953588252049377, 'feature_fraction': 0.7838260920863327, 'bagging_fraction': 0.9227215089426053, 'bagging_freq': 6, 'min_child_samples': 48}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,548] Trial 20 finished with value: 0.8293650793650794 and parameters: {'num_leaves': 161, 'learning_rate': 0.16358798637576763, 'feature_fraction': 0.9342127816535731, 'bagging_fraction': 0.6387016416772445, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,574] Trial 21 finished with value: 0.8194444444444444 and parameters: {'num_leaves': 154, 'learning_rate': 0.16173123771041323, 'feature_fraction': 0.9341363709435808, 'bagging_fraction': 0.6314561250946522, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,657] Trial 22 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 184, 'learning_rate': 0.22557726538905593, 'feature_fraction': 0.8441777777449351, 'bagging_fraction': 0.771172144669489, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,680] Trial 23 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 108, 'learning_rate': 0.17459157441660905, 'feature_fraction': 0.9377506101372306, 'bagging_fraction': 0.8811104657061448, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,709] Trial 24 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 208, 'learning_rate': 0.12222918686199762, 'feature_fraction': 0.5880187075189961, 'bagging_fraction': 0.6368118524589348, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,739] Trial 25 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 220, 'learning_rate': 0.04397978689199229, 'feature_fraction': 0.5493968672758913, 'bagging_fraction': 0.7905623633570793, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,780] Trial 26 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 266, 'learning_rate': 0.11447841182143917, 'feature_fraction': 0.46337217178137624, 'bagging_fraction': 0.7333856653010504, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,797] Trial 27 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 185, 'learning_rate': 0.07862292038378574, 'feature_fraction': 0.6072566489433782, 'bagging_fraction': 0.8323370753080379, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,810] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 253, 'learning_rate': 0.13683559228739614, 'feature_fraction': 0.6689343015997112, 'bagging_fraction': 0.930196255516619, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,822] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 210, 'learning_rate': 0.0367611694541803, 'feature_fraction': 0.45927818512358976, 'bagging_fraction': 0.6602551280236972, 'bagging_freq': 4, 'min_child_samples': 80}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,887] Trial 30 finished with value: 0.7539682539682541 and parameters: {'num_leaves': 143, 'learning_rate': 0.09689115514469678, 'feature_fraction': 0.5783964344984853, 'bagging_fraction': 0.5982837356577908, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,917] Trial 31 finished with value: 0.7837301587301587 and parameters: {'num_leaves': 168, 'learning_rate': 0.15640471181141552, 'feature_fraction': 0.8933121246998255, 'bagging_fraction': 0.6380041351798562, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,943] Trial 32 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 192, 'learning_rate': 0.17306049327912415, 'feature_fraction': 0.93841599255889, 'bagging_fraction': 0.5001493659153606, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:44,971] Trial 33 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 48, 'learning_rate': 0.20339101593050782, 'feature_fraction': 0.8609371956221938, 'bagging_fraction': 0.7312205323774723, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,022] Trial 34 finished with value: 0.7698412698412698 and parameters: {'num_leaves': 173, 'learning_rate': 0.061569124501403755, 'feature_fraction': 0.7691357981092772, 'bagging_fraction': 0.6844534760514829, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,038] Trial 35 finished with value: 0.8273809523809524 and parameters: {'num_leaves': 151, 'learning_rate': 0.2661272519761986, 'feature_fraction': 0.707361274765226, 'bagging_fraction': 0.6132242049424598, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,060] Trial 36 finished with value: 0.6468253968253969 and parameters: {'num_leaves': 83, 'learning_rate': 0.2218138000204505, 'feature_fraction': 0.5076864393051914, 'bagging_fraction': 0.4017017410733493, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,086] Trial 37 finished with value: 0.8055555555555557 and parameters: {'num_leaves': 222, 'learning_rate': 0.12228061606065424, 'feature_fraction': 0.641707694755749, 'bagging_fraction': 0.5183243879118434, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,101] Trial 38 finished with value: 0.7182539682539681 and parameters: {'num_leaves': 111, 'learning_rate': 0.14306545040062135, 'feature_fraction': 0.9066150383883136, 'bagging_fraction': 0.6685050547499604, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,144] Trial 39 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 284, 'learning_rate': 0.16610778426563533, 'feature_fraction': 0.810625237113873, 'bagging_fraction': 0.7261932570813338, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,173] Trial 40 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 74, 'learning_rate': 0.09250717125310937, 'feature_fraction': 0.7486472366055288, 'bagging_fraction': 0.7999043093755579, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,200] Trial 41 finished with value: 0.8214285714285715 and parameters: {'num_leaves': 200, 'learning_rate': 0.013596656487045122, 'feature_fraction': 0.44870744321658973, 'bagging_fraction': 0.8553257598990529, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 13 with value: 0.8531746031746031.
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.600553
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.591219
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.619747
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.590902
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.606742
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.61223
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.578836
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.60695
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.574864
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.596694
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.606401
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.580114
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.526206
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.623792
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.590757
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.676421
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.588431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.598818
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.611739
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.54835
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.591727
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.58755
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.620553
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.561629
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.597401
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.558741
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.62524
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.632334
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.54509
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.558074
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.601597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.55914
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.575862
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.592827
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.568077
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.626982
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.580363
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.569483
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.547265
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.567719
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.576977
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.581541
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.607323
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.569461
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.64094
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.572142
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.585944
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.624017
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:45,231] Trial 42 finished with value: 0.8214285714285715 and parameters: {'num_leaves': 170, 'learning_rate': 0.03261032104738675, 'feature_fraction': 0.4173711100554934, 'bagging_fraction': 0.7476481923769324, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,245] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 226, 'learning_rate': 0.025213059924318, 'feature_fraction': 0.44006307632216507, 'bagging_fraction': 0.6969368523483034, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,280] Trial 44 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 215, 'learning_rate': 0.05225334112161879, 'feature_fraction': 0.493656571003426, 'bagging_fraction': 0.7933429698335648, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,300] Trial 45 finished with value: 0.7658730158730159 and parameters: {'num_leaves': 198, 'learning_rate': 0.1851860571935387, 'feature_fraction': 0.554647499120806, 'bagging_fraction': 0.46717058103509956, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,321] Trial 46 finished with value: 0.7261904761904763 and parameters: {'num_leaves': 245, 'learning_rate': 0.013624879853552, 'feature_fraction': 0.47919029374801425, 'bagging_fraction': 0.5857345532985377, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,339] Trial 47 finished with value: 0.8194444444444444 and parameters: {'num_leaves': 127, 'learning_rate': 0.07298943970806376, 'feature_fraction': 0.9618864872756235, 'bagging_fraction': 0.864776718685661, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,391] Trial 48 finished with value: 0.6825396825396826 and parameters: {'num_leaves': 176, 'learning_rate': 0.05549498714406315, 'feature_fraction': 0.5788895394620373, 'bagging_fraction': 0.7611776923914925, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,423] Trial 49 finished with value: 0.7857142857142856 and parameters: {'num_leaves': 137, 'learning_rate': 0.21119902354098835, 'feature_fraction': 0.9995802211700743, 'bagging_fraction': 0.8126426999682849, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 13 with value: 0.8531746031746031.
[I 2025-09-17 13:17:45,802] A new study created in memory with name: no-name-ad992e20-5832-4851-ad79-5944ff3a364d
[I 2025-09-17 13:17:45,810] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 53, 'learning_rate': 0.18672076205887558, 'feature_fraction': 0.4712471097659775, 'bagging_fraction': 0.5719159785789838, 'bagging_freq': 7, 'min_child_samples': 89}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:45,833] Trial 1 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 120, 'learning_rate': 0.15869815147059593, 'feature_fraction': 0.512664649210062, 'bagging_fraction': 0.4848415500041026, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 1 with value: 0.8134920634920635.
[I 2025-09-17 13:17:45,875] Trial 2 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 203, 'learning_rate': 0.09693663934891628, 'feature_fraction': 0.6858556216487679, 'bagging_fraction': 0.863407999587988, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 1 with value: 0.8134920634920635.
[I 2025-09-17 13:17:45,888] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 130, 'learning_rate': 0.057439075115200584, 'feature_fraction': 0.5513967763115084, 'bagging_fraction': 0.4346063568572644, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 1 with value: 0.8134920634920635.
[I 2025-09-17 13:17:45,895] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 18, 'learning_rate': 0.19943068369266165, 'feature_fraction': 0.9289866675041395, 'bagging_fraction': 0.8376444208155427, 'bagging_freq': 7, 'min_child_samples': 95}. Best is trial 1 with value: 0.8134920634920635.
[I 2025-09-17 13:17:45,911] Trial 5 finished with value: 0.8253968253968256 and parameters: {'num_leaves': 129, 'learning_rate': 0.1528008494833815, 'feature_fraction': 0.5810810072679932, 'bagging_fraction': 0.40027896988472433, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 5 with value: 0.8253968253968256.
[I 2025-09-17 13:17:45,924] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 89, 'learning_rate': 0.11854158809384506, 'feature_fraction': 0.882827172564818, 'bagging_fraction': 0.7314350502962246, 'bagging_freq': 5, 'min_child_samples': 71}. Best is trial 5 with value: 0.8253968253968256.
[I 2025-09-17 13:17:45,933] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 296, 'learning_rate': 0.2472700329102159, 'feature_fraction': 0.6586353838323433, 'bagging_fraction': 0.653076529548918, 'bagging_freq': 7, 'min_child_samples': 92}. Best is trial 5 with value: 0.8253968253968256.
[I 2025-09-17 13:17:45,982] Trial 8 finished with value: 0.861111111111111 and parameters: {'num_leaves': 91, 'learning_rate': 0.17791889324969046, 'feature_fraction': 0.765757268397758, 'bagging_fraction': 0.9238798945494959, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:45,995] Trial 9 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 184, 'learning_rate': 0.16127778161066364, 'feature_fraction': 0.8041840701076697, 'bagging_fraction': 0.8164829212854792, 'bagging_freq': 5, 'min_child_samples': 57}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,014] Trial 10 finished with value: 0.7976190476190476 and parameters: {'num_leaves': 252, 'learning_rate': 0.2956704558768486, 'feature_fraction': 0.8058847897310095, 'bagging_fraction': 0.9975296634210282, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,186] Trial 11 finished with value: 0.76984126984127 and parameters: {'num_leaves': 78, 'learning_rate': 0.019198051368857355, 'feature_fraction': 0.6562931945980632, 'bagging_fraction': 0.9988652417718835, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,205] Trial 12 finished with value: 0.8174603174603176 and parameters: {'num_leaves': 161, 'learning_rate': 0.2227901487545513, 'feature_fraction': 0.5617245012483706, 'bagging_fraction': 0.5633585714063932, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,231] Trial 13 finished with value: 0.8452380952380953 and parameters: {'num_leaves': 99, 'learning_rate': 0.11350576783471263, 'feature_fraction': 0.7531193517165905, 'bagging_fraction': 0.7110129253914106, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,255] Trial 14 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 16, 'learning_rate': 0.10442357146906027, 'feature_fraction': 0.7692560277981337, 'bagging_fraction': 0.9106902527857795, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,325] Trial 15 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 82, 'learning_rate': 0.07055045163125884, 'feature_fraction': 0.7612063456328393, 'bagging_fraction': 0.7358160659447869, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,337] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 65, 'learning_rate': 0.13347875036134704, 'feature_fraction': 0.9814703538807594, 'bagging_fraction': 0.6277441823565658, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,358] Trial 17 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 109, 'learning_rate': 0.2535392287611124, 'feature_fraction': 0.8736400781419759, 'bagging_fraction': 0.759150714735288, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,379] Trial 18 finished with value: 0.757936507936508 and parameters: {'num_leaves': 48, 'learning_rate': 0.07105610977405874, 'feature_fraction': 0.40286299005063403, 'bagging_fraction': 0.9517205268109328, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,405] Trial 19 finished with value: 0.7757936507936508 and parameters: {'num_leaves': 160, 'learning_rate': 0.010731733639874563, 'feature_fraction': 0.7195478353285097, 'bagging_fraction': 0.7914184976842565, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,442] Trial 20 finished with value: 0.7499999999999999 and parameters: {'num_leaves': 207, 'learning_rate': 0.1781860129848078, 'feature_fraction': 0.6238139225870035, 'bagging_fraction': 0.8981846647345826, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,464] Trial 21 finished with value: 0.7658730158730159 and parameters: {'num_leaves': 137, 'learning_rate': 0.13592334944515846, 'feature_fraction': 0.6076463728606998, 'bagging_fraction': 0.41168604662964825, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,490] Trial 22 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 105, 'learning_rate': 0.20974376498764088, 'feature_fraction': 0.7397143327843907, 'bagging_fraction': 0.6824536205872087, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,507] Trial 23 finished with value: 0.755952380952381 and parameters: {'num_leaves': 149, 'learning_rate': 0.1477841139299062, 'feature_fraction': 0.8384116519513267, 'bagging_fraction': 0.5439116899151933, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,528] Trial 24 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 106, 'learning_rate': 0.17190062275847612, 'feature_fraction': 0.6983742911341099, 'bagging_fraction': 0.5109741413964544, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,577] Trial 25 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 180, 'learning_rate': 0.09770155537713042, 'feature_fraction': 0.5807180153157474, 'bagging_fraction': 0.6307230978316083, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,589] Trial 26 finished with value: 0.5 and parameters: {'num_leaves': 88, 'learning_rate': 0.1247867252717855, 'feature_fraction': 0.7943484355891782, 'bagging_fraction': 0.4782090943799123, 'bagging_freq': 7, 'min_child_samples': 72}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,609] Trial 27 finished with value: 0.8373015873015873 and parameters: {'num_leaves': 37, 'learning_rate': 0.23297395698629708, 'feature_fraction': 0.6437813486333888, 'bagging_fraction': 0.6894188162430374, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,627] Trial 28 finished with value: 0.6567460317460317 and parameters: {'num_leaves': 36, 'learning_rate': 0.23403437739396996, 'feature_fraction': 0.6458314680305648, 'bagging_fraction': 0.6850718283007045, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,643] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 41, 'learning_rate': 0.2845621956165174, 'feature_fraction': 0.8525006852307534, 'bagging_fraction': 0.6057507781928275, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,666] Trial 30 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 62, 'learning_rate': 0.2727631640060031, 'feature_fraction': 0.9203758611522443, 'bagging_fraction': 0.7622683115151637, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,690] Trial 31 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 67, 'learning_rate': 0.19288402037293917, 'feature_fraction': 0.4945640838629981, 'bagging_fraction': 0.5838477151430165, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,719] Trial 32 finished with value: 0.8412698412698414 and parameters: {'num_leaves': 29, 'learning_rate': 0.19448682589327765, 'feature_fraction': 0.4668757263836349, 'bagging_fraction': 0.5927256120510778, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,756] Trial 33 finished with value: 0.7777777777777777 and parameters: {'num_leaves': 31, 'learning_rate': 0.21656449387941432, 'feature_fraction': 0.43796931676720685, 'bagging_fraction': 0.7101951811623303, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 8 with value: 0.861111111111111.
[I 2025-09-17 13:17:46,805] Trial 34 finished with value: 0.8611111111111112 and parameters: {'num_leaves': 11, 'learning_rate': 0.1881681287522745, 'feature_fraction': 0.5229382159666691, 'bagging_fraction': 0.5433615797032371, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 34 with value: 0.8611111111111112.
[I 2025-09-17 13:17:46,846] Trial 35 finished with value: 0.8412698412698412 and parameters: {'num_leaves': 14, 'learning_rate': 0.1848060446190165, 'feature_fraction': 0.5185157847137861, 'bagging_fraction': 0.5217786953343304, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 34 with value: 0.8611111111111112.
[I 2025-09-17 13:17:46,890] Trial 36 finished with value: 0.880952380952381 and parameters: {'num_leaves': 57, 'learning_rate': 0.1667220441620954, 'feature_fraction': 0.45118016773560643, 'bagging_fraction': 0.49180162307825936, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:46,930] Trial 37 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 56, 'learning_rate': 0.16918687923016218, 'feature_fraction': 0.5293044813900841, 'bagging_fraction': 0.47068150385771945, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,019] Trial 38 finished with value: 0.8373015873015872 and parameters: {'num_leaves': 99, 'learning_rate': 0.14707044510622638, 'feature_fraction': 0.45538969599153445, 'bagging_fraction': 0.4566128300138032, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,074] Trial 39 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 124, 'learning_rate': 0.2057892239676741, 'feature_fraction': 0.4311652548021447, 'bagging_fraction': 0.8547424446200372, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,086] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 76, 'learning_rate': 0.16170437317078948, 'feature_fraction': 0.6939186897993618, 'bagging_fraction': 0.5166078871854223, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,115] Trial 41 finished with value: 0.7896825396825398 and parameters: {'num_leaves': 28, 'learning_rate': 0.19542226727329853, 'feature_fraction': 0.48182211627278815, 'bagging_fraction': 0.5813241470466749, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,155] Trial 42 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 23, 'learning_rate': 0.1872838018462007, 'feature_fraction': 0.4009842126664119, 'bagging_fraction': 0.44363028348887357, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,209] Trial 43 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 48, 'learning_rate': 0.11762930758516238, 'feature_fraction': 0.4729973882496295, 'bagging_fraction': 0.5502747966339343, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,241] Trial 44 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 11, 'learning_rate': 0.153654203528587, 'feature_fraction': 0.5398418952002225, 'bagging_fraction': 0.4958927791353247, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,288] Trial 45 finished with value: 0.8214285714285715 and parameters: {'num_leaves': 53, 'learning_rate': 0.08245208276276048, 'feature_fraction': 0.7401911214667695, 'bagging_fraction': 0.6614348853277251, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,388] Trial 46 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 93, 'learning_rate': 0.175573082124888, 'feature_fraction': 0.4939891979005062, 'bagging_fraction': 0.598883847579296, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,474] Trial 47 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 90, 'learning_rate': 0.11003356010543783, 'feature_fraction': 0.4978133862086125, 'bagging_fraction': 0.5354780254468331, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,502] Trial 48 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 115, 'learning_rate': 0.13570375917942124, 'feature_fraction': 0.5654017764323777, 'bagging_fraction': 0.6269870986420654, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,569] Trial 49 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 140, 'learning_rate': 0.16710223407776112, 'feature_fraction': 0.6048843144827409, 'bagging_fraction': 0.960625842008481, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 36 with value: 0.880952380952381.
[I 2025-09-17 13:17:47,981] A new study created in memory with name: no-name-394ff347-dbaa-4912-9048-9e647a1b4cb4
[I 2025-09-17 13:17:48,011] Trial 0 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 194, 'learning_rate': 0.08710254733966229, 'feature_fraction': 0.7472048290208657, 'bagging_fraction': 0.8825384713021446, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 0 with value: 0.8412698412698413.
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.604184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.587696
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.624476
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.659577
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.608584
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.609199
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.56283
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.553983
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.580043
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.512588
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.444768
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.649757
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.55286
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.597686
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.513548
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.46988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.542309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.510845
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.572404
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.598816
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.60139
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.582337
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.558302
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.580992
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.648808
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.543733
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.529022
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.492216
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.639013
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.523954
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.535747
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.527822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.56135
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.447977
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.50488
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.476318
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.500643
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.507933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.542376
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.539457
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.534613
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.543988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.555943
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.522066
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.502398
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.549795
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.524609
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.55839
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.538163
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:48,021] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 62, 'learning_rate': 0.07010169965107854, 'feature_fraction': 0.691861266415941, 'bagging_fraction': 0.48662167537511786, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 0 with value: 0.8412698412698413.
[I 2025-09-17 13:17:48,033] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 36, 'learning_rate': 0.25720385450242234, 'feature_fraction': 0.809026311433774, 'bagging_fraction': 0.6390652284020848, 'bagging_freq': 2, 'min_child_samples': 51}. Best is trial 0 with value: 0.8412698412698413.
[I 2025-09-17 13:17:48,057] Trial 3 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 243, 'learning_rate': 0.13943685707987374, 'feature_fraction': 0.6567899464947352, 'bagging_fraction': 0.5453224543586397, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 0 with value: 0.8412698412698413.
[I 2025-09-17 13:17:48,064] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 280, 'learning_rate': 0.019873766711036613, 'feature_fraction': 0.7647862850076323, 'bagging_fraction': 0.6851667558079307, 'bagging_freq': 1, 'min_child_samples': 49}. Best is trial 0 with value: 0.8412698412698413.
[I 2025-09-17 13:17:48,086] Trial 5 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 277, 'learning_rate': 0.11656915048093112, 'feature_fraction': 0.8454468770608083, 'bagging_fraction': 0.5271240152045809, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 0 with value: 0.8412698412698413.
[I 2025-09-17 13:17:48,102] Trial 6 finished with value: 0.7857142857142858 and parameters: {'num_leaves': 34, 'learning_rate': 0.25698996459871426, 'feature_fraction': 0.9949641133605557, 'bagging_fraction': 0.839197007363052, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 0 with value: 0.8412698412698413.
[I 2025-09-17 13:17:48,129] Trial 7 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 76, 'learning_rate': 0.1684747803684678, 'feature_fraction': 0.968533450204161, 'bagging_fraction': 0.5946348782739052, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,142] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 220, 'learning_rate': 0.0894945003216803, 'feature_fraction': 0.9111813209095386, 'bagging_fraction': 0.8165491988901692, 'bagging_freq': 7, 'min_child_samples': 70}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,206] Trial 9 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 164, 'learning_rate': 0.14933649562677173, 'feature_fraction': 0.8694187260275797, 'bagging_fraction': 0.5094724570990365, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,216] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 94, 'learning_rate': 0.21064445718583627, 'feature_fraction': 0.4633095209869047, 'bagging_fraction': 0.9792093014645048, 'bagging_freq': 3, 'min_child_samples': 99}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,263] Trial 11 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 130, 'learning_rate': 0.17665044940396823, 'feature_fraction': 0.9821826539054985, 'bagging_fraction': 0.4028720915671355, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,326] Trial 12 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 154, 'learning_rate': 0.188045882184975, 'feature_fraction': 0.895289692507963, 'bagging_fraction': 0.6121354904063303, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,340] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 109, 'learning_rate': 0.22443673395225905, 'feature_fraction': 0.49391565822712624, 'bagging_fraction': 0.4263015028785951, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,434] Trial 14 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 173, 'learning_rate': 0.15871758457580218, 'feature_fraction': 0.5992716105402273, 'bagging_fraction': 0.7351228042245406, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,464] Trial 15 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 81, 'learning_rate': 0.295977900474507, 'feature_fraction': 0.9215154713893321, 'bagging_fraction': 0.5929427733967347, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,482] Trial 16 finished with value: 0.6924603174603174 and parameters: {'num_leaves': 137, 'learning_rate': 0.13119128271421507, 'feature_fraction': 0.8486962118607199, 'bagging_fraction': 0.480616849406504, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,531] Trial 17 finished with value: 0.7936507936507936 and parameters: {'num_leaves': 189, 'learning_rate': 0.013990662637214407, 'feature_fraction': 0.9456566348947619, 'bagging_fraction': 0.7470413522737802, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,543] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.20165566762392034, 'feature_fraction': 0.588673059205984, 'bagging_fraction': 0.5542404218585413, 'bagging_freq': 3, 'min_child_samples': 69}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,566] Trial 19 finished with value: 0.746031746031746 and parameters: {'num_leaves': 120, 'learning_rate': 0.16092880103349866, 'feature_fraction': 0.8564181085775149, 'bagging_fraction': 0.664779414710214, 'bagging_freq': 6, 'min_child_samples': 42}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,618] Trial 20 finished with value: 0.757936507936508 and parameters: {'num_leaves': 68, 'learning_rate': 0.04887947197218427, 'feature_fraction': 0.4024000058249139, 'bagging_fraction': 0.4677493975800727, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,653] Trial 21 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 135, 'learning_rate': 0.18120704509118973, 'feature_fraction': 0.9834367084330333, 'bagging_fraction': 0.4231392631971554, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,725] Trial 22 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 161, 'learning_rate': 0.172562532344314, 'feature_fraction': 0.9584920388323249, 'bagging_fraction': 0.4204222847906407, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,747] Trial 23 finished with value: 0.873015873015873 and parameters: {'num_leaves': 165, 'learning_rate': 0.23597964597091858, 'feature_fraction': 0.9475636326175719, 'bagging_fraction': 0.5742265718714877, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,769] Trial 24 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 222, 'learning_rate': 0.23731030639895168, 'feature_fraction': 0.9331456379131067, 'bagging_fraction': 0.5884253194386573, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 7 with value: 0.8928571428571429.
[I 2025-09-17 13:17:48,800] Trial 25 finished with value: 0.9087301587301587 and parameters: {'num_leaves': 197, 'learning_rate': 0.2671947079630841, 'feature_fraction': 0.7871615957888192, 'bagging_fraction': 0.736423799374471, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:48,827] Trial 26 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 206, 'learning_rate': 0.2985432983291966, 'feature_fraction': 0.7627283671514655, 'bagging_fraction': 0.7363151157335466, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:48,844] Trial 27 finished with value: 0.8373015873015873 and parameters: {'num_leaves': 245, 'learning_rate': 0.26598705145920415, 'feature_fraction': 0.8060570959991429, 'bagging_fraction': 0.7780681538706554, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:48,879] Trial 28 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 249, 'learning_rate': 0.27852529832333084, 'feature_fraction': 0.8021823534919641, 'bagging_fraction': 0.6646707337776797, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:48,913] Trial 29 finished with value: 0.8293650793650794 and parameters: {'num_leaves': 184, 'learning_rate': 0.22158076481725747, 'feature_fraction': 0.7137275716459601, 'bagging_fraction': 0.9814697556366412, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:48,927] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.24401761465984972, 'feature_fraction': 0.8849005456824233, 'bagging_fraction': 0.9117647304782971, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:48,953] Trial 31 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 207, 'learning_rate': 0.29789835825476674, 'feature_fraction': 0.7320362237625019, 'bagging_fraction': 0.7015811658623272, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:48,982] Trial 32 finished with value: 0.8849206349206349 and parameters: {'num_leaves': 212, 'learning_rate': 0.27536176591037276, 'feature_fraction': 0.6527204708922891, 'bagging_fraction': 0.7234928988845496, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,012] Trial 33 finished with value: 0.7777777777777779 and parameters: {'num_leaves': 150, 'learning_rate': 0.2777575201995873, 'feature_fraction': 0.6418988048425748, 'bagging_fraction': 0.7908936394997145, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,036] Trial 34 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 228, 'learning_rate': 0.24278523903592247, 'feature_fraction': 0.6714254972572182, 'bagging_fraction': 0.6276669224165466, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,049] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.2715669837258833, 'feature_fraction': 0.5945859169452612, 'bagging_fraction': 0.706369811753974, 'bagging_freq': 5, 'min_child_samples': 88}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,062] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 182, 'learning_rate': 0.1969535289506259, 'feature_fraction': 0.548562538820656, 'bagging_fraction': 0.5550282068307961, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,076] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 260, 'learning_rate': 0.2543209607284096, 'feature_fraction': 0.6892565103924284, 'bagging_fraction': 0.6449559233150873, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,105] Trial 38 finished with value: 0.8690476190476191 and parameters: {'num_leaves': 43, 'learning_rate': 0.1116757318848895, 'feature_fraction': 0.7736101467706565, 'bagging_fraction': 0.5810947329185526, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,125] Trial 39 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 104, 'learning_rate': 0.23286457087097673, 'feature_fraction': 0.6366259506358065, 'bagging_fraction': 0.869513306824946, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,163] Trial 40 finished with value: 0.8134920634920636 and parameters: {'num_leaves': 226, 'learning_rate': 0.21217544772569724, 'feature_fraction': 0.9511155818094379, 'bagging_fraction': 0.6766635831150212, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,192] Trial 41 finished with value: 0.8293650793650794 and parameters: {'num_leaves': 41, 'learning_rate': 0.11112884792695757, 'feature_fraction': 0.7846904040618097, 'bagging_fraction': 0.5723211575488755, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,219] Trial 42 finished with value: 0.8293650793650794 and parameters: {'num_leaves': 52, 'learning_rate': 0.09430923227338306, 'feature_fraction': 0.8245222771078066, 'bagging_fraction': 0.5243107653992978, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,253] Trial 43 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 36, 'learning_rate': 0.12703403602032087, 'feature_fraction': 0.7253946076913327, 'bagging_fraction': 0.6146490816739086, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,277] Trial 44 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 73, 'learning_rate': 0.070861294723515, 'feature_fraction': 0.7623178324365376, 'bagging_fraction': 0.775732510661673, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,292] Trial 45 finished with value: 0.5 and parameters: {'num_leaves': 23, 'learning_rate': 0.10750117748139618, 'feature_fraction': 0.8955847439379168, 'bagging_fraction': 0.5050329901934805, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,323] Trial 46 finished with value: 0.873015873015873 and parameters: {'num_leaves': 55, 'learning_rate': 0.14745794952866323, 'feature_fraction': 0.8266779176812604, 'bagging_fraction': 0.6332084559603646, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,360] Trial 47 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 92, 'learning_rate': 0.15019329161812636, 'feature_fraction': 0.8259579733531419, 'bagging_fraction': 0.7186156098002565, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,404] Trial 48 finished with value: 0.7797619047619048 and parameters: {'num_leaves': 172, 'learning_rate': 0.28674464182677395, 'feature_fraction': 0.993579256149228, 'bagging_fraction': 0.6460971011802298, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,438] Trial 49 finished with value: 0.8670634920634921 and parameters: {'num_leaves': 146, 'learning_rate': 0.2511335766730845, 'feature_fraction': 0.8756578889238071, 'bagging_fraction': 0.8192370499065902, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 25 with value: 0.9087301587301587.
[I 2025-09-17 13:17:49,703] A new study created in memory with name: no-name-8bf22f27-4ca3-4dce-9d44-563b0300f699
[I 2025-09-17 13:17:49,710] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 170, 'learning_rate': 0.15080047029232402, 'feature_fraction': 0.731018079132733, 'bagging_fraction': 0.9674932555238188, 'bagging_freq': 7, 'min_child_samples': 91}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:49,717] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 263, 'learning_rate': 0.06706292779626623, 'feature_fraction': 0.5485939089947311, 'bagging_fraction': 0.43740000757646214, 'bagging_freq': 6, 'min_child_samples': 68}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:49,726] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 293, 'learning_rate': 0.19444862383166803, 'feature_fraction': 0.5627123922014774, 'bagging_fraction': 0.43123731222195777, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:49,732] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.1243249250965808, 'feature_fraction': 0.7891407109498298, 'bagging_fraction': 0.7177843611118162, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:49,752] Trial 4 finished with value: 0.7202380952380952 and parameters: {'num_leaves': 175, 'learning_rate': 0.13505497434516092, 'feature_fraction': 0.7644779294208076, 'bagging_fraction': 0.9852611930070239, 'bagging_freq': 7, 'min_child_samples': 34}. Best is trial 4 with value: 0.7202380952380952.
[I 2025-09-17 13:17:49,771] Trial 5 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 115, 'learning_rate': 0.19167226086087008, 'feature_fraction': 0.5305721580655333, 'bagging_fraction': 0.8787892923757954, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 4 with value: 0.7202380952380952.
[I 2025-09-17 13:17:49,780] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 291, 'learning_rate': 0.12392117617520564, 'feature_fraction': 0.7029434759456847, 'bagging_fraction': 0.6593820400777398, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 4 with value: 0.7202380952380952.
[I 2025-09-17 13:17:49,800] Trial 7 finished with value: 0.6587301587301587 and parameters: {'num_leaves': 291, 'learning_rate': 0.24808997905942845, 'feature_fraction': 0.8031953190378975, 'bagging_fraction': 0.48628825128796704, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 4 with value: 0.7202380952380952.
[I 2025-09-17 13:17:49,814] Trial 8 finished with value: 0.7023809523809524 and parameters: {'num_leaves': 266, 'learning_rate': 0.10974977479958296, 'feature_fraction': 0.97335235610076, 'bagging_fraction': 0.832931867307279, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 4 with value: 0.7202380952380952.
[I 2025-09-17 13:17:49,826] Trial 9 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 89, 'learning_rate': 0.1781840247047802, 'feature_fraction': 0.9434233695760548, 'bagging_fraction': 0.7149761942486059, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 4 with value: 0.7202380952380952.
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.535038
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.578897
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.542625
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.458847
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.467734
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.500404
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.517714
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.533655
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.478299
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.659817
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.574967
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.564028
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.598657
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.524468
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.463968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.52962
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.527992
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.441031
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.503654
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.514187
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.584422
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.522138
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.4874
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.489855
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.554433
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.598723
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.508322
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.533985
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.525418
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.518636
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.529764
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.53649
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.536194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.495587
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.512993
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.596956
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.504618
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.608318
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.613012
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.650107
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.650309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.642478
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:49,954] Trial 10 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 42, 'learning_rate': 0.027862684006666277, 'feature_fraction': 0.8570400602348721, 'bagging_fraction': 0.9580930275543078, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,044] Trial 11 finished with value: 0.6428571428571428 and parameters: {'num_leaves': 14, 'learning_rate': 0.01305477857985829, 'feature_fraction': 0.8687665083963164, 'bagging_fraction': 0.9986937403542749, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,222] Trial 12 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 20, 'learning_rate': 0.010229966682405583, 'feature_fraction': 0.4057843933039521, 'bagging_fraction': 0.867516760963948, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,333] Trial 13 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 10, 'learning_rate': 0.019378555988538236, 'feature_fraction': 0.40640350188747104, 'bagging_fraction': 0.8563313155617641, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,385] Trial 14 finished with value: 0.6746031746031746 and parameters: {'num_leaves': 59, 'learning_rate': 0.05971687525161288, 'feature_fraction': 0.4098888358295398, 'bagging_fraction': 0.8030591125816468, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,417] Trial 15 finished with value: 0.6369047619047619 and parameters: {'num_leaves': 45, 'learning_rate': 0.06322927592782368, 'feature_fraction': 0.6128104995117255, 'bagging_fraction': 0.904528685277938, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,466] Trial 16 finished with value: 0.5357142857142857 and parameters: {'num_leaves': 120, 'learning_rate': 0.2945344989070097, 'feature_fraction': 0.8677625490494625, 'bagging_fraction': 0.6087566955020839, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,485] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 69, 'learning_rate': 0.04069630698199238, 'feature_fraction': 0.6469565425562435, 'bagging_fraction': 0.9206686274894692, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,506] Trial 18 finished with value: 0.6646825396825397 and parameters: {'num_leaves': 31, 'learning_rate': 0.09515585119177827, 'feature_fraction': 0.8780769984563106, 'bagging_fraction': 0.7861339174460109, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,542] Trial 19 finished with value: 0.6746031746031745 and parameters: {'num_leaves': 97, 'learning_rate': 0.08592931145137275, 'feature_fraction': 0.49472405355185023, 'bagging_fraction': 0.5637248643095402, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,567] Trial 20 finished with value: 0.6845238095238096 and parameters: {'num_leaves': 137, 'learning_rate': 0.0362498717966229, 'feature_fraction': 0.6548408844355904, 'bagging_fraction': 0.9312089686105786, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,655] Trial 21 finished with value: 0.6984126984126984 and parameters: {'num_leaves': 188, 'learning_rate': 0.03674943114150869, 'feature_fraction': 0.7680855888550081, 'bagging_fraction': 0.9998372652311659, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,675] Trial 22 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 221, 'learning_rate': 0.25206437738630366, 'feature_fraction': 0.8413989708623889, 'bagging_fraction': 0.942078128036019, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,714] Trial 23 finished with value: 0.7023809523809523 and parameters: {'num_leaves': 229, 'learning_rate': 0.2331653858282941, 'feature_fraction': 0.9090710026622413, 'bagging_fraction': 0.7620566659380863, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,735] Trial 24 finished with value: 0.7123015873015874 and parameters: {'num_leaves': 230, 'learning_rate': 0.2890029048360811, 'feature_fraction': 0.8320935075659012, 'bagging_fraction': 0.9374613852193341, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 10 with value: 0.7341269841269842.
[I 2025-09-17 13:17:50,771] Trial 25 finished with value: 0.746031746031746 and parameters: {'num_leaves': 80, 'learning_rate': 0.24760878749274323, 'feature_fraction': 0.998016042170401, 'bagging_fraction': 0.8730410748457105, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 25 with value: 0.746031746031746.
[I 2025-09-17 13:17:50,807] Trial 26 finished with value: 0.746031746031746 and parameters: {'num_leaves': 65, 'learning_rate': 0.23140446696628242, 'feature_fraction': 0.9589958148178963, 'bagging_fraction': 0.840434934203725, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 25 with value: 0.746031746031746.
[I 2025-09-17 13:17:50,837] Trial 27 finished with value: 0.746031746031746 and parameters: {'num_leaves': 80, 'learning_rate': 0.22841431461598027, 'feature_fraction': 0.9846729896325237, 'bagging_fraction': 0.8129531124836982, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 25 with value: 0.746031746031746.
[I 2025-09-17 13:17:50,871] Trial 28 finished with value: 0.5595238095238095 and parameters: {'num_leaves': 84, 'learning_rate': 0.22219981371109768, 'feature_fraction': 0.9945908681928921, 'bagging_fraction': 0.7606373920167535, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 25 with value: 0.746031746031746.
[I 2025-09-17 13:17:50,885] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.2619047934435841, 'feature_fraction': 0.9303650228940535, 'bagging_fraction': 0.8224742037649424, 'bagging_freq': 4, 'min_child_samples': 93}. Best is trial 25 with value: 0.746031746031746.
[I 2025-09-17 13:17:50,900] Trial 30 finished with value: 0.49404761904761896 and parameters: {'num_leaves': 69, 'learning_rate': 0.21396473087650236, 'feature_fraction': 0.9612867798783468, 'bagging_fraction': 0.6760032757098632, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 25 with value: 0.746031746031746.
[I 2025-09-17 13:17:50,928] Trial 31 finished with value: 0.6884920634920635 and parameters: {'num_leaves': 47, 'learning_rate': 0.2675212858093197, 'feature_fraction': 0.9998180766592922, 'bagging_fraction': 0.8874516734824138, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 25 with value: 0.746031746031746.
[I 2025-09-17 13:17:50,971] Trial 32 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 111, 'learning_rate': 0.1553016218835896, 'feature_fraction': 0.9049878656045343, 'bagging_fraction': 0.8457746053901666, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,008] Trial 33 finished with value: 0.6190476190476191 and parameters: {'num_leaves': 111, 'learning_rate': 0.1604632737194215, 'feature_fraction': 0.9099466934417908, 'bagging_fraction': 0.7538538851821707, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,025] Trial 34 finished with value: 0.6984126984126984 and parameters: {'num_leaves': 99, 'learning_rate': 0.21541395943956698, 'feature_fraction': 0.910226082861723, 'bagging_fraction': 0.8450875002868559, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,037] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 148, 'learning_rate': 0.16840457550710308, 'feature_fraction': 0.9619094727544958, 'bagging_fraction': 0.8063271701931232, 'bagging_freq': 5, 'min_child_samples': 70}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,056] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 77, 'learning_rate': 0.18659269386421085, 'feature_fraction': 0.9440575599608498, 'bagging_fraction': 0.7414753487985617, 'bagging_freq': 4, 'min_child_samples': 86}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,096] Trial 37 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 125, 'learning_rate': 0.1401275121791822, 'feature_fraction': 0.988058177684338, 'bagging_fraction': 0.8837892011909695, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,139] Trial 38 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 127, 'learning_rate': 0.14340323393957988, 'feature_fraction': 0.9032553988763019, 'bagging_fraction': 0.8765888327900928, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,167] Trial 39 finished with value: 0.7440476190476191 and parameters: {'num_leaves': 128, 'learning_rate': 0.14915463228364467, 'feature_fraction': 0.725681738637096, 'bagging_fraction': 0.9003937430321238, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,194] Trial 40 finished with value: 0.6884920634920636 and parameters: {'num_leaves': 169, 'learning_rate': 0.13559782852082725, 'feature_fraction': 0.8112560559854728, 'bagging_fraction': 0.9656103970623515, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,248] Trial 41 finished with value: 0.7043650793650794 and parameters: {'num_leaves': 107, 'learning_rate': 0.20109812578017527, 'feature_fraction': 0.8990834039564575, 'bagging_fraction': 0.8710193798744665, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,298] Trial 42 finished with value: 0.6746031746031746 and parameters: {'num_leaves': 125, 'learning_rate': 0.14158702745831417, 'feature_fraction': 0.9463344144150745, 'bagging_fraction': 0.8488041710755707, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,310] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 158, 'learning_rate': 0.11802362439929634, 'feature_fraction': 0.9748333210465621, 'bagging_fraction': 0.899481077337253, 'bagging_freq': 5, 'min_child_samples': 76}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,342] Trial 44 finished with value: 0.7202380952380952 and parameters: {'num_leaves': 98, 'learning_rate': 0.10440940710292594, 'feature_fraction': 0.9265977774251077, 'bagging_fraction': 0.784344775861343, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,362] Trial 45 finished with value: 0.6884920634920635 and parameters: {'num_leaves': 59, 'learning_rate': 0.17137608260290782, 'feature_fraction': 0.8768772119421369, 'bagging_fraction': 0.8353788812186691, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,407] Trial 46 finished with value: 0.6309523809523809 and parameters: {'num_leaves': 158, 'learning_rate': 0.15385196982001972, 'feature_fraction': 0.9645024860266078, 'bagging_fraction': 0.8704770397495009, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,433] Trial 47 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 133, 'learning_rate': 0.20120961342247987, 'feature_fraction': 0.9974243537782145, 'bagging_fraction': 0.6958413433841784, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,461] Trial 48 finished with value: 0.7202380952380952 and parameters: {'num_leaves': 181, 'learning_rate': 0.2800691793399869, 'feature_fraction': 0.8906906130199199, 'bagging_fraction': 0.9571243054655099, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,492] Trial 49 finished with value: 0.5773809523809523 and parameters: {'num_leaves': 115, 'learning_rate': 0.2422683043163164, 'feature_fraction': 0.9323770765077041, 'bagging_fraction': 0.46313753620178255, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 32 with value: 0.7698412698412699.
[I 2025-09-17 13:17:51,846] A new study created in memory with name: no-name-595d829c-ad29-4323-b705-6c2125d2917a
[I 2025-09-17 13:17:51,855] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 115, 'learning_rate': 0.21730926913927756, 'feature_fraction': 0.43383285894446494, 'bagging_fraction': 0.7631482996550891, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:51,872] Trial 1 finished with value: 0.863157894736842 and parameters: {'num_leaves': 272, 'learning_rate': 0.1696176391457531, 'feature_fraction': 0.8209424008308119, 'bagging_fraction': 0.9863815658995375, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 1 with value: 0.863157894736842.
[I 2025-09-17 13:17:51,882] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 275, 'learning_rate': 0.12832878500048672, 'feature_fraction': 0.7765531522758697, 'bagging_fraction': 0.7594783325321912, 'bagging_freq': 4, 'min_child_samples': 97}. Best is trial 1 with value: 0.863157894736842.
[I 2025-09-17 13:17:51,891] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 230, 'learning_rate': 0.26866245205325084, 'feature_fraction': 0.7278086600801006, 'bagging_fraction': 0.7341816254851157, 'bagging_freq': 5, 'min_child_samples': 76}. Best is trial 1 with value: 0.863157894736842.
[I 2025-09-17 13:17:51,901] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 162, 'learning_rate': 0.21725722463971042, 'feature_fraction': 0.5066134890317973, 'bagging_fraction': 0.5680047398735355, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 1 with value: 0.863157894736842.
[I 2025-09-17 13:17:51,989] Trial 5 finished with value: 0.9614035087719298 and parameters: {'num_leaves': 277, 'learning_rate': 0.17132805119353495, 'feature_fraction': 0.4845853890865822, 'bagging_fraction': 0.8735470517210222, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 5 with value: 0.9614035087719298.
[I 2025-09-17 13:17:51,998] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 43, 'learning_rate': 0.25490507868216133, 'feature_fraction': 0.7756824320312057, 'bagging_fraction': 0.7928617207979349, 'bagging_freq': 3, 'min_child_samples': 87}. Best is trial 5 with value: 0.9614035087719298.
[I 2025-09-17 13:17:52,011] Trial 7 finished with value: 0.6631578947368422 and parameters: {'num_leaves': 101, 'learning_rate': 0.09360676360965352, 'feature_fraction': 0.8888849785134882, 'bagging_fraction': 0.8642507288207659, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 5 with value: 0.9614035087719298.
[I 2025-09-17 13:17:52,019] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 104, 'learning_rate': 0.27239426179470233, 'feature_fraction': 0.7300919977066558, 'bagging_fraction': 0.8360642097614619, 'bagging_freq': 4, 'min_child_samples': 71}. Best is trial 5 with value: 0.9614035087719298.
[I 2025-09-17 13:17:52,044] Trial 9 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 95, 'learning_rate': 0.09299599186504838, 'feature_fraction': 0.45594009236565763, 'bagging_fraction': 0.838356947828307, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 5 with value: 0.9614035087719298.
[I 2025-09-17 13:17:52,114] Trial 10 finished with value: 0.9719298245614036 and parameters: {'num_leaves': 205, 'learning_rate': 0.0502931095692872, 'feature_fraction': 0.5909897398366888, 'bagging_fraction': 0.4517723912322131, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 10 with value: 0.9719298245614036.
[I 2025-09-17 13:17:52,197] Trial 11 finished with value: 0.9543859649122808 and parameters: {'num_leaves': 205, 'learning_rate': 0.04323828870156298, 'feature_fraction': 0.591823328442141, 'bagging_fraction': 0.42508103761913574, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 10 with value: 0.9719298245614036.
[I 2025-09-17 13:17:52,296] Trial 12 finished with value: 0.9789473684210527 and parameters: {'num_leaves': 210, 'learning_rate': 0.16813427285512422, 'feature_fraction': 0.6011733942871083, 'bagging_fraction': 0.6052503475348978, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,319] Trial 13 finished with value: 0.9192982456140352 and parameters: {'num_leaves': 195, 'learning_rate': 0.030173489572394407, 'feature_fraction': 0.6194199418208698, 'bagging_fraction': 0.57748530340629, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,349] Trial 14 finished with value: 0.887719298245614 and parameters: {'num_leaves': 232, 'learning_rate': 0.1166621456022057, 'feature_fraction': 0.6048773799095719, 'bagging_fraction': 0.4054462860223183, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,371] Trial 15 finished with value: 0.856140350877193 and parameters: {'num_leaves': 161, 'learning_rate': 0.01150005304910394, 'feature_fraction': 0.6559634946632148, 'bagging_fraction': 0.5602170611729774, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,409] Trial 16 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 226, 'learning_rate': 0.0669372644773983, 'feature_fraction': 0.9822972108159731, 'bagging_fraction': 0.4928665360892512, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,516] Trial 17 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 184, 'learning_rate': 0.19403898179836251, 'feature_fraction': 0.5487826417295809, 'bagging_fraction': 0.6574151031952492, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,541] Trial 18 finished with value: 0.880701754385965 and parameters: {'num_leaves': 24, 'learning_rate': 0.14279340435854815, 'feature_fraction': 0.6737920600351555, 'bagging_fraction': 0.644032556634342, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 12 with value: 0.9789473684210527.
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.613913
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.654403
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.628142
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.636521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.62716
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.646672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.686414
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.641573
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.632743
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.634871
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.646044
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.647884
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.648766
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.640015
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.628603
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.632805
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.642335
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.670895
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.65178
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.623188
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.646764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.677934
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.633213
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.649916
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.649149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.60501
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.617446
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.623846
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.659679
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.685988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.621227
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.652618
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.650799
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.605256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.604123
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.678564
Training model for P045... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.441571
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.253224
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.674968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.43162
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.285464
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.302629
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.250043
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.421941
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.412274
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.584713
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.376569
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.306778
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.432292
[I 2025-09-17 13:17:52,566] Trial 19 finished with value: 0.8842105263157894 and parameters: {'num_leaves': 134, 'learning_rate': 0.07636983899264004, 'feature_fraction': 0.4043730644546867, 'bagging_fraction': 0.4954354552574054, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,610] Trial 20 finished with value: 0.9157894736842105 and parameters: {'num_leaves': 251, 'learning_rate': 0.22107086365584838, 'feature_fraction': 0.5445306240511448, 'bagging_fraction': 0.49726522765038295, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,685] Trial 21 finished with value: 0.8877192982456139 and parameters: {'num_leaves': 294, 'learning_rate': 0.1679736545307222, 'feature_fraction': 0.48977953698590826, 'bagging_fraction': 0.9399017711548341, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,723] Trial 22 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 259, 'learning_rate': 0.18359752654200223, 'feature_fraction': 0.5506548096946876, 'bagging_fraction': 0.6739576937562629, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,826] Trial 23 finished with value: 0.9614035087719298 and parameters: {'num_leaves': 212, 'learning_rate': 0.15308103096020492, 'feature_fraction': 0.4924296317557631, 'bagging_fraction': 0.6274421984094334, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,852] Trial 24 finished with value: 0.8385964912280703 and parameters: {'num_leaves': 177, 'learning_rate': 0.11572289625432003, 'feature_fraction': 0.6596373753586382, 'bagging_fraction': 0.8949490579809228, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,878] Trial 25 finished with value: 0.8245614035087718 and parameters: {'num_leaves': 290, 'learning_rate': 0.19636257041578375, 'feature_fraction': 0.5829032245344216, 'bagging_fraction': 0.453358909992782, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,945] Trial 26 finished with value: 0.943859649122807 and parameters: {'num_leaves': 140, 'learning_rate': 0.24065757631441176, 'feature_fraction': 0.525341579230165, 'bagging_fraction': 0.7031523371443779, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:52,974] Trial 27 finished with value: 0.9192982456140351 and parameters: {'num_leaves': 250, 'learning_rate': 0.13918224104676497, 'feature_fraction': 0.6300364428268146, 'bagging_fraction': 0.6065723690076756, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,023] Trial 28 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 214, 'learning_rate': 0.1683598747826524, 'feature_fraction': 0.46022018766385453, 'bagging_fraction': 0.5223307176613932, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,053] Trial 29 finished with value: 0.8982456140350877 and parameters: {'num_leaves': 76, 'learning_rate': 0.2144638592982559, 'feature_fraction': 0.41061421041516466, 'bagging_fraction': 0.7968204947012623, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,141] Trial 30 finished with value: 0.8526315789473684 and parameters: {'num_leaves': 187, 'learning_rate': 0.2989259650387389, 'feature_fraction': 0.7007285489204091, 'bagging_fraction': 0.7152047536656003, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,191] Trial 31 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 214, 'learning_rate': 0.15428021195632283, 'feature_fraction': 0.4757429916369276, 'bagging_fraction': 0.5470438776825056, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,332] Trial 32 finished with value: 0.9473684210526315 and parameters: {'num_leaves': 244, 'learning_rate': 0.1825740459173875, 'feature_fraction': 0.43847418932018456, 'bagging_fraction': 0.6319739879593697, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,402] Trial 33 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 273, 'learning_rate': 0.11513206902991639, 'feature_fraction': 0.571608492036907, 'bagging_fraction': 0.9946918260280564, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,468] Trial 34 finished with value: 0.9298245614035089 and parameters: {'num_leaves': 170, 'learning_rate': 0.1542469694111437, 'feature_fraction': 0.5104118525035112, 'bagging_fraction': 0.598698630748819, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,515] Trial 35 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 142, 'learning_rate': 0.05824481235833365, 'feature_fraction': 0.5005073873014224, 'bagging_fraction': 0.7534528504142983, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,585] Trial 36 finished with value: 0.9473684210526316 and parameters: {'num_leaves': 202, 'learning_rate': 0.1299804359722843, 'feature_fraction': 0.6278918454855177, 'bagging_fraction': 0.9447129698815613, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,601] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 214, 'learning_rate': 0.10140468547640125, 'feature_fraction': 0.5280798762435589, 'bagging_fraction': 0.6858294213311057, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,621] Trial 38 finished with value: 0.7578947368421053 and parameters: {'num_leaves': 231, 'learning_rate': 0.2009547374654814, 'feature_fraction': 0.5793515668518986, 'bagging_fraction': 0.7897998372567053, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,674] Trial 39 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 272, 'learning_rate': 0.235363908905721, 'feature_fraction': 0.7555286715249969, 'bagging_fraction': 0.6070688556574945, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,688] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.17128248342260535, 'feature_fraction': 0.8467656841862872, 'bagging_fraction': 0.44751046913172615, 'bagging_freq': 1, 'min_child_samples': 49}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,788] Trial 41 finished with value: 0.943859649122807 and parameters: {'num_leaves': 201, 'learning_rate': 0.04689433872524695, 'feature_fraction': 0.6017930274073349, 'bagging_fraction': 0.4090123513975532, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,847] Trial 42 finished with value: 0.9473684210526316 and parameters: {'num_leaves': 154, 'learning_rate': 0.04904991986474233, 'feature_fraction': 0.7056807200608562, 'bagging_fraction': 0.44783804423660517, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,883] Trial 43 finished with value: 0.9228070175438597 and parameters: {'num_leaves': 198, 'learning_rate': 0.015753963826956374, 'feature_fraction': 0.44288168597517447, 'bagging_fraction': 0.5374981170839833, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,921] Trial 44 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 241, 'learning_rate': 0.03367083379536612, 'feature_fraction': 0.5686841598575063, 'bagging_fraction': 0.4723544142761639, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,980] Trial 45 finished with value: 0.9508771929824561 and parameters: {'num_leaves': 221, 'learning_rate': 0.03164697892704588, 'feature_fraction': 0.4806774099840913, 'bagging_fraction': 0.41460197099004703, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:53,994] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 266, 'learning_rate': 0.08466858934882932, 'feature_fraction': 0.6437917649672705, 'bagging_fraction': 0.5810951015892125, 'bagging_freq': 6, 'min_child_samples': 78}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:54,018] Trial 47 finished with value: 0.849122807017544 and parameters: {'num_leaves': 282, 'learning_rate': 0.10359206643869343, 'feature_fraction': 0.6042890870656742, 'bagging_fraction': 0.5224442284388241, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:54,058] Trial 48 finished with value: 0.9508771929824562 and parameters: {'num_leaves': 120, 'learning_rate': 0.07065961675948719, 'feature_fraction': 0.6797941997554036, 'bagging_fraction': 0.4265442651509046, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:54,087] Trial 49 finished with value: 0.9122807017543859 and parameters: {'num_leaves': 170, 'learning_rate': 0.1399462584701171, 'feature_fraction': 0.9702964733199846, 'bagging_fraction': 0.47678711115815786, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 12 with value: 0.9789473684210527.
[I 2025-09-17 13:17:54,429] A new study created in memory with name: no-name-6430ed8e-cc29-4742-b308-9adf44474146
[I 2025-09-17 13:17:54,440] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 188, 'learning_rate': 0.11746330725275073, 'feature_fraction': 0.6615289548643974, 'bagging_fraction': 0.8462191261823387, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:54,449] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 15, 'learning_rate': 0.03364668283522299, 'feature_fraction': 0.6787167259550889, 'bagging_fraction': 0.4405306018250453, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:17:54,503] Trial 2 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 46, 'learning_rate': 0.04690170101966029, 'feature_fraction': 0.8091682804517071, 'bagging_fraction': 0.4110458748578963, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:54,512] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 188, 'learning_rate': 0.12653433103289768, 'feature_fraction': 0.7643792805327412, 'bagging_fraction': 0.7151270888139794, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:54,527] Trial 4 finished with value: 0.8596491228070176 and parameters: {'num_leaves': 191, 'learning_rate': 0.12842304607551763, 'feature_fraction': 0.877469458617921, 'bagging_fraction': 0.6889973784391634, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:54,537] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 107, 'learning_rate': 0.23764876014543918, 'feature_fraction': 0.9790244378969488, 'bagging_fraction': 0.7822442206079767, 'bagging_freq': 5, 'min_child_samples': 91}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:54,549] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 290, 'learning_rate': 0.274342442311568, 'feature_fraction': 0.4667922816946195, 'bagging_fraction': 0.7219410234534189, 'bagging_freq': 2, 'min_child_samples': 80}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:54,578] Trial 7 finished with value: 0.9192982456140351 and parameters: {'num_leaves': 194, 'learning_rate': 0.16127799462292747, 'feature_fraction': 0.679743643568431, 'bagging_fraction': 0.9092129329491717, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 7 with value: 0.9192982456140351.
[I 2025-09-17 13:17:54,592] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 231, 'learning_rate': 0.25509148885277466, 'feature_fraction': 0.851521651256719, 'bagging_fraction': 0.6501938161219376, 'bagging_freq': 6, 'min_child_samples': 93}. Best is trial 7 with value: 0.9192982456140351.
[I 2025-09-17 13:17:54,603] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.19851321581646697, 'feature_fraction': 0.6917180207974153, 'bagging_fraction': 0.49693664086948686, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 7 with value: 0.9192982456140351.
[I 2025-09-17 13:17:54,661] Trial 10 finished with value: 0.9333333333333332 and parameters: {'num_leaves': 291, 'learning_rate': 0.19381751242088782, 'feature_fraction': 0.49412318403574185, 'bagging_fraction': 0.9881243721089308, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 10 with value: 0.9333333333333332.
[I 2025-09-17 13:17:54,728] Trial 11 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 298, 'learning_rate': 0.19642156894323348, 'feature_fraction': 0.5107023523001063, 'bagging_fraction': 0.9902681257020087, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 11 with value: 0.9368421052631579.
[I 2025-09-17 13:17:54,862] Trial 12 finished with value: 0.9614035087719298 and parameters: {'num_leaves': 296, 'learning_rate': 0.20931280804556038, 'feature_fraction': 0.4445961999055692, 'bagging_fraction': 0.9731684476023459, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 12 with value: 0.9614035087719298.
[I 2025-09-17 13:17:54,904] Trial 13 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 243, 'learning_rate': 0.2138913013392803, 'feature_fraction': 0.4019300953041734, 'bagging_fraction': 0.9888178899960218, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 12 with value: 0.9614035087719298.
[I 2025-09-17 13:17:54,936] Trial 14 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 246, 'learning_rate': 0.296453315250086, 'feature_fraction': 0.41943530726682504, 'bagging_fraction': 0.8923894043955372, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 12 with value: 0.9614035087719298.
[I 2025-09-17 13:17:54,955] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 243, 'learning_rate': 0.22317167771646415, 'feature_fraction': 0.5733294930662785, 'bagging_fraction': 0.5712043337964661, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 12 with value: 0.9614035087719298.
[I 2025-09-17 13:17:54,987] Trial 16 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 265, 'learning_rate': 0.07944615866941021, 'feature_fraction': 0.4039243846983352, 'bagging_fraction': 0.9225140650247443, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 12 with value: 0.9614035087719298.
[I 2025-09-17 13:17:55,148] Trial 17 finished with value: 0.9649122807017544 and parameters: {'num_leaves': 224, 'learning_rate': 0.16539891046826594, 'feature_fraction': 0.5872070838365044, 'bagging_fraction': 0.8577229319017714, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,303] Trial 18 finished with value: 0.9614035087719298 and parameters: {'num_leaves': 215, 'learning_rate': 0.16747368363378443, 'feature_fraction': 0.5834187029569824, 'bagging_fraction': 0.7993732461150722, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,324] Trial 19 finished with value: 0.887719298245614 and parameters: {'num_leaves': 115, 'learning_rate': 0.06958413271242478, 'feature_fraction': 0.5851564767150826, 'bagging_fraction': 0.8409514847447302, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,345] Trial 20 finished with value: 0.8982456140350877 and parameters: {'num_leaves': 160, 'learning_rate': 0.09677989334324916, 'feature_fraction': 0.5443432794085215, 'bagging_fraction': 0.93173164820887, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,439] Trial 21 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 218, 'learning_rate': 0.15269814640678295, 'feature_fraction': 0.6075612501754355, 'bagging_fraction': 0.7920830713599926, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,534] Trial 22 finished with value: 0.9578947368421052 and parameters: {'num_leaves': 268, 'learning_rate': 0.172416966709145, 'feature_fraction': 0.626584436225462, 'bagging_fraction': 0.7923168299954718, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,586] Trial 23 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 214, 'learning_rate': 0.15034871124816943, 'feature_fraction': 0.5290763499479748, 'bagging_fraction': 0.858766076687694, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,689] Trial 24 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 161, 'learning_rate': 0.17807629156269775, 'feature_fraction': 0.752352486316474, 'bagging_fraction': 0.7615743722370366, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,702] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 265, 'learning_rate': 0.2355934439825232, 'feature_fraction': 0.4715003505787788, 'bagging_fraction': 0.6290093429992207, 'bagging_freq': 7, 'min_child_samples': 65}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,725] Trial 26 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 212, 'learning_rate': 0.18143081830128643, 'feature_fraction': 0.6284649575447785, 'bagging_fraction': 0.9361617203059129, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 17 with value: 0.9649122807017544.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.416658
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.36708
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.349734
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.342837
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.24179
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.463696
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.461091
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.279611
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.382318
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.346416
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.398625
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.510968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.329559
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.296776
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.310206
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.329927
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.349031
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.284826
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.626047
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.341902
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.310128
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.314436
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.456815
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.371059
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.346043
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.458351
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.31182
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.372063
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.378483
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.456244
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.342016
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.324455
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.323369
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.302681
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.287396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.341381
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.344534
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.255655
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.277862
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.442087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.422557
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.30464
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.268165
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.324981
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.319215
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.394864
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:17:55,760] Trial 27 finished with value: 0.943859649122807 and parameters: {'num_leaves': 262, 'learning_rate': 0.13919906366292653, 'feature_fraction': 0.5769569473645708, 'bagging_fraction': 0.8700560985621257, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,831] Trial 28 finished with value: 0.9192982456140351 and parameters: {'num_leaves': 76, 'learning_rate': 0.011382669831540987, 'feature_fraction': 0.45915264125023875, 'bagging_fraction': 0.8104447622150165, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,868] Trial 29 finished with value: 0.9157894736842106 and parameters: {'num_leaves': 146, 'learning_rate': 0.10094434101114967, 'feature_fraction': 0.743549279797511, 'bagging_fraction': 0.8401986672274725, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,894] Trial 30 finished with value: 0.9210526315789473 and parameters: {'num_leaves': 206, 'learning_rate': 0.20723380528494306, 'feature_fraction': 0.552743587453796, 'bagging_fraction': 0.9602363657479737, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:55,988] Trial 31 finished with value: 0.9578947368421054 and parameters: {'num_leaves': 276, 'learning_rate': 0.16943070504537974, 'feature_fraction': 0.6354795919822359, 'bagging_fraction': 0.753361320933347, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:56,050] Trial 32 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 280, 'learning_rate': 0.17085421344428567, 'feature_fraction': 0.6545356406852249, 'bagging_fraction': 0.741764128524269, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 17 with value: 0.9649122807017544.
[I 2025-09-17 13:17:56,168] Trial 33 finished with value: 0.968421052631579 and parameters: {'num_leaves': 233, 'learning_rate': 0.11112517072624728, 'feature_fraction': 0.645204820191368, 'bagging_fraction': 0.6764802989801142, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,204] Trial 34 finished with value: 0.9052631578947368 and parameters: {'num_leaves': 168, 'learning_rate': 0.11170241811345827, 'feature_fraction': 0.723859147815386, 'bagging_fraction': 0.6745295989186101, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,326] Trial 35 finished with value: 0.9192982456140351 and parameters: {'num_leaves': 229, 'learning_rate': 0.1339475268076173, 'feature_fraction': 0.7985874780700248, 'bagging_fraction': 0.5862238789290662, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,339] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 22, 'learning_rate': 0.11553997481455427, 'feature_fraction': 0.7150472479598194, 'bagging_fraction': 0.8138982904435039, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,420] Trial 37 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 176, 'learning_rate': 0.05831864800770989, 'feature_fraction': 0.66360556938187, 'bagging_fraction': 0.8871900024064021, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,449] Trial 38 finished with value: 0.8456140350877193 and parameters: {'num_leaves': 199, 'learning_rate': 0.14744464616273995, 'feature_fraction': 0.4459384119619658, 'bagging_fraction': 0.7065208361557074, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,462] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.2548106050575134, 'feature_fraction': 0.5034333479177645, 'bagging_fraction': 0.6171676789281422, 'bagging_freq': 4, 'min_child_samples': 71}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,490] Trial 40 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 179, 'learning_rate': 0.12366363236081018, 'feature_fraction': 0.9994863343305475, 'bagging_fraction': 0.5134492212117936, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,555] Trial 41 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 278, 'learning_rate': 0.18771890562748098, 'feature_fraction': 0.6388130783517325, 'bagging_fraction': 0.7472308121170462, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,696] Trial 42 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 228, 'learning_rate': 0.16565245686718527, 'feature_fraction': 0.6081729337622203, 'bagging_fraction': 0.678615158692883, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,728] Trial 43 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 278, 'learning_rate': 0.2208745477854327, 'feature_fraction': 0.6959350655961433, 'bagging_fraction': 0.7308837474341906, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,803] Trial 44 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 256, 'learning_rate': 0.16418867085553684, 'feature_fraction': 0.5926065943043924, 'bagging_fraction': 0.7607788434458228, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,849] Trial 45 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 297, 'learning_rate': 0.20413537121578607, 'feature_fraction': 0.5311937542829627, 'bagging_fraction': 0.8138607556709774, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,877] Trial 46 finished with value: 0.8894736842105263 and parameters: {'num_leaves': 233, 'learning_rate': 0.14198937566078113, 'feature_fraction': 0.921049071049098, 'bagging_fraction': 0.6521501360187749, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:56,928] Trial 47 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 285, 'learning_rate': 0.19195608064945535, 'feature_fraction': 0.7809583919331107, 'bagging_fraction': 0.707500264029315, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 33 with value: 0.968421052631579.
[I 2025-09-17 13:17:57,090] Trial 48 finished with value: 0.9894736842105263 and parameters: {'num_leaves': 247, 'learning_rate': 0.24243950079733967, 'feature_fraction': 0.5618073826272806, 'bagging_fraction': 0.9539590618490694, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 48 with value: 0.9894736842105263.
[I 2025-09-17 13:17:57,144] Trial 49 finished with value: 0.9578947368421052 and parameters: {'num_leaves': 252, 'learning_rate': 0.26526424218661765, 'feature_fraction': 0.4857383967500228, 'bagging_fraction': 0.9599307469739061, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 48 with value: 0.9894736842105263.
[I 2025-09-17 13:17:57,539] A new study created in memory with name: no-name-4d04745e-b1d5-424b-a562-8edfa4cc35ad
[I 2025-09-17 13:17:57,593] Trial 0 finished with value: 0.8912280701754387 and parameters: {'num_leaves': 114, 'learning_rate': 0.2149316558131552, 'feature_fraction': 0.4924548263376133, 'bagging_fraction': 0.6889945396910911, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 0 with value: 0.8912280701754387.
[I 2025-09-17 13:17:57,610] Trial 1 finished with value: 0.8438596491228071 and parameters: {'num_leaves': 180, 'learning_rate': 0.17646615752305264, 'feature_fraction': 0.7669676640192731, 'bagging_fraction': 0.7017332147960167, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 0 with value: 0.8912280701754387.
[I 2025-09-17 13:17:57,633] Trial 2 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 32, 'learning_rate': 0.23450939277411326, 'feature_fraction': 0.45286574627120046, 'bagging_fraction': 0.8804683935801465, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:57,664] Trial 3 finished with value: 0.8771929824561404 and parameters: {'num_leaves': 159, 'learning_rate': 0.21870314516612888, 'feature_fraction': 0.9180593505062825, 'bagging_fraction': 0.8418658150470812, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:57,673] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 252, 'learning_rate': 0.06916535387734898, 'feature_fraction': 0.653887355438101, 'bagging_fraction': 0.4280448654798743, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:57,682] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.25839209178878764, 'feature_fraction': 0.7476746686980993, 'bagging_fraction': 0.46408715432525016, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:57,695] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 253, 'learning_rate': 0.06891008558880565, 'feature_fraction': 0.5887126938595111, 'bagging_fraction': 0.821734832775773, 'bagging_freq': 5, 'min_child_samples': 93}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:57,724] Trial 7 finished with value: 0.9017543859649122 and parameters: {'num_leaves': 222, 'learning_rate': 0.09778861444618273, 'feature_fraction': 0.8713837519886505, 'bagging_fraction': 0.8855175702213076, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 2 with value: 0.9052631578947369.
[I 2025-09-17 13:17:57,796] Trial 8 finished with value: 0.9122807017543859 and parameters: {'num_leaves': 56, 'learning_rate': 0.12022977510409925, 'feature_fraction': 0.6884731068493346, 'bagging_fraction': 0.787819834056251, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 8 with value: 0.9122807017543859.
[I 2025-09-17 13:17:57,818] Trial 9 finished with value: 0.9070175438596491 and parameters: {'num_leaves': 131, 'learning_rate': 0.09275171679605458, 'feature_fraction': 0.4707734435875374, 'bagging_fraction': 0.9734130230642117, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 8 with value: 0.9122807017543859.
[I 2025-09-17 13:17:57,831] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 18, 'learning_rate': 0.021821664498897886, 'feature_fraction': 0.9853740394934574, 'bagging_fraction': 0.597458514045606, 'bagging_freq': 6, 'min_child_samples': 62}. Best is trial 8 with value: 0.9122807017543859.
[I 2025-09-17 13:17:58,049] Trial 11 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 88, 'learning_rate': 0.13649002465709872, 'feature_fraction': 0.4043670774519171, 'bagging_fraction': 0.9952383487982472, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 11 with value: 0.9263157894736842.
[I 2025-09-17 13:17:58,177] Trial 12 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 76, 'learning_rate': 0.1542354737301698, 'feature_fraction': 0.5912600255890843, 'bagging_fraction': 0.9831081955587777, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 12 with value: 0.9333333333333333.
[I 2025-09-17 13:17:58,292] Trial 13 finished with value: 0.9052631578947368 and parameters: {'num_leaves': 88, 'learning_rate': 0.17024135518329547, 'feature_fraction': 0.5471638908736196, 'bagging_fraction': 0.9870025063334646, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 12 with value: 0.9333333333333333.
[I 2025-09-17 13:17:58,314] Trial 14 finished with value: 0.7929824561403509 and parameters: {'num_leaves': 76, 'learning_rate': 0.29519183179468056, 'feature_fraction': 0.4040096618342985, 'bagging_fraction': 0.937846892741594, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 12 with value: 0.9333333333333333.
[I 2025-09-17 13:17:58,467] Trial 15 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 102, 'learning_rate': 0.13408660940116054, 'feature_fraction': 0.5940228303979818, 'bagging_fraction': 0.9960844257417124, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,480] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 124, 'learning_rate': 0.1704020445751279, 'feature_fraction': 0.5977161608934852, 'bagging_fraction': 0.748404240847961, 'bagging_freq': 6, 'min_child_samples': 65}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,501] Trial 17 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 184, 'learning_rate': 0.13754716243054838, 'feature_fraction': 0.6276541827922877, 'bagging_fraction': 0.588956243389338, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,545] Trial 18 finished with value: 0.9017543859649122 and parameters: {'num_leaves': 52, 'learning_rate': 0.19692243646759613, 'feature_fraction': 0.5451073542998282, 'bagging_fraction': 0.909083966769288, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,559] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 108, 'learning_rate': 0.02220009291590938, 'feature_fraction': 0.7639374922705446, 'bagging_fraction': 0.9313486472562131, 'bagging_freq': 5, 'min_child_samples': 86}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,570] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 150, 'learning_rate': 0.10474530466352103, 'feature_fraction': 0.8408929402960829, 'bagging_fraction': 0.553842946227469, 'bagging_freq': 1, 'min_child_samples': 57}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,643] Trial 21 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 84, 'learning_rate': 0.14242486205742175, 'feature_fraction': 0.5261681863384833, 'bagging_fraction': 0.9908397897100569, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,806] Trial 22 finished with value: 0.9087719298245615 and parameters: {'num_leaves': 55, 'learning_rate': 0.13788297441736386, 'feature_fraction': 0.4057778082440292, 'bagging_fraction': 0.9464504161283331, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,850] Trial 23 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 94, 'learning_rate': 0.06373611558738242, 'feature_fraction': 0.6940527775609822, 'bagging_fraction': 0.9995963874359993, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:58,879] Trial 24 finished with value: 0.9157894736842106 and parameters: {'num_leaves': 71, 'learning_rate': 0.12145865732361315, 'feature_fraction': 0.609236412958301, 'bagging_fraction': 0.8607248279195006, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 15 with value: 0.9438596491228071.
[I 2025-09-17 13:17:59,033] Trial 25 finished with value: 0.9543859649122807 and parameters: {'num_leaves': 34, 'learning_rate': 0.15854839493226444, 'feature_fraction': 0.5085909383082575, 'bagging_fraction': 0.9211773787167434, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,051] Trial 26 finished with value: 0.8140350877192981 and parameters: {'num_leaves': 31, 'learning_rate': 0.16116549843726036, 'feature_fraction': 0.5616769623604286, 'bagging_fraction': 0.8021748976178784, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,095] Trial 27 finished with value: 0.8912280701754387 and parameters: {'num_leaves': 10, 'learning_rate': 0.19519282269397664, 'feature_fraction': 0.49723889294408136, 'bagging_fraction': 0.9097184827778069, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,143] Trial 28 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 40, 'learning_rate': 0.18102333807457427, 'feature_fraction': 0.6664702900688972, 'bagging_fraction': 0.9435518608055417, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,191] Trial 29 finished with value: 0.9035087719298246 and parameters: {'num_leaves': 109, 'learning_rate': 0.20739225100509434, 'feature_fraction': 0.5217842597710494, 'bagging_fraction': 0.764645950888865, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,220] Trial 30 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 142, 'learning_rate': 0.15221386757848912, 'feature_fraction': 0.4613440251112193, 'bagging_fraction': 0.7076187115303071, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,337] Trial 31 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 67, 'learning_rate': 0.1216651211935826, 'feature_fraction': 0.4300366474482535, 'bagging_fraction': 0.9624683365431842, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,418] Trial 32 finished with value: 0.9052631578947368 and parameters: {'num_leaves': 60, 'learning_rate': 0.11729866785158595, 'feature_fraction': 0.5742337053280753, 'bagging_fraction': 0.9580227967475472, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,442] Trial 33 finished with value: 0.8999999999999999 and parameters: {'num_leaves': 36, 'learning_rate': 0.1554316257262775, 'feature_fraction': 0.49488194862110163, 'bagging_fraction': 0.8944632596165754, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,547] Trial 34 finished with value: 0.9192982456140351 and parameters: {'num_leaves': 104, 'learning_rate': 0.08620712687062866, 'feature_fraction': 0.43419985613553375, 'bagging_fraction': 0.8567773215475333, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,579] Trial 35 finished with value: 0.9105263157894736 and parameters: {'num_leaves': 66, 'learning_rate': 0.2272862944261243, 'feature_fraction': 0.6471085891572592, 'bagging_fraction': 0.9185876173688955, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 25 with value: 0.9543859649122807.
[I 2025-09-17 13:17:59,730] Trial 36 finished with value: 0.9543859649122808 and parameters: {'num_leaves': 25, 'learning_rate': 0.1835481035352256, 'feature_fraction': 0.5033346469887963, 'bagging_fraction': 0.9623584751016494, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 36 with value: 0.9543859649122808.
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.311855
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.436763
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.336197
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.38131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.292953
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.308418
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.248526
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.337275
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.333729
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.321084
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.472048
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.389339
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.295427
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.291242
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.310277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.304363
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.358992
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.42331
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.367788
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.170266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.28842
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.431368
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.504005
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.404436
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.434053
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.420793
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.430543
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.442403
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.37435
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.324887
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.403662
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.521825
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.329211
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.491925
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.428826
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.406462
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.3906
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.442499
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.415353
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.327899
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.522446
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.440663
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.389283
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.434076
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.430761
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.324699
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.409653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.437356
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.361543
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.428387
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.334242
[I 2025-09-17 13:17:59,835] Trial 37 finished with value: 0.8596491228070176 and parameters: {'num_leaves': 22, 'learning_rate': 0.24691943987489706, 'feature_fraction': 0.7283664034496516, 'bagging_fraction': 0.8341584683855694, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:17:59,857] Trial 38 finished with value: 0.8596491228070176 and parameters: {'num_leaves': 42, 'learning_rate': 0.18411716021890806, 'feature_fraction': 0.5098209500660058, 'bagging_fraction': 0.8712968022697958, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:17:59,879] Trial 39 finished with value: 0.8543859649122807 and parameters: {'num_leaves': 164, 'learning_rate': 0.21059000978733866, 'feature_fraction': 0.6213417794261511, 'bagging_fraction': 0.6401602200559757, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:17:59,893] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.19258892832542523, 'feature_fraction': 0.47075208987403594, 'bagging_fraction': 0.8819831722566445, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:17:59,985] Trial 41 finished with value: 0.912280701754386 and parameters: {'num_leaves': 46, 'learning_rate': 0.1241334665462359, 'feature_fraction': 0.4367141800038397, 'bagging_fraction': 0.9393153433655453, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,037] Trial 42 finished with value: 0.9087719298245613 and parameters: {'num_leaves': 25, 'learning_rate': 0.15936409949815297, 'feature_fraction': 0.5393914408346396, 'bagging_fraction': 0.9698050400517308, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,125] Trial 43 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 75, 'learning_rate': 0.14747445857651612, 'feature_fraction': 0.5784320244340264, 'bagging_fraction': 0.9633243686173609, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,196] Trial 44 finished with value: 0.9087719298245613 and parameters: {'num_leaves': 12, 'learning_rate': 0.14748935002169442, 'feature_fraction': 0.5811696662703172, 'bagging_fraction': 0.961748036688239, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,231] Trial 45 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 126, 'learning_rate': 0.17112561434824375, 'feature_fraction': 0.8030286947845364, 'bagging_fraction': 0.9070556307897515, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,379] Trial 46 finished with value: 0.9438596491228071 and parameters: {'num_leaves': 78, 'learning_rate': 0.10518782163347201, 'feature_fraction': 0.659128263711446, 'bagging_fraction': 0.9955481470714094, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,407] Trial 47 finished with value: 0.8771929824561404 and parameters: {'num_leaves': 279, 'learning_rate': 0.08298170883919292, 'feature_fraction': 0.7286557851973148, 'bagging_fraction': 0.45794271832469685, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,500] Trial 48 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 97, 'learning_rate': 0.1059916420874771, 'feature_fraction': 0.6643407653680011, 'bagging_fraction': 0.9959854242966749, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,516] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 79, 'learning_rate': 0.050301721642884045, 'feature_fraction': 0.6479402482911298, 'bagging_fraction': 0.9269463953602625, 'bagging_freq': 4, 'min_child_samples': 71}. Best is trial 36 with value: 0.9543859649122808.
[I 2025-09-17 13:18:00,972] A new study created in memory with name: no-name-33f1d463-146e-4f29-b464-acd448cd724c
[I 2025-09-17 13:18:01,042] Trial 0 finished with value: 0.8947368421052633 and parameters: {'num_leaves': 40, 'learning_rate': 0.12701193545926728, 'feature_fraction': 0.7497654491247956, 'bagging_fraction': 0.5919214350749419, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,056] Trial 1 finished with value: 0.8280701754385965 and parameters: {'num_leaves': 75, 'learning_rate': 0.10349984263452916, 'feature_fraction': 0.7043367862702505, 'bagging_fraction': 0.4581704460690077, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,064] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 284, 'learning_rate': 0.08795876111953793, 'feature_fraction': 0.8642174011650061, 'bagging_fraction': 0.9429406535851037, 'bagging_freq': 6, 'min_child_samples': 80}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,090] Trial 3 finished with value: 0.8771929824561404 and parameters: {'num_leaves': 261, 'learning_rate': 0.19448225617108553, 'feature_fraction': 0.6728962573591399, 'bagging_fraction': 0.9012763430109987, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,101] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 184, 'learning_rate': 0.17700341229759675, 'feature_fraction': 0.8138480277040494, 'bagging_fraction': 0.45713619317707277, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,128] Trial 5 finished with value: 0.8912280701754385 and parameters: {'num_leaves': 171, 'learning_rate': 0.14352618622746763, 'feature_fraction': 0.9847396553838036, 'bagging_fraction': 0.6949916264682738, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,138] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 242, 'learning_rate': 0.2418494054108857, 'feature_fraction': 0.8341735627897209, 'bagging_fraction': 0.65158147116234, 'bagging_freq': 3, 'min_child_samples': 66}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,144] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 16, 'learning_rate': 0.26347637113572225, 'feature_fraction': 0.4737089050743807, 'bagging_fraction': 0.7494591582592036, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,154] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 107, 'learning_rate': 0.15405023987502417, 'feature_fraction': 0.6981679306529864, 'bagging_fraction': 0.40801607436802423, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,165] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 122, 'learning_rate': 0.04399569847605997, 'feature_fraction': 0.9788430885128666, 'bagging_fraction': 0.8319457751115784, 'bagging_freq': 7, 'min_child_samples': 80}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,255] Trial 10 finished with value: 0.8807017543859649 and parameters: {'num_leaves': 19, 'learning_rate': 0.018774339763246856, 'feature_fraction': 0.4935731537979263, 'bagging_fraction': 0.5740522937280137, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 0 with value: 0.8947368421052633.
[I 2025-09-17 13:18:01,348] Trial 11 finished with value: 0.8982456140350876 and parameters: {'num_leaves': 197, 'learning_rate': 0.12568482640198259, 'feature_fraction': 0.9984319531994562, 'bagging_fraction': 0.6086096911461355, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 11 with value: 0.8982456140350876.
[I 2025-09-17 13:18:01,420] Trial 12 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 216, 'learning_rate': 0.09982811103549756, 'feature_fraction': 0.6086849471129209, 'bagging_fraction': 0.5598058553148989, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 12 with value: 0.9298245614035088.
[I 2025-09-17 13:18:01,462] Trial 13 finished with value: 0.8982456140350876 and parameters: {'num_leaves': 221, 'learning_rate': 0.05502938772333589, 'feature_fraction': 0.5424965884602688, 'bagging_fraction': 0.5512186446832839, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 12 with value: 0.9298245614035088.
[I 2025-09-17 13:18:01,501] Trial 14 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 204, 'learning_rate': 0.21764915478860036, 'feature_fraction': 0.6046113060980006, 'bagging_fraction': 0.777743852650673, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 12 with value: 0.9298245614035088.
[I 2025-09-17 13:18:01,538] Trial 15 finished with value: 0.9403508771929825 and parameters: {'num_leaves': 139, 'learning_rate': 0.2973431513659759, 'feature_fraction': 0.5901294978700842, 'bagging_fraction': 0.7878630465152676, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 15 with value: 0.9403508771929825.
[I 2025-09-17 13:18:01,565] Trial 16 finished with value: 0.9122807017543859 and parameters: {'num_leaves': 140, 'learning_rate': 0.2891458252081204, 'feature_fraction': 0.4219871131952214, 'bagging_fraction': 0.8579995102422319, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 15 with value: 0.9403508771929825.
[I 2025-09-17 13:18:01,624] Trial 17 finished with value: 0.9122807017543859 and parameters: {'num_leaves': 153, 'learning_rate': 0.07545701003130136, 'feature_fraction': 0.5855415615730855, 'bagging_fraction': 0.7442005760916205, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 15 with value: 0.9403508771929825.
[I 2025-09-17 13:18:01,642] Trial 18 finished with value: 0.8526315789473684 and parameters: {'num_leaves': 95, 'learning_rate': 0.28750573344601166, 'feature_fraction': 0.6212335157163434, 'bagging_fraction': 0.5148285988321907, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 15 with value: 0.9403508771929825.
[I 2025-09-17 13:18:01,654] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 238, 'learning_rate': 0.18810965169571695, 'feature_fraction': 0.560611110752878, 'bagging_fraction': 0.6645115808506369, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 15 with value: 0.9403508771929825.
[I 2025-09-17 13:18:01,725] Trial 20 finished with value: 0.9192982456140352 and parameters: {'num_leaves': 66, 'learning_rate': 0.227068673028768, 'feature_fraction': 0.401869651720531, 'bagging_fraction': 0.9812097107672226, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 15 with value: 0.9403508771929825.
[I 2025-09-17 13:18:01,764] Trial 21 finished with value: 0.9614035087719298 and parameters: {'num_leaves': 211, 'learning_rate': 0.22066065353705028, 'feature_fraction': 0.6262059257091377, 'bagging_fraction': 0.7805133028266777, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:01,786] Trial 22 finished with value: 0.894736842105263 and parameters: {'num_leaves': 171, 'learning_rate': 0.2613528699133423, 'feature_fraction': 0.646454738360231, 'bagging_fraction': 0.8024083192982404, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:01,811] Trial 23 finished with value: 0.912280701754386 and parameters: {'num_leaves': 219, 'learning_rate': 0.207497749597578, 'feature_fraction': 0.5347409715418814, 'bagging_fraction': 0.7122119619815905, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:01,891] Trial 24 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 296, 'learning_rate': 0.26432457450058344, 'feature_fraction': 0.49142965369841035, 'bagging_fraction': 0.8639443992222524, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:01,920] Trial 25 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 300, 'learning_rate': 0.25552038697960855, 'feature_fraction': 0.47882749094008736, 'bagging_fraction': 0.87155675181675, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:01,963] Trial 26 finished with value: 0.9368421052631579 and parameters: {'num_leaves': 271, 'learning_rate': 0.289624043165473, 'feature_fraction': 0.7276926837051727, 'bagging_fraction': 0.9270116328739968, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:01,987] Trial 27 finished with value: 0.9157894736842105 and parameters: {'num_leaves': 264, 'learning_rate': 0.29882466544627534, 'feature_fraction': 0.755707491485363, 'bagging_fraction': 0.9247147369540909, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,008] Trial 28 finished with value: 0.887719298245614 and parameters: {'num_leaves': 258, 'learning_rate': 0.27579533135498874, 'feature_fraction': 0.7619540929449471, 'bagging_fraction': 0.9696514510797988, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,035] Trial 29 finished with value: 0.912280701754386 and parameters: {'num_leaves': 136, 'learning_rate': 0.23928834453741063, 'feature_fraction': 0.7210464906658206, 'bagging_fraction': 0.8124496335982376, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,088] Trial 30 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 237, 'learning_rate': 0.23921676976718645, 'feature_fraction': 0.6583446770082324, 'bagging_fraction': 0.999585201806369, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,146] Trial 31 finished with value: 0.9192982456140351 and parameters: {'num_leaves': 299, 'learning_rate': 0.2721021118434116, 'feature_fraction': 0.5288094143450163, 'bagging_fraction': 0.8565085827865924, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,261] Trial 32 finished with value: 0.9122807017543859 and parameters: {'num_leaves': 276, 'learning_rate': 0.2977060962932762, 'feature_fraction': 0.439627662007402, 'bagging_fraction': 0.9108473419562185, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,305] Trial 33 finished with value: 0.9298245614035088 and parameters: {'num_leaves': 278, 'learning_rate': 0.27444761470880974, 'feature_fraction': 0.7911970964270957, 'bagging_fraction': 0.7737983451016975, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,339] Trial 34 finished with value: 0.9263157894736842 and parameters: {'num_leaves': 290, 'learning_rate': 0.24809698775677175, 'feature_fraction': 0.7001771980051071, 'bagging_fraction': 0.8886639931464344, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,382] Trial 35 finished with value: 0.9333333333333332 and parameters: {'num_leaves': 256, 'learning_rate': 0.2197323573680452, 'feature_fraction': 0.9106487996144152, 'bagging_fraction': 0.9477792123694251, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,409] Trial 36 finished with value: 0.9052631578947369 and parameters: {'num_leaves': 179, 'learning_rate': 0.17192511885048603, 'feature_fraction': 0.5663174130738317, 'bagging_fraction': 0.839910524083827, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,466] Trial 37 finished with value: 0.8912280701754385 and parameters: {'num_leaves': 155, 'learning_rate': 0.27997706786504456, 'feature_fraction': 0.6428319991372918, 'bagging_fraction': 0.8015107346126983, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,518] Trial 38 finished with value: 0.9192982456140352 and parameters: {'num_leaves': 197, 'learning_rate': 0.2004536964161004, 'feature_fraction': 0.5091905766329398, 'bagging_fraction': 0.7352712408421564, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,546] Trial 39 finished with value: 0.9087719298245613 and parameters: {'num_leaves': 275, 'learning_rate': 0.2613610355024353, 'feature_fraction': 0.6792452091628153, 'bagging_fraction': 0.8967853440106869, 'bagging_freq': 1, 'min_child_samples': 57}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,622] Trial 40 finished with value: 0.9017543859649123 and parameters: {'num_leaves': 247, 'learning_rate': 0.23170489698455674, 'feature_fraction': 0.732068086661974, 'bagging_fraction': 0.9475766260844563, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,660] Trial 41 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 254, 'learning_rate': 0.2151523274686539, 'feature_fraction': 0.917137416687465, 'bagging_fraction': 0.9157427286881448, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,696] Trial 42 finished with value: 0.9228070175438596 and parameters: {'num_leaves': 266, 'learning_rate': 0.17378172891393934, 'feature_fraction': 0.88194539164382, 'bagging_fraction': 0.8300801317768575, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,730] Trial 43 finished with value: 0.9122807017543859 and parameters: {'num_leaves': 231, 'learning_rate': 0.24889698140954494, 'feature_fraction': 0.9405511462932934, 'bagging_fraction': 0.7759358942775363, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,743] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 285, 'learning_rate': 0.29945862425092223, 'feature_fraction': 0.8561135736829244, 'bagging_fraction': 0.8755741524503199, 'bagging_freq': 2, 'min_child_samples': 74}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,753] Trial 45 finished with value: 0.5 and parameters: {'num_leaves': 250, 'learning_rate': 0.21116285127499262, 'feature_fraction': 0.793083377294872, 'bagging_fraction': 0.6842773112908754, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 21 with value: 0.9614035087719298.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.460878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.488041
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.490254
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.387743
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.406795
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.33646
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.382848
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.424908
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.316942
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.472129
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.358061
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.429101
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.589077
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.445601
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.408472
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.428587
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.406171
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.331924
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.41127
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.327716
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.314914
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.385381
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.376996
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.452255
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.37937
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.278041
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.417518
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.391899
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.397518
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.356771
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.322803
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.380812
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.415477
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.396021
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.313013
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.360291
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.384792
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.3223
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.335708
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.320654
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.396779
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.371938
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.367706
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.39807
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.416955
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.319139
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.349249
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.346623
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.686352
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.686352
[I 2025-09-17 13:18:02,812] Trial 46 finished with value: 0.9192982456140352 and parameters: {'num_leaves': 92, 'learning_rate': 0.18857000700124452, 'feature_fraction': 0.4634711971626876, 'bagging_fraction': 0.9295909371160926, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,838] Trial 47 finished with value: 0.8912280701754385 and parameters: {'num_leaves': 208, 'learning_rate': 0.26883622259303785, 'feature_fraction': 0.5723794477003956, 'bagging_fraction': 0.9005480250214386, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,862] Trial 48 finished with value: 0.8842105263157894 and parameters: {'num_leaves': 186, 'learning_rate': 0.13355005501577566, 'feature_fraction': 0.6195054258109639, 'bagging_fraction': 0.8410941608312015, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:02,957] Trial 49 finished with value: 0.894736842105263 and parameters: {'num_leaves': 122, 'learning_rate': 0.28567327474654025, 'feature_fraction': 0.9426659384327227, 'bagging_fraction': 0.7117154804868913, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 21 with value: 0.9614035087719298.
[I 2025-09-17 13:18:03,205] A new study created in memory with name: no-name-e2a6ca91-6d36-4cee-b2fa-b8866222d9a4
[I 2025-09-17 13:18:03,235] Trial 0 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 94, 'learning_rate': 0.2516218489945849, 'feature_fraction': 0.5381209374364924, 'bagging_fraction': 0.9763705327708314, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,241] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 42, 'learning_rate': 0.1486325802162446, 'feature_fraction': 0.6589579945335147, 'bagging_fraction': 0.5721892332205136, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,255] Trial 2 finished with value: 0.8614035087719298 and parameters: {'num_leaves': 73, 'learning_rate': 0.2945329947402413, 'feature_fraction': 0.9928029662993569, 'bagging_fraction': 0.7504901529544858, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,262] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 276, 'learning_rate': 0.2145106778274584, 'feature_fraction': 0.5588872214313876, 'bagging_fraction': 0.48461579533706306, 'bagging_freq': 7, 'min_child_samples': 83}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,274] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 174, 'learning_rate': 0.16673469742122787, 'feature_fraction': 0.7958871262653977, 'bagging_fraction': 0.42532076293068927, 'bagging_freq': 7, 'min_child_samples': 76}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,282] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 222, 'learning_rate': 0.09549795709648798, 'feature_fraction': 0.7870840310217055, 'bagging_fraction': 0.6409344874757963, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,304] Trial 6 finished with value: 0.8736842105263158 and parameters: {'num_leaves': 189, 'learning_rate': 0.16591643259980143, 'feature_fraction': 0.68082954821409, 'bagging_fraction': 0.7008305283159145, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,312] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.2985198796987847, 'feature_fraction': 0.8799089780530058, 'bagging_fraction': 0.6892346377105731, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,397] Trial 8 finished with value: 0.8245614035087719 and parameters: {'num_leaves': 172, 'learning_rate': 0.07870228654674416, 'feature_fraction': 0.6147843934288466, 'bagging_fraction': 0.710565502746218, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,410] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 290, 'learning_rate': 0.061139617936235846, 'feature_fraction': 0.8431063491461057, 'bagging_fraction': 0.7739487387638042, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,428] Trial 10 finished with value: 0.7701754385964912 and parameters: {'num_leaves': 104, 'learning_rate': 0.2363039460090182, 'feature_fraction': 0.4101250244472447, 'bagging_fraction': 0.9735620392806369, 'bagging_freq': 2, 'min_child_samples': 44}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,504] Trial 11 finished with value: 0.8526315789473684 and parameters: {'num_leaves': 122, 'learning_rate': 0.22173494411441325, 'feature_fraction': 0.49951204089507584, 'bagging_fraction': 0.9945106345565042, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,538] Trial 12 finished with value: 0.8736842105263158 and parameters: {'num_leaves': 25, 'learning_rate': 0.011954351880715697, 'feature_fraction': 0.7188043576700336, 'bagging_fraction': 0.8725347205356211, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 0 with value: 0.8912280701754386.
[I 2025-09-17 13:18:03,581] Trial 13 finished with value: 0.8947368421052633 and parameters: {'num_leaves': 130, 'learning_rate': 0.1630994057336595, 'feature_fraction': 0.4872539804085772, 'bagging_fraction': 0.8557790951480669, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,596] Trial 14 finished with value: 0.7701754385964912 and parameters: {'num_leaves': 122, 'learning_rate': 0.2597912264977234, 'feature_fraction': 0.4284503182549928, 'bagging_fraction': 0.8875843836275649, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,615] Trial 15 finished with value: 0.8315789473684211 and parameters: {'num_leaves': 76, 'learning_rate': 0.1244984526823876, 'feature_fraction': 0.526377483212208, 'bagging_fraction': 0.8481406444323509, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,636] Trial 16 finished with value: 0.7736842105263158 and parameters: {'num_leaves': 135, 'learning_rate': 0.19957030400208434, 'feature_fraction': 0.47225154898472854, 'bagging_fraction': 0.9344100489152967, 'bagging_freq': 1, 'min_child_samples': 58}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,667] Trial 17 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 81, 'learning_rate': 0.2583271851757004, 'feature_fraction': 0.5906130150725576, 'bagging_fraction': 0.8110950934885893, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,713] Trial 18 finished with value: 0.8807017543859649 and parameters: {'num_leaves': 13, 'learning_rate': 0.12140842862246182, 'feature_fraction': 0.6062522493164245, 'bagging_fraction': 0.8019009589298143, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,728] Trial 19 finished with value: 0.7298245614035088 and parameters: {'num_leaves': 55, 'learning_rate': 0.18829483293483545, 'feature_fraction': 0.608678173497368, 'bagging_fraction': 0.8147615847134513, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,740] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 148, 'learning_rate': 0.2697646409021539, 'feature_fraction': 0.4589503122031251, 'bagging_fraction': 0.5962753797889445, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,771] Trial 21 finished with value: 0.8736842105263158 and parameters: {'num_leaves': 93, 'learning_rate': 0.24681865165923608, 'feature_fraction': 0.5477189244765213, 'bagging_fraction': 0.9138662817759461, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 13 with value: 0.8947368421052633.
[I 2025-09-17 13:18:03,813] Trial 22 finished with value: 0.8964912280701756 and parameters: {'num_leaves': 98, 'learning_rate': 0.271751291082022, 'feature_fraction': 0.5672628631374051, 'bagging_fraction': 0.9408860852200496, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 22 with value: 0.8964912280701756.
[I 2025-09-17 13:18:03,852] Trial 23 finished with value: 0.856140350877193 and parameters: {'num_leaves': 59, 'learning_rate': 0.27803824147434136, 'feature_fraction': 0.5861596413939324, 'bagging_fraction': 0.834997828694268, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 22 with value: 0.8964912280701756.
[I 2025-09-17 13:18:03,952] Trial 24 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 116, 'learning_rate': 0.1922197794372381, 'feature_fraction': 0.6633008577662116, 'bagging_fraction': 0.9012200917619151, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 22 with value: 0.8964912280701756.
[I 2025-09-17 13:18:03,973] Trial 25 finished with value: 0.7929824561403509 and parameters: {'num_leaves': 151, 'learning_rate': 0.23143410708598838, 'feature_fraction': 0.4947610848365471, 'bagging_fraction': 0.9413416278501288, 'bagging_freq': 2, 'min_child_samples': 37}. Best is trial 22 with value: 0.8964912280701756.
[I 2025-09-17 13:18:03,999] Trial 26 finished with value: 0.8245614035087719 and parameters: {'num_leaves': 86, 'learning_rate': 0.03689217778107537, 'feature_fraction': 0.7462093930220115, 'bagging_fraction': 0.7638555049549185, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 22 with value: 0.8964912280701756.
[I 2025-09-17 13:18:04,039] Trial 27 finished with value: 0.9140350877192982 and parameters: {'num_leaves': 30, 'learning_rate': 0.2804504484570947, 'feature_fraction': 0.6414666495602692, 'bagging_fraction': 0.8564694109021613, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,089] Trial 28 finished with value: 0.8912280701754386 and parameters: {'num_leaves': 41, 'learning_rate': 0.2799690537262026, 'feature_fraction': 0.6439959673386055, 'bagging_fraction': 0.8709220640251831, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,111] Trial 29 finished with value: 0.8350877192982457 and parameters: {'num_leaves': 237, 'learning_rate': 0.13169067103744225, 'feature_fraction': 0.5333185869797757, 'bagging_fraction': 0.999802572011901, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,148] Trial 30 finished with value: 0.8736842105263158 and parameters: {'num_leaves': 104, 'learning_rate': 0.20745557286930882, 'feature_fraction': 0.44018396555248296, 'bagging_fraction': 0.949830843553903, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,183] Trial 31 finished with value: 0.880701754385965 and parameters: {'num_leaves': 57, 'learning_rate': 0.2524312805562825, 'feature_fraction': 0.5765445674887651, 'bagging_fraction': 0.8031679171959971, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,202] Trial 32 finished with value: 0.8052631578947369 and parameters: {'num_leaves': 37, 'learning_rate': 0.2810982513862391, 'feature_fraction': 0.6369790436474466, 'bagging_fraction': 0.8549511988133014, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,256] Trial 33 finished with value: 0.8912280701754385 and parameters: {'num_leaves': 72, 'learning_rate': 0.2555418030037267, 'feature_fraction': 0.6982080655870172, 'bagging_fraction': 0.7265059062498817, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,298] Trial 34 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 12, 'learning_rate': 0.2925769869616904, 'feature_fraction': 0.5140541600952885, 'bagging_fraction': 0.8291656667492407, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,325] Trial 35 finished with value: 0.8736842105263157 and parameters: {'num_leaves': 135, 'learning_rate': 0.23148382470740878, 'feature_fraction': 0.5686841125758519, 'bagging_fraction': 0.9192377354137024, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,362] Trial 36 finished with value: 0.880701754385965 and parameters: {'num_leaves': 83, 'learning_rate': 0.14884931973869028, 'feature_fraction': 0.9983940541621603, 'bagging_fraction': 0.7821725798627301, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,417] Trial 37 finished with value: 0.8842105263157894 and parameters: {'num_leaves': 105, 'learning_rate': 0.183276211439366, 'feature_fraction': 0.7391955424107797, 'bagging_fraction': 0.7418645973205842, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,436] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 64, 'learning_rate': 0.26724628998956756, 'feature_fraction': 0.48781718515209815, 'bagging_fraction': 0.6667567091878374, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,460] Trial 39 finished with value: 0.6631578947368422 and parameters: {'num_leaves': 29, 'learning_rate': 0.17436405347597386, 'feature_fraction': 0.9301106256039828, 'bagging_fraction': 0.9533394706959255, 'bagging_freq': 4, 'min_child_samples': 65}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,481] Trial 40 finished with value: 0.7438596491228071 and parameters: {'num_leaves': 167, 'learning_rate': 0.29944155955400653, 'feature_fraction': 0.6744926709210732, 'bagging_fraction': 0.5125971154742779, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,615] Trial 41 finished with value: 0.8982456140350877 and parameters: {'num_leaves': 92, 'learning_rate': 0.23931255519870967, 'feature_fraction': 0.5448367031679033, 'bagging_fraction': 0.8944089752358269, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,748] Trial 42 finished with value: 0.8842105263157894 and parameters: {'num_leaves': 139, 'learning_rate': 0.2482131717955769, 'feature_fraction': 0.5450385024171454, 'bagging_fraction': 0.8921330719581092, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,793] Trial 43 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 102, 'learning_rate': 0.22087404872712957, 'feature_fraction': 0.595183673824323, 'bagging_fraction': 0.8615580698670943, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,867] Trial 44 finished with value: 0.887719298245614 and parameters: {'num_leaves': 187, 'learning_rate': 0.28490999785065335, 'feature_fraction': 0.5619797892074173, 'bagging_fraction': 0.9183430086057931, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,908] Trial 45 finished with value: 0.8842105263157893 and parameters: {'num_leaves': 119, 'learning_rate': 0.10130168994515035, 'feature_fraction': 0.629114742592669, 'bagging_fraction': 0.9724110561579512, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,934] Trial 46 finished with value: 0.8403508771929824 and parameters: {'num_leaves': 46, 'learning_rate': 0.23914036575989137, 'feature_fraction': 0.5121073984071387, 'bagging_fraction': 0.8834256873412036, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:04,953] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 73, 'learning_rate': 0.26753485165096225, 'feature_fraction': 0.4639114037628304, 'bagging_fraction': 0.7908760409598691, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:05,002] Trial 48 finished with value: 0.8701754385964913 and parameters: {'num_leaves': 95, 'learning_rate': 0.21312428000465503, 'feature_fraction': 0.6963612098262855, 'bagging_fraction': 0.8149873244108029, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:05,083] Trial 49 finished with value: 0.9052631578947368 and parameters: {'num_leaves': 164, 'learning_rate': 0.1604288702865116, 'feature_fraction': 0.7819412915548023, 'bagging_fraction': 0.8388974882853287, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 27 with value: 0.9140350877192982.
[I 2025-09-17 13:18:05,280] A new study created in memory with name: no-name-0a818093-0194-4860-bc72-aacafe623f15
[I 2025-09-17 13:18:05,323] Trial 0 finished with value: 0.9586776859504131 and parameters: {'num_leaves': 222, 'learning_rate': 0.07444287081283538, 'feature_fraction': 0.7631963568771429, 'bagging_fraction': 0.4558285133733066, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,335] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.013470459645237466, 'feature_fraction': 0.4244058750451613, 'bagging_fraction': 0.6620780057649563, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,345] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 76, 'learning_rate': 0.07083774797036753, 'feature_fraction': 0.8305015224697181, 'bagging_fraction': 0.4264598880807307, 'bagging_freq': 7, 'min_child_samples': 46}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,354] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 215, 'learning_rate': 0.1065479631842545, 'feature_fraction': 0.8496622085598475, 'bagging_fraction': 0.5300760802960091, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,393] Trial 4 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 132, 'learning_rate': 0.05743753460374017, 'feature_fraction': 0.9954805696663159, 'bagging_fraction': 0.8394006088526786, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 0 with value: 0.9586776859504131.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.381821
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.410737
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.424035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.417236
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.429613
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.509642
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.485498
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.517188
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.58214
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.492455
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.500605
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.447624
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.583605
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.537162
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.578951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.46407
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.451751
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.606056
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.437774
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.427019
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.476634
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.475674
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.564653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.551372
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.445313
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.445613
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.554949
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.455727
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.431635
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.542038
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.45816
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.495133
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.453418
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.446728
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.458395
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.637216
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.583336
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.454263
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.451643
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.476446
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.44256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.440028
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.491845
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.68672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.481607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.440632
Training model for P046... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.288473
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.323763
[I 2025-09-17 13:18:05,407] Trial 5 finished with value: 0.7499999999999999 and parameters: {'num_leaves': 243, 'learning_rate': 0.13655128704316521, 'feature_fraction': 0.9666427544810448, 'bagging_fraction': 0.8358154251704584, 'bagging_freq': 7, 'min_child_samples': 51}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,433] Trial 6 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 84, 'learning_rate': 0.10338783365195078, 'feature_fraction': 0.45992870776047545, 'bagging_fraction': 0.6824161234969586, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,442] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 205, 'learning_rate': 0.04641548801789582, 'feature_fraction': 0.8489546059929057, 'bagging_fraction': 0.6572519740597673, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,453] Trial 8 finished with value: 0.6074380165289256 and parameters: {'num_leaves': 249, 'learning_rate': 0.11714062714737843, 'feature_fraction': 0.8370181933918002, 'bagging_fraction': 0.9624883694440526, 'bagging_freq': 5, 'min_child_samples': 61}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,463] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.056935925607849866, 'feature_fraction': 0.5085645329013136, 'bagging_fraction': 0.4713599026061605, 'bagging_freq': 3, 'min_child_samples': 82}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,515] Trial 10 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 19, 'learning_rate': 0.21753543593419242, 'feature_fraction': 0.6234242599778743, 'bagging_fraction': 0.5285234781286727, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,535] Trial 11 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 300, 'learning_rate': 0.1971004205973741, 'feature_fraction': 0.6686531937230821, 'bagging_fraction': 0.7652716704607823, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,562] Trial 12 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 298, 'learning_rate': 0.21455643759142398, 'feature_fraction': 0.6705801708737661, 'bagging_fraction': 0.787097022938747, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,675] Trial 13 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 294, 'learning_rate': 0.28422843344035154, 'feature_fraction': 0.5689575353257942, 'bagging_fraction': 0.7592101382617447, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,695] Trial 14 finished with value: 0.7727272727272727 and parameters: {'num_leaves': 258, 'learning_rate': 0.19642651819484036, 'feature_fraction': 0.7352448526674826, 'bagging_fraction': 0.5820689013159634, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,732] Trial 15 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 185, 'learning_rate': 0.1761455854440803, 'feature_fraction': 0.7482018654360056, 'bagging_fraction': 0.9531076757324916, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,746] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 270, 'learning_rate': 0.27364047138663705, 'feature_fraction': 0.652408811956959, 'bagging_fraction': 0.4005726219579772, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,756] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 221, 'learning_rate': 0.24642086813701763, 'feature_fraction': 0.7636421676691948, 'bagging_fraction': 0.5885667089600783, 'bagging_freq': 1, 'min_child_samples': 70}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,780] Trial 18 finished with value: 0.9545454545454545 and parameters: {'num_leaves': 182, 'learning_rate': 0.16524322996543733, 'feature_fraction': 0.573243675276223, 'bagging_fraction': 0.871726086979018, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,838] Trial 19 finished with value: 0.9462809917355371 and parameters: {'num_leaves': 275, 'learning_rate': 0.13746615282436012, 'feature_fraction': 0.9173426620751483, 'bagging_fraction': 0.7660064838597668, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,864] Trial 20 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 236, 'learning_rate': 0.017207345498175916, 'feature_fraction': 0.7843661646977943, 'bagging_fraction': 0.9089894281958657, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,890] Trial 21 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 182, 'learning_rate': 0.17324273901486148, 'feature_fraction': 0.578680747534513, 'bagging_fraction': 0.8733329256775394, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,926] Trial 22 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 124, 'learning_rate': 0.16486211249118984, 'feature_fraction': 0.57958158147758, 'bagging_fraction': 0.7250251642576478, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:05,948] Trial 23 finished with value: 0.9380165289256198 and parameters: {'num_leaves': 175, 'learning_rate': 0.24201620999658113, 'feature_fraction': 0.6807731752393842, 'bagging_fraction': 0.8287534528745906, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:06,034] Trial 24 finished with value: 0.9586776859504131 and parameters: {'num_leaves': 199, 'learning_rate': 0.08623082343779653, 'feature_fraction': 0.5048051513568381, 'bagging_fraction': 0.9159037718250476, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:06,124] Trial 25 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 217, 'learning_rate': 0.08632658731679785, 'feature_fraction': 0.504473294115821, 'bagging_fraction': 0.9977874539597951, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:06,181] Trial 26 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 272, 'learning_rate': 0.08573855336002809, 'feature_fraction': 0.40648476010497636, 'bagging_fraction': 0.5958344721948649, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:06,213] Trial 27 finished with value: 0.9462809917355371 and parameters: {'num_leaves': 113, 'learning_rate': 0.03442598631511442, 'feature_fraction': 0.7064139378715781, 'bagging_fraction': 0.7094362392225437, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:06,255] Trial 28 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 201, 'learning_rate': 0.12506338837124104, 'feature_fraction': 0.6255699323123087, 'bagging_fraction': 0.7985031586109059, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:06,392] Trial 29 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 151, 'learning_rate': 0.01517638397158333, 'feature_fraction': 0.46159583587064146, 'bagging_fraction': 0.6288040835366124, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:06,460] Trial 30 finished with value: 0.9380165289256199 and parameters: {'num_leaves': 234, 'learning_rate': 0.149079950187929, 'feature_fraction': 0.7961307177584765, 'bagging_fraction': 0.9146298937018813, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 0 with value: 0.9586776859504131.
[I 2025-09-17 13:18:06,602] Trial 31 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 149, 'learning_rate': 0.01780886504623977, 'feature_fraction': 0.4994033130077257, 'bagging_fraction': 0.6609180516731694, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 31 with value: 0.9628099173553719.
[I 2025-09-17 13:18:06,630] Trial 32 finished with value: 0.921487603305785 and parameters: {'num_leaves': 90, 'learning_rate': 0.08042597570859951, 'feature_fraction': 0.5110112213760319, 'bagging_fraction': 0.47605249875038286, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 31 with value: 0.9628099173553719.
[I 2025-09-17 13:18:06,688] Trial 33 finished with value: 0.9669421487603305 and parameters: {'num_leaves': 158, 'learning_rate': 0.030739485467147394, 'feature_fraction': 0.4609715249856527, 'bagging_fraction': 0.5262042408578598, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:06,747] Trial 34 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 161, 'learning_rate': 0.03432334441989729, 'feature_fraction': 0.45196783871113033, 'bagging_fraction': 0.46073594332965695, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:06,819] Trial 35 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 106, 'learning_rate': 0.032899463037272446, 'feature_fraction': 0.461840117248996, 'bagging_fraction': 0.46116744634955015, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:06,849] Trial 36 finished with value: 0.9462809917355371 and parameters: {'num_leaves': 140, 'learning_rate': 0.03701504596828418, 'feature_fraction': 0.4290771054703176, 'bagging_fraction': 0.5321530061036935, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:06,949] Trial 37 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 65, 'learning_rate': 0.06374120796912967, 'feature_fraction': 0.889244245550551, 'bagging_fraction': 0.5140248951596486, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:06,963] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 168, 'learning_rate': 0.011384457863919156, 'feature_fraction': 0.5408973981380346, 'bagging_fraction': 0.4348523871922985, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:06,999] Trial 39 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 145, 'learning_rate': 0.05029651607150547, 'feature_fraction': 0.4317834793543958, 'bagging_fraction': 0.5576823174564447, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,016] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 64, 'learning_rate': 0.10320966628916052, 'feature_fraction': 0.46732765953006977, 'bagging_fraction': 0.49262284394178335, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,073] Trial 41 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 195, 'learning_rate': 0.0293710969686494, 'feature_fraction': 0.4958346147369266, 'bagging_fraction': 0.4440039934137513, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,138] Trial 42 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 162, 'learning_rate': 0.0688144238218667, 'feature_fraction': 0.5368378575168613, 'bagging_fraction': 0.6418167888419943, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,200] Trial 43 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 126, 'learning_rate': 0.050399697840067544, 'feature_fraction': 0.5453440605336587, 'bagging_fraction': 0.42126813445613104, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,234] Trial 44 finished with value: 0.9545454545454545 and parameters: {'num_leaves': 194, 'learning_rate': 0.0242487371974844, 'feature_fraction': 0.4146205061509988, 'bagging_fraction': 0.5024346218869028, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,260] Trial 45 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 208, 'learning_rate': 0.09784370271037221, 'feature_fraction': 0.47913787219473203, 'bagging_fraction': 0.558777115428082, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,293] Trial 46 finished with value: 0.9380165289256198 and parameters: {'num_leaves': 157, 'learning_rate': 0.041098660504409405, 'feature_fraction': 0.4487528671651746, 'bagging_fraction': 0.674026768888765, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,355] Trial 47 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 137, 'learning_rate': 0.07490582749441119, 'feature_fraction': 0.6030871198588634, 'bagging_fraction': 0.6121569185193669, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,366] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 226, 'learning_rate': 0.058024979668969856, 'feature_fraction': 0.4001086364025726, 'bagging_fraction': 0.5412707290137758, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:07,382] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 170, 'learning_rate': 0.09269663484354697, 'feature_fraction': 0.5287166731746774, 'bagging_fraction': 0.4005824229707533, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 33 with value: 0.9669421487603305.
[I 2025-09-17 13:18:08,035] A new study created in memory with name: no-name-d428eeeb-325c-4b93-839c-184d99736273
[I 2025-09-17 13:18:08,047] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 29, 'learning_rate': 0.2806083438083179, 'feature_fraction': 0.6881756340990128, 'bagging_fraction': 0.45973931841265825, 'bagging_freq': 4, 'min_child_samples': 88}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:08,121] Trial 1 finished with value: 0.9752066115702479 and parameters: {'num_leaves': 74, 'learning_rate': 0.2207915464632481, 'feature_fraction': 0.5469632656453549, 'bagging_fraction': 0.9252705363667609, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 1 with value: 0.9752066115702479.
[I 2025-09-17 13:18:08,149] Trial 2 finished with value: 0.9834710743801653 and parameters: {'num_leaves': 15, 'learning_rate': 0.24384803096148241, 'feature_fraction': 0.6910166454522637, 'bagging_fraction': 0.7313610355740807, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,163] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 94, 'learning_rate': 0.2991558468646671, 'feature_fraction': 0.8219719368749387, 'bagging_fraction': 0.45253481592896544, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,173] Trial 4 finished with value: 0.6756198347107438 and parameters: {'num_leaves': 99, 'learning_rate': 0.2281413307789825, 'feature_fraction': 0.6575225951094061, 'bagging_fraction': 0.8446191550592212, 'bagging_freq': 1, 'min_child_samples': 58}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,210] Trial 5 finished with value: 0.9834710743801653 and parameters: {'num_leaves': 43, 'learning_rate': 0.2752445815377228, 'feature_fraction': 0.8646824104332551, 'bagging_fraction': 0.5106731532724426, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,223] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 159, 'learning_rate': 0.2991510787021402, 'feature_fraction': 0.885153727522188, 'bagging_fraction': 0.6695920346762987, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,230] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 106, 'learning_rate': 0.07245389571465773, 'feature_fraction': 0.6657077999372429, 'bagging_fraction': 0.8674263357218714, 'bagging_freq': 7, 'min_child_samples': 81}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,239] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.17313731621750222, 'feature_fraction': 0.43376957299888186, 'bagging_fraction': 0.5350923613028771, 'bagging_freq': 5, 'min_child_samples': 92}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,281] Trial 9 finished with value: 0.9793388429752066 and parameters: {'num_leaves': 235, 'learning_rate': 0.1944193999141722, 'feature_fraction': 0.62037064639645, 'bagging_fraction': 0.702801698680039, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,305] Trial 10 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 296, 'learning_rate': 0.10636097789751864, 'feature_fraction': 0.9898766448137388, 'bagging_fraction': 0.7241504069389149, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,327] Trial 11 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 23, 'learning_rate': 0.23517295829378837, 'feature_fraction': 0.8177794333887343, 'bagging_fraction': 0.5863391088215482, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 2 with value: 0.9834710743801653.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.602936
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.307648
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.618197
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.385036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.324773
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.325757
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.334002
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.563216
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.286992
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.299519
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.288608
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.50005
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.322432
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.264576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.325775
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.261971
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.274647
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.327868
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.348959
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.303368
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.374688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.311432
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.332736
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.361446
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.318803
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.303678
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.339468
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.388344
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.34485
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.354561
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.348043
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.310991
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.31967
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.358645
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.330439
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.370286
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.322889
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.636901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.284958
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.248287
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.620326
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.19018
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.218681
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.286051
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.295375
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:08,451] Trial 12 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 44, 'learning_rate': 0.1333257387203554, 'feature_fraction': 0.8165912557338909, 'bagging_fraction': 0.7733861679479044, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,478] Trial 13 finished with value: 0.8347107438016529 and parameters: {'num_leaves': 180, 'learning_rate': 0.017038940647776585, 'feature_fraction': 0.9562797859051226, 'bagging_fraction': 0.5975963561422575, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,504] Trial 14 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 13, 'learning_rate': 0.2589966326228222, 'feature_fraction': 0.760087206507386, 'bagging_fraction': 0.41554090495902524, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,529] Trial 15 finished with value: 0.6570247933884298 and parameters: {'num_leaves': 57, 'learning_rate': 0.1932889033534934, 'feature_fraction': 0.5544729701655094, 'bagging_fraction': 0.6435866833352182, 'bagging_freq': 4, 'min_child_samples': 43}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,537] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.2637310932093075, 'feature_fraction': 0.8986402272228814, 'bagging_fraction': 0.9982432354481046, 'bagging_freq': 2, 'min_child_samples': 69}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,569] Trial 17 finished with value: 0.9834710743801653 and parameters: {'num_leaves': 68, 'learning_rate': 0.24631161198164547, 'feature_fraction': 0.7381583903934298, 'bagging_fraction': 0.5317340950025105, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,632] Trial 18 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 129, 'learning_rate': 0.14730218674412485, 'feature_fraction': 0.5583586933586818, 'bagging_fraction': 0.7926881224613493, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,651] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 10, 'learning_rate': 0.21372451380272497, 'feature_fraction': 0.7563156527702081, 'bagging_fraction': 0.535420557013515, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,664] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 49, 'learning_rate': 0.2678992206191244, 'feature_fraction': 0.898508968852314, 'bagging_fraction': 0.7478073200509184, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,687] Trial 21 finished with value: 0.9752066115702479 and parameters: {'num_leaves': 71, 'learning_rate': 0.24502210697579008, 'feature_fraction': 0.7434405659341434, 'bagging_fraction': 0.5195788666918226, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,728] Trial 22 finished with value: 0.9380165289256199 and parameters: {'num_leaves': 76, 'learning_rate': 0.20175772583622462, 'feature_fraction': 0.610386848720313, 'bagging_fraction': 0.6139629719228236, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,745] Trial 23 finished with value: 0.5 and parameters: {'num_leaves': 42, 'learning_rate': 0.2511481422796069, 'feature_fraction': 0.749170497397341, 'bagging_fraction': 0.48986597690742145, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,784] Trial 24 finished with value: 0.9793388429752067 and parameters: {'num_leaves': 122, 'learning_rate': 0.1726341951345104, 'feature_fraction': 0.8559083945433407, 'bagging_fraction': 0.5601404342215316, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 2 with value: 0.9834710743801653.
[I 2025-09-17 13:18:08,811] Trial 25 finished with value: 0.9917355371900827 and parameters: {'num_leaves': 64, 'learning_rate': 0.2786015489032195, 'feature_fraction': 0.7249331950515285, 'bagging_fraction': 0.661692488134067, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:08,840] Trial 26 finished with value: 0.9752066115702479 and parameters: {'num_leaves': 39, 'learning_rate': 0.28338052617251996, 'feature_fraction': 0.49053854180294626, 'bagging_fraction': 0.6698598318637088, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:08,865] Trial 27 finished with value: 0.9628099173553718 and parameters: {'num_leaves': 95, 'learning_rate': 0.2792552542036808, 'feature_fraction': 0.7057654557342227, 'bagging_fraction': 0.8306921743927878, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:08,876] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.2973155341288253, 'feature_fraction': 0.9460830953729726, 'bagging_fraction': 0.6623516300302166, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:08,929] Trial 29 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 26, 'learning_rate': 0.27554120712686425, 'feature_fraction': 0.6930367865494297, 'bagging_fraction': 0.4116000923024163, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:08,963] Trial 30 finished with value: 0.9752066115702479 and parameters: {'num_leaves': 35, 'learning_rate': 0.23259232272804253, 'feature_fraction': 0.622386309838216, 'bagging_fraction': 0.4674883982088482, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:08,990] Trial 31 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 70, 'learning_rate': 0.2536281669552628, 'feature_fraction': 0.7890840779371463, 'bagging_fraction': 0.4937897852610335, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,032] Trial 32 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 58, 'learning_rate': 0.21040751524091855, 'feature_fraction': 0.7187267595603823, 'bagging_fraction': 0.6379109168764163, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,048] Trial 33 finished with value: 0.5 and parameters: {'num_leaves': 83, 'learning_rate': 0.2809593482758339, 'feature_fraction': 0.6529350563062898, 'bagging_fraction': 0.5633371755042059, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,116] Trial 34 finished with value: 0.9586776859504132 and parameters: {'num_leaves': 112, 'learning_rate': 0.2354168214533601, 'feature_fraction': 0.7760007949128125, 'bagging_fraction': 0.7004503990714974, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,207] Trial 35 finished with value: 0.9545454545454545 and parameters: {'num_leaves': 154, 'learning_rate': 0.22222640827162077, 'feature_fraction': 0.8512812638382083, 'bagging_fraction': 0.44078406051197583, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,238] Trial 36 finished with value: 0.9545454545454546 and parameters: {'num_leaves': 61, 'learning_rate': 0.2975024207165834, 'feature_fraction': 0.7167975941415968, 'bagging_fraction': 0.918294478920562, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,265] Trial 37 finished with value: 0.743801652892562 and parameters: {'num_leaves': 89, 'learning_rate': 0.17710030969368518, 'feature_fraction': 0.5873947346054684, 'bagging_fraction': 0.801929374079499, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,288] Trial 38 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 31, 'learning_rate': 0.2677256984031764, 'feature_fraction': 0.6681765680301374, 'bagging_fraction': 0.6280688139279188, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,323] Trial 39 finished with value: 0.9710743801652892 and parameters: {'num_leaves': 149, 'learning_rate': 0.24805733437902888, 'feature_fraction': 0.7903138841977241, 'bagging_fraction': 0.7360487265014019, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,353] Trial 40 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 254, 'learning_rate': 0.05506384163236282, 'feature_fraction': 0.8550876975884913, 'bagging_fraction': 0.5678863539722997, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,405] Trial 41 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 108, 'learning_rate': 0.11001864011814484, 'feature_fraction': 0.8611870038012732, 'bagging_fraction': 0.5426747773910038, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,432] Trial 42 finished with value: 0.9628099173553719 and parameters: {'num_leaves': 128, 'learning_rate': 0.1749118559170461, 'feature_fraction': 0.931497660906212, 'bagging_fraction': 0.4962893601693903, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,472] Trial 43 finished with value: 0.9710743801652892 and parameters: {'num_leaves': 171, 'learning_rate': 0.2866574638813301, 'feature_fraction': 0.8254761801312845, 'bagging_fraction': 0.5835838504975085, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,558] Trial 44 finished with value: 0.9297520661157025 and parameters: {'num_leaves': 121, 'learning_rate': 0.15748703352330604, 'feature_fraction': 0.9882333929181643, 'bagging_fraction': 0.6732003584947974, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,588] Trial 45 finished with value: 0.9669421487603306 and parameters: {'num_leaves': 52, 'learning_rate': 0.23941557071038766, 'feature_fraction': 0.6759709056955974, 'bagging_fraction': 0.45335209863492026, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,617] Trial 46 finished with value: 0.9380165289256198 and parameters: {'num_leaves': 24, 'learning_rate': 0.22539514841136182, 'feature_fraction': 0.8086798578852394, 'bagging_fraction': 0.5573017646859396, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,649] Trial 47 finished with value: 0.9256198347107437 and parameters: {'num_leaves': 65, 'learning_rate': 0.18612096985052506, 'feature_fraction': 0.6404818276298594, 'bagging_fraction': 0.6056509108214851, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,750] Trial 48 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 143, 'learning_rate': 0.12904424247674046, 'feature_fraction': 0.8705613321680593, 'bagging_fraction': 0.5069921713837581, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,792] Trial 49 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 79, 'learning_rate': 0.26035900340435164, 'feature_fraction': 0.9202586924704602, 'bagging_fraction': 0.7607967333967462, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 25 with value: 0.9917355371900827.
[I 2025-09-17 13:18:09,980] A new study created in memory with name: no-name-3069cd27-c8bc-465a-b6b9-830b7ef7ad6b
[I 2025-09-17 13:18:09,988] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 238, 'learning_rate': 0.2721594992027611, 'feature_fraction': 0.8361752687797679, 'bagging_fraction': 0.7384356874094997, 'bagging_freq': 3, 'min_child_samples': 80}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:10,011] Trial 1 finished with value: 0.884297520661157 and parameters: {'num_leaves': 218, 'learning_rate': 0.2055262319961721, 'feature_fraction': 0.9185292027567659, 'bagging_fraction': 0.599367514351773, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 1 with value: 0.884297520661157.
[I 2025-09-17 13:18:10,075] Trial 2 finished with value: 0.8760330578512396 and parameters: {'num_leaves': 268, 'learning_rate': 0.06082632604391798, 'feature_fraction': 0.6346065819814187, 'bagging_fraction': 0.8418191503914931, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 1 with value: 0.884297520661157.
[I 2025-09-17 13:18:10,094] Trial 3 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 40, 'learning_rate': 0.025961172120936578, 'feature_fraction': 0.5535734799426243, 'bagging_fraction': 0.8256941176678712, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 3 with value: 0.9049586776859504.
[I 2025-09-17 13:18:10,112] Trial 4 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 219, 'learning_rate': 0.22262765144056906, 'feature_fraction': 0.8288744937899606, 'bagging_fraction': 0.6170721975358009, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 4 with value: 0.9090909090909091.
[I 2025-09-17 13:18:10,251] Trial 5 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 75, 'learning_rate': 0.08850975712554013, 'feature_fraction': 0.5292070623853815, 'bagging_fraction': 0.8398329672592231, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 4 with value: 0.9090909090909091.
[I 2025-09-17 13:18:10,354] Trial 6 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 192, 'learning_rate': 0.20283549694561814, 'feature_fraction': 0.5119865319669836, 'bagging_fraction': 0.9396978050915161, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 4 with value: 0.9090909090909091.
[I 2025-09-17 13:18:10,367] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 219, 'learning_rate': 0.09038117974787262, 'feature_fraction': 0.4479137414974424, 'bagging_fraction': 0.8601288038438089, 'bagging_freq': 6, 'min_child_samples': 98}. Best is trial 4 with value: 0.9090909090909091.
[I 2025-09-17 13:18:10,384] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 230, 'learning_rate': 0.12641799111680022, 'feature_fraction': 0.4473417408610283, 'bagging_fraction': 0.6308069708794806, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 4 with value: 0.9090909090909091.
[I 2025-09-17 13:18:10,420] Trial 9 finished with value: 0.9049586776859505 and parameters: {'num_leaves': 219, 'learning_rate': 0.04500037504516777, 'feature_fraction': 0.8711302403935055, 'bagging_fraction': 0.42887688306607946, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 4 with value: 0.9090909090909091.
[I 2025-09-17 13:18:10,434] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.2805914598468911, 'feature_fraction': 0.7725575680207852, 'bagging_fraction': 0.4648223866596428, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial 4 with value: 0.9090909090909091.
[I 2025-09-17 13:18:10,461] Trial 11 finished with value: 0.7892561983471074 and parameters: {'num_leaves': 297, 'learning_rate': 0.18284580206360418, 'feature_fraction': 0.9779674487150742, 'bagging_fraction': 0.40748038738546755, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 4 with value: 0.9090909090909091.
[I 2025-09-17 13:18:10,484] Trial 12 finished with value: 0.9090909090909092 and parameters: {'num_leaves': 150, 'learning_rate': 0.01239662019175776, 'feature_fraction': 0.8161847449244105, 'bagging_fraction': 0.5215089138133391, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 12 with value: 0.9090909090909092.
[I 2025-09-17 13:18:10,503] Trial 13 finished with value: 0.6735537190082646 and parameters: {'num_leaves': 152, 'learning_rate': 0.23965780509388865, 'feature_fraction': 0.7274924371073538, 'bagging_fraction': 0.5445569717485244, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 12 with value: 0.9090909090909092.
[I 2025-09-17 13:18:10,527] Trial 14 finished with value: 0.896694214876033 and parameters: {'num_leaves': 114, 'learning_rate': 0.14409140724838848, 'feature_fraction': 0.7854267438756835, 'bagging_fraction': 0.5296098024422519, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 12 with value: 0.9090909090909092.
[I 2025-09-17 13:18:10,551] Trial 15 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 180, 'learning_rate': 0.23537947857349006, 'feature_fraction': 0.6605098689884312, 'bagging_fraction': 0.7073814990041571, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 12 with value: 0.9090909090909092.
[I 2025-09-17 13:18:10,569] Trial 16 finished with value: 0.6652892561983472 and parameters: {'num_leaves': 89, 'learning_rate': 0.1618367052495641, 'feature_fraction': 0.9905272448207693, 'bagging_fraction': 0.6340955054222719, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 12 with value: 0.9090909090909092.
[I 2025-09-17 13:18:10,581] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 181, 'learning_rate': 0.015009234770958585, 'feature_fraction': 0.8724512480517841, 'bagging_fraction': 0.5060113877621368, 'bagging_freq': 7, 'min_child_samples': 67}. Best is trial 12 with value: 0.9090909090909092.
[I 2025-09-17 13:18:10,609] Trial 18 finished with value: 0.9090909090909092 and parameters: {'num_leaves': 148, 'learning_rate': 0.11373724776884357, 'feature_fraction': 0.7186402040556205, 'bagging_fraction': 0.5659997991223242, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 12 with value: 0.9090909090909092.
[I 2025-09-17 13:18:10,641] Trial 19 finished with value: 0.9008264462809918 and parameters: {'num_leaves': 109, 'learning_rate': 0.10847145939261146, 'feature_fraction': 0.7117890541687779, 'bagging_fraction': 0.5736975901570958, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 12 with value: 0.9090909090909092.
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.229812
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.572378
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.247884
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.549135
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.241652
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.291863
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.242703
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.304543
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.203173
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.222043
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.252037
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.26594
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.210025
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.23036
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.244466
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.246722
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.636576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.254474
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.28374
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.283437
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.53501
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.282684
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.250591
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.331072
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.229696
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.263108
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.219037
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.321224
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.233499
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.31272
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.398261
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.290832
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.263778
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.420659
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.430994
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.474831
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.38729
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.42112
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.461538
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.382359
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.490134
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.516745
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.599974
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.401456
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.413558
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.607941
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.375289
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.387747
[I 2025-09-17 13:18:10,664] Trial 20 finished with value: 0.743801652892562 and parameters: {'num_leaves': 58, 'learning_rate': 0.06299224570264142, 'feature_fraction': 0.6505491666273805, 'bagging_fraction': 0.7596499691471882, 'bagging_freq': 3, 'min_child_samples': 52}. Best is trial 12 with value: 0.9090909090909092.
[I 2025-09-17 13:18:10,689] Trial 21 finished with value: 0.9173553719008264 and parameters: {'num_leaves': 12, 'learning_rate': 0.1591095933181511, 'feature_fraction': 0.7786975808069405, 'bagging_fraction': 0.6725400618295205, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 21 with value: 0.9173553719008264.
[I 2025-09-17 13:18:10,726] Trial 22 finished with value: 0.8760330578512397 and parameters: {'num_leaves': 11, 'learning_rate': 0.16640199483424173, 'feature_fraction': 0.769065045363209, 'bagging_fraction': 0.6721393640251347, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 21 with value: 0.9173553719008264.
[I 2025-09-17 13:18:10,752] Trial 23 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 149, 'learning_rate': 0.12871408278030186, 'feature_fraction': 0.5957677674931893, 'bagging_fraction': 0.48380705074030983, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 21 with value: 0.9173553719008264.
[I 2025-09-17 13:18:10,776] Trial 24 finished with value: 0.8347107438016529 and parameters: {'num_leaves': 15, 'learning_rate': 0.13135258095616298, 'feature_fraction': 0.5790164964763405, 'bagging_fraction': 0.48391183818377514, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 21 with value: 0.9173553719008264.
[I 2025-09-17 13:18:10,790] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 118, 'learning_rate': 0.09053123367642715, 'feature_fraction': 0.5996808168301714, 'bagging_fraction': 0.450940610332713, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 21 with value: 0.9173553719008264.
[I 2025-09-17 13:18:10,821] Trial 26 finished with value: 0.8884297520661157 and parameters: {'num_leaves': 89, 'learning_rate': 0.19065309470968783, 'feature_fraction': 0.9403268175506259, 'bagging_fraction': 0.6729372371586402, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 21 with value: 0.9173553719008264.
[I 2025-09-17 13:18:10,882] Trial 27 finished with value: 0.9421487603305785 and parameters: {'num_leaves': 165, 'learning_rate': 0.15229023065159636, 'feature_fraction': 0.6762016479021833, 'bagging_fraction': 0.4930869016046769, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:10,936] Trial 28 finished with value: 0.8719008264462811 and parameters: {'num_leaves': 168, 'learning_rate': 0.14937373652958622, 'feature_fraction': 0.6167324532534959, 'bagging_fraction': 0.9938858309573897, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:10,949] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 261, 'learning_rate': 0.262566982080526, 'feature_fraction': 0.6918193008890704, 'bagging_fraction': 0.7626663735948576, 'bagging_freq': 2, 'min_child_samples': 72}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:10,992] Trial 30 finished with value: 0.8925619834710744 and parameters: {'num_leaves': 45, 'learning_rate': 0.2997890524228115, 'feature_fraction': 0.40306607820574136, 'bagging_fraction': 0.40089191772426047, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,015] Trial 31 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 137, 'learning_rate': 0.17339084315526837, 'feature_fraction': 0.8225394560939432, 'bagging_fraction': 0.5128076076725621, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,032] Trial 32 finished with value: 0.7169421487603307 and parameters: {'num_leaves': 191, 'learning_rate': 0.13463697488650495, 'feature_fraction': 0.7486559212406745, 'bagging_fraction': 0.4844440086396168, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,065] Trial 33 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 164, 'learning_rate': 0.19676977216198635, 'feature_fraction': 0.8868223133360311, 'bagging_fraction': 0.5745827677788952, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,105] Trial 34 finished with value: 0.884297520661157 and parameters: {'num_leaves': 201, 'learning_rate': 0.06453499533182683, 'feature_fraction': 0.6748546557194471, 'bagging_fraction': 0.44858429119970544, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,132] Trial 35 finished with value: 0.884297520661157 and parameters: {'num_leaves': 260, 'learning_rate': 0.04138730752358674, 'feature_fraction': 0.8048973392409559, 'bagging_fraction': 0.5407219578078903, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,149] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.21686000981484269, 'feature_fraction': 0.5607952955417755, 'bagging_fraction': 0.5935319173753455, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,161] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 93, 'learning_rate': 0.1062828692087927, 'feature_fraction': 0.6342208526132107, 'bagging_fraction': 0.48965660118056087, 'bagging_freq': 5, 'min_child_samples': 85}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,309] Trial 38 finished with value: 0.8719008264462811 and parameters: {'num_leaves': 66, 'learning_rate': 0.07776871969966384, 'feature_fraction': 0.8500849753369212, 'bagging_fraction': 0.7191110691817341, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,337] Trial 39 finished with value: 0.871900826446281 and parameters: {'num_leaves': 36, 'learning_rate': 0.17556391616748385, 'feature_fraction': 0.5115991595861861, 'bagging_fraction': 0.8093705201337178, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,358] Trial 40 finished with value: 0.8739669421487604 and parameters: {'num_leaves': 244, 'learning_rate': 0.15701991949233016, 'feature_fraction': 0.7361476403253989, 'bagging_fraction': 0.6093359934058934, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,390] Trial 41 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 147, 'learning_rate': 0.11026282147824798, 'feature_fraction': 0.6901574154297406, 'bagging_fraction': 0.5690056541007834, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,433] Trial 42 finished with value: 0.8925619834710743 and parameters: {'num_leaves': 166, 'learning_rate': 0.11773301511415904, 'feature_fraction': 0.7943141070708916, 'bagging_fraction': 0.6391572230650715, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,456] Trial 43 finished with value: 0.7768595041322315 and parameters: {'num_leaves': 205, 'learning_rate': 0.13768846907051535, 'feature_fraction': 0.7530480932310668, 'bagging_fraction': 0.5407083219361832, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,482] Trial 44 finished with value: 0.8842975206611571 and parameters: {'num_leaves': 148, 'learning_rate': 0.09263866643077126, 'feature_fraction': 0.7198891892355295, 'bagging_fraction': 0.6677117418532231, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,506] Trial 45 finished with value: 0.9173553719008264 and parameters: {'num_leaves': 101, 'learning_rate': 0.04180866922608893, 'feature_fraction': 0.8282296060986521, 'bagging_fraction': 0.5162905148267583, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,529] Trial 46 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 103, 'learning_rate': 0.02254697439251917, 'feature_fraction': 0.8206570611472648, 'bagging_fraction': 0.43248010224355615, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,547] Trial 47 finished with value: 0.6735537190082644 and parameters: {'num_leaves': 126, 'learning_rate': 0.03520627618212227, 'feature_fraction': 0.928105919652684, 'bagging_fraction': 0.4700710198649264, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,586] Trial 48 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 79, 'learning_rate': 0.050633537444894794, 'feature_fraction': 0.8368235501467294, 'bagging_fraction': 0.49756087188437575, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:11,715] Trial 49 finished with value: 0.8925619834710743 and parameters: {'num_leaves': 180, 'learning_rate': 0.017080156463225235, 'feature_fraction': 0.5306329452443204, 'bagging_fraction': 0.8818449188213626, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 27 with value: 0.9421487603305785.
[I 2025-09-17 13:18:12,004] A new study created in memory with name: no-name-7c240f34-6b7a-48a5-8ca7-39dac12ae0aa
[I 2025-09-17 13:18:12,012] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 245, 'learning_rate': 0.05688243553063523, 'feature_fraction': 0.921580011144169, 'bagging_fraction': 0.8655469659578516, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:12,020] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 49, 'learning_rate': 0.1848518823773086, 'feature_fraction': 0.696254129346659, 'bagging_fraction': 0.8634316630203399, 'bagging_freq': 2, 'min_child_samples': 70}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:12,030] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 261, 'learning_rate': 0.1489935938512717, 'feature_fraction': 0.6708400342868877, 'bagging_fraction': 0.7321648291746943, 'bagging_freq': 7, 'min_child_samples': 83}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:12,046] Trial 3 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 15, 'learning_rate': 0.25095307386037913, 'feature_fraction': 0.5037111717656543, 'bagging_fraction': 0.7966913891878195, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 3 with value: 0.8677685950413223.
[I 2025-09-17 13:18:12,065] Trial 4 finished with value: 0.768595041322314 and parameters: {'num_leaves': 174, 'learning_rate': 0.2790031690266699, 'feature_fraction': 0.5881613278672042, 'bagging_fraction': 0.9943127263610558, 'bagging_freq': 1, 'min_child_samples': 57}. Best is trial 3 with value: 0.8677685950413223.
[I 2025-09-17 13:18:12,073] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 16, 'learning_rate': 0.16426468389700288, 'feature_fraction': 0.7977250927031729, 'bagging_fraction': 0.8937589042530176, 'bagging_freq': 5, 'min_child_samples': 96}. Best is trial 3 with value: 0.8677685950413223.
[I 2025-09-17 13:18:12,082] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 155, 'learning_rate': 0.05890743331792185, 'feature_fraction': 0.7030763213180853, 'bagging_fraction': 0.9165255950365572, 'bagging_freq': 1, 'min_child_samples': 72}. Best is trial 3 with value: 0.8677685950413223.
[I 2025-09-17 13:18:12,090] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.06964081173489745, 'feature_fraction': 0.8654642519495688, 'bagging_fraction': 0.4561029418430175, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 3 with value: 0.8677685950413223.
[I 2025-09-17 13:18:12,101] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.2596138536799834, 'feature_fraction': 0.885918652179595, 'bagging_fraction': 0.7869040428058944, 'bagging_freq': 5, 'min_child_samples': 68}. Best is trial 3 with value: 0.8677685950413223.
[I 2025-09-17 13:18:12,123] Trial 9 finished with value: 0.8657024793388429 and parameters: {'num_leaves': 13, 'learning_rate': 0.14096936109355698, 'feature_fraction': 0.5829080639634543, 'bagging_fraction': 0.943857549245955, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 3 with value: 0.8677685950413223.
[I 2025-09-17 13:18:12,210] Trial 10 finished with value: 0.871900826446281 and parameters: {'num_leaves': 91, 'learning_rate': 0.21632488863379823, 'feature_fraction': 0.40064315154988633, 'bagging_fraction': 0.5690110989976175, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 10 with value: 0.871900826446281.
[I 2025-09-17 13:18:12,300] Trial 11 finished with value: 0.8140495867768596 and parameters: {'num_leaves': 89, 'learning_rate': 0.22944050025782237, 'feature_fraction': 0.40809345536797254, 'bagging_fraction': 0.5624507250006476, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 10 with value: 0.871900826446281.
[I 2025-09-17 13:18:12,323] Trial 12 finished with value: 0.8801652892561983 and parameters: {'num_leaves': 93, 'learning_rate': 0.22534955756021696, 'feature_fraction': 0.403501119226883, 'bagging_fraction': 0.6196216024161775, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 12 with value: 0.8801652892561983.
[I 2025-09-17 13:18:12,433] Trial 13 finished with value: 0.884297520661157 and parameters: {'num_leaves': 104, 'learning_rate': 0.20596001632829405, 'feature_fraction': 0.41910733924095017, 'bagging_fraction': 0.607308714000373, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 13 with value: 0.884297520661157.
[I 2025-09-17 13:18:12,465] Trial 14 finished with value: 0.8884297520661157 and parameters: {'num_leaves': 99, 'learning_rate': 0.2007229269299324, 'feature_fraction': 0.48920166511864066, 'bagging_fraction': 0.6214000657429601, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 14 with value: 0.8884297520661157.
[I 2025-09-17 13:18:12,512] Trial 15 finished with value: 0.8966942148760331 and parameters: {'num_leaves': 123, 'learning_rate': 0.10522110685047702, 'feature_fraction': 0.5064227229292303, 'bagging_fraction': 0.6563451851897165, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,532] Trial 16 finished with value: 0.8615702479338843 and parameters: {'num_leaves': 130, 'learning_rate': 0.09813247731324704, 'feature_fraction': 0.5168601797172379, 'bagging_fraction': 0.4628953923801621, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,582] Trial 17 finished with value: 0.8801652892561984 and parameters: {'num_leaves': 212, 'learning_rate': 0.0191500581155922, 'feature_fraction': 0.5102363618108364, 'bagging_fraction': 0.664978910746388, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,604] Trial 18 finished with value: 0.5929752066115703 and parameters: {'num_leaves': 121, 'learning_rate': 0.11524727231584789, 'feature_fraction': 0.6077060517439993, 'bagging_fraction': 0.5149410350913757, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,628] Trial 19 finished with value: 0.5764462809917356 and parameters: {'num_leaves': 300, 'learning_rate': 0.1152822505249746, 'feature_fraction': 0.4880770555382319, 'bagging_fraction': 0.6664200707711992, 'bagging_freq': 2, 'min_child_samples': 44}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,662] Trial 20 finished with value: 0.884297520661157 and parameters: {'num_leaves': 57, 'learning_rate': 0.1885027519823765, 'feature_fraction': 0.6425268355327249, 'bagging_fraction': 0.7469372643515338, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,717] Trial 21 finished with value: 0.8471074380165289 and parameters: {'num_leaves': 115, 'learning_rate': 0.18993978968588024, 'feature_fraction': 0.4664406570464299, 'bagging_fraction': 0.6101202063199417, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,738] Trial 22 finished with value: 0.5537190082644629 and parameters: {'num_leaves': 60, 'learning_rate': 0.2976406986567557, 'feature_fraction': 0.46221670966615613, 'bagging_fraction': 0.40334733814670337, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,780] Trial 23 finished with value: 0.828512396694215 and parameters: {'num_leaves': 139, 'learning_rate': 0.20867745651665137, 'feature_fraction': 0.5446704090673753, 'bagging_fraction': 0.6737600976599578, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,807] Trial 24 finished with value: 0.8760330578512396 and parameters: {'num_leaves': 82, 'learning_rate': 0.16418545583586705, 'feature_fraction': 0.7771146967895846, 'bagging_fraction': 0.6114026293786224, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 15 with value: 0.8966942148760331.
[I 2025-09-17 13:18:12,874] Trial 25 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 110, 'learning_rate': 0.1269628242154683, 'feature_fraction': 0.4464400484937037, 'bagging_fraction': 0.5503239143795955, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:12,888] Trial 26 finished with value: 0.5 and parameters: {'num_leaves': 197, 'learning_rate': 0.08902615182289822, 'feature_fraction': 0.5460778333241239, 'bagging_fraction': 0.5386837060832022, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:12,909] Trial 27 finished with value: 0.8305785123966942 and parameters: {'num_leaves': 148, 'learning_rate': 0.1261831778178818, 'feature_fraction': 0.45402819361913227, 'bagging_fraction': 0.49319124438622275, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 25 with value: 0.9049586776859504.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.589597
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.367041
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.429596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.371057
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.505378
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.400048
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.332689
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.434964
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.39187
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.397443
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.617043
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.406367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.39506
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.508436
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.456251
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.417639
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.423231
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.384239
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.423578
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.490263
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.386474
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.392615
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.536258
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.624599
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.381395
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.411591
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.467987
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.560138
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.419343
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.446774
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.474184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.425672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.380918
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.422024
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.403602
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.470026
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.432196
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.627309
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.621458
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.40615
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.445414
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.617516
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.481275
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.421866
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.396088
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.470413
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:12,986] Trial 28 finished with value: 0.8884297520661157 and parameters: {'num_leaves': 73, 'learning_rate': 0.01773860942435032, 'feature_fraction': 0.5344174143630307, 'bagging_fraction': 0.7067288827044556, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,003] Trial 29 finished with value: 0.5165289256198348 and parameters: {'num_leaves': 37, 'learning_rate': 0.08717668357481052, 'feature_fraction': 0.4480481786403472, 'bagging_fraction': 0.5745214627136868, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,036] Trial 30 finished with value: 0.8925619834710744 and parameters: {'num_leaves': 113, 'learning_rate': 0.04138096579601404, 'feature_fraction': 0.629604165925036, 'bagging_fraction': 0.6446323374292772, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,070] Trial 31 finished with value: 0.8636363636363635 and parameters: {'num_leaves': 115, 'learning_rate': 0.035621167569014345, 'feature_fraction': 0.6296081581444202, 'bagging_fraction': 0.6379828125707216, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,104] Trial 32 finished with value: 0.8719008264462811 and parameters: {'num_leaves': 134, 'learning_rate': 0.052162101440416664, 'feature_fraction': 0.5693287406562796, 'bagging_fraction': 0.7125314547510958, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,145] Trial 33 finished with value: 0.8512396694214877 and parameters: {'num_leaves': 103, 'learning_rate': 0.13394614481819173, 'feature_fraction': 0.9601912444309335, 'bagging_fraction': 0.7664262188067823, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,178] Trial 34 finished with value: 0.8719008264462811 and parameters: {'num_leaves': 72, 'learning_rate': 0.1590878107807466, 'feature_fraction': 0.713216259755685, 'bagging_fraction': 0.8180919169830115, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,200] Trial 35 finished with value: 0.8099173553719008 and parameters: {'num_leaves': 42, 'learning_rate': 0.10328184284516026, 'feature_fraction': 0.6382396762858139, 'bagging_fraction': 0.6535023284809849, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,244] Trial 36 finished with value: 0.8677685950413223 and parameters: {'num_leaves': 177, 'learning_rate': 0.1743728131008757, 'feature_fraction': 0.6670837911419797, 'bagging_fraction': 0.5319799585509736, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,268] Trial 37 finished with value: 0.6115702479338843 and parameters: {'num_leaves': 162, 'learning_rate': 0.075370810510497, 'feature_fraction': 0.4913093509528639, 'bagging_fraction': 0.6932641697327823, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,282] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 224, 'learning_rate': 0.04813166318626457, 'feature_fraction': 0.6018736049214833, 'bagging_fraction': 0.8371306793714225, 'bagging_freq': 4, 'min_child_samples': 96}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,296] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 107, 'learning_rate': 0.14577228593095537, 'feature_fraction': 0.7438828109153608, 'bagging_fraction': 0.5725040154050935, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,326] Trial 40 finished with value: 0.8801652892561984 and parameters: {'num_leaves': 144, 'learning_rate': 0.033786245021008854, 'feature_fraction': 0.5616624203992349, 'bagging_fraction': 0.7273123258958258, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,413] Trial 41 finished with value: 0.8801652892561984 and parameters: {'num_leaves': 75, 'learning_rate': 0.01123022310011526, 'feature_fraction': 0.5216141708339271, 'bagging_fraction': 0.7044058672820219, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,427] Trial 42 finished with value: 0.5 and parameters: {'num_leaves': 67, 'learning_rate': 0.03126106424346112, 'feature_fraction': 0.4357519522329518, 'bagging_fraction': 0.6319371572635784, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,461] Trial 43 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 26, 'learning_rate': 0.06717532113281352, 'feature_fraction': 0.5423147691050346, 'bagging_fraction': 0.5903282204491815, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 25 with value: 0.9049586776859504.
[I 2025-09-17 13:18:13,499] Trial 44 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 27, 'learning_rate': 0.06552554024571051, 'feature_fraction': 0.48771681957099344, 'bagging_fraction': 0.581103197727297, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 44 with value: 0.9132231404958677.
[I 2025-09-17 13:18:13,534] Trial 45 finished with value: 0.8884297520661156 and parameters: {'num_leaves': 26, 'learning_rate': 0.06442536436399494, 'feature_fraction': 0.4749477010741434, 'bagging_fraction': 0.5871595985353869, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 44 with value: 0.9132231404958677.
[I 2025-09-17 13:18:13,601] Trial 46 finished with value: 0.8636363636363635 and parameters: {'num_leaves': 22, 'learning_rate': 0.07867253365366764, 'feature_fraction': 0.5816293528631197, 'bagging_fraction': 0.4797727683899614, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 44 with value: 0.9132231404958677.
[I 2025-09-17 13:18:13,649] Trial 47 finished with value: 0.884297520661157 and parameters: {'num_leaves': 49, 'learning_rate': 0.046365823682999255, 'feature_fraction': 0.43197692311997826, 'bagging_fraction': 0.5399022801210096, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 44 with value: 0.9132231404958677.
[I 2025-09-17 13:18:13,679] Trial 48 finished with value: 0.8760330578512396 and parameters: {'num_leaves': 31, 'learning_rate': 0.10506720834784054, 'feature_fraction': 0.676077766509816, 'bagging_fraction': 0.5962497535881146, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 44 with value: 0.9132231404958677.
[I 2025-09-17 13:18:13,699] Trial 49 finished with value: 0.4834710743801653 and parameters: {'num_leaves': 125, 'learning_rate': 0.06904808735262712, 'feature_fraction': 0.5125543152355264, 'bagging_fraction': 0.42896897911207044, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 44 with value: 0.9132231404958677.
[I 2025-09-17 13:18:14,157] A new study created in memory with name: no-name-730664b1-5549-4864-bd7f-266291a01244
[I 2025-09-17 13:18:14,165] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.2755921594264965, 'feature_fraction': 0.745383120390366, 'bagging_fraction': 0.40590695671251514, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:14,189] Trial 1 finished with value: 0.9173553719008264 and parameters: {'num_leaves': 223, 'learning_rate': 0.13151331150942566, 'feature_fraction': 0.8800157946125844, 'bagging_fraction': 0.6600736885082891, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 1 with value: 0.9173553719008264.
[I 2025-09-17 13:18:14,197] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 26, 'learning_rate': 0.11233004417042795, 'feature_fraction': 0.9803334981755462, 'bagging_fraction': 0.6781384856897843, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 1 with value: 0.9173553719008264.
[I 2025-09-17 13:18:14,205] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 18, 'learning_rate': 0.06636139675166453, 'feature_fraction': 0.4070751164893517, 'bagging_fraction': 0.7007300329901727, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 1 with value: 0.9173553719008264.
[I 2025-09-17 13:18:14,224] Trial 4 finished with value: 0.8801652892561983 and parameters: {'num_leaves': 31, 'learning_rate': 0.163729551491016, 'feature_fraction': 0.8759008727061087, 'bagging_fraction': 0.88492627227908, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 1 with value: 0.9173553719008264.
[I 2025-09-17 13:18:14,234] Trial 5 finished with value: 0.5888429752066116 and parameters: {'num_leaves': 277, 'learning_rate': 0.03202589059752164, 'feature_fraction': 0.952662687921924, 'bagging_fraction': 0.5737263637544082, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 1 with value: 0.9173553719008264.
[I 2025-09-17 13:18:14,254] Trial 6 finished with value: 0.8223140495867769 and parameters: {'num_leaves': 76, 'learning_rate': 0.03223675988295211, 'feature_fraction': 0.7391126158705912, 'bagging_fraction': 0.8406639427653761, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 1 with value: 0.9173553719008264.
[I 2025-09-17 13:18:14,277] Trial 7 finished with value: 0.9380165289256198 and parameters: {'num_leaves': 214, 'learning_rate': 0.2579296539722427, 'feature_fraction': 0.6106064939126137, 'bagging_fraction': 0.9540646249226338, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,289] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 212, 'learning_rate': 0.2097497551938263, 'feature_fraction': 0.9494767464348096, 'bagging_fraction': 0.4269667963464068, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,317] Trial 9 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 207, 'learning_rate': 0.21204429238077538, 'feature_fraction': 0.4957582499660011, 'bagging_fraction': 0.43278272135817064, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,328] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 125, 'learning_rate': 0.27973779678816185, 'feature_fraction': 0.5638171486495508, 'bagging_fraction': 0.9473749387431478, 'bagging_freq': 7, 'min_child_samples': 76}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,421] Trial 11 finished with value: 0.9132231404958676 and parameters: {'num_leaves': 278, 'learning_rate': 0.22008726574502735, 'feature_fraction': 0.546309624465393, 'bagging_fraction': 0.5212574699759543, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,479] Trial 12 finished with value: 0.9090909090909092 and parameters: {'num_leaves': 143, 'learning_rate': 0.22390170628668116, 'feature_fraction': 0.5889397126619942, 'bagging_fraction': 0.8089167938882533, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,512] Trial 13 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 235, 'learning_rate': 0.18450897247503462, 'feature_fraction': 0.428322638517802, 'bagging_fraction': 0.9772700533508352, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,522] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 249, 'learning_rate': 0.17423005371061404, 'feature_fraction': 0.4040442584209528, 'bagging_fraction': 0.987092422417941, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,552] Trial 15 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 174, 'learning_rate': 0.256201996958603, 'feature_fraction': 0.6650079382853227, 'bagging_fraction': 0.9119289892772486, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,587] Trial 16 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 297, 'learning_rate': 0.24375083096406194, 'feature_fraction': 0.6527272075900397, 'bagging_fraction': 0.7971144975818146, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,608] Trial 17 finished with value: 0.7231404958677686 and parameters: {'num_leaves': 247, 'learning_rate': 0.17990341461829104, 'feature_fraction': 0.4813696976013614, 'bagging_fraction': 0.9985576126910329, 'bagging_freq': 4, 'min_child_samples': 63}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,674] Trial 18 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 123, 'learning_rate': 0.11388446199467366, 'feature_fraction': 0.48132982474414426, 'bagging_fraction': 0.7721561386678746, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,693] Trial 19 finished with value: 0.9008264462809918 and parameters: {'num_leaves': 238, 'learning_rate': 0.290857273577232, 'feature_fraction': 0.6151834938790494, 'bagging_fraction': 0.880462764422175, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,705] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.18999600253628413, 'feature_fraction': 0.7969409425462244, 'bagging_fraction': 0.7332657590572635, 'bagging_freq': 6, 'min_child_samples': 83}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,737] Trial 21 finished with value: 0.9380165289256198 and parameters: {'num_leaves': 199, 'learning_rate': 0.24474288903287053, 'feature_fraction': 0.4840092150758817, 'bagging_fraction': 0.5745757810108072, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 7 with value: 0.9380165289256198.
[I 2025-09-17 13:18:14,833] Trial 22 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 191, 'learning_rate': 0.24724034857101793, 'feature_fraction': 0.5152603385807297, 'bagging_fraction': 0.6008653267799872, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:14,931] Trial 23 finished with value: 0.8884297520661156 and parameters: {'num_leaves': 191, 'learning_rate': 0.24914113482156544, 'feature_fraction': 0.531174065461951, 'bagging_fraction': 0.5691119081529897, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:14,967] Trial 24 finished with value: 0.9504132231404958 and parameters: {'num_leaves': 137, 'learning_rate': 0.26903020178950804, 'feature_fraction': 0.6077516932694619, 'bagging_fraction': 0.6186794760453118, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,011] Trial 25 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 99, 'learning_rate': 0.29943439780323367, 'feature_fraction': 0.6382451381783769, 'bagging_fraction': 0.5052450479498471, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,035] Trial 26 finished with value: 0.8760330578512397 and parameters: {'num_leaves': 62, 'learning_rate': 0.26030799196022036, 'feature_fraction': 0.6999983300265705, 'bagging_fraction': 0.6422426927613689, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,064] Trial 27 finished with value: 0.9132231404958678 and parameters: {'num_leaves': 153, 'learning_rate': 0.2719592187341862, 'feature_fraction': 0.5973107152958114, 'bagging_fraction': 0.616379679387956, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,125] Trial 28 finished with value: 0.9338842975206612 and parameters: {'num_leaves': 134, 'learning_rate': 0.22750069537675988, 'feature_fraction': 0.6856174422867146, 'bagging_fraction': 0.7361109398138306, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,137] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 167, 'learning_rate': 0.27726325891881254, 'feature_fraction': 0.7451343922606376, 'bagging_fraction': 0.5172425456775958, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,160] Trial 30 finished with value: 0.9214876033057852 and parameters: {'num_leaves': 181, 'learning_rate': 0.14331664944973238, 'feature_fraction': 0.531852149668059, 'bagging_fraction': 0.6073034004632951, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,207] Trial 31 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 201, 'learning_rate': 0.23803888708333332, 'feature_fraction': 0.4623051901696843, 'bagging_fraction': 0.5629788843596222, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,230] Trial 32 finished with value: 0.8925619834710743 and parameters: {'num_leaves': 221, 'learning_rate': 0.20091551379510003, 'feature_fraction': 0.513699500794537, 'bagging_fraction': 0.4759237789738979, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,320] Trial 33 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 104, 'learning_rate': 0.26883380919952743, 'feature_fraction': 0.5752327066917134, 'bagging_fraction': 0.6262331445382804, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,351] Trial 34 finished with value: 0.8884297520661157 and parameters: {'num_leaves': 194, 'learning_rate': 0.23595811430416222, 'feature_fraction': 0.4581884638085542, 'bagging_fraction': 0.677410119989156, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 22 with value: 0.9504132231404958.
[I 2025-09-17 13:18:15,385] Trial 35 finished with value: 0.9586776859504131 and parameters: {'num_leaves': 266, 'learning_rate': 0.2824656100762777, 'feature_fraction': 0.6140470748865616, 'bagging_fraction': 0.7028953854667581, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 35 with value: 0.9586776859504131.
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.413751
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.627597
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.409264
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.422593
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.422702
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.455739
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.425414
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.485688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.412018
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.616688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.426849
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.443969
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.378635
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.370363
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.409883
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.461717
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.398737
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.414527
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.633387
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.345079
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.415773
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.633573
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.522085
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.327988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.347278
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.391893
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.390785
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.325214
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.38127
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.338702
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.542718
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.319676
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.378742
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.306493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.299987
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.439973
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.280081
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.378571
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.409608
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.346548
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.345706
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.37492
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.349528
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.367652
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.391037
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.402269
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.284412
[I 2025-09-17 13:18:15,398] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 259, 'learning_rate': 0.2879264902718742, 'feature_fraction': 0.789446900273627, 'bagging_fraction': 0.7093024912841406, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,432] Trial 37 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 272, 'learning_rate': 0.25713168555398963, 'feature_fraction': 0.6234625429964612, 'bagging_fraction': 0.6621088035161978, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,460] Trial 38 finished with value: 0.8801652892561984 and parameters: {'num_leaves': 228, 'learning_rate': 0.07715654623340179, 'feature_fraction': 0.6684651737043631, 'bagging_fraction': 0.8551638750495241, 'bagging_freq': 1, 'min_child_samples': 41}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,473] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 221, 'learning_rate': 0.29658551468275685, 'feature_fraction': 0.5991111393884941, 'bagging_fraction': 0.5981283691780793, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,496] Trial 40 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 294, 'learning_rate': 0.26691918451806884, 'feature_fraction': 0.7167625179568573, 'bagging_fraction': 0.7576839710321637, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,530] Trial 41 finished with value: 0.9049586776859504 and parameters: {'num_leaves': 186, 'learning_rate': 0.2412957570332943, 'feature_fraction': 0.44126660756036085, 'bagging_fraction': 0.5626862806293739, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,589] Trial 42 finished with value: 0.9132231404958677 and parameters: {'num_leaves': 210, 'learning_rate': 0.28192097832667384, 'feature_fraction': 0.5610100799381056, 'bagging_fraction': 0.5887711199803527, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,625] Trial 43 finished with value: 0.859504132231405 and parameters: {'num_leaves': 153, 'learning_rate': 0.20744924770072384, 'feature_fraction': 0.512855755908853, 'bagging_fraction': 0.47460203533218004, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,645] Trial 44 finished with value: 0.884297520661157 and parameters: {'num_leaves': 175, 'learning_rate': 0.25570773564165955, 'feature_fraction': 0.5562157782575372, 'bagging_fraction': 0.542486446778007, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,682] Trial 45 finished with value: 0.9380165289256199 and parameters: {'num_leaves': 262, 'learning_rate': 0.2176267310422962, 'feature_fraction': 0.6276787266629779, 'bagging_fraction': 0.6457591659312596, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,707] Trial 46 finished with value: 0.8801652892561983 and parameters: {'num_leaves': 265, 'learning_rate': 0.22687751225835562, 'feature_fraction': 0.6272972497553206, 'bagging_fraction': 0.6888403735407922, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,779] Trial 47 finished with value: 0.9256198347107438 and parameters: {'num_leaves': 284, 'learning_rate': 0.010674918641092546, 'feature_fraction': 0.7188673215884734, 'bagging_fraction': 0.6353566638898595, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,814] Trial 48 finished with value: 0.9297520661157024 and parameters: {'num_leaves': 253, 'learning_rate': 0.19904145556628589, 'feature_fraction': 0.5802747580786057, 'bagging_fraction': 0.6522362040611434, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:15,829] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 236, 'learning_rate': 0.16160918868803947, 'feature_fraction': 0.6045708597770523, 'bagging_fraction': 0.7142767138598168, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 35 with value: 0.9586776859504131.
[I 2025-09-17 13:18:16,040] A new study created in memory with name: no-name-0ce75e34-a155-44f9-98af-6a112157efac
[I 2025-09-17 13:18:16,047] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 33, 'learning_rate': 0.09575973942635894, 'feature_fraction': 0.9018090538480037, 'bagging_fraction': 0.6893023980419064, 'bagging_freq': 1, 'min_child_samples': 92}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:16,068] Trial 1 finished with value: 0.780952380952381 and parameters: {'num_leaves': 24, 'learning_rate': 0.14245809908267693, 'feature_fraction': 0.770919499322652, 'bagging_fraction': 0.9669945119114072, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 1 with value: 0.780952380952381.
[I 2025-09-17 13:18:16,080] Trial 2 finished with value: 0.7023809523809523 and parameters: {'num_leaves': 115, 'learning_rate': 0.1140477569512154, 'feature_fraction': 0.40534891900450587, 'bagging_fraction': 0.9919309051079032, 'bagging_freq': 1, 'min_child_samples': 47}. Best is trial 1 with value: 0.780952380952381.
[I 2025-09-17 13:18:16,088] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 140, 'learning_rate': 0.1772781076605927, 'feature_fraction': 0.43307740017175445, 'bagging_fraction': 0.7716671318457227, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 1 with value: 0.780952380952381.
[I 2025-09-17 13:18:16,121] Trial 4 finished with value: 0.8714285714285716 and parameters: {'num_leaves': 56, 'learning_rate': 0.11604647280539383, 'feature_fraction': 0.9175156146551149, 'bagging_fraction': 0.9101095701553958, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 4 with value: 0.8714285714285716.
[I 2025-09-17 13:18:16,134] Trial 5 finished with value: 0.65 and parameters: {'num_leaves': 24, 'learning_rate': 0.22413852517905977, 'feature_fraction': 0.6107894705092753, 'bagging_fraction': 0.5859579273356832, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 4 with value: 0.8714285714285716.
[I 2025-09-17 13:18:16,142] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 96, 'learning_rate': 0.12606400059502607, 'feature_fraction': 0.7034514222687145, 'bagging_fraction': 0.43020552041827725, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 4 with value: 0.8714285714285716.
[I 2025-09-17 13:18:16,153] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.04837970719571209, 'feature_fraction': 0.5315278370101074, 'bagging_fraction': 0.6363822215984537, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 4 with value: 0.8714285714285716.
[I 2025-09-17 13:18:16,165] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 143, 'learning_rate': 0.16413604974460352, 'feature_fraction': 0.5901953731155104, 'bagging_fraction': 0.8403070790087759, 'bagging_freq': 5, 'min_child_samples': 89}. Best is trial 4 with value: 0.8714285714285716.
[I 2025-09-17 13:18:16,173] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 102, 'learning_rate': 0.18024384137929272, 'feature_fraction': 0.7871269896427074, 'bagging_fraction': 0.8010245092494552, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 4 with value: 0.8714285714285716.
[I 2025-09-17 13:18:16,237] Trial 10 finished with value: 0.9095238095238096 and parameters: {'num_leaves': 264, 'learning_rate': 0.2799242171209477, 'feature_fraction': 0.9963657739071706, 'bagging_fraction': 0.8922945530238634, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,286] Trial 11 finished with value: 0.8952380952380953 and parameters: {'num_leaves': 293, 'learning_rate': 0.2951755797372338, 'feature_fraction': 0.9898399240380366, 'bagging_fraction': 0.8830327974370138, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,369] Trial 12 finished with value: 0.8666666666666666 and parameters: {'num_leaves': 299, 'learning_rate': 0.28655390223589167, 'feature_fraction': 0.9948929152287826, 'bagging_fraction': 0.8799938459022248, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,457] Trial 13 finished with value: 0.8809523809523809 and parameters: {'num_leaves': 300, 'learning_rate': 0.29660287672932506, 'feature_fraction': 0.9973799805190211, 'bagging_fraction': 0.7613171747168845, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,488] Trial 14 finished with value: 0.9095238095238095 and parameters: {'num_leaves': 218, 'learning_rate': 0.2424259300610369, 'feature_fraction': 0.87363964178478, 'bagging_fraction': 0.9136098562277477, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,528] Trial 15 finished with value: 0.8952380952380953 and parameters: {'num_leaves': 207, 'learning_rate': 0.2458116347118457, 'feature_fraction': 0.8649143516170951, 'bagging_fraction': 0.9480263558500305, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,539] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.2376542725678673, 'feature_fraction': 0.8291449779306631, 'bagging_fraction': 0.5314232770566732, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,572] Trial 17 finished with value: 0.8666666666666666 and parameters: {'num_leaves': 196, 'learning_rate': 0.2162807102402149, 'feature_fraction': 0.9259652358236274, 'bagging_fraction': 0.8215837191801878, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,603] Trial 18 finished with value: 0.9 and parameters: {'num_leaves': 252, 'learning_rate': 0.26509912344795494, 'feature_fraction': 0.7507272508942766, 'bagging_fraction': 0.7018984430910665, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,635] Trial 19 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 253, 'learning_rate': 0.1992851148726443, 'feature_fraction': 0.8615476169456531, 'bagging_fraction': 0.9171563571865636, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,653] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.2611025508331966, 'feature_fraction': 0.9371335254178911, 'bagging_fraction': 0.7345987843856032, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,681] Trial 21 finished with value: 0.8952380952380953 and parameters: {'num_leaves': 244, 'learning_rate': 0.26578337828488613, 'feature_fraction': 0.7133627333250033, 'bagging_fraction': 0.6962488114032498, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,705] Trial 22 finished with value: 0.7999999999999999 and parameters: {'num_leaves': 271, 'learning_rate': 0.26584360098288434, 'feature_fraction': 0.7758173283927955, 'bagging_fraction': 0.4740000377297018, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,730] Trial 23 finished with value: 0.7666666666666667 and parameters: {'num_leaves': 223, 'learning_rate': 0.20698525661529132, 'feature_fraction': 0.8307877283274523, 'bagging_fraction': 0.6208539978998387, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,773] Trial 24 finished with value: 0.8619047619047618 and parameters: {'num_leaves': 170, 'learning_rate': 0.24786150708723775, 'feature_fraction': 0.6616880596489374, 'bagging_fraction': 0.8352338361011733, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,806] Trial 25 finished with value: 0.8619047619047618 and parameters: {'num_leaves': 271, 'learning_rate': 0.2779062223674399, 'feature_fraction': 0.7513699774920688, 'bagging_fraction': 0.8740002472686963, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,853] Trial 26 finished with value: 0.9095238095238096 and parameters: {'num_leaves': 230, 'learning_rate': 0.029805121331250323, 'feature_fraction': 0.8750089354467832, 'bagging_fraction': 0.9336560710889018, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,868] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.03492519957035886, 'feature_fraction': 0.874977519785011, 'bagging_fraction': 0.9354677008953015, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,935] Trial 28 finished with value: 0.9 and parameters: {'num_leaves': 180, 'learning_rate': 0.08872579988081702, 'feature_fraction': 0.9528174404458949, 'bagging_fraction': 0.9776471400048012, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,959] Trial 29 finished with value: 0.7238095238095238 and parameters: {'num_leaves': 216, 'learning_rate': 0.01266917592941948, 'feature_fraction': 0.8246969555262919, 'bagging_fraction': 0.9030674170793948, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:16,992] Trial 30 finished with value: 0.8047619047619047 and parameters: {'num_leaves': 269, 'learning_rate': 0.08436689758274643, 'feature_fraction': 0.9609111799355502, 'bagging_fraction': 0.9933326937839738, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,031] Trial 31 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 236, 'learning_rate': 0.23843183720452532, 'feature_fraction': 0.870356082623684, 'bagging_fraction': 0.8511361901148711, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,046] Trial 32 finished with value: 0.5 and parameters: {'num_leaves': 259, 'learning_rate': 0.06391321622994747, 'feature_fraction': 0.9064231262399731, 'bagging_fraction': 0.7289706654098039, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,118] Trial 33 finished with value: 0.8904761904761904 and parameters: {'num_leaves': 277, 'learning_rate': 0.1394885316416909, 'feature_fraction': 0.7494421316583569, 'bagging_fraction': 0.9490380470835831, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,146] Trial 34 finished with value: 0.8761904761904762 and parameters: {'num_leaves': 163, 'learning_rate': 0.27558992494225465, 'feature_fraction': 0.637511935409016, 'bagging_fraction': 0.7941159137026201, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,231] Trial 35 finished with value: 0.9095238095238095 and parameters: {'num_leaves': 231, 'learning_rate': 0.18821045865176528, 'feature_fraction': 0.8103171551772044, 'bagging_fraction': 0.661323291176651, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,285] Trial 36 finished with value: 0.8761904761904763 and parameters: {'num_leaves': 230, 'learning_rate': 0.19044556743716384, 'feature_fraction': 0.8948844210467514, 'bagging_fraction': 0.5964401941064098, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,359] Trial 37 finished with value: 0.9000000000000001 and parameters: {'num_leaves': 64, 'learning_rate': 0.1549285559921823, 'feature_fraction': 0.8088455195682436, 'bagging_fraction': 0.9651584642473392, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,384] Trial 38 finished with value: 0.761904761904762 and parameters: {'num_leaves': 202, 'learning_rate': 0.2249188109276218, 'feature_fraction': 0.9582274473427206, 'bagging_fraction': 0.6463074702654362, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,411] Trial 39 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 217, 'learning_rate': 0.11231594660916665, 'feature_fraction': 0.4734577715125087, 'bagging_fraction': 0.6617350478956198, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,425] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 146, 'learning_rate': 0.17283523716676705, 'feature_fraction': 0.8495740277689555, 'bagging_fraction': 0.5537711401587461, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,487] Trial 41 finished with value: 0.9095238095238095 and parameters: {'num_leaves': 33, 'learning_rate': 0.14658445442971815, 'feature_fraction': 0.811046114867071, 'bagging_fraction': 0.9990972791855524, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,555] Trial 42 finished with value: 0.880952380952381 and parameters: {'num_leaves': 123, 'learning_rate': 0.15640482264843153, 'feature_fraction': 0.7999378255438168, 'bagging_fraction': 0.991182525916781, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,625] Trial 43 finished with value: 0.9 and parameters: {'num_leaves': 45, 'learning_rate': 0.1348587375671634, 'feature_fraction': 0.8997198597403204, 'bagging_fraction': 0.9135814366532887, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 10 with value: 0.9095238095238096.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.33589
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.432863
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.63665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.424941
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.383794
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.368256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.427482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.428622
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.331784
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.410828
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.430597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.329666
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.63665
Training model for P048... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.541202
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.633985
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.472816
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.659422
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.424787
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.443389
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.428474
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.434631
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.423267
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.418982
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.44957
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.401598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.509831
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.419165
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.562208
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.56618
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.451257
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.46335
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.409551
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.435396
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.63751
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.523509
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.443899
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.412812
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.451877
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.374897
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.510572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.40499
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.575951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.532009
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.408167
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.432201
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.421717
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:17,731] Trial 44 finished with value: 0.8666666666666667 and parameters: {'num_leaves': 19, 'learning_rate': 0.07031692542835785, 'feature_fraction': 0.7223842857531642, 'bagging_fraction': 0.9323842495089996, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,762] Trial 45 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 183, 'learning_rate': 0.1021243414399719, 'feature_fraction': 0.6823704947357296, 'bagging_fraction': 0.88470819867812, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,804] Trial 46 finished with value: 0.9047619047619048 and parameters: {'num_leaves': 288, 'learning_rate': 0.19070972957135182, 'feature_fraction': 0.8913007945954005, 'bagging_fraction': 0.9671584946061321, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,835] Trial 47 finished with value: 0.9 and parameters: {'num_leaves': 86, 'learning_rate': 0.25199459343811187, 'feature_fraction': 0.8475917108259791, 'bagging_fraction': 0.8626027383349397, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,893] Trial 48 finished with value: 0.9047619047619048 and parameters: {'num_leaves': 127, 'learning_rate': 0.22816352644093363, 'feature_fraction': 0.97162267391717, 'bagging_fraction': 0.7710959980273954, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:17,909] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 259, 'learning_rate': 0.012485376916132884, 'feature_fraction': 0.9266170624555964, 'bagging_fraction': 0.8166134018621896, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 10 with value: 0.9095238095238096.
[I 2025-09-17 13:18:18,110] A new study created in memory with name: no-name-e0c8e062-afbd-4b69-88a0-33e3fbd95370
[I 2025-09-17 13:18:18,121] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 45, 'learning_rate': 0.2648753242035492, 'feature_fraction': 0.8079985217756218, 'bagging_fraction': 0.4517343223856425, 'bagging_freq': 6, 'min_child_samples': 54}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:18,146] Trial 1 finished with value: 0.7714285714285714 and parameters: {'num_leaves': 125, 'learning_rate': 0.08112073318054165, 'feature_fraction': 0.545747172171764, 'bagging_fraction': 0.40227336865587615, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 1 with value: 0.7714285714285714.
[I 2025-09-17 13:18:18,156] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 117, 'learning_rate': 0.22901314598851094, 'feature_fraction': 0.7947742839517651, 'bagging_fraction': 0.5340363892702964, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 1 with value: 0.7714285714285714.
[I 2025-09-17 13:18:18,165] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 193, 'learning_rate': 0.04227278169226856, 'feature_fraction': 0.9094067464388765, 'bagging_fraction': 0.714180321440536, 'bagging_freq': 3, 'min_child_samples': 92}. Best is trial 1 with value: 0.7714285714285714.
[I 2025-09-17 13:18:18,175] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 91, 'learning_rate': 0.20089835944376577, 'feature_fraction': 0.9023793693517046, 'bagging_fraction': 0.4703258476446129, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial 1 with value: 0.7714285714285714.
[I 2025-09-17 13:18:18,202] Trial 5 finished with value: 0.8761904761904762 and parameters: {'num_leaves': 293, 'learning_rate': 0.24086772194835807, 'feature_fraction': 0.7798404240793925, 'bagging_fraction': 0.9738487614767304, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 5 with value: 0.8761904761904762.
[I 2025-09-17 13:18:18,222] Trial 6 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 115, 'learning_rate': 0.13555719290672472, 'feature_fraction': 0.7135838013973217, 'bagging_fraction': 0.8060669526540335, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 5 with value: 0.8761904761904762.
[I 2025-09-17 13:18:18,247] Trial 7 finished with value: 0.8380952380952381 and parameters: {'num_leaves': 130, 'learning_rate': 0.21176704707568797, 'feature_fraction': 0.5487553546912487, 'bagging_fraction': 0.9428463827195378, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 5 with value: 0.8761904761904762.
[I 2025-09-17 13:18:18,255] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 64, 'learning_rate': 0.07586252346564992, 'feature_fraction': 0.5187878905560355, 'bagging_fraction': 0.773990507181022, 'bagging_freq': 6, 'min_child_samples': 71}. Best is trial 5 with value: 0.8761904761904762.
[I 2025-09-17 13:18:18,262] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 287, 'learning_rate': 0.14767480811260036, 'feature_fraction': 0.5470331522804115, 'bagging_fraction': 0.6702922643697069, 'bagging_freq': 4, 'min_child_samples': 80}. Best is trial 5 with value: 0.8761904761904762.
[I 2025-09-17 13:18:18,361] Trial 10 finished with value: 0.8761904761904762 and parameters: {'num_leaves': 297, 'learning_rate': 0.29528627082546083, 'feature_fraction': 0.41027493220320804, 'bagging_fraction': 0.986429148630075, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 5 with value: 0.8761904761904762.
[I 2025-09-17 13:18:18,450] Trial 11 finished with value: 0.9238095238095239 and parameters: {'num_leaves': 259, 'learning_rate': 0.29958206388822933, 'feature_fraction': 0.6667270164216639, 'bagging_fraction': 0.995385731864433, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:18:18,540] Trial 12 finished with value: 0.9190476190476191 and parameters: {'num_leaves': 230, 'learning_rate': 0.2902947203154815, 'feature_fraction': 0.6793438185017245, 'bagging_fraction': 0.8894609514919858, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:18:18,622] Trial 13 finished with value: 0.9238095238095239 and parameters: {'num_leaves': 218, 'learning_rate': 0.29566956464789024, 'feature_fraction': 0.6584606673256101, 'bagging_fraction': 0.8859955591101913, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:18:18,672] Trial 14 finished with value: 0.9142857142857143 and parameters: {'num_leaves': 226, 'learning_rate': 0.1759266639772895, 'feature_fraction': 0.6919361860173344, 'bagging_fraction': 0.8538951978112307, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 11 with value: 0.9238095238095239.
[I 2025-09-17 13:18:18,715] Trial 15 finished with value: 0.9761904761904763 and parameters: {'num_leaves': 185, 'learning_rate': 0.257250707643466, 'feature_fraction': 0.6272751116710911, 'bagging_fraction': 0.9072765098438751, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:18,734] Trial 16 finished with value: 0.7904761904761904 and parameters: {'num_leaves': 174, 'learning_rate': 0.25244587349169617, 'feature_fraction': 0.6080171899104784, 'bagging_fraction': 0.6138659412478705, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:18,781] Trial 17 finished with value: 0.9238095238095239 and parameters: {'num_leaves': 12, 'learning_rate': 0.18250710156284616, 'feature_fraction': 0.4531316498623654, 'bagging_fraction': 0.9992454023595583, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:18,805] Trial 18 finished with value: 0.8761904761904762 and parameters: {'num_leaves': 257, 'learning_rate': 0.26562506035631717, 'feature_fraction': 0.6155390692947624, 'bagging_fraction': 0.9191297134031127, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:18,851] Trial 19 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 257, 'learning_rate': 0.1061820353822977, 'feature_fraction': 0.9855103508075088, 'bagging_fraction': 0.8196771539365273, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:18,869] Trial 20 finished with value: 0.7761904761904762 and parameters: {'num_leaves': 165, 'learning_rate': 0.09525597114332561, 'feature_fraction': 0.9715732825986764, 'bagging_fraction': 0.7928741603951625, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:18,923] Trial 21 finished with value: 0.9619047619047619 and parameters: {'num_leaves': 257, 'learning_rate': 0.11276751219902352, 'feature_fraction': 0.7588976362130914, 'bagging_fraction': 0.8359134093108626, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:18,971] Trial 22 finished with value: 0.9714285714285714 and parameters: {'num_leaves': 256, 'learning_rate': 0.12208009115480895, 'feature_fraction': 0.8711357030878818, 'bagging_fraction': 0.8298620660435408, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,003] Trial 23 finished with value: 0.8238095238095239 and parameters: {'num_leaves': 205, 'learning_rate': 0.12644042870664943, 'feature_fraction': 0.8448708971550846, 'bagging_fraction': 0.7276889335764856, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,037] Trial 24 finished with value: 0.9047619047619047 and parameters: {'num_leaves': 244, 'learning_rate': 0.04239881977542391, 'feature_fraction': 0.7466827394254775, 'bagging_fraction': 0.8597777135560092, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,109] Trial 25 finished with value: 0.9476190476190477 and parameters: {'num_leaves': 188, 'learning_rate': 0.012764463510951729, 'feature_fraction': 0.8859943592275558, 'bagging_fraction': 0.7599223119403039, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,129] Trial 26 finished with value: 0.8333333333333334 and parameters: {'num_leaves': 275, 'learning_rate': 0.16607021431467306, 'feature_fraction': 0.743277434987565, 'bagging_fraction': 0.648997655894415, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,154] Trial 27 finished with value: 0.8142857142857144 and parameters: {'num_leaves': 152, 'learning_rate': 0.12265268491773959, 'feature_fraction': 0.845267286015327, 'bagging_fraction': 0.9303029550064327, 'bagging_freq': 2, 'min_child_samples': 50}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,207] Trial 28 finished with value: 0.9619047619047619 and parameters: {'num_leaves': 206, 'learning_rate': 0.1517255906430428, 'feature_fraction': 0.941163083286104, 'bagging_fraction': 0.836595119037396, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,223] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 236, 'learning_rate': 0.06694883435095353, 'feature_fraction': 0.839529967774856, 'bagging_fraction': 0.7481632183780942, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,256] Trial 30 finished with value: 0.8285714285714286 and parameters: {'num_leaves': 153, 'learning_rate': 0.11687762245931581, 'feature_fraction': 0.6135422300819273, 'bagging_fraction': 0.8975812774743561, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,305] Trial 31 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 212, 'learning_rate': 0.16021967837255285, 'feature_fraction': 0.9431620927743947, 'bagging_fraction': 0.8353087171898606, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,339] Trial 32 finished with value: 0.9238095238095239 and parameters: {'num_leaves': 271, 'learning_rate': 0.19670880657295134, 'feature_fraction': 0.9503631679471293, 'bagging_fraction': 0.8603602511101803, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,407] Trial 33 finished with value: 0.9476190476190476 and parameters: {'num_leaves': 209, 'learning_rate': 0.09205609011109141, 'feature_fraction': 0.8794128534325841, 'bagging_fraction': 0.8163634644750718, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,448] Trial 34 finished with value: 0.8523809523809525 and parameters: {'num_leaves': 190, 'learning_rate': 0.057470694162092384, 'feature_fraction': 0.8020830546235808, 'bagging_fraction': 0.6934562808678816, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,475] Trial 35 finished with value: 0.780952380952381 and parameters: {'num_leaves': 245, 'learning_rate': 0.1398444299882546, 'feature_fraction': 0.9332032271665794, 'bagging_fraction': 0.6082009986001264, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,488] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.21288408044374585, 'feature_fraction': 0.7582709213634463, 'bagging_fraction': 0.7819967678703666, 'bagging_freq': 5, 'min_child_samples': 91}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,554] Trial 37 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 278, 'learning_rate': 0.10729003539528281, 'feature_fraction': 0.823221349975545, 'bagging_fraction': 0.9098578152195221, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,625] Trial 38 finished with value: 0.9476190476190477 and parameters: {'num_leaves': 284, 'learning_rate': 0.26991472975325553, 'feature_fraction': 0.8244225235481767, 'bagging_fraction': 0.9536391745104016, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,661] Trial 39 finished with value: 0.8047619047619048 and parameters: {'num_leaves': 216, 'learning_rate': 0.08994409054159064, 'feature_fraction': 0.8993416384335079, 'bagging_fraction': 0.9130541828032936, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,675] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 139, 'learning_rate': 0.22681035663952104, 'feature_fraction': 0.8634047392206556, 'bagging_fraction': 0.4947360528463868, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,724] Trial 41 finished with value: 0.9380952380952381 and parameters: {'num_leaves': 271, 'learning_rate': 0.10936051680598864, 'feature_fraction': 0.7773945119483892, 'bagging_fraction': 0.9544849642265232, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,772] Trial 42 finished with value: 0.9476190476190477 and parameters: {'num_leaves': 244, 'learning_rate': 0.13297303658411144, 'feature_fraction': 0.9155527698751675, 'bagging_fraction': 0.8761516975987884, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,824] Trial 43 finished with value: 0.9238095238095239 and parameters: {'num_leaves': 262, 'learning_rate': 0.16129651279178236, 'feature_fraction': 0.8138882597024106, 'bagging_fraction': 0.8316337681483672, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,867] Trial 44 finished with value: 0.8428571428571429 and parameters: {'num_leaves': 297, 'learning_rate': 0.10692617157581769, 'feature_fraction': 0.7267240378247483, 'bagging_fraction': 0.961240475454386, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,917] Trial 45 finished with value: 0.8952380952380953 and parameters: {'num_leaves': 230, 'learning_rate': 0.14507817329001693, 'feature_fraction': 0.6461213144061135, 'bagging_fraction': 0.42197802371552273, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,961] Trial 46 finished with value: 0.9428571428571428 and parameters: {'num_leaves': 279, 'learning_rate': 0.07720176375764586, 'feature_fraction': 0.7857202581180783, 'bagging_fraction': 0.9069682978813368, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,972] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 93, 'learning_rate': 0.1918994118366953, 'feature_fraction': 0.5780651076660137, 'bagging_fraction': 0.842264340350955, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:19,986] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 251, 'learning_rate': 0.060792073511291574, 'feature_fraction': 0.9135132608206398, 'bagging_fraction': 0.7984312645605887, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:20,062] Trial 49 finished with value: 0.9523809523809523 and parameters: {'num_leaves': 199, 'learning_rate': 0.1738428635226905, 'feature_fraction': 0.7076474434182369, 'bagging_fraction': 0.8808835955432652, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 15 with value: 0.9761904761904763.
[I 2025-09-17 13:18:20,337] A new study created in memory with name: no-name-d9d8373f-c27c-4835-87ae-038f779577ce
[I 2025-09-17 13:18:20,364] Trial 0 finished with value: 0.8348214285714285 and parameters: {'num_leaves': 270, 'learning_rate': 0.10781840858101362, 'feature_fraction': 0.49174225958953005, 'bagging_fraction': 0.9795635414800178, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 0 with value: 0.8348214285714285.
[I 2025-09-17 13:18:20,376] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 40, 'learning_rate': 0.11970233827094989, 'feature_fraction': 0.7727814299249918, 'bagging_fraction': 0.5089730615473392, 'bagging_freq': 7, 'min_child_samples': 46}. Best is trial 0 with value: 0.8348214285714285.
[I 2025-09-17 13:18:20,385] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 154, 'learning_rate': 0.07790731603551174, 'feature_fraction': 0.6788448873388702, 'bagging_fraction': 0.8045955632689712, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 0 with value: 0.8348214285714285.
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.443972
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.512718
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.407302
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.407437
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.373118
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.693149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.585629
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.46873
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.556622
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.500287
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.433223
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.342615
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.330989
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.355936
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.391016
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.310939
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.579844
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.363941
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.448438
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.401113
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.622784
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.322274
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.307397
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.520822
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.455451
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.431288
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.574346
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.540283
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.27672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.531786
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.295965
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.441377
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.332257
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.474641
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.532724
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.296323
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.273372
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.536649
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.381995
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.333535
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.378454
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.47581
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.457814
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.428528
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.692701
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.35731
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.515158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:20,393] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 252, 'learning_rate': 0.05262682128329217, 'feature_fraction': 0.6860798108670771, 'bagging_fraction': 0.7846394328062931, 'bagging_freq': 5, 'min_child_samples': 92}. Best is trial 0 with value: 0.8348214285714285.
[I 2025-09-17 13:18:20,402] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 293, 'learning_rate': 0.28332177750018117, 'feature_fraction': 0.6616019176516297, 'bagging_fraction': 0.7304533284429235, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 0 with value: 0.8348214285714285.
[I 2025-09-17 13:18:20,437] Trial 5 finished with value: 0.9196428571428572 and parameters: {'num_leaves': 229, 'learning_rate': 0.1706184385320228, 'feature_fraction': 0.6327235013700875, 'bagging_fraction': 0.8921310179742543, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 5 with value: 0.9196428571428572.
[I 2025-09-17 13:18:20,465] Trial 6 finished with value: 0.8616071428571428 and parameters: {'num_leaves': 297, 'learning_rate': 0.19404473976346662, 'feature_fraction': 0.7912442362239549, 'bagging_fraction': 0.9176693173838012, 'bagging_freq': 1, 'min_child_samples': 41}. Best is trial 5 with value: 0.9196428571428572.
[I 2025-09-17 13:18:20,492] Trial 7 finished with value: 0.875 and parameters: {'num_leaves': 180, 'learning_rate': 0.0533785856181517, 'feature_fraction': 0.7646556024582669, 'bagging_fraction': 0.7997070587128097, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 5 with value: 0.9196428571428572.
[I 2025-09-17 13:18:20,503] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 24, 'learning_rate': 0.08558468284239669, 'feature_fraction': 0.7069778747145711, 'bagging_fraction': 0.7530505405016439, 'bagging_freq': 4, 'min_child_samples': 83}. Best is trial 5 with value: 0.9196428571428572.
[I 2025-09-17 13:18:20,512] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 177, 'learning_rate': 0.07897379426826585, 'feature_fraction': 0.9114450333553926, 'bagging_fraction': 0.4123907565588911, 'bagging_freq': 2, 'min_child_samples': 97}. Best is trial 5 with value: 0.9196428571428572.
[I 2025-09-17 13:18:20,633] Trial 10 finished with value: 0.90625 and parameters: {'num_leaves': 100, 'learning_rate': 0.1941747756969019, 'feature_fraction': 0.41844562215533887, 'bagging_fraction': 0.6186224566476182, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 5 with value: 0.9196428571428572.
[I 2025-09-17 13:18:20,732] Trial 11 finished with value: 0.8169642857142857 and parameters: {'num_leaves': 93, 'learning_rate': 0.19682628638744248, 'feature_fraction': 0.40276684574983135, 'bagging_fraction': 0.5994740078012457, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 5 with value: 0.9196428571428572.
[I 2025-09-17 13:18:20,816] Trial 12 finished with value: 0.9285714285714285 and parameters: {'num_leaves': 118, 'learning_rate': 0.17851486848838255, 'feature_fraction': 0.532572930989384, 'bagging_fraction': 0.6308624062773118, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 12 with value: 0.9285714285714285.
[I 2025-09-17 13:18:20,847] Trial 13 finished with value: 0.875 and parameters: {'num_leaves': 224, 'learning_rate': 0.2571985889289794, 'feature_fraction': 0.5526532840537445, 'bagging_fraction': 0.6101377124293869, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 12 with value: 0.9285714285714285.
[I 2025-09-17 13:18:20,913] Trial 14 finished with value: 0.9330357142857143 and parameters: {'num_leaves': 120, 'learning_rate': 0.15117890953888433, 'feature_fraction': 0.565833040263695, 'bagging_fraction': 0.8864069634373275, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:20,977] Trial 15 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 120, 'learning_rate': 0.14497994134441927, 'feature_fraction': 0.5556562781121348, 'bagging_fraction': 0.6752051083931798, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:20,995] Trial 16 finished with value: 0.65625 and parameters: {'num_leaves': 67, 'learning_rate': 0.2363182081625696, 'feature_fraction': 0.5862054223491306, 'bagging_fraction': 0.513704653802725, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:21,006] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 137, 'learning_rate': 0.019680146922645997, 'feature_fraction': 0.49598624701990457, 'bagging_fraction': 0.8512432175319639, 'bagging_freq': 6, 'min_child_samples': 58}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:21,044] Trial 18 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 68, 'learning_rate': 0.15067089461800398, 'feature_fraction': 0.4755495908554055, 'bagging_fraction': 0.9936062565115409, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:21,072] Trial 19 finished with value: 0.8080357142857143 and parameters: {'num_leaves': 194, 'learning_rate': 0.22441520218294092, 'feature_fraction': 0.9993971763881342, 'bagging_fraction': 0.5535691772036385, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:21,085] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 119, 'learning_rate': 0.1291979125154, 'feature_fraction': 0.5920745555408097, 'bagging_fraction': 0.6922798319039665, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:21,145] Trial 21 finished with value: 0.90625 and parameters: {'num_leaves': 212, 'learning_rate': 0.17152079374334012, 'feature_fraction': 0.6302937502584227, 'bagging_fraction': 0.8964289182189344, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:21,179] Trial 22 finished with value: 0.8705357142857143 and parameters: {'num_leaves': 153, 'learning_rate': 0.17171691831636005, 'feature_fraction': 0.5322461386504108, 'bagging_fraction': 0.9222272054390406, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 14 with value: 0.9330357142857143.
[I 2025-09-17 13:18:21,225] Trial 23 finished with value: 0.9375 and parameters: {'num_leaves': 228, 'learning_rate': 0.1734202224222977, 'feature_fraction': 0.6024597565644518, 'bagging_fraction': 0.8438058708205589, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 23 with value: 0.9375.
[I 2025-09-17 13:18:21,303] Trial 24 finished with value: 0.9553571428571429 and parameters: {'num_leaves': 89, 'learning_rate': 0.2148285940004964, 'feature_fraction': 0.45895384092145997, 'bagging_fraction': 0.8494354655844168, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,365] Trial 25 finished with value: 0.9375 and parameters: {'num_leaves': 70, 'learning_rate': 0.2249451142463755, 'feature_fraction': 0.4514484967057569, 'bagging_fraction': 0.8554770939661693, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,396] Trial 26 finished with value: 0.8482142857142858 and parameters: {'num_leaves': 73, 'learning_rate': 0.2232019319841999, 'feature_fraction': 0.4412375763097997, 'bagging_fraction': 0.8430859579476313, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,422] Trial 27 finished with value: 0.875 and parameters: {'num_leaves': 44, 'learning_rate': 0.2633141969708914, 'feature_fraction': 0.4530233949412632, 'bagging_fraction': 0.9502266497916098, 'bagging_freq': 5, 'min_child_samples': 39}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,495] Trial 28 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 88, 'learning_rate': 0.21303220332252282, 'feature_fraction': 0.5147303539009023, 'bagging_fraction': 0.8439092031567825, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,528] Trial 29 finished with value: 0.8660714285714286 and parameters: {'num_leaves': 14, 'learning_rate': 0.29670493287379385, 'feature_fraction': 0.47602338861885285, 'bagging_fraction': 0.9630660794263437, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,563] Trial 30 finished with value: 0.8794642857142857 and parameters: {'num_leaves': 270, 'learning_rate': 0.24678816659632696, 'feature_fraction': 0.6123903369869031, 'bagging_fraction': 0.7486876099522924, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,608] Trial 31 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 45, 'learning_rate': 0.20632881740085462, 'feature_fraction': 0.5640446723509085, 'bagging_fraction': 0.8574382688003986, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,680] Trial 32 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 136, 'learning_rate': 0.12591537794028979, 'feature_fraction': 0.508616593015073, 'bagging_fraction': 0.8884379919492319, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,758] Trial 33 finished with value: 0.9330357142857143 and parameters: {'num_leaves': 106, 'learning_rate': 0.1106793602794878, 'feature_fraction': 0.4387236679481503, 'bagging_fraction': 0.814109430260287, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,782] Trial 34 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 85, 'learning_rate': 0.14192304090219732, 'feature_fraction': 0.4776175001399359, 'bagging_fraction': 0.9396801314960284, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,805] Trial 35 finished with value: 0.8794642857142856 and parameters: {'num_leaves': 54, 'learning_rate': 0.2697264702171951, 'feature_fraction': 0.7056867005721927, 'bagging_fraction': 0.7941558663380297, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,819] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 254, 'learning_rate': 0.1816789804268246, 'feature_fraction': 0.6585892049743001, 'bagging_fraction': 0.764685164453, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,858] Trial 37 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 146, 'learning_rate': 0.1591876455485018, 'feature_fraction': 0.5836620343501501, 'bagging_fraction': 0.8794658979787366, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,888] Trial 38 finished with value: 0.8839285714285714 and parameters: {'num_leaves': 166, 'learning_rate': 0.23685366781484932, 'feature_fraction': 0.742699349368225, 'bagging_fraction': 0.7123394572625101, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,900] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 143, 'learning_rate': 0.09594149643966854, 'feature_fraction': 0.833430900461169, 'bagging_fraction': 0.8218266552801762, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:21,931] Trial 40 finished with value: 0.8125 and parameters: {'num_leaves': 202, 'learning_rate': 0.1594019645618327, 'feature_fraction': 0.6045855063333948, 'bagging_fraction': 0.8703768934810682, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 24 with value: 0.9553571428571429.
[I 2025-09-17 13:18:22,037] Trial 41 finished with value: 0.9598214285714286 and parameters: {'num_leaves': 113, 'learning_rate': 0.1883257347781076, 'feature_fraction': 0.6610503276779683, 'bagging_fraction': 0.9074360182471818, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,119] Trial 42 finished with value: 0.9017857142857143 and parameters: {'num_leaves': 105, 'learning_rate': 0.20903880993382315, 'feature_fraction': 0.6290663318255654, 'bagging_fraction': 0.916827391932338, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,162] Trial 43 finished with value: 0.9375 and parameters: {'num_leaves': 81, 'learning_rate': 0.19637651384153057, 'feature_fraction': 0.6563153364158058, 'bagging_fraction': 0.978973931818366, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,226] Trial 44 finished with value: 0.8660714285714285 and parameters: {'num_leaves': 167, 'learning_rate': 0.18677634984195585, 'feature_fraction': 0.6822927823628182, 'bagging_fraction': 0.91580205965096, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,324] Trial 45 finished with value: 0.9375 and parameters: {'num_leaves': 59, 'learning_rate': 0.22396083964746255, 'feature_fraction': 0.7166833159354364, 'bagging_fraction': 0.7714714379634936, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,367] Trial 46 finished with value: 0.9017857142857143 and parameters: {'num_leaves': 242, 'learning_rate': 0.16614669114446806, 'feature_fraction': 0.8019337274287562, 'bagging_fraction': 0.8365541086012195, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,432] Trial 47 finished with value: 0.9330357142857142 and parameters: {'num_leaves': 32, 'learning_rate': 0.1343638490321677, 'feature_fraction': 0.40567202166784366, 'bagging_fraction': 0.8776587688170201, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,465] Trial 48 finished with value: 0.8973214285714286 and parameters: {'num_leaves': 127, 'learning_rate': 0.2426868879095132, 'feature_fraction': 0.5368837650564284, 'bagging_fraction': 0.8174789570397208, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,512] Trial 49 finished with value: 0.9598214285714286 and parameters: {'num_leaves': 101, 'learning_rate': 0.18501872633828553, 'feature_fraction': 0.5807197560627821, 'bagging_fraction': 0.7890388409391373, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 41 with value: 0.9598214285714286.
[I 2025-09-17 13:18:22,841] A new study created in memory with name: no-name-db389b5d-12d8-4f5b-b962-0488d9dca644
[I 2025-09-17 13:18:22,860] Trial 0 finished with value: 0.8482142857142857 and parameters: {'num_leaves': 225, 'learning_rate': 0.2709031002531561, 'feature_fraction': 0.6658313977134509, 'bagging_fraction': 0.8411443675981165, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 0 with value: 0.8482142857142857.
[I 2025-09-17 13:18:22,881] Trial 1 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 250, 'learning_rate': 0.12266100031264113, 'feature_fraction': 0.9151736924394175, 'bagging_fraction': 0.8223631930315182, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 0 with value: 0.8482142857142857.
[I 2025-09-17 13:18:22,919] Trial 2 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 297, 'learning_rate': 0.1135905590825031, 'feature_fraction': 0.6098347465452085, 'bagging_fraction': 0.9278337178084709, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 2 with value: 0.9151785714285714.
[I 2025-09-17 13:18:22,926] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 276, 'learning_rate': 0.186134264604671, 'feature_fraction': 0.8435937530314487, 'bagging_fraction': 0.5177984235322539, 'bagging_freq': 6, 'min_child_samples': 92}. Best is trial 2 with value: 0.9151785714285714.
[I 2025-09-17 13:18:22,964] Trial 4 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 120, 'learning_rate': 0.12454677830489912, 'feature_fraction': 0.7340907460687243, 'bagging_fraction': 0.577827682628318, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 2 with value: 0.9151785714285714.
[I 2025-09-17 13:18:22,973] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 191, 'learning_rate': 0.18662781132149703, 'feature_fraction': 0.7563324481628928, 'bagging_fraction': 0.753483214874391, 'bagging_freq': 4, 'min_child_samples': 80}. Best is trial 2 with value: 0.9151785714285714.
[I 2025-09-17 13:18:22,994] Trial 6 finished with value: 0.8125 and parameters: {'num_leaves': 127, 'learning_rate': 0.2990461539723173, 'feature_fraction': 0.4576786388690312, 'bagging_fraction': 0.8879511286907319, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 2 with value: 0.9151785714285714.
[I 2025-09-17 13:18:23,006] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 120, 'learning_rate': 0.19614248984803376, 'feature_fraction': 0.41028700668186807, 'bagging_fraction': 0.5282951770449534, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 2 with value: 0.9151785714285714.
[I 2025-09-17 13:18:23,020] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 227, 'learning_rate': 0.011320532441614019, 'feature_fraction': 0.7791656899721018, 'bagging_fraction': 0.652528417174818, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 2 with value: 0.9151785714285714.
[I 2025-09-17 13:18:23,040] Trial 9 finished with value: 0.875 and parameters: {'num_leaves': 233, 'learning_rate': 0.2932979989975595, 'feature_fraction': 0.7189343319139913, 'bagging_fraction': 0.6633757329958743, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 2 with value: 0.9151785714285714.
[I 2025-09-17 13:18:23,192] Trial 10 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 43, 'learning_rate': 0.03236084124224871, 'feature_fraction': 0.5703154565638537, 'bagging_fraction': 0.9884686527074609, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 2 with value: 0.9151785714285714.
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.351851
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.471825
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.473122
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.415547
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.502404
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.304223
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.410021
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.353345
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.367767
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.664008
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.356652
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.543383
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.362626
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.437462
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.360671
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.274934
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.328317
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.49647
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.447954
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.399259
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.484007
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.431628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.372286
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.365659
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.344871
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.528454
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.435525
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.336721
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.404062
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.525341
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.332429
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.410244
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.303539
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.407676
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.324856
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.38497
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.318689
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.385762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.330259
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.479977
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.498223
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.402926
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.402375
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.524541
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.477123
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.344802
[I 2025-09-17 13:18:23,369] Trial 11 finished with value: 0.9330357142857143 and parameters: {'num_leaves': 21, 'learning_rate': 0.03407425131437958, 'feature_fraction': 0.5946292855735964, 'bagging_fraction': 0.9977663137911121, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,410] Trial 12 finished with value: 0.8616071428571428 and parameters: {'num_leaves': 16, 'learning_rate': 0.0671515451385587, 'feature_fraction': 0.5801672917796893, 'bagging_fraction': 0.9981390507298915, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,457] Trial 13 finished with value: 0.90625 and parameters: {'num_leaves': 76, 'learning_rate': 0.07825092582934001, 'feature_fraction': 0.5665901799324472, 'bagging_fraction': 0.9339957911313397, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,473] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.06910051461224816, 'feature_fraction': 0.6333220697664111, 'bagging_fraction': 0.774192493578055, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,511] Trial 15 finished with value: 0.8883928571428571 and parameters: {'num_leaves': 76, 'learning_rate': 0.1203855012374066, 'feature_fraction': 0.4895526418033574, 'bagging_fraction': 0.9153920959658827, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,526] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.03817153723315439, 'feature_fraction': 0.9803539981877452, 'bagging_fraction': 0.42645676018578216, 'bagging_freq': 5, 'min_child_samples': 61}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,646] Trial 17 finished with value: 0.9107142857142856 and parameters: {'num_leaves': 155, 'learning_rate': 0.0903286224080817, 'feature_fraction': 0.6282506649321824, 'bagging_fraction': 0.9391852978310052, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,674] Trial 18 finished with value: 0.9062500000000001 and parameters: {'num_leaves': 79, 'learning_rate': 0.23014855816819918, 'feature_fraction': 0.5147131585117599, 'bagging_fraction': 0.8424522974598048, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,711] Trial 19 finished with value: 0.8973214285714285 and parameters: {'num_leaves': 18, 'learning_rate': 0.15319071974971543, 'feature_fraction': 0.832465738525694, 'bagging_fraction': 0.7644217004020017, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,732] Trial 20 finished with value: 0.7723214285714286 and parameters: {'num_leaves': 194, 'learning_rate': 0.1050164143856584, 'feature_fraction': 0.656921501709768, 'bagging_fraction': 0.9985523165280437, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,885] Trial 21 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 42, 'learning_rate': 0.011327071450643954, 'feature_fraction': 0.5757969561501611, 'bagging_fraction': 0.9693842613469574, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,921] Trial 22 finished with value: 0.8660714285714286 and parameters: {'num_leaves': 43, 'learning_rate': 0.0418069329951425, 'feature_fraction': 0.512954985442243, 'bagging_fraction': 0.8860371851899899, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:23,990] Trial 23 finished with value: 0.8973214285714285 and parameters: {'num_leaves': 47, 'learning_rate': 0.043273107699142145, 'feature_fraction': 0.5798657513487688, 'bagging_fraction': 0.9542277181258166, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,125] Trial 24 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 95, 'learning_rate': 0.04572989561735444, 'feature_fraction': 0.6933190619933286, 'bagging_fraction': 0.8715627301557136, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,171] Trial 25 finished with value: 0.9017857142857142 and parameters: {'num_leaves': 10, 'learning_rate': 0.15737467613572406, 'feature_fraction': 0.5464044483090217, 'bagging_fraction': 0.9992499231787044, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,202] Trial 26 finished with value: 0.8839285714285714 and parameters: {'num_leaves': 152, 'learning_rate': 0.09610209002150012, 'feature_fraction': 0.6106294194490682, 'bagging_fraction': 0.9149099057749777, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,260] Trial 27 finished with value: 0.90625 and parameters: {'num_leaves': 51, 'learning_rate': 0.14949254089483613, 'feature_fraction': 0.43906149822704355, 'bagging_fraction': 0.8078255102228751, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,271] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 101, 'learning_rate': 0.025729366791573855, 'feature_fraction': 0.6771327191772708, 'bagging_fraction': 0.9627420263730593, 'bagging_freq': 4, 'min_child_samples': 68}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,283] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 253, 'learning_rate': 0.059552081373979715, 'feature_fraction': 0.5278835722682881, 'bagging_fraction': 0.8547010929386077, 'bagging_freq': 5, 'min_child_samples': 98}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,300] Trial 30 finished with value: 0.765625 and parameters: {'num_leaves': 60, 'learning_rate': 0.22415831968438543, 'feature_fraction': 0.6140161279828453, 'bagging_fraction': 0.7028813134534722, 'bagging_freq': 7, 'min_child_samples': 40}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,479] Trial 31 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 32, 'learning_rate': 0.017917055075250134, 'feature_fraction': 0.47872132619069063, 'bagging_fraction': 0.9649667427750479, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,567] Trial 32 finished with value: 0.9241071428571428 and parameters: {'num_leaves': 29, 'learning_rate': 0.011572653185856128, 'feature_fraction': 0.5858691182303457, 'bagging_fraction': 0.9046220075983064, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,630] Trial 33 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 29, 'learning_rate': 0.058134390261627755, 'feature_fraction': 0.6471056613704598, 'bagging_fraction': 0.9168006159552214, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,661] Trial 34 finished with value: 0.8303571428571428 and parameters: {'num_leaves': 67, 'learning_rate': 0.03373106046600442, 'feature_fraction': 0.5987217009345006, 'bagging_fraction': 0.8952952684877106, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,699] Trial 35 finished with value: 0.8794642857142857 and parameters: {'num_leaves': 270, 'learning_rate': 0.07994805720152687, 'feature_fraction': 0.5426363623883075, 'bagging_fraction': 0.8113320340785725, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,779] Trial 36 finished with value: 0.9196428571428572 and parameters: {'num_leaves': 104, 'learning_rate': 0.11172228944312929, 'feature_fraction': 0.6502975808931372, 'bagging_fraction': 0.9715071197068125, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,804] Trial 37 finished with value: 0.8705357142857143 and parameters: {'num_leaves': 99, 'learning_rate': 0.13388511770189104, 'feature_fraction': 0.7708723121461751, 'bagging_fraction': 0.822684409577504, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,817] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.11206427163558634, 'feature_fraction': 0.7158009705965017, 'bagging_fraction': 0.9323834454581892, 'bagging_freq': 7, 'min_child_samples': 85}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,859] Trial 39 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 203, 'learning_rate': 0.1381381955796952, 'feature_fraction': 0.6737936092207044, 'bagging_fraction': 0.588218776234191, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,890] Trial 40 finished with value: 0.8482142857142857 and parameters: {'num_leaves': 116, 'learning_rate': 0.17489570065162932, 'feature_fraction': 0.7382308866730544, 'bagging_fraction': 0.8614671517365647, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:24,985] Trial 41 finished with value: 0.9062499999999999 and parameters: {'num_leaves': 30, 'learning_rate': 0.026336224467723456, 'feature_fraction': 0.6019698440467999, 'bagging_fraction': 0.9756065444577178, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:25,028] Trial 42 finished with value: 0.8794642857142857 and parameters: {'num_leaves': 60, 'learning_rate': 0.05426571959789439, 'feature_fraction': 0.5518567537431234, 'bagging_fraction': 0.9027896367907571, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 11 with value: 0.9330357142857143.
[I 2025-09-17 13:18:25,105] Trial 43 finished with value: 0.9375 and parameters: {'num_leaves': 89, 'learning_rate': 0.09186751318733244, 'feature_fraction': 0.6550612004179782, 'bagging_fraction': 0.9742630612255185, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 43 with value: 0.9375.
[I 2025-09-17 13:18:25,163] Trial 44 finished with value: 0.9062499999999999 and parameters: {'num_leaves': 155, 'learning_rate': 0.09081143656698129, 'feature_fraction': 0.8045264473635318, 'bagging_fraction': 0.9439026065383188, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 43 with value: 0.9375.
[I 2025-09-17 13:18:25,213] Trial 45 finished with value: 0.8705357142857143 and parameters: {'num_leaves': 91, 'learning_rate': 0.11251976089274546, 'feature_fraction': 0.6811529633760425, 'bagging_fraction': 0.7244261044736525, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 43 with value: 0.9375.
[I 2025-09-17 13:18:25,258] Trial 46 finished with value: 0.8883928571428572 and parameters: {'num_leaves': 109, 'learning_rate': 0.07742578149113799, 'feature_fraction': 0.641030099409271, 'bagging_fraction': 0.9727765770395262, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 43 with value: 0.9375.
[I 2025-09-17 13:18:25,272] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 172, 'learning_rate': 0.17451733236587255, 'feature_fraction': 0.7229435347097164, 'bagging_fraction': 0.4067670603730266, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 43 with value: 0.9375.
[I 2025-09-17 13:18:25,332] Trial 48 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 135, 'learning_rate': 0.1319458366093269, 'feature_fraction': 0.8915837755082587, 'bagging_fraction': 0.9303803870321846, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 48 with value: 0.9464285714285714.
[I 2025-09-17 13:18:25,393] Trial 49 finished with value: 0.9151785714285714 and parameters: {'num_leaves': 139, 'learning_rate': 0.12723519825566307, 'feature_fraction': 0.8813366582889162, 'bagging_fraction': 0.8814336803269716, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 48 with value: 0.9464285714285714.
[I 2025-09-17 13:18:25,706] A new study created in memory with name: no-name-ec0e4307-bdd9-4f8b-b48a-7a89ded9f210
[I 2025-09-17 13:18:25,719] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 238, 'learning_rate': 0.12591345006292592, 'feature_fraction': 0.6489024811744635, 'bagging_fraction': 0.814591249736575, 'bagging_freq': 6, 'min_child_samples': 98}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:25,739] Trial 1 finished with value: 0.7232142857142857 and parameters: {'num_leaves': 276, 'learning_rate': 0.28165262424622045, 'feature_fraction': 0.43429178985618744, 'bagging_fraction': 0.9232984484142743, 'bagging_freq': 4, 'min_child_samples': 54}. Best is trial 1 with value: 0.7232142857142857.
[I 2025-09-17 13:18:25,796] Trial 2 finished with value: 0.8705357142857142 and parameters: {'num_leaves': 54, 'learning_rate': 0.29844526937743926, 'feature_fraction': 0.5609726155719046, 'bagging_fraction': 0.7954440053503056, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 2 with value: 0.8705357142857142.
[I 2025-09-17 13:18:25,820] Trial 3 finished with value: 0.8080357142857142 and parameters: {'num_leaves': 295, 'learning_rate': 0.05282882698760762, 'feature_fraction': 0.9242555693391407, 'bagging_fraction': 0.45247317218376293, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 2 with value: 0.8705357142857142.
[I 2025-09-17 13:18:25,868] Trial 4 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 207, 'learning_rate': 0.19824280490745153, 'feature_fraction': 0.6362280839655232, 'bagging_fraction': 0.9586028002541549, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 4 with value: 0.8928571428571428.
[I 2025-09-17 13:18:25,876] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 27, 'learning_rate': 0.047677620614649883, 'feature_fraction': 0.8512773217702883, 'bagging_fraction': 0.5997122581194196, 'bagging_freq': 3, 'min_child_samples': 93}. Best is trial 4 with value: 0.8928571428571428.
[I 2025-09-17 13:18:25,885] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.0719963968964843, 'feature_fraction': 0.4008439378606016, 'bagging_fraction': 0.7818423223758535, 'bagging_freq': 6, 'min_child_samples': 76}. Best is trial 4 with value: 0.8928571428571428.
[I 2025-09-17 13:18:25,898] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 101, 'learning_rate': 0.0853917017082446, 'feature_fraction': 0.9603890493089379, 'bagging_fraction': 0.9065659448938787, 'bagging_freq': 3, 'min_child_samples': 64}. Best is trial 4 with value: 0.8928571428571428.
[I 2025-09-17 13:18:25,924] Trial 8 finished with value: 0.8482142857142857 and parameters: {'num_leaves': 290, 'learning_rate': 0.036297379819559286, 'feature_fraction': 0.7016926391750073, 'bagging_fraction': 0.8862247878454053, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 4 with value: 0.8928571428571428.
[I 2025-09-17 13:18:25,941] Trial 9 finished with value: 0.7700892857142857 and parameters: {'num_leaves': 95, 'learning_rate': 0.028431599177306983, 'feature_fraction': 0.5921634219762139, 'bagging_fraction': 0.5531288260741342, 'bagging_freq': 2, 'min_child_samples': 35}. Best is trial 4 with value: 0.8928571428571428.
[I 2025-09-17 13:18:25,996] Trial 10 finished with value: 0.8973214285714285 and parameters: {'num_leaves': 195, 'learning_rate': 0.2151439215485794, 'feature_fraction': 0.7465905968909186, 'bagging_fraction': 0.9995457057257873, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 10 with value: 0.8973214285714285.
[I 2025-09-17 13:18:26,042] Trial 11 finished with value: 0.90625 and parameters: {'num_leaves': 200, 'learning_rate': 0.21582802339060422, 'feature_fraction': 0.7706440465490719, 'bagging_fraction': 0.9885632736651561, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,145] Trial 12 finished with value: 0.8660714285714286 and parameters: {'num_leaves': 184, 'learning_rate': 0.21421538117296118, 'feature_fraction': 0.7824330055681687, 'bagging_fraction': 0.9895228726867594, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,165] Trial 13 finished with value: 0.7633928571428572 and parameters: {'num_leaves': 169, 'learning_rate': 0.2291802262907977, 'feature_fraction': 0.780862689222285, 'bagging_fraction': 0.6601858087257295, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,214] Trial 14 finished with value: 0.8169642857142857 and parameters: {'num_leaves': 227, 'learning_rate': 0.16560449447513137, 'feature_fraction': 0.756981024690939, 'bagging_fraction': 0.9940464772778578, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,232] Trial 15 finished with value: 0.8035714285714285 and parameters: {'num_leaves': 136, 'learning_rate': 0.24904033965049982, 'feature_fraction': 0.8641576505696573, 'bagging_fraction': 0.8559558732199084, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,281] Trial 16 finished with value: 0.8169642857142858 and parameters: {'num_leaves': 236, 'learning_rate': 0.16793587493613854, 'feature_fraction': 0.5035711148112404, 'bagging_fraction': 0.7192885481302695, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,314] Trial 17 finished with value: 0.8169642857142857 and parameters: {'num_leaves': 188, 'learning_rate': 0.11551534104449333, 'feature_fraction': 0.7220434013599052, 'bagging_fraction': 0.7274070580904001, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,339] Trial 18 finished with value: 0.7991071428571429 and parameters: {'num_leaves': 144, 'learning_rate': 0.25918866796706036, 'feature_fraction': 0.8478984695580359, 'bagging_fraction': 0.8530802996486537, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 11 with value: 0.90625.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.334964
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.472668
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.406597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.419416
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.379955
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.397417
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.392174
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.562322
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.40592
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.505299
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.387398
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.389292
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.379314
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.437957
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.382995
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.556592
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.370633
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.407123
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.354928
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.535861
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.431981
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.355334
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.491627
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.38637
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.503798
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.351729
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.423072
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.335122
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.359468
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.458851
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.446897
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.35456
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.372669
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.579864
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.435463
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.559419
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.468435
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.515723
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.631247
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.444162
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.420911
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.498454
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.572208
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.519408
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.567094
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.500222
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.507331
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.537739
[I 2025-09-17 13:18:26,385] Trial 19 finished with value: 0.8705357142857143 and parameters: {'num_leaves': 264, 'learning_rate': 0.19010710584076662, 'feature_fraction': 0.6565432113029961, 'bagging_fraction': 0.9400896690503217, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,397] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.1383363992980612, 'feature_fraction': 0.9099823096497328, 'bagging_fraction': 0.41474257433283634, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,445] Trial 21 finished with value: 0.8749999999999999 and parameters: {'num_leaves': 212, 'learning_rate': 0.20117641871647143, 'feature_fraction': 0.6422777709342644, 'bagging_fraction': 0.9965254977263991, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,489] Trial 22 finished with value: 0.875 and parameters: {'num_leaves': 253, 'learning_rate': 0.24313239938623288, 'feature_fraction': 0.5758599644731108, 'bagging_fraction': 0.9470331101097909, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,521] Trial 23 finished with value: 0.8303571428571428 and parameters: {'num_leaves': 197, 'learning_rate': 0.1905813805017808, 'feature_fraction': 0.8142057698836836, 'bagging_fraction': 0.9418837993264325, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,587] Trial 24 finished with value: 0.84375 and parameters: {'num_leaves': 165, 'learning_rate': 0.21261153200121094, 'feature_fraction': 0.7176075734032248, 'bagging_fraction': 0.8634269866824914, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,625] Trial 25 finished with value: 0.8169642857142857 and parameters: {'num_leaves': 112, 'learning_rate': 0.1739854905709751, 'feature_fraction': 0.6710374603127325, 'bagging_fraction': 0.9647504971970335, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,672] Trial 26 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 221, 'learning_rate': 0.27162625695754355, 'feature_fraction': 0.6113293360137183, 'bagging_fraction': 0.9078896583900092, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,693] Trial 27 finished with value: 0.8125 and parameters: {'num_leaves': 166, 'learning_rate': 0.27064342182745055, 'feature_fraction': 0.4859191087304333, 'bagging_fraction': 0.8876648456162358, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,725] Trial 28 finished with value: 0.8437500000000001 and parameters: {'num_leaves': 227, 'learning_rate': 0.23206116657468928, 'feature_fraction': 0.758237193080358, 'bagging_fraction': 0.8285067988845773, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,739] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 260, 'learning_rate': 0.29708969782464933, 'feature_fraction': 0.6102696539888808, 'bagging_fraction': 0.7740803726533036, 'bagging_freq': 6, 'min_child_samples': 88}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,855] Trial 30 finished with value: 0.84375 and parameters: {'num_leaves': 249, 'learning_rate': 0.1478662177982146, 'feature_fraction': 0.5482655877770074, 'bagging_fraction': 0.9092486572148768, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 11 with value: 0.90625.
[I 2025-09-17 13:18:26,904] Trial 31 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 218, 'learning_rate': 0.22536136174876367, 'feature_fraction': 0.6286634610628621, 'bagging_fraction': 0.9699351292547125, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:26,944] Trial 32 finished with value: 0.8727678571428572 and parameters: {'num_leaves': 224, 'learning_rate': 0.2680916635088943, 'feature_fraction': 0.6807861397763048, 'bagging_fraction': 0.9982265397155802, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,004] Trial 33 finished with value: 0.8616071428571429 and parameters: {'num_leaves': 186, 'learning_rate': 0.22666855403706793, 'feature_fraction': 0.5271331116534457, 'bagging_fraction': 0.9196006887695267, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,034] Trial 34 finished with value: 0.7946428571428571 and parameters: {'num_leaves': 243, 'learning_rate': 0.2782380780954705, 'feature_fraction': 0.6093036956884378, 'bagging_fraction': 0.9663498273239504, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,069] Trial 35 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 279, 'learning_rate': 0.2461235742273894, 'feature_fraction': 0.7345289709725467, 'bagging_fraction': 0.8317891609526591, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,140] Trial 36 finished with value: 0.875 and parameters: {'num_leaves': 214, 'learning_rate': 0.010321950393272605, 'feature_fraction': 0.8117839605306044, 'bagging_fraction': 0.9281101079451541, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,157] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 198, 'learning_rate': 0.29888505047330277, 'feature_fraction': 0.6880751372708965, 'bagging_fraction': 0.5035782726380299, 'bagging_freq': 6, 'min_child_samples': 60}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,203] Trial 38 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 173, 'learning_rate': 0.21051352831758194, 'feature_fraction': 0.472188758231922, 'bagging_fraction': 0.6713432091491788, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,219] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 145, 'learning_rate': 0.18105655091152117, 'feature_fraction': 0.626733320963104, 'bagging_fraction': 0.8872037659179025, 'bagging_freq': 4, 'min_child_samples': 79}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,286] Trial 40 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 45, 'learning_rate': 0.2576557906859448, 'feature_fraction': 0.5543381285134719, 'bagging_fraction': 0.9604732348569338, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,346] Trial 41 finished with value: 0.8392857142857142 and parameters: {'num_leaves': 205, 'learning_rate': 0.2035920630921667, 'feature_fraction': 0.6493664220927807, 'bagging_fraction': 0.9686744782209159, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,398] Trial 42 finished with value: 0.8258928571428572 and parameters: {'num_leaves': 219, 'learning_rate': 0.23131450494033934, 'feature_fraction': 0.5904323486306168, 'bagging_fraction': 0.9106510551540933, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,504] Trial 43 finished with value: 0.8348214285714286 and parameters: {'num_leaves': 239, 'learning_rate': 0.2250749422050769, 'feature_fraction': 0.6974713894421449, 'bagging_fraction': 0.9741193155057785, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,549] Trial 44 finished with value: 0.8839285714285714 and parameters: {'num_leaves': 271, 'learning_rate': 0.19136086709411848, 'feature_fraction': 0.6228291952238783, 'bagging_fraction': 0.9341037450036573, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,579] Trial 45 finished with value: 0.7991071428571429 and parameters: {'num_leaves': 180, 'learning_rate': 0.24388315984330552, 'feature_fraction': 0.7555995809771328, 'bagging_fraction': 0.7947993211399288, 'bagging_freq': 1, 'min_child_samples': 36}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,599] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 156, 'learning_rate': 0.1557324001055447, 'feature_fraction': 0.7976286634873498, 'bagging_fraction': 0.615581817260832, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,652] Trial 47 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 196, 'learning_rate': 0.10636510713102679, 'feature_fraction': 0.711852710198348, 'bagging_fraction': 0.8641825090142464, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,705] Trial 48 finished with value: 0.8772321428571429 and parameters: {'num_leaves': 231, 'learning_rate': 0.28591754400660974, 'feature_fraction': 0.7446431562072795, 'bagging_fraction': 0.894829093340206, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:27,728] Trial 49 finished with value: 0.71875 and parameters: {'num_leaves': 122, 'learning_rate': 0.2197633528824539, 'feature_fraction': 0.8549659182363732, 'bagging_fraction': 0.764608431551826, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 31 with value: 0.9107142857142857.
[I 2025-09-17 13:18:28,021] A new study created in memory with name: no-name-bece91b2-e93f-4ada-90c8-fc52758841ee
[I 2025-09-17 13:18:28,031] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 123, 'learning_rate': 0.2500950941081925, 'feature_fraction': 0.6325855882179049, 'bagging_fraction': 0.9329040149810646, 'bagging_freq': 2, 'min_child_samples': 91}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:28,039] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 14, 'learning_rate': 0.2832064205927696, 'feature_fraction': 0.703968016196832, 'bagging_fraction': 0.41176570190707773, 'bagging_freq': 5, 'min_child_samples': 49}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:28,047] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 242, 'learning_rate': 0.04667045352591922, 'feature_fraction': 0.8781046068730258, 'bagging_fraction': 0.45580543390837647, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:28,054] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 23, 'learning_rate': 0.2971729239876907, 'feature_fraction': 0.8228498670345226, 'bagging_fraction': 0.4886406222650521, 'bagging_freq': 1, 'min_child_samples': 75}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:28,062] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 223, 'learning_rate': 0.06769848626987396, 'feature_fraction': 0.8957430473061706, 'bagging_fraction': 0.663653069696953, 'bagging_freq': 5, 'min_child_samples': 70}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:28,094] Trial 5 finished with value: 0.8006993006993006 and parameters: {'num_leaves': 14, 'learning_rate': 0.06510899374751074, 'feature_fraction': 0.7447811133692321, 'bagging_fraction': 0.8797929389257686, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 5 with value: 0.8006993006993006.
[I 2025-09-17 13:18:28,162] Trial 6 finished with value: 0.7937062937062936 and parameters: {'num_leaves': 127, 'learning_rate': 0.19965462317058696, 'feature_fraction': 0.4269859364833359, 'bagging_fraction': 0.4563301145916112, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 5 with value: 0.8006993006993006.
[I 2025-09-17 13:18:28,170] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 241, 'learning_rate': 0.07978727952532186, 'feature_fraction': 0.8160785232002372, 'bagging_fraction': 0.6982804667575244, 'bagging_freq': 7, 'min_child_samples': 87}. Best is trial 5 with value: 0.8006993006993006.
[I 2025-09-17 13:18:28,177] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 194, 'learning_rate': 0.20577017094657876, 'feature_fraction': 0.957260463552591, 'bagging_fraction': 0.6695920388862102, 'bagging_freq': 6, 'min_child_samples': 69}. Best is trial 5 with value: 0.8006993006993006.
[I 2025-09-17 13:18:28,185] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 223, 'learning_rate': 0.27928789729176384, 'feature_fraction': 0.6387120789339176, 'bagging_fraction': 0.5011761624530296, 'bagging_freq': 6, 'min_child_samples': 99}. Best is trial 5 with value: 0.8006993006993006.
[I 2025-09-17 13:18:28,228] Trial 10 finished with value: 0.8706293706293706 and parameters: {'num_leaves': 67, 'learning_rate': 0.12678012309974312, 'feature_fraction': 0.4839575059299513, 'bagging_fraction': 0.9987065466903775, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 10 with value: 0.8706293706293706.
[I 2025-09-17 13:18:28,273] Trial 11 finished with value: 0.8776223776223777 and parameters: {'num_leaves': 71, 'learning_rate': 0.12480194646883269, 'feature_fraction': 0.41993290425512747, 'bagging_fraction': 0.9793403826764311, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,331] Trial 12 finished with value: 0.8426573426573427 and parameters: {'num_leaves': 74, 'learning_rate': 0.12710380081797173, 'feature_fraction': 0.4010471119850016, 'bagging_fraction': 0.999550078210839, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,368] Trial 13 finished with value: 0.8776223776223776 and parameters: {'num_leaves': 77, 'learning_rate': 0.12621852122209556, 'feature_fraction': 0.521568628803097, 'bagging_fraction': 0.8420452813632244, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,557] Trial 14 finished with value: 0.7482517482517482 and parameters: {'num_leaves': 83, 'learning_rate': 0.01048111916724577, 'feature_fraction': 0.5478362732646739, 'bagging_fraction': 0.8185116729613504, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,598] Trial 15 finished with value: 0.8426573426573427 and parameters: {'num_leaves': 161, 'learning_rate': 0.16364216371103835, 'feature_fraction': 0.5260747553860007, 'bagging_fraction': 0.791664275040764, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,625] Trial 16 finished with value: 0.7937062937062938 and parameters: {'num_leaves': 111, 'learning_rate': 0.11183241268824762, 'feature_fraction': 0.5879660401688032, 'bagging_fraction': 0.7973048788977218, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,686] Trial 17 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 51, 'learning_rate': 0.16495593133474787, 'feature_fraction': 0.46452811191658333, 'bagging_fraction': 0.8967737851487471, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,705] Trial 18 finished with value: 0.6940559440559441 and parameters: {'num_leaves': 290, 'learning_rate': 0.20124298287357167, 'feature_fraction': 0.5054539086101278, 'bagging_fraction': 0.584148463038292, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,725] Trial 19 finished with value: 0.5891608391608392 and parameters: {'num_leaves': 170, 'learning_rate': 0.14483985619989226, 'feature_fraction': 0.5835912551909835, 'bagging_fraction': 0.8444595013890659, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,794] Trial 20 finished with value: 0.8601398601398602 and parameters: {'num_leaves': 101, 'learning_rate': 0.09670996917253255, 'feature_fraction': 0.4447037790701201, 'bagging_fraction': 0.7539707613997559, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,838] Trial 21 finished with value: 0.8566433566433566 and parameters: {'num_leaves': 56, 'learning_rate': 0.1327330354890692, 'feature_fraction': 0.4906583202485998, 'bagging_fraction': 0.9861146907948392, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 11 with value: 0.8776223776223777.
[I 2025-09-17 13:18:28,877] Trial 22 finished with value: 0.9090909090909091 and parameters: {'num_leaves': 64, 'learning_rate': 0.1748332959976744, 'feature_fraction': 0.40525760930490373, 'bagging_fraction': 0.9401070159403963, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 22 with value: 0.9090909090909091.
[I 2025-09-17 13:18:28,895] Trial 23 finished with value: 0.6031468531468531 and parameters: {'num_leaves': 39, 'learning_rate': 0.17308065086579535, 'feature_fraction': 0.41021601351300485, 'bagging_fraction': 0.9281084374486179, 'bagging_freq': 2, 'min_child_samples': 56}. Best is trial 22 with value: 0.9090909090909091.
[I 2025-09-17 13:18:28,933] Trial 24 finished with value: 0.9195804195804196 and parameters: {'num_leaves': 93, 'learning_rate': 0.2339031441518356, 'feature_fraction': 0.56338859287081, 'bagging_fraction': 0.9466707224313734, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 24 with value: 0.9195804195804196.
[I 2025-09-17 13:18:28,969] Trial 25 finished with value: 0.8006993006993006 and parameters: {'num_leaves': 145, 'learning_rate': 0.23105259550079504, 'feature_fraction': 0.6278085708551483, 'bagging_fraction': 0.9471102133734929, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 24 with value: 0.9195804195804196.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.455811
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.46797
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.484947
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.500628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.482206
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.533343
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.458373
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.528377
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.486892
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.484945
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.41613
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.463207
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.490341
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.538167
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.52004
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.48358
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.466267
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.493987
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.485787
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.526973
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.495357
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.454856
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.539571
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.691035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.473108
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.453347
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.614488
Training model for P050... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.518485
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.512943
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.459763
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.422689
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.459252
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.445554
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.582514
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.471385
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.524998
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.469101
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.611793
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.660371
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.436698
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.471132
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.410657
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.650259
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.385233
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.511649
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:29,011] Trial 26 finished with value: 0.8741258741258742 and parameters: {'num_leaves': 94, 'learning_rate': 0.23849999879090417, 'feature_fraction': 0.5674430885343503, 'bagging_fraction': 0.8714577007636517, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 24 with value: 0.9195804195804196.
[I 2025-09-17 13:18:29,034] Trial 27 finished with value: 0.7552447552447552 and parameters: {'num_leaves': 44, 'learning_rate': 0.22007566381637356, 'feature_fraction': 0.45566561138622175, 'bagging_fraction': 0.9429013130388355, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 24 with value: 0.9195804195804196.
[I 2025-09-17 13:18:29,110] Trial 28 finished with value: 0.8111888111888113 and parameters: {'num_leaves': 136, 'learning_rate': 0.18259225956520825, 'feature_fraction': 0.4024378108103108, 'bagging_fraction': 0.743670698792827, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 24 with value: 0.9195804195804196.
[I 2025-09-17 13:18:29,146] Trial 29 finished with value: 0.9125874125874126 and parameters: {'num_leaves': 105, 'learning_rate': 0.2533169698207155, 'feature_fraction': 0.6442503170742433, 'bagging_fraction': 0.9131835473528215, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 24 with value: 0.9195804195804196.
[I 2025-09-17 13:18:29,186] Trial 30 finished with value: 0.8916083916083916 and parameters: {'num_leaves': 116, 'learning_rate': 0.2592860360644522, 'feature_fraction': 0.6643206746772363, 'bagging_fraction': 0.9100610388767806, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 24 with value: 0.9195804195804196.
[I 2025-09-17 13:18:29,219] Trial 31 finished with value: 0.9335664335664335 and parameters: {'num_leaves': 113, 'learning_rate': 0.2572866669871437, 'feature_fraction': 0.6737172562463768, 'bagging_fraction': 0.9124589071750281, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,250] Trial 32 finished with value: 0.8601398601398601 and parameters: {'num_leaves': 95, 'learning_rate': 0.25977722395651864, 'feature_fraction': 0.7341250325243951, 'bagging_fraction': 0.9473292652090407, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,271] Trial 33 finished with value: 0.7132867132867133 and parameters: {'num_leaves': 122, 'learning_rate': 0.2739902035198736, 'feature_fraction': 0.6848119131352172, 'bagging_fraction': 0.8560782663042387, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,306] Trial 34 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 175, 'learning_rate': 0.2407776283451074, 'feature_fraction': 0.6143901884763089, 'bagging_fraction': 0.9013448380449693, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,331] Trial 35 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 147, 'learning_rate': 0.29086427622490657, 'feature_fraction': 0.7283417600265916, 'bagging_fraction': 0.9529314504771322, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,345] Trial 36 finished with value: 0.4143356643356643 and parameters: {'num_leaves': 33, 'learning_rate': 0.21603548091459154, 'feature_fraction': 0.770200962629373, 'bagging_fraction': 0.9059612096466595, 'bagging_freq': 1, 'min_child_samples': 63}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,386] Trial 37 finished with value: 0.8531468531468532 and parameters: {'num_leaves': 106, 'learning_rate': 0.26157547142584725, 'feature_fraction': 0.6641125913035103, 'bagging_fraction': 0.5925069714530219, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,419] Trial 38 finished with value: 0.8706293706293706 and parameters: {'num_leaves': 91, 'learning_rate': 0.1852157579591239, 'feature_fraction': 0.7854970443886635, 'bagging_fraction': 0.8209318789114399, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,452] Trial 39 finished with value: 0.8636363636363635 and parameters: {'num_leaves': 128, 'learning_rate': 0.299919845187905, 'feature_fraction': 0.7104509317222927, 'bagging_fraction': 0.9665760334636126, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,518] Trial 40 finished with value: 0.846153846153846 and parameters: {'num_leaves': 16, 'learning_rate': 0.22442851905952066, 'feature_fraction': 0.8668866966398113, 'bagging_fraction': 0.8746818227408028, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,555] Trial 41 finished with value: 0.895104895104895 and parameters: {'num_leaves': 110, 'learning_rate': 0.2523200791615688, 'feature_fraction': 0.6646363021273628, 'bagging_fraction': 0.9146868778495113, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,585] Trial 42 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 62, 'learning_rate': 0.2443240472360984, 'feature_fraction': 0.685661369036445, 'bagging_fraction': 0.9217941890614129, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,623] Trial 43 finished with value: 0.8321678321678322 and parameters: {'num_leaves': 111, 'learning_rate': 0.27214288089801025, 'feature_fraction': 0.6083201999847427, 'bagging_fraction': 0.8823349831397821, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,669] Trial 44 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 140, 'learning_rate': 0.2529950885532408, 'feature_fraction': 0.6541828656192699, 'bagging_fraction': 0.9650748260036098, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,700] Trial 45 finished with value: 0.8601398601398602 and parameters: {'num_leaves': 85, 'learning_rate': 0.20871569773472734, 'feature_fraction': 0.5509121788116603, 'bagging_fraction': 0.9293462658027127, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,722] Trial 46 finished with value: 0.8146853146853147 and parameters: {'num_leaves': 191, 'learning_rate': 0.2855015600449833, 'feature_fraction': 0.7133533916443525, 'bagging_fraction': 0.7771035899229369, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,735] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 129, 'learning_rate': 0.2740452306276409, 'feature_fraction': 0.604994557638747, 'bagging_fraction': 0.8536947049377085, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,766] Trial 48 finished with value: 0.8986013986013986 and parameters: {'num_leaves': 66, 'learning_rate': 0.1929580925187368, 'feature_fraction': 0.7784443441993187, 'bagging_fraction': 0.8190715533489814, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:29,815] Trial 49 finished with value: 0.8601398601398602 and parameters: {'num_leaves': 73, 'learning_rate': 0.1912424844784524, 'feature_fraction': 0.8202407005918625, 'bagging_fraction': 0.8251254622661677, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 31 with value: 0.9335664335664335.
[I 2025-09-17 13:18:30,062] A new study created in memory with name: no-name-7aca1c79-23d5-4fe1-8cbc-8cc71c0ab057
[I 2025-09-17 13:18:30,077] Trial 0 finished with value: 0.8041958041958043 and parameters: {'num_leaves': 257, 'learning_rate': 0.27245643788673846, 'feature_fraction': 0.9218073651943401, 'bagging_fraction': 0.6801068847775513, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 0 with value: 0.8041958041958043.
[I 2025-09-17 13:18:30,084] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 191, 'learning_rate': 0.2428377210964694, 'feature_fraction': 0.7743264349071655, 'bagging_fraction': 0.9273820459353522, 'bagging_freq': 7, 'min_child_samples': 87}. Best is trial 0 with value: 0.8041958041958043.
[I 2025-09-17 13:18:30,092] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 121, 'learning_rate': 0.12418493109139775, 'feature_fraction': 0.6622495533901475, 'bagging_fraction': 0.6833959885657378, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 0 with value: 0.8041958041958043.
[I 2025-09-17 13:18:30,234] Trial 3 finished with value: 0.9090909090909092 and parameters: {'num_leaves': 63, 'learning_rate': 0.14540419617161854, 'feature_fraction': 0.4550177497292, 'bagging_fraction': 0.9329430455411314, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,243] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 20, 'learning_rate': 0.1254740091800037, 'feature_fraction': 0.9649378324646409, 'bagging_fraction': 0.6056285766730395, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,247] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 99, 'learning_rate': 0.18902189527398774, 'feature_fraction': 0.8574968917950038, 'bagging_fraction': 0.9972088310215975, 'bagging_freq': 7, 'min_child_samples': 96}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,255] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 64, 'learning_rate': 0.1909802406446819, 'feature_fraction': 0.443708690439528, 'bagging_fraction': 0.5788185438580019, 'bagging_freq': 4, 'min_child_samples': 58}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,284] Trial 7 finished with value: 0.8111888111888113 and parameters: {'num_leaves': 215, 'learning_rate': 0.07908759892359503, 'feature_fraction': 0.4867900949483623, 'bagging_fraction': 0.9114918816820824, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,303] Trial 8 finished with value: 0.7552447552447552 and parameters: {'num_leaves': 140, 'learning_rate': 0.08867298467871049, 'feature_fraction': 0.6512608562534761, 'bagging_fraction': 0.7157662436384105, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,319] Trial 9 finished with value: 0.6608391608391608 and parameters: {'num_leaves': 226, 'learning_rate': 0.1840143162883964, 'feature_fraction': 0.9810271964081235, 'bagging_fraction': 0.9041381526272936, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,417] Trial 10 finished with value: 0.8916083916083917 and parameters: {'num_leaves': 14, 'learning_rate': 0.02220115419293603, 'feature_fraction': 0.5558402180642468, 'bagging_fraction': 0.4245207616168651, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,536] Trial 11 finished with value: 0.881118881118881 and parameters: {'num_leaves': 10, 'learning_rate': 0.010847145957906538, 'feature_fraction': 0.5668592448321041, 'bagging_fraction': 0.41651557863806743, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,615] Trial 12 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 62, 'learning_rate': 0.01600137921412767, 'feature_fraction': 0.5310737087366757, 'bagging_fraction': 0.4022453656217092, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,678] Trial 13 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 54, 'learning_rate': 0.056996090149008166, 'feature_fraction': 0.42618090265415415, 'bagging_fraction': 0.8034227489184866, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,707] Trial 14 finished with value: 0.8566433566433567 and parameters: {'num_leaves': 88, 'learning_rate': 0.23760033632519856, 'feature_fraction': 0.5737237881277373, 'bagging_fraction': 0.5079268265891388, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,768] Trial 15 finished with value: 0.8916083916083916 and parameters: {'num_leaves': 39, 'learning_rate': 0.1397324348685623, 'feature_fraction': 0.7289845926550794, 'bagging_fraction': 0.7930599730932051, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,793] Trial 16 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 300, 'learning_rate': 0.043510793653294494, 'feature_fraction': 0.6194908646247183, 'bagging_fraction': 0.4911588807271453, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,820] Trial 17 finished with value: 0.8146853146853148 and parameters: {'num_leaves': 168, 'learning_rate': 0.1029153258688992, 'feature_fraction': 0.40537751740506583, 'bagging_fraction': 0.8003568471738328, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,860] Trial 18 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 87, 'learning_rate': 0.16575596942935739, 'feature_fraction': 0.49499128431394895, 'bagging_fraction': 0.5928688932515055, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:30,878] Trial 19 finished with value: 0.6258741258741258 and parameters: {'num_leaves': 34, 'learning_rate': 0.29870126359518745, 'feature_fraction': 0.595063143067702, 'bagging_fraction': 0.9805271248361698, 'bagging_freq': 5, 'min_child_samples': 69}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,027] Trial 20 finished with value: 0.9090909090909092 and parameters: {'num_leaves': 126, 'learning_rate': 0.2201303646036702, 'feature_fraction': 0.4981751555861554, 'bagging_fraction': 0.8482300681130619, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,161] Trial 21 finished with value: 0.895104895104895 and parameters: {'num_leaves': 117, 'learning_rate': 0.2299614958740024, 'feature_fraction': 0.48157594453410174, 'bagging_fraction': 0.8557101358395247, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,192] Trial 22 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 124, 'learning_rate': 0.23372840766646907, 'feature_fraction': 0.47811347599423065, 'bagging_fraction': 0.8584313848862005, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,258] Trial 23 finished with value: 0.9090909090909092 and parameters: {'num_leaves': 169, 'learning_rate': 0.2193276208769, 'feature_fraction': 0.5173605311793709, 'bagging_fraction': 0.8574509236144366, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,313] Trial 24 finished with value: 0.881118881118881 and parameters: {'num_leaves': 165, 'learning_rate': 0.21266473826162374, 'feature_fraction': 0.5288780569130908, 'bagging_fraction': 0.7454803951836808, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,347] Trial 25 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 190, 'learning_rate': 0.1579001544066934, 'feature_fraction': 0.4023804949087371, 'bagging_fraction': 0.8705903393773821, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,418] Trial 26 finished with value: 0.9055944055944056 and parameters: {'num_leaves': 146, 'learning_rate': 0.2572047473879205, 'feature_fraction': 0.7213813032975619, 'bagging_fraction': 0.9479546883709583, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,443] Trial 27 finished with value: 0.846153846153846 and parameters: {'num_leaves': 188, 'learning_rate': 0.2068892779873861, 'feature_fraction': 0.5172246910989247, 'bagging_fraction': 0.8293978024959864, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,466] Trial 28 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 100, 'learning_rate': 0.172091132688613, 'feature_fraction': 0.45461566434080763, 'bagging_fraction': 0.7588120464293995, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,491] Trial 29 finished with value: 0.8286713286713286 and parameters: {'num_leaves': 242, 'learning_rate': 0.2824048400316603, 'feature_fraction': 0.8202633753538132, 'bagging_fraction': 0.9563063818766149, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,527] Trial 30 finished with value: 0.8006993006993006 and parameters: {'num_leaves': 76, 'learning_rate': 0.2679262963205952, 'feature_fraction': 0.6600780316075479, 'bagging_fraction': 0.8807434541260013, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,588] Trial 31 finished with value: 0.9020979020979021 and parameters: {'num_leaves': 145, 'learning_rate': 0.259482135934168, 'feature_fraction': 0.6952609487409765, 'bagging_fraction': 0.9498242733039802, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 3 with value: 0.9090909090909092.
[I 2025-09-17 13:18:31,647] Trial 32 finished with value: 0.9265734265734266 and parameters: {'num_leaves': 170, 'learning_rate': 0.21095738762806404, 'feature_fraction': 0.7874852259211604, 'bagging_fraction': 0.9371594282280427, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:31,698] Trial 33 finished with value: 0.8811188811188811 and parameters: {'num_leaves': 172, 'learning_rate': 0.21659082558595655, 'feature_fraction': 0.8064848730436198, 'bagging_fraction': 0.896165780926168, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 32 with value: 0.9265734265734266.
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.445515
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.539221
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.513739
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.409399
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.412585
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.353256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.444347
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.602586
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.480337
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.515135
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.669098
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.519801
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.445988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.437815
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.47126
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.43147
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.470733
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.5062
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.492921
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.458901
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.536584
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.407362
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.432672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.523087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.379303
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.508647
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.56404
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.601407
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.443092
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.502019
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.504955
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.456521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.494976
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.405784
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.546185
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.515218
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.517462
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.640963
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.387925
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.416678
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.498102
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.374622
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.454048
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.491072
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.375633
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.456462
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.553442
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.513021
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.490206
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.370433
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.346838
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.450568
[I 2025-09-17 13:18:31,782] Trial 34 finished with value: 0.9125874125874126 and parameters: {'num_leaves': 125, 'learning_rate': 0.1379804574543375, 'feature_fraction': 0.8797960647812326, 'bagging_fraction': 0.9275793832145253, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:31,814] Trial 35 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 122, 'learning_rate': 0.13518001211870342, 'feature_fraction': 0.8822173399418652, 'bagging_fraction': 0.9272025888654538, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:31,858] Trial 36 finished with value: 0.8391608391608392 and parameters: {'num_leaves': 206, 'learning_rate': 0.14339901202645425, 'feature_fraction': 0.91959353555527, 'bagging_fraction': 0.9799543211006001, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:31,873] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 112, 'learning_rate': 0.1151810421053395, 'feature_fraction': 0.7782354444153149, 'bagging_fraction': 0.926018375999524, 'bagging_freq': 4, 'min_child_samples': 81}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:31,929] Trial 38 finished with value: 0.8391608391608392 and parameters: {'num_leaves': 132, 'learning_rate': 0.19363923509380576, 'feature_fraction': 0.8724903221528492, 'bagging_fraction': 0.6530167540655295, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:31,953] Trial 39 finished with value: 0.8041958041958042 and parameters: {'num_leaves': 103, 'learning_rate': 0.15069030759315882, 'feature_fraction': 0.920819530524326, 'bagging_fraction': 0.9997114606328681, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:31,982] Trial 40 finished with value: 0.8076923076923076 and parameters: {'num_leaves': 156, 'learning_rate': 0.17636442544055098, 'feature_fraction': 0.8327986940847638, 'bagging_fraction': 0.8285895308013332, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,054] Trial 41 finished with value: 0.8986013986013985 and parameters: {'num_leaves': 181, 'learning_rate': 0.1983618676010558, 'feature_fraction': 0.7663993934929982, 'bagging_fraction': 0.9049755092264051, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,188] Trial 42 finished with value: 0.8636363636363635 and parameters: {'num_leaves': 203, 'learning_rate': 0.24913342627328106, 'feature_fraction': 0.4475285807679092, 'bagging_fraction': 0.8438250628174075, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,202] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 156, 'learning_rate': 0.22406985699186988, 'feature_fraction': 0.9609868321885193, 'bagging_fraction': 0.9596099039361933, 'bagging_freq': 3, 'min_child_samples': 99}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,280] Trial 44 finished with value: 0.8776223776223775 and parameters: {'num_leaves': 130, 'learning_rate': 0.11989064809766456, 'feature_fraction': 0.6261709948473991, 'bagging_fraction': 0.886647478880127, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,386] Trial 45 finished with value: 0.9020979020979021 and parameters: {'num_leaves': 236, 'learning_rate': 0.10320005175350927, 'feature_fraction': 0.8485844973668151, 'bagging_fraction': 0.9341726732148028, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,415] Trial 46 finished with value: 0.7744755244755246 and parameters: {'num_leaves': 78, 'learning_rate': 0.18039233127237048, 'feature_fraction': 0.7875023508943985, 'bagging_fraction': 0.7764736474901234, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,482] Trial 47 finished with value: 0.916083916083916 and parameters: {'num_leaves': 273, 'learning_rate': 0.1609041521205363, 'feature_fraction': 0.8895281055774057, 'bagging_fraction': 0.6630557133878934, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,618] Trial 48 finished with value: 0.9090909090909092 and parameters: {'num_leaves': 277, 'learning_rate': 0.1300684758630257, 'feature_fraction': 0.898931974179231, 'bagging_fraction': 0.6518236957244211, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,656] Trial 49 finished with value: 0.7972027972027973 and parameters: {'num_leaves': 36, 'learning_rate': 0.16052197880122204, 'feature_fraction': 0.9489901552995116, 'bagging_fraction': 0.6931577928775918, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 32 with value: 0.9265734265734266.
[I 2025-09-17 13:18:32,908] A new study created in memory with name: no-name-457176ad-4b27-498b-90bb-76cd49aee6f8
[I 2025-09-17 13:18:32,917] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 56, 'learning_rate': 0.21415419954880863, 'feature_fraction': 0.6540660843488133, 'bagging_fraction': 0.9070897510188207, 'bagging_freq': 5, 'min_child_samples': 86}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:32,928] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 136, 'learning_rate': 0.029094067500715283, 'feature_fraction': 0.757145326388673, 'bagging_fraction': 0.9508535586321571, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:32,936] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 82, 'learning_rate': 0.2895320220691941, 'feature_fraction': 0.8134362118695558, 'bagging_fraction': 0.4270983519576248, 'bagging_freq': 5, 'min_child_samples': 69}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:32,957] Trial 3 finished with value: 0.7272727272727273 and parameters: {'num_leaves': 218, 'learning_rate': 0.04535492817594294, 'feature_fraction': 0.7530830792103761, 'bagging_fraction': 0.6308671686250367, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 3 with value: 0.7272727272727273.
[I 2025-09-17 13:18:32,977] Trial 4 finished with value: 0.7377622377622378 and parameters: {'num_leaves': 113, 'learning_rate': 0.07516570686978721, 'feature_fraction': 0.9979593426319566, 'bagging_fraction': 0.7241524685327372, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 4 with value: 0.7377622377622378.
[I 2025-09-17 13:18:32,986] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 140, 'learning_rate': 0.12291739285954614, 'feature_fraction': 0.9557791200719242, 'bagging_fraction': 0.9433913599948636, 'bagging_freq': 2, 'min_child_samples': 90}. Best is trial 4 with value: 0.7377622377622378.
[I 2025-09-17 13:18:33,013] Trial 6 finished with value: 0.6660839160839161 and parameters: {'num_leaves': 198, 'learning_rate': 0.2364297604729039, 'feature_fraction': 0.6207456481706062, 'bagging_fraction': 0.7083580225550796, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 4 with value: 0.7377622377622378.
[I 2025-09-17 13:18:33,038] Trial 7 finished with value: 0.7272727272727273 and parameters: {'num_leaves': 72, 'learning_rate': 0.030206411290851755, 'feature_fraction': 0.5926610820028556, 'bagging_fraction': 0.6305098463325768, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 4 with value: 0.7377622377622378.
[I 2025-09-17 13:18:33,058] Trial 8 finished with value: 0.7482517482517483 and parameters: {'num_leaves': 287, 'learning_rate': 0.10244839522558295, 'feature_fraction': 0.9169506869670182, 'bagging_fraction': 0.5787845427435565, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 8 with value: 0.7482517482517483.
[I 2025-09-17 13:18:33,067] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 76, 'learning_rate': 0.09147188515140413, 'feature_fraction': 0.893325933698756, 'bagging_fraction': 0.8932457132538498, 'bagging_freq': 3, 'min_child_samples': 80}. Best is trial 8 with value: 0.7482517482517483.
[I 2025-09-17 13:18:33,078] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 297, 'learning_rate': 0.1688098720371216, 'feature_fraction': 0.4117576690352488, 'bagging_fraction': 0.4474288312184901, 'bagging_freq': 1, 'min_child_samples': 59}. Best is trial 8 with value: 0.7482517482517483.
[I 2025-09-17 13:18:33,100] Trial 11 finished with value: 0.7867132867132867 and parameters: {'num_leaves': 281, 'learning_rate': 0.09412811528925426, 'feature_fraction': 0.9861453021968789, 'bagging_fraction': 0.7640906140251431, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 11 with value: 0.7867132867132867.
[I 2025-09-17 13:18:33,178] Trial 12 finished with value: 0.7657342657342657 and parameters: {'num_leaves': 286, 'learning_rate': 0.13810505250708413, 'feature_fraction': 0.8804676689409033, 'bagging_fraction': 0.7979110330487895, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 11 with value: 0.7867132867132867.
[I 2025-09-17 13:18:33,224] Trial 13 finished with value: 0.736013986013986 and parameters: {'num_leaves': 240, 'learning_rate': 0.1553094597995167, 'feature_fraction': 0.8542131065774639, 'bagging_fraction': 0.783133492437571, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 11 with value: 0.7867132867132867.
[I 2025-09-17 13:18:33,297] Trial 14 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 255, 'learning_rate': 0.18913753456507326, 'feature_fraction': 0.9850967699379548, 'bagging_fraction': 0.82232519425072, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 14 with value: 0.7902097902097902.
[I 2025-09-17 13:18:33,319] Trial 15 finished with value: 0.7657342657342657 and parameters: {'num_leaves': 255, 'learning_rate': 0.19415182835026162, 'feature_fraction': 0.9918433733230052, 'bagging_fraction': 0.8301336512067168, 'bagging_freq': 6, 'min_child_samples': 55}. Best is trial 14 with value: 0.7902097902097902.
[I 2025-09-17 13:18:33,344] Trial 16 finished with value: 0.7237762237762237 and parameters: {'num_leaves': 188, 'learning_rate': 0.2715831278665839, 'feature_fraction': 0.5109117614418458, 'bagging_fraction': 0.8441981014745126, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 14 with value: 0.7902097902097902.
[I 2025-09-17 13:18:33,419] Trial 17 finished with value: 0.81993006993007 and parameters: {'num_leaves': 16, 'learning_rate': 0.17807302405702807, 'feature_fraction': 0.8006558516820773, 'bagging_fraction': 0.7477374527818993, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 17 with value: 0.81993006993007.
[I 2025-09-17 13:18:33,487] Trial 18 finished with value: 0.6748251748251749 and parameters: {'num_leaves': 15, 'learning_rate': 0.24086359886104594, 'feature_fraction': 0.7938813535707391, 'bagging_fraction': 0.5253294888261412, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 17 with value: 0.81993006993007.
[I 2025-09-17 13:18:33,533] Trial 19 finished with value: 0.7657342657342658 and parameters: {'num_leaves': 13, 'learning_rate': 0.196265669548974, 'feature_fraction': 0.7024188800074673, 'bagging_fraction': 0.648705522583133, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 17 with value: 0.81993006993007.
[I 2025-09-17 13:18:33,571] Trial 20 finished with value: 0.6853146853146854 and parameters: {'num_leaves': 173, 'learning_rate': 0.1704930639397426, 'feature_fraction': 0.8364487922202188, 'bagging_fraction': 0.8620477829884081, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 17 with value: 0.81993006993007.
[I 2025-09-17 13:18:33,672] Trial 21 finished with value: 0.8426573426573426 and parameters: {'num_leaves': 244, 'learning_rate': 0.13481040096020247, 'feature_fraction': 0.9353257032357545, 'bagging_fraction': 0.7432791740758711, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 21 with value: 0.8426573426573426.
[I 2025-09-17 13:18:33,780] Trial 22 finished with value: 0.8601398601398601 and parameters: {'num_leaves': 244, 'learning_rate': 0.1902460024564131, 'feature_fraction': 0.9259775454063857, 'bagging_fraction': 0.7410814555381329, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:33,805] Trial 23 finished with value: 0.7342657342657342 and parameters: {'num_leaves': 235, 'learning_rate': 0.1396620472469202, 'feature_fraction': 0.9215435315864652, 'bagging_fraction': 0.7400991872689913, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:33,843] Trial 24 finished with value: 0.6923076923076923 and parameters: {'num_leaves': 216, 'learning_rate': 0.225736576260853, 'feature_fraction': 0.9259319558773682, 'bagging_fraction': 0.6813911817408252, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:33,929] Trial 25 finished with value: 0.8391608391608392 and parameters: {'num_leaves': 172, 'learning_rate': 0.26159487560853356, 'feature_fraction': 0.7437696834528956, 'bagging_fraction': 0.68090407182423, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:33,974] Trial 26 finished with value: 0.7447552447552448 and parameters: {'num_leaves': 159, 'learning_rate': 0.26354371043109237, 'feature_fraction': 0.7352470272049871, 'bagging_fraction': 0.5696604633091369, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,002] Trial 27 finished with value: 0.8146853146853148 and parameters: {'num_leaves': 262, 'learning_rate': 0.26142805852435425, 'feature_fraction': 0.5718780426083787, 'bagging_fraction': 0.6803501044807632, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,030] Trial 28 finished with value: 0.7797202797202798 and parameters: {'num_leaves': 210, 'learning_rate': 0.2917805433033377, 'feature_fraction': 0.686028784485245, 'bagging_fraction': 0.5688334962900741, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,043] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.20560149184035578, 'feature_fraction': 0.8739875630156071, 'bagging_fraction': 0.5002306453641668, 'bagging_freq': 5, 'min_child_samples': 71}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,069] Trial 30 finished with value: 0.6608391608391608 and parameters: {'num_leaves': 227, 'learning_rate': 0.21446882689328717, 'feature_fraction': 0.44293087048786217, 'bagging_fraction': 0.6703069751706968, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,169] Trial 31 finished with value: 0.8548951048951048 and parameters: {'num_leaves': 96, 'learning_rate': 0.1795571270408829, 'feature_fraction': 0.7827479215927955, 'bagging_fraction': 0.7486994271056788, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,219] Trial 32 finished with value: 0.7342657342657343 and parameters: {'num_leaves': 112, 'learning_rate': 0.12037039302812944, 'feature_fraction': 0.6532195389018446, 'bagging_fraction': 0.7111510223969439, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,232] Trial 33 finished with value: 0.5 and parameters: {'num_leaves': 111, 'learning_rate': 0.15196690936835267, 'feature_fraction': 0.7694368223257716, 'bagging_fraction': 0.7783819800681748, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,310] Trial 34 finished with value: 0.7832167832167833 and parameters: {'num_leaves': 51, 'learning_rate': 0.24128117154771947, 'feature_fraction': 0.8232425122861133, 'bagging_fraction': 0.609225873283568, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,382] Trial 35 finished with value: 0.7482517482517483 and parameters: {'num_leaves': 136, 'learning_rate': 0.07621972971621524, 'feature_fraction': 0.7133312632234774, 'bagging_fraction': 0.8043208055481164, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,418] Trial 36 finished with value: 0.7027972027972028 and parameters: {'num_leaves': 161, 'learning_rate': 0.1184960550886326, 'feature_fraction': 0.7724744412375651, 'bagging_fraction': 0.7375731684755714, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,482] Trial 37 finished with value: 0.7762237762237763 and parameters: {'num_leaves': 93, 'learning_rate': 0.21562479712583343, 'feature_fraction': 0.9524178110307484, 'bagging_fraction': 0.9693995549816279, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,505] Trial 38 finished with value: 0.6800699300699301 and parameters: {'num_leaves': 135, 'learning_rate': 0.2789307693581781, 'feature_fraction': 0.6719822304435403, 'bagging_fraction': 0.8989470664119004, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,537] Trial 39 finished with value: 0.7132867132867133 and parameters: {'num_leaves': 45, 'learning_rate': 0.1551771654669938, 'feature_fraction': 0.7382507662858437, 'bagging_fraction': 0.6932538119273854, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,563] Trial 40 finished with value: 0.7797202797202798 and parameters: {'num_leaves': 203, 'learning_rate': 0.1798712777533784, 'feature_fraction': 0.8509389480434861, 'bagging_fraction': 0.6214455391667437, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,674] Trial 41 finished with value: 0.8374125874125875 and parameters: {'num_leaves': 92, 'learning_rate': 0.17422696852168368, 'feature_fraction': 0.8002134824329271, 'bagging_fraction': 0.748165349431976, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,762] Trial 42 finished with value: 0.7849650349650349 and parameters: {'num_leaves': 123, 'learning_rate': 0.13848031848468056, 'feature_fraction': 0.8034218392232771, 'bagging_fraction': 0.6530730074095412, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 22 with value: 0.8601398601398601.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.391078
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.506344
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.448551
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.451219
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.514766
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.491669
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.388093
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.454588
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.399492
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.390573
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.52426
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.379723
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.367737
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.515014
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.601026
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.555186
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.61161
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.574206
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.582333
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.55073
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.568794
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.574582
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.536709
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.552663
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.585151
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.512764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.616877
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.601511
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.610076
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.489786
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.488607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.556131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.616107
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.476679
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.601092
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.530885
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.537984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.617869
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.48472
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.594429
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.539633
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.577268
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.596934
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.540805
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.609997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.600707
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.52593
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.476619
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.537035
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:34,808] Trial 43 finished with value: 0.7412587412587412 and parameters: {'num_leaves': 94, 'learning_rate': 0.1670864242901641, 'feature_fraction': 0.9447042029568286, 'bagging_fraction': 0.7176800619310277, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,858] Trial 44 finished with value: 0.7657342657342657 and parameters: {'num_leaves': 63, 'learning_rate': 0.10782568417639342, 'feature_fraction': 0.8875074775810807, 'bagging_fraction': 0.7617439144045898, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,929] Trial 45 finished with value: 0.7342657342657343 and parameters: {'num_leaves': 267, 'learning_rate': 0.049150615555915225, 'feature_fraction': 0.7772834750945212, 'bagging_fraction': 0.8664910789312332, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,983] Trial 46 finished with value: 0.7797202797202797 and parameters: {'num_leaves': 31, 'learning_rate': 0.20456894114530058, 'feature_fraction': 0.6301783732453989, 'bagging_fraction': 0.7143333128147463, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:34,995] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 88, 'learning_rate': 0.25244742797358344, 'feature_fraction': 0.7384199080094407, 'bagging_fraction': 0.7828787103966285, 'bagging_freq': 1, 'min_child_samples': 63}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:35,016] Trial 48 finished with value: 0.7482517482517482 and parameters: {'num_leaves': 101, 'learning_rate': 0.2304818791804934, 'feature_fraction': 0.9034536893361522, 'bagging_fraction': 0.7472078093271906, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:35,028] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 74, 'learning_rate': 0.01046917861261265, 'feature_fraction': 0.866571882038601, 'bagging_fraction': 0.8083354203090208, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 22 with value: 0.8601398601398601.
[I 2025-09-17 13:18:35,378] A new study created in memory with name: no-name-98884e7a-f869-48c5-b978-fa522c48581a
[I 2025-09-17 13:18:35,418] Trial 0 finished with value: 0.8496503496503497 and parameters: {'num_leaves': 50, 'learning_rate': 0.06365844563199646, 'feature_fraction': 0.7439232822274155, 'bagging_fraction': 0.43198816442069343, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,470] Trial 1 finished with value: 0.7972027972027972 and parameters: {'num_leaves': 35, 'learning_rate': 0.03732928796576468, 'feature_fraction': 0.982504207396433, 'bagging_fraction': 0.569944636723447, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,486] Trial 2 finished with value: 0.5227272727272727 and parameters: {'num_leaves': 45, 'learning_rate': 0.1630830651511941, 'feature_fraction': 0.49684658810152166, 'bagging_fraction': 0.9870180804616047, 'bagging_freq': 7, 'min_child_samples': 70}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,495] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 27, 'learning_rate': 0.201373915447428, 'feature_fraction': 0.937629825209186, 'bagging_fraction': 0.7407218492983167, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,516] Trial 4 finished with value: 0.7762237762237763 and parameters: {'num_leaves': 138, 'learning_rate': 0.09515394817270195, 'feature_fraction': 0.8324553862187544, 'bagging_fraction': 0.9976380205829393, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,539] Trial 5 finished with value: 0.7272727272727273 and parameters: {'num_leaves': 249, 'learning_rate': 0.22072289263696046, 'feature_fraction': 0.42955550563839096, 'bagging_fraction': 0.7397445357210953, 'bagging_freq': 7, 'min_child_samples': 51}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,550] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 143, 'learning_rate': 0.029842062364555687, 'feature_fraction': 0.5106814431999759, 'bagging_fraction': 0.4011535812397284, 'bagging_freq': 2, 'min_child_samples': 60}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,562] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 133, 'learning_rate': 0.20324764941855827, 'feature_fraction': 0.8385758412419334, 'bagging_fraction': 0.8986932106663459, 'bagging_freq': 4, 'min_child_samples': 86}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,606] Trial 8 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 129, 'learning_rate': 0.014073266165533418, 'feature_fraction': 0.4060880502496689, 'bagging_fraction': 0.7214906839785156, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,694] Trial 9 finished with value: 0.8216783216783217 and parameters: {'num_leaves': 146, 'learning_rate': 0.0269655754271547, 'feature_fraction': 0.7996217555082041, 'bagging_fraction': 0.6975961079930575, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,711] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.29621156867333187, 'feature_fraction': 0.6712142691508658, 'bagging_fraction': 0.40550472533104887, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,741] Trial 11 finished with value: 0.7727272727272728 and parameters: {'num_leaves': 84, 'learning_rate': 0.08357551818427936, 'feature_fraction': 0.6436258189188119, 'bagging_fraction': 0.5770492859916567, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,769] Trial 12 finished with value: 0.8006993006993007 and parameters: {'num_leaves': 84, 'learning_rate': 0.0987982623305891, 'feature_fraction': 0.5924394797372677, 'bagging_fraction': 0.6040247389281861, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 0 with value: 0.8496503496503497.
[I 2025-09-17 13:18:35,877] Trial 13 finished with value: 0.8776223776223776 and parameters: {'num_leaves': 200, 'learning_rate': 0.06820679741890974, 'feature_fraction': 0.7700200345339479, 'bagging_fraction': 0.8387244220656291, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:35,965] Trial 14 finished with value: 0.8426573426573427 and parameters: {'num_leaves': 198, 'learning_rate': 0.13699437990461358, 'feature_fraction': 0.7403084865934066, 'bagging_fraction': 0.8581005921099735, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:35,984] Trial 15 finished with value: 0.4807692307692307 and parameters: {'num_leaves': 200, 'learning_rate': 0.07057046676950283, 'feature_fraction': 0.7528827078233686, 'bagging_fraction': 0.4906894028380203, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,122] Trial 16 finished with value: 0.8496503496503497 and parameters: {'num_leaves': 300, 'learning_rate': 0.1317320876311411, 'feature_fraction': 0.9152457645677775, 'bagging_fraction': 0.8377980976809559, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,165] Trial 17 finished with value: 0.8111888111888113 and parameters: {'num_leaves': 92, 'learning_rate': 0.05997638973422361, 'feature_fraction': 0.5975829045788463, 'bagging_fraction': 0.6378623445415899, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,176] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.12412054775955096, 'feature_fraction': 0.721537618374034, 'bagging_fraction': 0.8103583503369207, 'bagging_freq': 4, 'min_child_samples': 97}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,201] Trial 19 finished with value: 0.826923076923077 and parameters: {'num_leaves': 174, 'learning_rate': 0.16438012207121638, 'feature_fraction': 0.7958276086708787, 'bagging_fraction': 0.9106604666408876, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,248] Trial 20 finished with value: 0.8006993006993007 and parameters: {'num_leaves': 284, 'learning_rate': 0.057332038633679534, 'feature_fraction': 0.9153547507022135, 'bagging_fraction': 0.499909334396051, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,356] Trial 21 finished with value: 0.8391608391608393 and parameters: {'num_leaves': 294, 'learning_rate': 0.11987973212247366, 'feature_fraction': 0.8907541960104619, 'bagging_fraction': 0.8137843201412179, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,449] Trial 22 finished with value: 0.8111888111888111 and parameters: {'num_leaves': 234, 'learning_rate': 0.10484771045394749, 'feature_fraction': 0.8631010913437932, 'bagging_fraction': 0.7967269697524948, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,489] Trial 23 finished with value: 0.8741258741258742 and parameters: {'num_leaves': 275, 'learning_rate': 0.14995111390778804, 'feature_fraction': 0.9992926794979075, 'bagging_fraction': 0.8912319444155258, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 13 with value: 0.8776223776223776.
[I 2025-09-17 13:18:36,529] Trial 24 finished with value: 0.9055944055944056 and parameters: {'num_leaves': 268, 'learning_rate': 0.28364857849655456, 'feature_fraction': 0.9987087475779561, 'bagging_fraction': 0.9281003313915035, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,551] Trial 25 finished with value: 0.8006993006993007 and parameters: {'num_leaves': 256, 'learning_rate': 0.28643245062824935, 'feature_fraction': 0.9934321623631509, 'bagging_fraction': 0.941885804518695, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,577] Trial 26 finished with value: 0.8146853146853148 and parameters: {'num_leaves': 260, 'learning_rate': 0.2726952643826722, 'feature_fraction': 0.9649114124445054, 'bagging_fraction': 0.9484712974868725, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,616] Trial 27 finished with value: 0.8566433566433567 and parameters: {'num_leaves': 276, 'learning_rate': 0.2493653631299062, 'feature_fraction': 0.9636699486154532, 'bagging_fraction': 0.8838815284486018, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,642] Trial 28 finished with value: 0.8111888111888113 and parameters: {'num_leaves': 223, 'learning_rate': 0.18393308525994062, 'feature_fraction': 0.8789860846144892, 'bagging_fraction': 0.9228171117095523, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,682] Trial 29 finished with value: 0.8111888111888113 and parameters: {'num_leaves': 171, 'learning_rate': 0.2305751037296257, 'feature_fraction': 0.9984725392412702, 'bagging_fraction': 0.7844630044680594, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,705] Trial 30 finished with value: 0.7797202797202798 and parameters: {'num_leaves': 272, 'learning_rate': 0.2565713585339854, 'feature_fraction': 0.7748838012967451, 'bagging_fraction': 0.863727415048516, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,744] Trial 31 finished with value: 0.8671328671328671 and parameters: {'num_leaves': 262, 'learning_rate': 0.25077006230655524, 'feature_fraction': 0.9563886109237032, 'bagging_fraction': 0.8800822353230887, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,790] Trial 32 finished with value: 0.8129370629370628 and parameters: {'num_leaves': 246, 'learning_rate': 0.2648136282684803, 'feature_fraction': 0.9391975967675517, 'bagging_fraction': 0.9537153435939817, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,836] Trial 33 finished with value: 0.8898601398601399 and parameters: {'num_leaves': 215, 'learning_rate': 0.2270801151741006, 'feature_fraction': 0.9493289036057453, 'bagging_fraction': 0.9741387917229114, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,887] Trial 34 finished with value: 0.8811188811188813 and parameters: {'num_leaves': 224, 'learning_rate': 0.1806299936552178, 'feature_fraction': 0.912600043851073, 'bagging_fraction': 0.9746283095711419, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,945] Trial 35 finished with value: 0.8181818181818182 and parameters: {'num_leaves': 208, 'learning_rate': 0.1832115620987041, 'feature_fraction': 0.9090609181821382, 'bagging_fraction': 0.9717409375583346, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:36,963] Trial 36 finished with value: 0.6206293706293706 and parameters: {'num_leaves': 171, 'learning_rate': 0.23644521915043923, 'feature_fraction': 0.8440988693745289, 'bagging_fraction': 0.9999822706991852, 'bagging_freq': 1, 'min_child_samples': 65}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,015] Trial 37 finished with value: 0.8356643356643357 and parameters: {'num_leaves': 213, 'learning_rate': 0.20022604597002144, 'feature_fraction': 0.9334081754243818, 'bagging_fraction': 0.9729299954727909, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,040] Trial 38 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 184, 'learning_rate': 0.21198583318669126, 'feature_fraction': 0.8730986973655611, 'bagging_fraction': 0.9320453445902719, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,076] Trial 39 finished with value: 0.7762237762237763 and parameters: {'num_leaves': 239, 'learning_rate': 0.189916199483756, 'feature_fraction': 0.82057811192635, 'bagging_fraction': 0.7676692164767785, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,086] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 220, 'learning_rate': 0.16431603674949527, 'feature_fraction': 0.961287896095618, 'bagging_fraction': 0.8409602252552835, 'bagging_freq': 1, 'min_child_samples': 74}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,140] Trial 41 finished with value: 0.8496503496503497 and parameters: {'num_leaves': 273, 'learning_rate': 0.14783028967401216, 'feature_fraction': 0.9898987892636554, 'bagging_fraction': 0.9029555333276772, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,174] Trial 42 finished with value: 0.8846153846153846 and parameters: {'num_leaves': 247, 'learning_rate': 0.22501699960177196, 'feature_fraction': 0.9363565918204775, 'bagging_fraction': 0.9721975942286143, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,241] Trial 43 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 242, 'learning_rate': 0.22453108844979525, 'feature_fraction': 0.9025678871783909, 'bagging_fraction': 0.969131037338609, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,274] Trial 44 finished with value: 0.8776223776223776 and parameters: {'num_leaves': 187, 'learning_rate': 0.2806772044590027, 'feature_fraction': 0.9375086305531697, 'bagging_fraction': 0.9931751727735918, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,304] Trial 45 finished with value: 0.8461538461538461 and parameters: {'num_leaves': 158, 'learning_rate': 0.23575917651192863, 'feature_fraction': 0.6822487944108404, 'bagging_fraction': 0.9264914034413712, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,372] Trial 46 finished with value: 0.8129370629370629 and parameters: {'num_leaves': 228, 'learning_rate': 0.21411163380516096, 'feature_fraction': 0.8466385590342852, 'bagging_fraction': 0.9617578520116944, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,426] Trial 47 finished with value: 0.7657342657342657 and parameters: {'num_leaves': 255, 'learning_rate': 0.17407435219623438, 'feature_fraction': 0.5220724629484317, 'bagging_fraction': 0.9294230957583124, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,437] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 211, 'learning_rate': 0.202652318519604, 'feature_fraction': 0.8111417059909637, 'bagging_fraction': 0.684964585896536, 'bagging_freq': 1, 'min_child_samples': 55}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,476] Trial 49 finished with value: 0.8041958041958043 and parameters: {'num_leaves': 121, 'learning_rate': 0.2416761332867605, 'feature_fraction': 0.9387259214100886, 'bagging_fraction': 0.8609229387502945, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 24 with value: 0.9055944055944056.
[I 2025-09-17 13:18:37,712] A new study created in memory with name: no-name-4aacea17-3848-437e-ada1-141fa7c7d34f
[I 2025-09-17 13:18:37,746] Trial 0 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 118, 'learning_rate': 0.05764605750803401, 'feature_fraction': 0.4971869136845604, 'bagging_fraction': 0.8250807081224878, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 0 with value: 0.8076923076923077.
[I 2025-09-17 13:18:37,756] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 249, 'learning_rate': 0.05059841538177407, 'feature_fraction': 0.5288089939529745, 'bagging_fraction': 0.4399490586493176, 'bagging_freq': 1, 'min_child_samples': 78}. Best is trial 0 with value: 0.8076923076923077.
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.58566
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.568514
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.549388
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.529198
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.565147
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.659919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.460976
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.519331
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.654056
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.547705
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.569269
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.557792
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.49019
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.561399
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.514423
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.50205
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.509526
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.656712
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.467907
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.51121
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.510049
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.504392
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.48667
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.486915
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.438213
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.397547
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.541698
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.529527
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.451885
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.50597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.522226
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.524357
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.443742
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.515676
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.477808
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.52587
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.500397
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.643579
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.489204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.546986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.536204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.465939
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.463979
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.48683
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.463242
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.48334
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.534325
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.546603
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.516623
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.523087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:37,764] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.13998853078733547, 'feature_fraction': 0.6066774511150785, 'bagging_fraction': 0.7298006599891158, 'bagging_freq': 7, 'min_child_samples': 77}. Best is trial 0 with value: 0.8076923076923077.
[I 2025-09-17 13:18:37,794] Trial 3 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 294, 'learning_rate': 0.1021373370514613, 'feature_fraction': 0.6148592286969718, 'bagging_fraction': 0.8585217327709089, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 3 with value: 0.8181818181818181.
[I 2025-09-17 13:18:37,804] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 273, 'learning_rate': 0.09422472315768113, 'feature_fraction': 0.839333648363278, 'bagging_fraction': 0.9178644734014061, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 3 with value: 0.8181818181818181.
[I 2025-09-17 13:18:37,843] Trial 5 finished with value: 0.7395104895104896 and parameters: {'num_leaves': 51, 'learning_rate': 0.16633689822487063, 'feature_fraction': 0.9681350224032261, 'bagging_fraction': 0.8870126950678339, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 3 with value: 0.8181818181818181.
[I 2025-09-17 13:18:37,866] Trial 6 finished with value: 0.7937062937062938 and parameters: {'num_leaves': 21, 'learning_rate': 0.09715898635002057, 'feature_fraction': 0.662183863652648, 'bagging_fraction': 0.8418358565722067, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 3 with value: 0.8181818181818181.
[I 2025-09-17 13:18:37,885] Trial 7 finished with value: 0.5174825174825175 and parameters: {'num_leaves': 243, 'learning_rate': 0.018937870481557942, 'feature_fraction': 0.42929948673390744, 'bagging_fraction': 0.9559187190653141, 'bagging_freq': 7, 'min_child_samples': 69}. Best is trial 3 with value: 0.8181818181818181.
[I 2025-09-17 13:18:37,894] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 30, 'learning_rate': 0.2122482768903473, 'feature_fraction': 0.6868559766320579, 'bagging_fraction': 0.6947110006862635, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 3 with value: 0.8181818181818181.
[I 2025-09-17 13:18:37,902] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 107, 'learning_rate': 0.1146048966730568, 'feature_fraction': 0.8358555893976853, 'bagging_fraction': 0.48632370222705396, 'bagging_freq': 1, 'min_child_samples': 55}. Best is trial 3 with value: 0.8181818181818181.
[I 2025-09-17 13:18:37,924] Trial 10 finished with value: 0.8391608391608392 and parameters: {'num_leaves': 184, 'learning_rate': 0.29417900520037166, 'feature_fraction': 0.7709335770420869, 'bagging_fraction': 0.6403473001289955, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 10 with value: 0.8391608391608392.
[I 2025-09-17 13:18:37,955] Trial 11 finished with value: 0.8181818181818182 and parameters: {'num_leaves': 199, 'learning_rate': 0.29964241447606954, 'feature_fraction': 0.7945074811857339, 'bagging_fraction': 0.6228807379989602, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 10 with value: 0.8391608391608392.
[I 2025-09-17 13:18:37,980] Trial 12 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 201, 'learning_rate': 0.2889847061554331, 'feature_fraction': 0.7945008162554444, 'bagging_fraction': 0.6115498410205673, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 10 with value: 0.8391608391608392.
[I 2025-09-17 13:18:38,001] Trial 13 finished with value: 0.7832167832167831 and parameters: {'num_leaves': 179, 'learning_rate': 0.2999817040694617, 'feature_fraction': 0.7561708013698002, 'bagging_fraction': 0.5545051961038073, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 10 with value: 0.8391608391608392.
[I 2025-09-17 13:18:38,014] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.2450286512140334, 'feature_fraction': 0.9307668249156711, 'bagging_fraction': 0.6179099149943608, 'bagging_freq': 5, 'min_child_samples': 95}. Best is trial 10 with value: 0.8391608391608392.
[I 2025-09-17 13:18:38,037] Trial 15 finished with value: 0.7972027972027972 and parameters: {'num_leaves': 151, 'learning_rate': 0.2515197684957135, 'feature_fraction': 0.9115960246717421, 'bagging_fraction': 0.7425361523526535, 'bagging_freq': 5, 'min_child_samples': 49}. Best is trial 10 with value: 0.8391608391608392.
[I 2025-09-17 13:18:38,059] Trial 16 finished with value: 0.8566433566433567 and parameters: {'num_leaves': 149, 'learning_rate': 0.25849249069216895, 'feature_fraction': 0.7406647026482641, 'bagging_fraction': 0.5464374874086588, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,092] Trial 17 finished with value: 0.8531468531468531 and parameters: {'num_leaves': 139, 'learning_rate': 0.19803896364671814, 'feature_fraction': 0.7304756881010265, 'bagging_fraction': 0.532312044970768, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,141] Trial 18 finished with value: 0.7972027972027972 and parameters: {'num_leaves': 143, 'learning_rate': 0.1892034431651953, 'feature_fraction': 0.7229295122099162, 'bagging_fraction': 0.5211280775664202, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,194] Trial 19 finished with value: 0.7832167832167832 and parameters: {'num_leaves': 74, 'learning_rate': 0.2310439720162975, 'feature_fraction': 0.6021418148854891, 'bagging_fraction': 0.40258524476553464, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,220] Trial 20 finished with value: 0.7937062937062936 and parameters: {'num_leaves': 119, 'learning_rate': 0.19778552605565308, 'feature_fraction': 0.8721126054709443, 'bagging_fraction': 0.5587551025786983, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,243] Trial 21 finished with value: 0.8059440559440559 and parameters: {'num_leaves': 172, 'learning_rate': 0.26735870421790014, 'feature_fraction': 0.7400441289825856, 'bagging_fraction': 0.6499104434675615, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,275] Trial 22 finished with value: 0.7902097902097902 and parameters: {'num_leaves': 149, 'learning_rate': 0.26685312147436097, 'feature_fraction': 0.647896151945943, 'bagging_fraction': 0.5152941060317967, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,290] Trial 23 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.2234282969424029, 'feature_fraction': 0.7728296321847316, 'bagging_fraction': 0.5724876726820021, 'bagging_freq': 2, 'min_child_samples': 56}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,315] Trial 24 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 177, 'learning_rate': 0.270462150564572, 'feature_fraction': 0.6947845308476904, 'bagging_fraction': 0.6697840435851327, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,350] Trial 25 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 134, 'learning_rate': 0.2446604390280439, 'feature_fraction': 0.8161672451305111, 'bagging_fraction': 0.7714520412804455, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,396] Trial 26 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 93, 'learning_rate': 0.17197895772789512, 'feature_fraction': 0.8707895428696806, 'bagging_fraction': 0.4693133206404887, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,422] Trial 27 finished with value: 0.7447552447552447 and parameters: {'num_leaves': 174, 'learning_rate': 0.2064112519301938, 'feature_fraction': 0.5593480757255198, 'bagging_fraction': 0.5897017177949783, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,437] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 213, 'learning_rate': 0.2756041829676208, 'feature_fraction': 0.7310463223593948, 'bagging_fraction': 0.5328294558553345, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,466] Trial 29 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 120, 'learning_rate': 0.1427794436343156, 'feature_fraction': 0.45091866535087555, 'bagging_fraction': 0.7863226486081022, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,489] Trial 30 finished with value: 0.7727272727272727 and parameters: {'num_leaves': 163, 'learning_rate': 0.22951110007105702, 'feature_fraction': 0.6569825482259692, 'bagging_fraction': 0.4778503240367912, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,511] Trial 31 finished with value: 0.8304195804195804 and parameters: {'num_leaves': 208, 'learning_rate': 0.2884240165095242, 'feature_fraction': 0.7834827261103567, 'bagging_fraction': 0.6299631171915941, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,536] Trial 32 finished with value: 0.7657342657342657 and parameters: {'num_leaves': 190, 'learning_rate': 0.28279727528869625, 'feature_fraction': 0.77132790200579, 'bagging_fraction': 0.6511460612189871, 'bagging_freq': 6, 'min_child_samples': 46}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,563] Trial 33 finished with value: 0.8024475524475525 and parameters: {'num_leaves': 225, 'learning_rate': 0.25903476028648514, 'feature_fraction': 0.7034882475717528, 'bagging_fraction': 0.6907924866360471, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,600] Trial 34 finished with value: 0.7972027972027973 and parameters: {'num_leaves': 133, 'learning_rate': 0.18454749591385014, 'feature_fraction': 0.8596604716579873, 'bagging_fraction': 0.4420995346041184, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,614] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.28363716270554634, 'feature_fraction': 0.7719431212473042, 'bagging_fraction': 0.7290321171667336, 'bagging_freq': 7, 'min_child_samples': 59}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,636] Trial 36 finished with value: 0.8479020979020979 and parameters: {'num_leaves': 160, 'learning_rate': 0.2401416146461594, 'feature_fraction': 0.8042971546361752, 'bagging_fraction': 0.6098604785913511, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,693] Trial 37 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 86, 'learning_rate': 0.23577803501474262, 'feature_fraction': 0.896922474392799, 'bagging_fraction': 0.5983545603933439, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,709] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 159, 'learning_rate': 0.20966494248179757, 'feature_fraction': 0.8307660533075653, 'bagging_fraction': 0.5430913070186282, 'bagging_freq': 1, 'min_child_samples': 61}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,742] Trial 39 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 127, 'learning_rate': 0.16040114625965937, 'feature_fraction': 0.9588894001121127, 'bagging_fraction': 0.49570775705234615, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,770] Trial 40 finished with value: 0.8111888111888111 and parameters: {'num_leaves': 108, 'learning_rate': 0.2206617062366802, 'feature_fraction': 0.606192807639255, 'bagging_fraction': 0.5768873545035813, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 16 with value: 0.8566433566433567.
[I 2025-09-17 13:18:38,790] Trial 41 finished with value: 0.8636363636363636 and parameters: {'num_leaves': 186, 'learning_rate': 0.2524416797840659, 'feature_fraction': 0.7945158147703952, 'bagging_fraction': 0.6682744778567321, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:38,816] Trial 42 finished with value: 0.8251748251748252 and parameters: {'num_leaves': 188, 'learning_rate': 0.26046811831233346, 'feature_fraction': 0.8117230869405384, 'bagging_fraction': 0.6755690144371812, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:38,839] Trial 43 finished with value: 0.7412587412587412 and parameters: {'num_leaves': 154, 'learning_rate': 0.24712288984155661, 'feature_fraction': 0.7200646559130185, 'bagging_fraction': 0.6448635282133129, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:38,874] Trial 44 finished with value: 0.8076923076923077 and parameters: {'num_leaves': 292, 'learning_rate': 0.06059404789367005, 'feature_fraction': 0.6773551494673449, 'bagging_fraction': 0.9999024869109993, 'bagging_freq': 7, 'min_child_samples': 31}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:38,905] Trial 45 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 189, 'learning_rate': 0.2553198660075943, 'feature_fraction': 0.6363027034567431, 'bagging_fraction': 0.7224681937375358, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:38,921] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 139, 'learning_rate': 0.23801766224744725, 'feature_fraction': 0.7445668170926253, 'bagging_fraction': 0.5883673521527872, 'bagging_freq': 3, 'min_child_samples': 85}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:38,945] Trial 47 finished with value: 0.7657342657342657 and parameters: {'num_leaves': 162, 'learning_rate': 0.1796519745916042, 'feature_fraction': 0.840169100296308, 'bagging_fraction': 0.5022179681142941, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:38,969] Trial 48 finished with value: 0.8391608391608392 and parameters: {'num_leaves': 228, 'learning_rate': 0.21438657879549516, 'feature_fraction': 0.8006103927638187, 'bagging_fraction': 0.7054591670246609, 'bagging_freq': 1, 'min_child_samples': 43}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:38,982] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 109, 'learning_rate': 0.1979177775068605, 'feature_fraction': 0.7560032009406037, 'bagging_fraction': 0.6154709646498332, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 41 with value: 0.8636363636363636.
[I 2025-09-17 13:18:39,177] A new study created in memory with name: no-name-8346b28c-6fab-4cf6-b268-15576a16b02f
[I 2025-09-17 13:18:39,188] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 49, 'learning_rate': 0.16578502483434804, 'feature_fraction': 0.8500058426697221, 'bagging_fraction': 0.7190796424962742, 'bagging_freq': 3, 'min_child_samples': 95}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:39,196] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 83, 'learning_rate': 0.15540943282315714, 'feature_fraction': 0.5808394271303865, 'bagging_fraction': 0.5304297190575794, 'bagging_freq': 2, 'min_child_samples': 70}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:39,217] Trial 2 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 277, 'learning_rate': 0.036716057595444745, 'feature_fraction': 0.940410393014644, 'bagging_fraction': 0.59416905040662, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 2 with value: 0.7103174603174603.
[I 2025-09-17 13:18:39,227] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 157, 'learning_rate': 0.1936967023738291, 'feature_fraction': 0.508109811524637, 'bagging_fraction': 0.8402712781190995, 'bagging_freq': 7, 'min_child_samples': 77}. Best is trial 2 with value: 0.7103174603174603.
[I 2025-09-17 13:18:39,251] Trial 4 finished with value: 0.7757936507936508 and parameters: {'num_leaves': 114, 'learning_rate': 0.2707396020173882, 'feature_fraction': 0.5912660331960081, 'bagging_fraction': 0.7931196210819391, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 4 with value: 0.7757936507936508.
[I 2025-09-17 13:18:39,272] Trial 5 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 121, 'learning_rate': 0.010752749677971997, 'feature_fraction': 0.7931513636593015, 'bagging_fraction': 0.6039324601294479, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 4 with value: 0.7757936507936508.
[I 2025-09-17 13:18:39,307] Trial 6 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 112, 'learning_rate': 0.17154657566021558, 'feature_fraction': 0.9905000324282879, 'bagging_fraction': 0.8152998744999522, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 6 with value: 0.8174603174603174.
[I 2025-09-17 13:18:39,383] Trial 7 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 149, 'learning_rate': 0.17874895398652224, 'feature_fraction': 0.995913857711708, 'bagging_fraction': 0.7363492963533802, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 7 with value: 0.8650793650793651.
[I 2025-09-17 13:18:39,403] Trial 8 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 293, 'learning_rate': 0.24069476862929873, 'feature_fraction': 0.7470494975278756, 'bagging_fraction': 0.6731030001142653, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 7 with value: 0.8650793650793651.
[I 2025-09-17 13:18:39,453] Trial 9 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 133, 'learning_rate': 0.10472717845028534, 'feature_fraction': 0.537607192226544, 'bagging_fraction': 0.7967703096099299, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 7 with value: 0.8650793650793651.
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.515671
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.576643
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.53609
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.659696
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.486226
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.520421
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.482435
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.543898
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.542416
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.487192
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.518936
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.531499
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.5461
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.553882
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.55089
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.543645
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.500009
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.499892
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.537455
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.548004
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.529802
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.546271
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.492907
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.556158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.507931
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.550249
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.507253
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.51565
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.528328
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.526714
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.472831
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.50532
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.580904
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.542681
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.51178
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.660144
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.554622
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.511579
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.660144
Training model for P052... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.591438
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.528614
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.607101
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.468537
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.460164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.514881
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.501053
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:39,682] Trial 10 finished with value: 0.9444444444444444 and parameters: {'num_leaves': 201, 'learning_rate': 0.09728041828960327, 'feature_fraction': 0.4198159911530382, 'bagging_fraction': 0.9346961347481972, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:39,766] Trial 11 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 206, 'learning_rate': 0.08017910699361522, 'feature_fraction': 0.400740688463099, 'bagging_fraction': 0.9809972871915236, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,001] Trial 12 finished with value: 0.9325396825396826 and parameters: {'num_leaves': 222, 'learning_rate': 0.09350080486104205, 'feature_fraction': 0.4156304677016084, 'bagging_fraction': 0.9995093013509818, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,024] Trial 13 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 217, 'learning_rate': 0.10106862596447018, 'feature_fraction': 0.4001816608900184, 'bagging_fraction': 0.9949824860972181, 'bagging_freq': 1, 'min_child_samples': 47}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,213] Trial 14 finished with value: 0.9325396825396826 and parameters: {'num_leaves': 223, 'learning_rate': 0.07014709910305846, 'feature_fraction': 0.46999649244022, 'bagging_fraction': 0.9135380946035605, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,239] Trial 15 finished with value: 0.7698412698412698 and parameters: {'num_leaves': 252, 'learning_rate': 0.12084105321406509, 'feature_fraction': 0.6232902311542962, 'bagging_fraction': 0.9018728917632689, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,271] Trial 16 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 178, 'learning_rate': 0.05301548403043552, 'feature_fraction': 0.6693728216238494, 'bagging_fraction': 0.9141990157114124, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,284] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 252, 'learning_rate': 0.12469228658100508, 'feature_fraction': 0.4559287081861611, 'bagging_fraction': 0.44508009298843043, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,356] Trial 18 finished with value: 0.876984126984127 and parameters: {'num_leaves': 11, 'learning_rate': 0.21001904764055968, 'feature_fraction': 0.4787785800527222, 'bagging_fraction': 0.9973554474644135, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,369] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 186, 'learning_rate': 0.1370500406412987, 'feature_fraction': 0.6674576085831412, 'bagging_fraction': 0.8805256672559669, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,466] Trial 20 finished with value: 0.9246031746031746 and parameters: {'num_leaves': 245, 'learning_rate': 0.2993396605455977, 'feature_fraction': 0.5524671963661086, 'bagging_fraction': 0.9439720081746821, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,617] Trial 21 finished with value: 0.9246031746031746 and parameters: {'num_leaves': 225, 'learning_rate': 0.07806231943631006, 'feature_fraction': 0.4481850190902457, 'bagging_fraction': 0.8610235757123195, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,802] Trial 22 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 190, 'learning_rate': 0.06545388731955457, 'feature_fraction': 0.44200755509540784, 'bagging_fraction': 0.939511796486781, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,866] Trial 23 finished with value: 0.7896825396825398 and parameters: {'num_leaves': 234, 'learning_rate': 0.025777700001370793, 'feature_fraction': 0.5021555122898687, 'bagging_fraction': 0.9429306649425284, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,904] Trial 24 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 270, 'learning_rate': 0.09566446360356853, 'feature_fraction': 0.40329684769523727, 'bagging_fraction': 0.8858138933124946, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:40,964] Trial 25 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 204, 'learning_rate': 0.049687357427312014, 'feature_fraction': 0.5185612356884989, 'bagging_fraction': 0.7543145505295278, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,148] Trial 26 finished with value: 0.9365079365079365 and parameters: {'num_leaves': 170, 'learning_rate': 0.13779999452021635, 'feature_fraction': 0.46766606291567825, 'bagging_fraction': 0.9543315618554997, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,171] Trial 27 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 178, 'learning_rate': 0.1348878343608979, 'feature_fraction': 0.6256857043716979, 'bagging_fraction': 0.9724460684582927, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,231] Trial 28 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 157, 'learning_rate': 0.11613465885978888, 'feature_fraction': 0.44878992362140574, 'bagging_fraction': 0.8420054234291316, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,243] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 64, 'learning_rate': 0.14847712050076933, 'feature_fraction': 0.8817298674654241, 'bagging_fraction': 0.7031402099207925, 'bagging_freq': 3, 'min_child_samples': 99}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,305] Trial 30 finished with value: 0.9365079365079364 and parameters: {'num_leaves': 166, 'learning_rate': 0.2141023964788531, 'feature_fraction': 0.7371475335348554, 'bagging_fraction': 0.9562543707639606, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,356] Trial 31 finished with value: 0.896825396825397 and parameters: {'num_leaves': 166, 'learning_rate': 0.21457330825466528, 'feature_fraction': 0.7522641259130527, 'bagging_fraction': 0.9529474491568294, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,419] Trial 32 finished with value: 0.9047619047619047 and parameters: {'num_leaves': 202, 'learning_rate': 0.15891366651280933, 'feature_fraction': 0.847142935196465, 'bagging_fraction': 0.9978818006646466, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,548] Trial 33 finished with value: 0.9404761904761905 and parameters: {'num_leaves': 137, 'learning_rate': 0.23123830511129853, 'feature_fraction': 0.7363892239497906, 'bagging_fraction': 0.9271856214838589, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,622] Trial 34 finished with value: 0.8888888888888888 and parameters: {'num_leaves': 93, 'learning_rate': 0.2418069281417732, 'feature_fraction': 0.7107163734594223, 'bagging_fraction': 0.9132881103212703, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,659] Trial 35 finished with value: 0.8253968253968254 and parameters: {'num_leaves': 143, 'learning_rate': 0.24238204022672652, 'feature_fraction': 0.8130310449203917, 'bagging_fraction': 0.8579420251080787, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,699] Trial 36 finished with value: 0.8373015873015874 and parameters: {'num_leaves': 166, 'learning_rate': 0.20572576403663506, 'feature_fraction': 0.7402290078815843, 'bagging_fraction': 0.6645278045008304, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,719] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 98, 'learning_rate': 0.2271473925324051, 'feature_fraction': 0.8042744437485086, 'bagging_fraction': 0.762490038428812, 'bagging_freq': 6, 'min_child_samples': 79}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,760] Trial 38 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 126, 'learning_rate': 0.18930799085515604, 'feature_fraction': 0.5837321318403959, 'bagging_fraction': 0.575547777156983, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,823] Trial 39 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 136, 'learning_rate': 0.1865473680930963, 'feature_fraction': 0.9121272947268013, 'bagging_fraction': 0.8202812551456952, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,853] Trial 40 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 113, 'learning_rate': 0.2629716179885144, 'feature_fraction': 0.684542968141955, 'bagging_fraction': 0.8793927588038004, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:41,970] Trial 41 finished with value: 0.8968253968253969 and parameters: {'num_leaves': 161, 'learning_rate': 0.26586223801386155, 'feature_fraction': 0.6401300909178143, 'bagging_fraction': 0.9637562257907667, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:42,055] Trial 42 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 202, 'learning_rate': 0.09010085228003994, 'feature_fraction': 0.7265549658587701, 'bagging_fraction': 0.9325427814118032, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:42,109] Trial 43 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 186, 'learning_rate': 0.15022703753412514, 'feature_fraction': 0.786690570793723, 'bagging_fraction': 0.9634897643567211, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:42,265] Trial 44 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 151, 'learning_rate': 0.1705658091746756, 'feature_fraction': 0.4325371243991743, 'bagging_fraction': 0.9199191640404295, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:42,319] Trial 45 finished with value: 0.9047619047619047 and parameters: {'num_leaves': 176, 'learning_rate': 0.1113964574060304, 'feature_fraction': 0.49002933777666324, 'bagging_fraction': 0.45037480694664656, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:42,355] Trial 46 finished with value: 0.8690476190476191 and parameters: {'num_leaves': 215, 'learning_rate': 0.2279047131932824, 'feature_fraction': 0.7644421877892225, 'bagging_fraction': 0.9739907245275471, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:42,464] Trial 47 finished with value: 0.9007936507936508 and parameters: {'num_leaves': 266, 'learning_rate': 0.13401476853724228, 'feature_fraction': 0.5563252271307084, 'bagging_fraction': 0.8993056812044631, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:42,505] Trial 48 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 235, 'learning_rate': 0.10295833762215163, 'feature_fraction': 0.8331378935964189, 'bagging_fraction': 0.7934261830481698, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:42,568] Trial 49 finished with value: 0.8968253968253969 and parameters: {'num_leaves': 193, 'learning_rate': 0.2948948885890481, 'feature_fraction': 0.4218271367565033, 'bagging_fraction': 0.996729631407842, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 10 with value: 0.9444444444444444.
[I 2025-09-17 13:18:43,269] A new study created in memory with name: no-name-7718dc38-8c43-4c64-aa94-937447a91cc5
[I 2025-09-17 13:18:43,279] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 68, 'learning_rate': 0.2622860143811783, 'feature_fraction': 0.5594908580701942, 'bagging_fraction': 0.8042149206394282, 'bagging_freq': 4, 'min_child_samples': 69}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:43,286] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 226, 'learning_rate': 0.21634294773397097, 'feature_fraction': 0.8138054265162438, 'bagging_fraction': 0.973148281748928, 'bagging_freq': 5, 'min_child_samples': 70}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:43,311] Trial 2 finished with value: 0.6706349206349206 and parameters: {'num_leaves': 171, 'learning_rate': 0.25191822005588266, 'feature_fraction': 0.4370723716381096, 'bagging_fraction': 0.7520443260354743, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 2 with value: 0.6706349206349206.
[I 2025-09-17 13:18:43,320] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 17, 'learning_rate': 0.21106680283205498, 'feature_fraction': 0.8878190191371508, 'bagging_fraction': 0.5379196397101116, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 2 with value: 0.6706349206349206.
[I 2025-09-17 13:18:43,332] Trial 4 finished with value: 0.6686507936507936 and parameters: {'num_leaves': 210, 'learning_rate': 0.2785393119870398, 'feature_fraction': 0.9212562781392426, 'bagging_fraction': 0.5581661127057761, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 2 with value: 0.6706349206349206.
[I 2025-09-17 13:18:43,340] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 216, 'learning_rate': 0.11204810079659783, 'feature_fraction': 0.6505442718468311, 'bagging_fraction': 0.5575101020422704, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 2 with value: 0.6706349206349206.
[I 2025-09-17 13:18:43,404] Trial 6 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 287, 'learning_rate': 0.12722987632481136, 'feature_fraction': 0.8525279220100813, 'bagging_fraction': 0.9319193620472661, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 6 with value: 0.8293650793650793.
[I 2025-09-17 13:18:43,420] Trial 7 finished with value: 0.634920634920635 and parameters: {'num_leaves': 213, 'learning_rate': 0.14641385914757357, 'feature_fraction': 0.9773684596860596, 'bagging_fraction': 0.8450920931816875, 'bagging_freq': 7, 'min_child_samples': 34}. Best is trial 6 with value: 0.8293650793650793.
[I 2025-09-17 13:18:43,442] Trial 8 finished with value: 0.5912698412698412 and parameters: {'num_leaves': 64, 'learning_rate': 0.036615786401136385, 'feature_fraction': 0.9987858703256878, 'bagging_fraction': 0.7053615197020764, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 6 with value: 0.8293650793650793.
[I 2025-09-17 13:18:43,450] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.17155780917565644, 'feature_fraction': 0.9631925075012248, 'bagging_fraction': 0.5792022518125617, 'bagging_freq': 4, 'min_child_samples': 85}. Best is trial 6 with value: 0.8293650793650793.
[I 2025-09-17 13:18:43,555] Trial 10 finished with value: 0.9007936507936507 and parameters: {'num_leaves': 296, 'learning_rate': 0.06428135856286948, 'feature_fraction': 0.7519198813124078, 'bagging_fraction': 0.9682942400486884, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 10 with value: 0.9007936507936507.
[I 2025-09-17 13:18:43,650] Trial 11 finished with value: 0.8888888888888888 and parameters: {'num_leaves': 299, 'learning_rate': 0.06396860525822777, 'feature_fraction': 0.7827238609141967, 'bagging_fraction': 0.9931705437548544, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 10 with value: 0.9007936507936507.
[I 2025-09-17 13:18:43,799] Trial 12 finished with value: 0.9007936507936508 and parameters: {'num_leaves': 291, 'learning_rate': 0.024071768775521633, 'feature_fraction': 0.7434868223737262, 'bagging_fraction': 0.9996559477216986, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:43,834] Trial 13 finished with value: 0.6468253968253969 and parameters: {'num_leaves': 168, 'learning_rate': 0.0759612314216156, 'feature_fraction': 0.7026722003842784, 'bagging_fraction': 0.42051054198931453, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,011] Trial 14 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 254, 'learning_rate': 0.024648630709251416, 'feature_fraction': 0.7173340332861893, 'bagging_fraction': 0.8753028322394608, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,026] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 136, 'learning_rate': 0.010464328000794979, 'feature_fraction': 0.6190752222864215, 'bagging_fraction': 0.8942897817464732, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,065] Trial 16 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 265, 'learning_rate': 0.08011025539547484, 'feature_fraction': 0.763182872943128, 'bagging_fraction': 0.9931628101010185, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,091] Trial 17 finished with value: 0.5873015873015873 and parameters: {'num_leaves': 111, 'learning_rate': 0.05127309450503051, 'feature_fraction': 0.5526015450683175, 'bagging_fraction': 0.809203079953497, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 12 with value: 0.9007936507936508.
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.329597
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.35664
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.355819
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.494223
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.356215
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.539979
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.508101
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.388899
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.327126
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.366415
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.387284
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.504647
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.487684
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.468791
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.326056
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.533099
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.502251
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.30409
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.38543
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.355531
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.333123
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.392662
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.442056
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.445313
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.493877
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.330249
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.50972
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.346566
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.312403
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.386322
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.348327
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.373998
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.394294
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.356096
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.434385
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.396986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.608115
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.61639
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.489169
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.629542
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.639163
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.453845
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.457094
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.446048
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.626506
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.469895
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.59392
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.640556
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:44,137] Trial 18 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 290, 'learning_rate': 0.08474057478540331, 'feature_fraction': 0.6437868617199002, 'bagging_fraction': 0.9263750894279437, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,165] Trial 19 finished with value: 0.5793650793650793 and parameters: {'num_leaves': 242, 'learning_rate': 0.1110345796838764, 'feature_fraction': 0.43068330680302697, 'bagging_fraction': 0.6577641564347141, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,182] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 193, 'learning_rate': 0.17200765365067017, 'feature_fraction': 0.7515004248106398, 'bagging_fraction': 0.7661836690295701, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,323] Trial 21 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 293, 'learning_rate': 0.05748238492109508, 'feature_fraction': 0.7980947004644865, 'bagging_fraction': 0.9997768507463081, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,381] Trial 22 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 271, 'learning_rate': 0.040162958870142706, 'feature_fraction': 0.8487718276081232, 'bagging_fraction': 0.9335597834544814, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,519] Trial 23 finished with value: 0.8968253968253969 and parameters: {'num_leaves': 297, 'learning_rate': 0.07019154479769842, 'feature_fraction': 0.7625803668831338, 'bagging_fraction': 0.9572475073585629, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,550] Trial 24 finished with value: 0.6428571428571428 and parameters: {'num_leaves': 244, 'learning_rate': 0.0945416449441169, 'feature_fraction': 0.7157765304784403, 'bagging_fraction': 0.8807090088288594, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,618] Trial 25 finished with value: 0.7063492063492063 and parameters: {'num_leaves': 277, 'learning_rate': 0.014092000731317644, 'feature_fraction': 0.6682933473367964, 'bagging_fraction': 0.9461460935054027, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,677] Trial 26 finished with value: 0.7063492063492064 and parameters: {'num_leaves': 240, 'learning_rate': 0.043431080761703364, 'feature_fraction': 0.5857547128657835, 'bagging_fraction': 0.8388226131492519, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,702] Trial 27 finished with value: 0.6249999999999999 and parameters: {'num_leaves': 271, 'learning_rate': 0.10790580042825443, 'feature_fraction': 0.4901521859833606, 'bagging_fraction': 0.8977757448867862, 'bagging_freq': 1, 'min_child_samples': 43}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,863] Trial 28 finished with value: 0.8888888888888888 and parameters: {'num_leaves': 190, 'learning_rate': 0.06247512934547347, 'feature_fraction': 0.8476707965173524, 'bagging_fraction': 0.9633036024726573, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,876] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.13429770460217885, 'feature_fraction': 0.7479633964127846, 'bagging_fraction': 0.7898747198394951, 'bagging_freq': 3, 'min_child_samples': 75}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,915] Trial 30 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 101, 'learning_rate': 0.03272696823639266, 'feature_fraction': 0.6727615462130582, 'bagging_fraction': 0.8575402293506139, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:44,990] Trial 31 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 300, 'learning_rate': 0.06472183972759095, 'feature_fraction': 0.7833730031109263, 'bagging_fraction': 0.9948774966866525, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,055] Trial 32 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 280, 'learning_rate': 0.09822718404050128, 'feature_fraction': 0.8215067901191726, 'bagging_fraction': 0.9469972227903211, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,106] Trial 33 finished with value: 0.7023809523809524 and parameters: {'num_leaves': 233, 'learning_rate': 0.06684573871939253, 'feature_fraction': 0.7421662067749496, 'bagging_fraction': 0.9689105858438064, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,220] Trial 34 finished with value: 0.8095238095238094 and parameters: {'num_leaves': 260, 'learning_rate': 0.025449746630425082, 'feature_fraction': 0.9141724962055228, 'bagging_fraction': 0.9061556904214996, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,258] Trial 35 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 282, 'learning_rate': 0.22398172495351737, 'feature_fraction': 0.8097082694923312, 'bagging_fraction': 0.9777119213221843, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,284] Trial 36 finished with value: 0.6369047619047619 and parameters: {'num_leaves': 34, 'learning_rate': 0.05515521795970825, 'feature_fraction': 0.8881513586242805, 'bagging_fraction': 0.7109072823949952, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,322] Trial 37 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 300, 'learning_rate': 0.2969954422830956, 'feature_fraction': 0.6889496449885798, 'bagging_fraction': 0.9140362062584871, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,344] Trial 38 finished with value: 0.5972222222222222 and parameters: {'num_leaves': 223, 'learning_rate': 0.0854158177401781, 'feature_fraction': 0.7878274019239638, 'bagging_fraction': 0.9541234597104356, 'bagging_freq': 3, 'min_child_samples': 58}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,433] Trial 39 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 252, 'learning_rate': 0.12788993058484346, 'feature_fraction': 0.7252108414059633, 'bagging_fraction': 0.6592794287990043, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,483] Trial 40 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 281, 'learning_rate': 0.17168452000897622, 'feature_fraction': 0.8776372578930377, 'bagging_fraction': 0.8223002204916415, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,569] Trial 41 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 197, 'learning_rate': 0.06868190960182735, 'feature_fraction': 0.8426828480544573, 'bagging_fraction': 0.9586572315079697, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 12 with value: 0.9007936507936508.
[I 2025-09-17 13:18:45,719] Trial 42 finished with value: 0.9047619047619048 and parameters: {'num_leaves': 146, 'learning_rate': 0.05246352944018275, 'feature_fraction': 0.8269204155165769, 'bagging_fraction': 0.9702453967463308, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 42 with value: 0.9047619047619048.
[I 2025-09-17 13:18:45,767] Trial 43 finished with value: 0.7063492063492064 and parameters: {'num_leaves': 145, 'learning_rate': 0.0458283672362825, 'feature_fraction': 0.7629688363099886, 'bagging_fraction': 0.9961232723135792, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 42 with value: 0.9047619047619048.
[I 2025-09-17 13:18:45,813] Trial 44 finished with value: 0.6547619047619048 and parameters: {'num_leaves': 167, 'learning_rate': 0.028501143138315595, 'feature_fraction': 0.8260965929795655, 'bagging_fraction': 0.9213639933519001, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 42 with value: 0.9047619047619048.
[I 2025-09-17 13:18:45,899] Trial 45 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 137, 'learning_rate': 0.01038279623111571, 'feature_fraction': 0.7818962135997256, 'bagging_fraction': 0.8727394321291561, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 42 with value: 0.9047619047619048.
[I 2025-09-17 13:18:45,923] Trial 46 finished with value: 0.621031746031746 and parameters: {'num_leaves': 105, 'learning_rate': 0.09308930813138283, 'feature_fraction': 0.8761088361398804, 'bagging_fraction': 0.40321415368880337, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 42 with value: 0.9047619047619048.
[I 2025-09-17 13:18:45,974] Trial 47 finished with value: 0.6825396825396824 and parameters: {'num_leaves': 120, 'learning_rate': 0.07371274143656835, 'feature_fraction': 0.925404170240261, 'bagging_fraction': 0.4791771836316463, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 42 with value: 0.9047619047619048.
[I 2025-09-17 13:18:46,017] Trial 48 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 86, 'learning_rate': 0.1561420613108478, 'feature_fraction': 0.6258031724088482, 'bagging_fraction': 0.9736840757080091, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 42 with value: 0.9047619047619048.
[I 2025-09-17 13:18:46,034] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 154, 'learning_rate': 0.02217094918424186, 'feature_fraction': 0.6865526037340816, 'bagging_fraction': 0.94216084097033, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 42 with value: 0.9047619047619048.
[I 2025-09-17 13:18:46,798] A new study created in memory with name: no-name-df663fc6-410b-4f06-81eb-08767c631d62
[I 2025-09-17 13:18:46,817] Trial 0 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 219, 'learning_rate': 0.20447306281310842, 'feature_fraction': 0.6813385437738828, 'bagging_fraction': 0.5193734460535374, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 0 with value: 0.8134920634920635.
[I 2025-09-17 13:18:46,832] Trial 1 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 148, 'learning_rate': 0.16871881580273734, 'feature_fraction': 0.7235003624382905, 'bagging_fraction': 0.5615492422128188, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 0 with value: 0.8134920634920635.
[I 2025-09-17 13:18:46,862] Trial 2 finished with value: 0.8194444444444444 and parameters: {'num_leaves': 107, 'learning_rate': 0.24678842629305683, 'feature_fraction': 0.6629857423051637, 'bagging_fraction': 0.8170019851109231, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 2 with value: 0.8194444444444444.
[I 2025-09-17 13:18:46,875] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 92, 'learning_rate': 0.2829201376568604, 'feature_fraction': 0.6021284737830933, 'bagging_fraction': 0.44780605954929587, 'bagging_freq': 4, 'min_child_samples': 67}. Best is trial 2 with value: 0.8194444444444444.
[I 2025-09-17 13:18:46,925] Trial 4 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 167, 'learning_rate': 0.24337296418230384, 'feature_fraction': 0.6870845336574468, 'bagging_fraction': 0.9861487465464255, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 4 with value: 0.8293650793650793.
[I 2025-09-17 13:18:46,937] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 68, 'learning_rate': 0.06964777650868478, 'feature_fraction': 0.7406464716348671, 'bagging_fraction': 0.4052867457008403, 'bagging_freq': 7, 'min_child_samples': 57}. Best is trial 4 with value: 0.8293650793650793.
[I 2025-09-17 13:18:46,949] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.19346308476867513, 'feature_fraction': 0.7716235563453835, 'bagging_fraction': 0.6973222067554702, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 4 with value: 0.8293650793650793.
[I 2025-09-17 13:18:46,960] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 280, 'learning_rate': 0.09569820320629341, 'feature_fraction': 0.5949035959777997, 'bagging_fraction': 0.6629191079653529, 'bagging_freq': 7, 'min_child_samples': 70}. Best is trial 4 with value: 0.8293650793650793.
[I 2025-09-17 13:18:46,967] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 298, 'learning_rate': 0.1896687547780433, 'feature_fraction': 0.8843807469305378, 'bagging_fraction': 0.8361796786326252, 'bagging_freq': 1, 'min_child_samples': 72}. Best is trial 4 with value: 0.8293650793650793.
[I 2025-09-17 13:18:47,001] Trial 9 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 60, 'learning_rate': 0.16036651845650934, 'feature_fraction': 0.5668579932372484, 'bagging_fraction': 0.4957162380043662, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 4 with value: 0.8293650793650793.
[I 2025-09-17 13:18:47,123] Trial 10 finished with value: 0.8531746031746033 and parameters: {'num_leaves': 194, 'learning_rate': 0.013392174850339222, 'feature_fraction': 0.4320120212084957, 'bagging_fraction': 0.9974671466979047, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 10 with value: 0.8531746031746033.
[I 2025-09-17 13:18:47,351] Trial 11 finished with value: 0.8809523809523809 and parameters: {'num_leaves': 201, 'learning_rate': 0.010737994995948318, 'feature_fraction': 0.4186366462410043, 'bagging_fraction': 0.9846441529601585, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 11 with value: 0.8809523809523809.
[I 2025-09-17 13:18:47,567] Trial 12 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 216, 'learning_rate': 0.013647444416164028, 'feature_fraction': 0.42553604618470325, 'bagging_fraction': 0.9967417937814983, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 12 with value: 0.8928571428571428.
[I 2025-09-17 13:18:47,598] Trial 13 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 226, 'learning_rate': 0.010335885305040872, 'feature_fraction': 0.40468749819314, 'bagging_fraction': 0.8860443159969834, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 12 with value: 0.8928571428571428.
[I 2025-09-17 13:18:47,706] Trial 14 finished with value: 0.9126984126984127 and parameters: {'num_leaves': 243, 'learning_rate': 0.07501277065771506, 'feature_fraction': 0.48397085251338257, 'bagging_fraction': 0.929514229443884, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:47,719] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 254, 'learning_rate': 0.08782442816665921, 'feature_fraction': 0.5122271334168272, 'bagging_fraction': 0.8996354252342009, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:47,753] Trial 16 finished with value: 0.7698412698412698 and parameters: {'num_leaves': 255, 'learning_rate': 0.05692458685880844, 'feature_fraction': 0.49916150950360705, 'bagging_fraction': 0.7793676581082243, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:47,780] Trial 17 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 148, 'learning_rate': 0.11823155167425246, 'feature_fraction': 0.49615133765462177, 'bagging_fraction': 0.9138497573199856, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:47,828] Trial 18 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 254, 'learning_rate': 0.05190499799462539, 'feature_fraction': 0.956365003185327, 'bagging_fraction': 0.7606674501495914, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:47,892] Trial 19 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 182, 'learning_rate': 0.13449913850168663, 'feature_fraction': 0.46751317198879466, 'bagging_fraction': 0.6239125751797809, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:48,078] Trial 20 finished with value: 0.8849206349206349 and parameters: {'num_leaves': 128, 'learning_rate': 0.04185943495668713, 'feature_fraction': 0.8123037496002017, 'bagging_fraction': 0.9434665732456817, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:48,234] Trial 21 finished with value: 0.8888888888888888 and parameters: {'num_leaves': 126, 'learning_rate': 0.04124166922834581, 'feature_fraction': 0.8309152012150895, 'bagging_fraction': 0.9397768911699144, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:48,284] Trial 22 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 26, 'learning_rate': 0.0373113510864915, 'feature_fraction': 0.8512285647000866, 'bagging_fraction': 0.8616908604268989, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 14 with value: 0.9126984126984127.
[I 2025-09-17 13:18:48,342] Trial 23 finished with value: 0.9166666666666667 and parameters: {'num_leaves': 233, 'learning_rate': 0.08410736957166398, 'feature_fraction': 0.9894525320318888, 'bagging_fraction': 0.951844592095536, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:48,390] Trial 24 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 239, 'learning_rate': 0.09879985999228731, 'feature_fraction': 0.9918677204278162, 'bagging_fraction': 0.9475014032840338, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:48,467] Trial 25 finished with value: 0.8293650793650794 and parameters: {'num_leaves': 211, 'learning_rate': 0.07593681076678879, 'feature_fraction': 0.5727565600488033, 'bagging_fraction': 0.766175523511388, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 23 with value: 0.9166666666666667.
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.601271
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.643986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.441381
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.521894
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.423557
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.624089
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.592859
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.592237
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.643277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.428845
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.612496
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.491319
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.506896
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.59819
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.519043
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.572951
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.624523
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.595838
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.64466
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.467877
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.535085
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.502439
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.413988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.591505
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.624939
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.540164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.623052
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.608182
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.583055
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.490265
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.533632
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.495572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.481312
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.510122
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.497688
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.486567
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.47066
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.595655
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.412476
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.530717
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.544838
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.511268
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.495862
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.432915
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.405477
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.502343
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.414601
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.501959
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.478668
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:48,496] Trial 26 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 270, 'learning_rate': 0.12234554292054853, 'feature_fraction': 0.9180713410271357, 'bagging_fraction': 0.8483091523299798, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:48,541] Trial 27 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 233, 'learning_rate': 0.11010102301914652, 'feature_fraction': 0.6374145138641039, 'bagging_fraction': 0.9453075273735996, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:48,566] Trial 28 finished with value: 0.7063492063492063 and parameters: {'num_leaves': 172, 'learning_rate': 0.07313759786095408, 'feature_fraction': 0.5437482698802428, 'bagging_fraction': 0.8912976338838665, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:48,615] Trial 29 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 209, 'learning_rate': 0.1485411458823555, 'feature_fraction': 0.4352614264931508, 'bagging_fraction': 0.8101039388555473, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:48,720] Trial 30 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 223, 'learning_rate': 0.03297908163616289, 'feature_fraction': 0.459983346830855, 'bagging_fraction': 0.9946513560114103, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:48,901] Trial 31 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 132, 'learning_rate': 0.02862782759866708, 'feature_fraction': 0.8061326590316747, 'bagging_fraction': 0.9351260182985307, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:48,999] Trial 32 finished with value: 0.8690476190476191 and parameters: {'num_leaves': 274, 'learning_rate': 0.053122081606088174, 'feature_fraction': 0.8880029797260524, 'bagging_fraction': 0.9594677434570485, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,040] Trial 33 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 185, 'learning_rate': 0.06848047787537323, 'feature_fraction': 0.9847666163236343, 'bagging_fraction': 0.873479356738222, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,098] Trial 34 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 111, 'learning_rate': 0.029627705458518633, 'feature_fraction': 0.7189034123506016, 'bagging_fraction': 0.919487080763491, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,212] Trial 35 finished with value: 0.9047619047619048 and parameters: {'num_leaves': 151, 'learning_rate': 0.08624633460336463, 'feature_fraction': 0.6469608233978769, 'bagging_fraction': 0.9666714072627107, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,268] Trial 36 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 165, 'learning_rate': 0.14613201972390563, 'feature_fraction': 0.6422217739488414, 'bagging_fraction': 0.9707681931860834, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,304] Trial 37 finished with value: 0.8412698412698414 and parameters: {'num_leaves': 243, 'learning_rate': 0.2336368026273063, 'feature_fraction': 0.5350080269087136, 'bagging_fraction': 0.5911395268342351, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,380] Trial 38 finished with value: 0.8214285714285715 and parameters: {'num_leaves': 156, 'learning_rate': 0.09342506854981131, 'feature_fraction': 0.7579528520418974, 'bagging_fraction': 0.7136668028224884, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,396] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 216, 'learning_rate': 0.13094397034316502, 'feature_fraction': 0.6926565908509408, 'bagging_fraction': 0.8237378800518584, 'bagging_freq': 6, 'min_child_samples': 63}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,430] Trial 40 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 286, 'learning_rate': 0.08592028722922734, 'feature_fraction': 0.6282600971125522, 'bagging_fraction': 0.998701819134748, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,648] Trial 41 finished with value: 0.876984126984127 and parameters: {'num_leaves': 88, 'learning_rate': 0.05375174298213293, 'feature_fraction': 0.7953047253468742, 'bagging_fraction': 0.9648847649481078, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,747] Trial 42 finished with value: 0.9007936507936509 and parameters: {'num_leaves': 120, 'learning_rate': 0.10595952071672644, 'feature_fraction': 0.8462185773148703, 'bagging_fraction': 0.925227267319546, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,827] Trial 43 finished with value: 0.9047619047619048 and parameters: {'num_leaves': 136, 'learning_rate': 0.10284812313636123, 'feature_fraction': 0.933790404460658, 'bagging_fraction': 0.9100718276710773, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,878] Trial 44 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 109, 'learning_rate': 0.1084237883393498, 'feature_fraction': 0.9447231201500895, 'bagging_fraction': 0.9128970453578094, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,924] Trial 45 finished with value: 0.8611111111111112 and parameters: {'num_leaves': 92, 'learning_rate': 0.10885210759927715, 'feature_fraction': 0.8975705597723774, 'bagging_fraction': 0.8748763535984189, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,937] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 139, 'learning_rate': 0.08264435268623782, 'feature_fraction': 0.8585954493135691, 'bagging_fraction': 0.8488227849969896, 'bagging_freq': 2, 'min_child_samples': 80}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:49,992] Trial 47 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 62, 'learning_rate': 0.1741173180067786, 'feature_fraction': 0.9469105585447677, 'bagging_fraction': 0.9147429664664846, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:50,025] Trial 48 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 81, 'learning_rate': 0.29451457342249077, 'feature_fraction': 0.9122243004718851, 'bagging_fraction': 0.8085069134801474, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:50,050] Trial 49 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 117, 'learning_rate': 0.06673195163049711, 'feature_fraction': 0.9777441931221948, 'bagging_fraction': 0.7260969333378297, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 23 with value: 0.9166666666666667.
[I 2025-09-17 13:18:50,500] A new study created in memory with name: no-name-495b0720-b82a-402b-8da4-ec846a71bae2
[I 2025-09-17 13:18:50,522] Trial 0 finished with value: 0.746031746031746 and parameters: {'num_leaves': 68, 'learning_rate': 0.14644813142583377, 'feature_fraction': 0.7088913218745404, 'bagging_fraction': 0.8525562409935463, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 0 with value: 0.746031746031746.
[I 2025-09-17 13:18:50,547] Trial 1 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 159, 'learning_rate': 0.2790730784618165, 'feature_fraction': 0.6989214931846193, 'bagging_fraction': 0.9519586178694656, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 1 with value: 0.7857142857142857.
[I 2025-09-17 13:18:50,555] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 128, 'learning_rate': 0.07251582315603637, 'feature_fraction': 0.9787498106477911, 'bagging_fraction': 0.907768725812975, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 1 with value: 0.7857142857142857.
[I 2025-09-17 13:18:50,567] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 263, 'learning_rate': 0.20701285399266434, 'feature_fraction': 0.9437336106746728, 'bagging_fraction': 0.4065231618480948, 'bagging_freq': 5, 'min_child_samples': 95}. Best is trial 1 with value: 0.7857142857142857.
[I 2025-09-17 13:18:50,572] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 19, 'learning_rate': 0.11820496625549862, 'feature_fraction': 0.6059243024030183, 'bagging_fraction': 0.9754450813538738, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 1 with value: 0.7857142857142857.
[I 2025-09-17 13:18:50,596] Trial 5 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 242, 'learning_rate': 0.048535481050770324, 'feature_fraction': 0.8338320250339848, 'bagging_fraction': 0.745160705406501, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 1 with value: 0.7857142857142857.
[I 2025-09-17 13:18:50,667] Trial 6 finished with value: 0.8849206349206349 and parameters: {'num_leaves': 265, 'learning_rate': 0.07276721872800902, 'feature_fraction': 0.9460121383238794, 'bagging_fraction': 0.7686440224125978, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 6 with value: 0.8849206349206349.
[I 2025-09-17 13:18:50,700] Trial 7 finished with value: 0.7559523809523808 and parameters: {'num_leaves': 154, 'learning_rate': 0.18476631288523196, 'feature_fraction': 0.7941506557951961, 'bagging_fraction': 0.9561917735647967, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 6 with value: 0.8849206349206349.
[I 2025-09-17 13:18:50,709] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.26624973602378793, 'feature_fraction': 0.874104392074382, 'bagging_fraction': 0.9191222773291773, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 6 with value: 0.8849206349206349.
[I 2025-09-17 13:18:50,722] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 143, 'learning_rate': 0.16207579492574395, 'feature_fraction': 0.6316013083195335, 'bagging_fraction': 0.8862355363382026, 'bagging_freq': 2, 'min_child_samples': 78}. Best is trial 6 with value: 0.8849206349206349.
[I 2025-09-17 13:18:50,826] Trial 10 finished with value: 0.8293650793650793 and parameters: {'num_leaves': 284, 'learning_rate': 0.015018391872722157, 'feature_fraction': 0.4622841850330426, 'bagging_fraction': 0.5547598003088801, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 6 with value: 0.8849206349206349.
[I 2025-09-17 13:18:50,942] Trial 11 finished with value: 0.8690476190476191 and parameters: {'num_leaves': 293, 'learning_rate': 0.019907979615221498, 'feature_fraction': 0.4168103140741494, 'bagging_fraction': 0.5419300516060102, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 6 with value: 0.8849206349206349.
[I 2025-09-17 13:18:51,092] Trial 12 finished with value: 0.8968253968253967 and parameters: {'num_leaves': 299, 'learning_rate': 0.07886450886751092, 'feature_fraction': 0.4604260049883775, 'bagging_fraction': 0.6497333539398641, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,140] Trial 13 finished with value: 0.7103174603174602 and parameters: {'num_leaves': 212, 'learning_rate': 0.09617840061534008, 'feature_fraction': 0.522136899083941, 'bagging_fraction': 0.7317418067790997, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,152] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 194, 'learning_rate': 0.07073226256396664, 'feature_fraction': 0.5325145713582624, 'bagging_fraction': 0.6397669091984788, 'bagging_freq': 1, 'min_child_samples': 56}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,187] Trial 15 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 300, 'learning_rate': 0.11620861290860793, 'feature_fraction': 0.7594524755470975, 'bagging_fraction': 0.8016584432435082, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,211] Trial 16 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 246, 'learning_rate': 0.06060616405966304, 'feature_fraction': 0.9195059187212463, 'bagging_fraction': 0.6693233921720162, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,354] Trial 17 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 185, 'learning_rate': 0.11734628638491837, 'feature_fraction': 0.6110922910687963, 'bagging_fraction': 0.5762453754826624, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,377] Trial 18 finished with value: 0.6865079365079365 and parameters: {'num_leaves': 98, 'learning_rate': 0.2418432585574151, 'feature_fraction': 0.50887926914329, 'bagging_fraction': 0.8029434116950126, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,418] Trial 19 finished with value: 0.7301587301587302 and parameters: {'num_leaves': 260, 'learning_rate': 0.09330121923784337, 'feature_fraction': 0.40258320048282853, 'bagging_fraction': 0.45745018724468295, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,446] Trial 20 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 213, 'learning_rate': 0.03847532726902956, 'feature_fraction': 0.9968623610908366, 'bagging_fraction': 0.6169788780475659, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,514] Trial 21 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 298, 'learning_rate': 0.01395963996144272, 'feature_fraction': 0.4043653553297536, 'bagging_fraction': 0.50214607597088, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,603] Trial 22 finished with value: 0.865079365079365 and parameters: {'num_leaves': 274, 'learning_rate': 0.033596556278050464, 'feature_fraction': 0.4508014550804241, 'bagging_fraction': 0.7015792242698128, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,627] Trial 23 finished with value: 0.7123015873015873 and parameters: {'num_leaves': 276, 'learning_rate': 0.08699296716278769, 'feature_fraction': 0.5649170050725382, 'bagging_fraction': 0.5581295142029445, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,655] Trial 24 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 249, 'learning_rate': 0.035508417938173165, 'feature_fraction': 0.4424060893942075, 'bagging_fraction': 0.7849625648050598, 'bagging_freq': 1, 'min_child_samples': 45}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,716] Trial 25 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 299, 'learning_rate': 0.14916830805418385, 'feature_fraction': 0.6647203444652717, 'bagging_fraction': 0.6098760968043333, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 12 with value: 0.8968253968253967.
[I 2025-09-17 13:18:51,845] Trial 26 finished with value: 0.8968253968253969 and parameters: {'num_leaves': 228, 'learning_rate': 0.05304660589077596, 'feature_fraction': 0.4869663849150832, 'bagging_fraction': 0.49715490486604386, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:51,876] Trial 27 finished with value: 0.7380952380952381 and parameters: {'num_leaves': 229, 'learning_rate': 0.1328618618912765, 'feature_fraction': 0.5739894459038702, 'bagging_fraction': 0.4926427414920471, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:51,925] Trial 28 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 197, 'learning_rate': 0.06745835263741608, 'feature_fraction': 0.4736674628825608, 'bagging_fraction': 0.6689356414890062, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:51,953] Trial 29 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 38, 'learning_rate': 0.08890125514936457, 'feature_fraction': 0.7484575655139176, 'bagging_fraction': 0.8500447764330212, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,063] Trial 30 finished with value: 0.8809523809523808 and parameters: {'num_leaves': 172, 'learning_rate': 0.05659444229858713, 'feature_fraction': 0.4969771603783819, 'bagging_fraction': 0.4068499699844303, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,182] Trial 31 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 168, 'learning_rate': 0.05501073694916799, 'feature_fraction': 0.4957476408340019, 'bagging_fraction': 0.40425808604427377, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,214] Trial 32 finished with value: 0.6785714285714285 and parameters: {'num_leaves': 221, 'learning_rate': 0.1059046373565969, 'feature_fraction': 0.5489469565886654, 'bagging_fraction': 0.4416793575094984, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,231] Trial 33 finished with value: 0.5 and parameters: {'num_leaves': 101, 'learning_rate': 0.07571936970909401, 'feature_fraction': 0.70440954414483, 'bagging_fraction': 0.49437881884024215, 'bagging_freq': 2, 'min_child_samples': 64}. Best is trial 26 with value: 0.8968253968253969.
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.535821
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.496343
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.58542
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.491976
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.472932
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.420169
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.437164
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.50435
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.493277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.404921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.478002
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.480807
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.515112
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.517448
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.408986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.418243
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.403733
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.511376
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.466525
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.655984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.496175
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.441214
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.500975
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.573888
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.5391
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.595697
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.412652
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.562796
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.510684
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.468118
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.386265
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.60361
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.568737
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.578521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.451361
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.583936
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.601097
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.608646
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.554329
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.448397
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.598708
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.602086
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.491731
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.425767
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.578418
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.591886
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.584265
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.433593
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.480934
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.607473
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:18:52,301] Trial 34 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 175, 'learning_rate': 0.05085588369882359, 'feature_fraction': 0.48964346608321385, 'bagging_fraction': 0.4488034616465939, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,329] Trial 35 finished with value: 0.6746031746031745 and parameters: {'num_leaves': 264, 'learning_rate': 0.1337258931060661, 'feature_fraction': 0.6689457713840034, 'bagging_fraction': 0.7558742557726159, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,358] Trial 36 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 115, 'learning_rate': 0.17046664399455888, 'feature_fraction': 0.5871828540373598, 'bagging_fraction': 0.8554084430219581, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,398] Trial 37 finished with value: 0.742063492063492 and parameters: {'num_leaves': 257, 'learning_rate': 0.07568875250609865, 'feature_fraction': 0.8667015763551784, 'bagging_fraction': 0.7030683135215424, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,442] Trial 38 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 143, 'learning_rate': 0.29895062867417843, 'feature_fraction': 0.9574888791052392, 'bagging_fraction': 0.5256210817589517, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,457] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 241, 'learning_rate': 0.2162566533058064, 'feature_fraction': 0.4389718910011311, 'bagging_fraction': 0.4234326570580268, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,507] Trial 40 finished with value: 0.7142857142857142 and parameters: {'num_leaves': 273, 'learning_rate': 0.030522168767106717, 'feature_fraction': 0.646366322797512, 'bagging_fraction': 0.5909004060476645, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,613] Trial 41 finished with value: 0.861111111111111 and parameters: {'num_leaves': 285, 'learning_rate': 0.027952930272505873, 'feature_fraction': 0.42297320956235573, 'bagging_fraction': 0.5271050556342889, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,689] Trial 42 finished with value: 0.7976190476190476 and parameters: {'num_leaves': 285, 'learning_rate': 0.010456619738665813, 'feature_fraction': 0.4753875397562979, 'bagging_fraction': 0.4655860545197492, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,848] Trial 43 finished with value: 0.888888888888889 and parameters: {'num_leaves': 233, 'learning_rate': 0.049417565678090886, 'feature_fraction': 0.42723573039024, 'bagging_fraction': 0.5287610924518606, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,865] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 198, 'learning_rate': 0.04618728877362192, 'feature_fraction': 0.5189246943421809, 'bagging_fraction': 0.4902711590543657, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,910] Trial 45 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 232, 'learning_rate': 0.05965383903712608, 'feature_fraction': 0.8063147951797244, 'bagging_fraction': 0.42870409373243434, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:52,949] Trial 46 finished with value: 0.7182539682539683 and parameters: {'num_leaves': 213, 'learning_rate': 0.10341815585174145, 'feature_fraction': 0.4629997013473771, 'bagging_fraction': 0.6540095584203132, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:53,077] Trial 47 finished with value: 0.8650793650793651 and parameters: {'num_leaves': 237, 'learning_rate': 0.07947860959466646, 'feature_fraction': 0.5434128174601013, 'bagging_fraction': 0.47723936218334284, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:53,099] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.04992907710772046, 'feature_fraction': 0.9009071302120678, 'bagging_fraction': 0.40012000820373844, 'bagging_freq': 1, 'min_child_samples': 84}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:53,135] Trial 49 finished with value: 0.6666666666666666 and parameters: {'num_leaves': 181, 'learning_rate': 0.1346111760256864, 'feature_fraction': 0.4936329167021515, 'bagging_fraction': 0.7246916540195252, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 26 with value: 0.8968253968253969.
[I 2025-09-17 13:18:54,089] A new study created in memory with name: no-name-947bd6f3-fb03-4b27-826d-6e5b0e075d90
[I 2025-09-17 13:18:54,097] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 30, 'learning_rate': 0.05625381701614555, 'feature_fraction': 0.9670564252825269, 'bagging_fraction': 0.7322972129365258, 'bagging_freq': 6, 'min_child_samples': 88}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:54,107] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 192, 'learning_rate': 0.2012986357138088, 'feature_fraction': 0.5763349940399032, 'bagging_fraction': 0.7018909281971857, 'bagging_freq': 2, 'min_child_samples': 79}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:54,115] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 151, 'learning_rate': 0.010245478003386592, 'feature_fraction': 0.49377905586750465, 'bagging_fraction': 0.6189826445321268, 'bagging_freq': 3, 'min_child_samples': 75}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:54,167] Trial 3 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 299, 'learning_rate': 0.1422720530565322, 'feature_fraction': 0.43443644179091534, 'bagging_fraction': 0.9309313827389607, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,202] Trial 4 finished with value: 0.7420634920634921 and parameters: {'num_leaves': 211, 'learning_rate': 0.026953124176282053, 'feature_fraction': 0.8643377374857092, 'bagging_fraction': 0.5255346019629094, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,211] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 24, 'learning_rate': 0.09465834434765687, 'feature_fraction': 0.8465381483743373, 'bagging_fraction': 0.4962867770031061, 'bagging_freq': 1, 'min_child_samples': 80}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,219] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 112, 'learning_rate': 0.0838445994686164, 'feature_fraction': 0.4346973880775538, 'bagging_fraction': 0.9043033694321896, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,227] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 271, 'learning_rate': 0.11670042443001374, 'feature_fraction': 0.6792582033500776, 'bagging_fraction': 0.9052480468876767, 'bagging_freq': 2, 'min_child_samples': 77}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,235] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 117, 'learning_rate': 0.25903294226047896, 'feature_fraction': 0.7864440038540254, 'bagging_fraction': 0.5258635468070749, 'bagging_freq': 2, 'min_child_samples': 64}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,245] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 168, 'learning_rate': 0.05711756473170048, 'feature_fraction': 0.7811407900415168, 'bagging_fraction': 0.5115897402656377, 'bagging_freq': 3, 'min_child_samples': 95}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,290] Trial 10 finished with value: 0.7698412698412698 and parameters: {'num_leaves': 295, 'learning_rate': 0.1542519658794335, 'feature_fraction': 0.6036574706650353, 'bagging_fraction': 0.9748310629034198, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,337] Trial 11 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 293, 'learning_rate': 0.16685651040503935, 'feature_fraction': 0.5811345575484685, 'bagging_fraction': 0.9968458573669872, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,362] Trial 12 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 244, 'learning_rate': 0.17894177445871395, 'feature_fraction': 0.40251579160686635, 'bagging_fraction': 0.8374291517260222, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 3 with value: 0.8055555555555556.
[I 2025-09-17 13:18:54,430] Trial 13 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 243, 'learning_rate': 0.23292106603285673, 'feature_fraction': 0.5293965790166735, 'bagging_fraction': 0.9939431204165451, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:18:54,546] Trial 14 finished with value: 0.8095238095238094 and parameters: {'num_leaves': 233, 'learning_rate': 0.2918817181109908, 'feature_fraction': 0.5004049744339514, 'bagging_fraction': 0.8014710269453205, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:18:54,617] Trial 15 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 225, 'learning_rate': 0.2845443832464666, 'feature_fraction': 0.5211598041432177, 'bagging_fraction': 0.7957464920941535, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 13 with value: 0.8492063492063492.
[I 2025-09-17 13:18:54,702] Trial 16 finished with value: 0.9206349206349206 and parameters: {'num_leaves': 245, 'learning_rate': 0.2308686268623338, 'feature_fraction': 0.6194067223881699, 'bagging_fraction': 0.4050630263005873, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 16 with value: 0.9206349206349206.
[I 2025-09-17 13:18:54,716] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 256, 'learning_rate': 0.22370836318704207, 'feature_fraction': 0.6676842718199673, 'bagging_fraction': 0.41807373497761385, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 16 with value: 0.9206349206349206.
[I 2025-09-17 13:18:54,767] Trial 18 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 190, 'learning_rate': 0.2432377279925014, 'feature_fraction': 0.6254831960434452, 'bagging_fraction': 0.6195140451418073, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 16 with value: 0.9206349206349206.
[I 2025-09-17 13:18:54,781] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 130, 'learning_rate': 0.20891579385733677, 'feature_fraction': 0.7361597575752018, 'bagging_fraction': 0.402985517498298, 'bagging_freq': 7, 'min_child_samples': 39}. Best is trial 16 with value: 0.9206349206349206.
[I 2025-09-17 13:18:54,798] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 86, 'learning_rate': 0.23610754817640936, 'feature_fraction': 0.5572889438649117, 'bagging_fraction': 0.6264115667067919, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 16 with value: 0.9206349206349206.
[I 2025-09-17 13:18:54,844] Trial 21 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 195, 'learning_rate': 0.25795716803765173, 'feature_fraction': 0.6602651709353257, 'bagging_fraction': 0.6253560966846425, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 16 with value: 0.9206349206349206.
[I 2025-09-17 13:18:54,883] Trial 22 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 181, 'learning_rate': 0.25309014422840215, 'feature_fraction': 0.6245618746421215, 'bagging_fraction': 0.5826727999870104, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 16 with value: 0.9206349206349206.
[I 2025-09-17 13:18:54,907] Trial 23 finished with value: 0.7182539682539681 and parameters: {'num_leaves': 262, 'learning_rate': 0.2698972231812579, 'feature_fraction': 0.7295965353837739, 'bagging_fraction': 0.45103485826310286, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 16 with value: 0.9206349206349206.
[I 2025-09-17 13:18:55,024] Trial 24 finished with value: 0.9246031746031745 and parameters: {'num_leaves': 216, 'learning_rate': 0.20315874011467763, 'feature_fraction': 0.6327553773022653, 'bagging_fraction': 0.5728856859349616, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,152] Trial 25 finished with value: 0.9047619047619048 and parameters: {'num_leaves': 215, 'learning_rate': 0.19541489730494366, 'feature_fraction': 0.5359586219315202, 'bagging_fraction': 0.4652458499394609, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,242] Trial 26 finished with value: 0.876984126984127 and parameters: {'num_leaves': 213, 'learning_rate': 0.19303150526205798, 'feature_fraction': 0.716632943182775, 'bagging_fraction': 0.4627303602655488, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,280] Trial 27 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 161, 'learning_rate': 0.14008405864203444, 'feature_fraction': 0.6377558772252083, 'bagging_fraction': 0.556141029756566, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,299] Trial 28 finished with value: 0.626984126984127 and parameters: {'num_leaves': 224, 'learning_rate': 0.21587531364758006, 'feature_fraction': 0.47339761427030363, 'bagging_fraction': 0.4536345751112773, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,325] Trial 29 finished with value: 0.7916666666666666 and parameters: {'num_leaves': 53, 'learning_rate': 0.1907164735501431, 'feature_fraction': 0.9766303672281145, 'bagging_fraction': 0.5729095284622232, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,359] Trial 30 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 270, 'learning_rate': 0.17631078074559203, 'feature_fraction': 0.9093993755431555, 'bagging_fraction': 0.479582228080987, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,447] Trial 31 finished with value: 0.9087301587301587 and parameters: {'num_leaves': 198, 'learning_rate': 0.20411896989597672, 'feature_fraction': 0.7132359978931428, 'bagging_fraction': 0.4513033406473216, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,553] Trial 32 finished with value: 0.8412698412698413 and parameters: {'num_leaves': 209, 'learning_rate': 0.20276579126439667, 'feature_fraction': 0.5495354566217638, 'bagging_fraction': 0.41736601517184996, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,597] Trial 33 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 145, 'learning_rate': 0.22042376261491345, 'feature_fraction': 0.7789128138246134, 'bagging_fraction': 0.6837758390628261, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,630] Trial 34 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 179, 'learning_rate': 0.18670695316833907, 'feature_fraction': 0.5920101096973609, 'bagging_fraction': 0.4425949275644472, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,756] Trial 35 finished with value: 0.8809523809523809 and parameters: {'num_leaves': 201, 'learning_rate': 0.15924664567250918, 'feature_fraction': 0.7534899157018808, 'bagging_fraction': 0.540023856218954, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,815] Trial 36 finished with value: 0.869047619047619 and parameters: {'num_leaves': 240, 'learning_rate': 0.137997613700323, 'feature_fraction': 0.6932642905931926, 'bagging_fraction': 0.6851988902585013, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,840] Trial 37 finished with value: 0.7361111111111112 and parameters: {'num_leaves': 219, 'learning_rate': 0.20750789356717106, 'feature_fraction': 0.64172066830009, 'bagging_fraction': 0.49331641998522435, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,885] Trial 38 finished with value: 0.9007936507936508 and parameters: {'num_leaves': 177, 'learning_rate': 0.2750459593963607, 'feature_fraction': 0.851167272135196, 'bagging_fraction': 0.5933336909359848, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,897] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.1178846312735459, 'feature_fraction': 0.4674167562871808, 'bagging_fraction': 0.4012593040270471, 'bagging_freq': 4, 'min_child_samples': 69}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,912] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 253, 'learning_rate': 0.2290889605375281, 'feature_fraction': 0.5557792714943609, 'bagging_fraction': 0.5006034117748297, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:55,957] Trial 41 finished with value: 0.869047619047619 and parameters: {'num_leaves': 176, 'learning_rate': 0.28389858819125624, 'feature_fraction': 0.8239523262078613, 'bagging_fraction': 0.6513546102424462, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:56,026] Trial 42 finished with value: 0.9047619047619048 and parameters: {'num_leaves': 145, 'learning_rate': 0.2715351009327997, 'feature_fraction': 0.877996548210041, 'bagging_fraction': 0.593159716788242, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 24 with value: 0.9246031746031745.
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.528054
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.626969
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.599314
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.619654
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.557176
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.57964
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.459198
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.56309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.408955
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.577473
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.59965
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.436169
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.61339
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.491967
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.563725
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.549598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.545026
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.551006
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.476521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.548147
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.498128
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.371341
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.489731
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.537133
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.498466
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.557178
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.3569
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.378885
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.430949
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.493418
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.59673
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.576012
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.573504
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.337996
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.521193
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.522537
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.534971
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.411675
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.439003
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.587269
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.4229
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.431309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.391407
[I 2025-09-17 13:18:56,063] Trial 43 finished with value: 0.8015873015873016 and parameters: {'num_leaves': 85, 'learning_rate': 0.2988158723075026, 'feature_fraction': 0.9363432193323618, 'bagging_fraction': 0.7352366248360913, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:56,143] Trial 44 finished with value: 0.880952380952381 and parameters: {'num_leaves': 141, 'learning_rate': 0.24593278495082255, 'feature_fraction': 0.5962518171854357, 'bagging_fraction': 0.5417188421574788, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:56,171] Trial 45 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 155, 'learning_rate': 0.17098532149023865, 'feature_fraction': 0.8126407809746284, 'bagging_fraction': 0.47787955119510717, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:56,186] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 202, 'learning_rate': 0.26194336824002373, 'feature_fraction': 0.8869303405138884, 'bagging_fraction': 0.4407274303690358, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:56,268] Trial 47 finished with value: 0.8690476190476191 and parameters: {'num_leaves': 126, 'learning_rate': 0.19625640424072582, 'feature_fraction': 0.9458525787285879, 'bagging_fraction': 0.5230917844898757, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:56,294] Trial 48 finished with value: 0.7281746031746031 and parameters: {'num_leaves': 232, 'learning_rate': 0.21519344055720915, 'feature_fraction': 0.698768786543589, 'bagging_fraction': 0.7337569762512116, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:56,339] Trial 49 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 165, 'learning_rate': 0.24179637185253428, 'feature_fraction': 0.6155781717899466, 'bagging_fraction': 0.5133680507561942, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 24 with value: 0.9246031746031745.
[I 2025-09-17 13:18:56,649] A new study created in memory with name: no-name-fe65c516-9211-4704-bf86-de646ce63305
[I 2025-09-17 13:18:56,662] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 223, 'learning_rate': 0.13226541916676057, 'feature_fraction': 0.44108294665982345, 'bagging_fraction': 0.411601896524801, 'bagging_freq': 6, 'min_child_samples': 96}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:18:56,680] Trial 1 finished with value: 0.8277511961722487 and parameters: {'num_leaves': 244, 'learning_rate': 0.08316069875858968, 'feature_fraction': 0.6193923839656004, 'bagging_fraction': 0.7945080511913247, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,689] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 163, 'learning_rate': 0.27647754743863895, 'feature_fraction': 0.6848210410698465, 'bagging_fraction': 0.8977095276840776, 'bagging_freq': 2, 'min_child_samples': 77}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,702] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 209, 'learning_rate': 0.2918518081665664, 'feature_fraction': 0.6846581784293733, 'bagging_fraction': 0.6226875785907728, 'bagging_freq': 5, 'min_child_samples': 73}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,768] Trial 4 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 110, 'learning_rate': 0.09332144214633058, 'feature_fraction': 0.721463893935959, 'bagging_fraction': 0.6211886930535104, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,777] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 65, 'learning_rate': 0.2184797127347364, 'feature_fraction': 0.5977946019183018, 'bagging_fraction': 0.9151568194333797, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,783] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 73, 'learning_rate': 0.22358916124790126, 'feature_fraction': 0.5005175570263716, 'bagging_fraction': 0.7110833338055491, 'bagging_freq': 1, 'min_child_samples': 78}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,821] Trial 7 finished with value: 0.7488038277511961 and parameters: {'num_leaves': 172, 'learning_rate': 0.23557337369340478, 'feature_fraction': 0.7502277137821673, 'bagging_fraction': 0.7282507839591236, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,828] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 189, 'learning_rate': 0.2887890249780159, 'feature_fraction': 0.5481102853466646, 'bagging_fraction': 0.5802245614711392, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,851] Trial 9 finished with value: 0.8133971291866028 and parameters: {'num_leaves': 25, 'learning_rate': 0.01804046583714449, 'feature_fraction': 0.6092202302775328, 'bagging_fraction': 0.6501313457972574, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,873] Trial 10 finished with value: 0.8181818181818182 and parameters: {'num_leaves': 297, 'learning_rate': 0.04197292500747444, 'feature_fraction': 0.9588271033513713, 'bagging_fraction': 0.9999453568197447, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 1 with value: 0.8277511961722487.
[I 2025-09-17 13:18:56,899] Trial 11 finished with value: 0.832535885167464 and parameters: {'num_leaves': 286, 'learning_rate': 0.04196029112006669, 'feature_fraction': 0.9704105803734095, 'bagging_fraction': 0.819957890175929, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 11 with value: 0.832535885167464.
[I 2025-09-17 13:18:56,928] Trial 12 finished with value: 0.8277511961722488 and parameters: {'num_leaves': 298, 'learning_rate': 0.07424945244821579, 'feature_fraction': 0.9980348910671002, 'bagging_fraction': 0.8302377789239187, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 11 with value: 0.832535885167464.
[I 2025-09-17 13:18:56,955] Trial 13 finished with value: 0.7033492822966507 and parameters: {'num_leaves': 299, 'learning_rate': 0.06991714454600519, 'feature_fraction': 0.9866257405366116, 'bagging_fraction': 0.8455044282099955, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 11 with value: 0.832535885167464.
[I 2025-09-17 13:18:56,978] Trial 14 finished with value: 0.8277511961722489 and parameters: {'num_leaves': 255, 'learning_rate': 0.1477980410141948, 'feature_fraction': 0.8911285380520793, 'bagging_fraction': 0.7911233394446192, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 11 with value: 0.832535885167464.
[I 2025-09-17 13:18:57,011] Trial 15 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 254, 'learning_rate': 0.15745370721776317, 'feature_fraction': 0.8672113545288477, 'bagging_fraction': 0.7677729037669323, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,035] Trial 16 finished with value: 0.84688995215311 and parameters: {'num_leaves': 258, 'learning_rate': 0.17708849797461654, 'feature_fraction': 0.8159167893114666, 'bagging_fraction': 0.5135636766880686, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,068] Trial 17 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 131, 'learning_rate': 0.1625378046590692, 'feature_fraction': 0.820295380285461, 'bagging_fraction': 0.49387613293421684, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,095] Trial 18 finished with value: 0.8229665071770335 and parameters: {'num_leaves': 254, 'learning_rate': 0.18526811282884686, 'feature_fraction': 0.8278435070562817, 'bagging_fraction': 0.5222621656146612, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,152] Trial 19 finished with value: 0.8516746411483254 and parameters: {'num_leaves': 215, 'learning_rate': 0.11435167112840192, 'feature_fraction': 0.878167691345275, 'bagging_fraction': 0.4066181627407943, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,204] Trial 20 finished with value: 0.7942583732057416 and parameters: {'num_leaves': 210, 'learning_rate': 0.1301764914314383, 'feature_fraction': 0.8862940621753993, 'bagging_fraction': 0.40177411738501195, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,229] Trial 21 finished with value: 0.7033492822966507 and parameters: {'num_leaves': 238, 'learning_rate': 0.18127065082543775, 'feature_fraction': 0.8128689482935141, 'bagging_fraction': 0.47690390251269477, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,271] Trial 22 finished with value: 0.8133971291866029 and parameters: {'num_leaves': 266, 'learning_rate': 0.12161136337118432, 'feature_fraction': 0.9025999453361936, 'bagging_fraction': 0.5505624283468376, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,302] Trial 23 finished with value: 0.7966507177033493 and parameters: {'num_leaves': 189, 'learning_rate': 0.18877087676148624, 'feature_fraction': 0.7715447247558296, 'bagging_fraction': 0.4500949067564562, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,407] Trial 24 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 273, 'learning_rate': 0.10759099321740143, 'feature_fraction': 0.8565119018720854, 'bagging_fraction': 0.7271544036768036, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,507] Trial 25 finished with value: 0.799043062200957 and parameters: {'num_leaves': 223, 'learning_rate': 0.10347579935297122, 'feature_fraction': 0.9273865445220772, 'bagging_fraction': 0.7381013142972053, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,520] Trial 26 finished with value: 0.5 and parameters: {'num_leaves': 271, 'learning_rate': 0.11127389431255764, 'feature_fraction': 0.8702588004400171, 'bagging_fraction': 0.6878266494427383, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,612] Trial 27 finished with value: 0.8851674641148326 and parameters: {'num_leaves': 132, 'learning_rate': 0.14681171589067687, 'feature_fraction': 0.8572543835081953, 'bagging_fraction': 0.7572072705098081, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,643] Trial 28 finished with value: 0.861244019138756 and parameters: {'num_leaves': 127, 'learning_rate': 0.1529257899610801, 'feature_fraction': 0.7657368400413439, 'bagging_fraction': 0.7660490577607979, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,656] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 143, 'learning_rate': 0.14194951797665478, 'feature_fraction': 0.8432858974120911, 'bagging_fraction': 0.8833620636213383, 'bagging_freq': 4, 'min_child_samples': 91}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,666] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 97, 'learning_rate': 0.21284955914696485, 'feature_fraction': 0.9354302807221351, 'bagging_fraction': 0.6829753993341452, 'bagging_freq': 1, 'min_child_samples': 59}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,691] Trial 31 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 125, 'learning_rate': 0.16356054494860986, 'feature_fraction': 0.7450446041451222, 'bagging_fraction': 0.7649667650222436, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,739] Trial 32 finished with value: 0.84688995215311 and parameters: {'num_leaves': 99, 'learning_rate': 0.1405267153572421, 'feature_fraction': 0.7899436741294381, 'bagging_fraction': 0.7585128921272084, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,768] Trial 33 finished with value: 0.8516746411483254 and parameters: {'num_leaves': 176, 'learning_rate': 0.15747630691889794, 'feature_fraction': 0.41169627010323917, 'bagging_fraction': 0.793269738740902, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,799] Trial 34 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 149, 'learning_rate': 0.2584247434005266, 'feature_fraction': 0.675117065657901, 'bagging_fraction': 0.6706902203910848, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,847] Trial 35 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 76, 'learning_rate': 0.1998188248138814, 'feature_fraction': 0.8538037627635697, 'bagging_fraction': 0.8710843236288197, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:57,874] Trial 36 finished with value: 0.8325358851674641 and parameters: {'num_leaves': 125, 'learning_rate': 0.08718790871525041, 'feature_fraction': 0.7848964883263385, 'bagging_fraction': 0.7622136545807875, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 15 with value: 0.8947368421052632.
[I 2025-09-17 13:18:58,006] Trial 37 finished with value: 0.923444976076555 and parameters: {'num_leaves': 53, 'learning_rate': 0.13398335939773937, 'feature_fraction': 0.7181114368066437, 'bagging_fraction': 0.9390436557550084, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 37 with value: 0.923444976076555.
[I 2025-09-17 13:18:58,127] Trial 38 finished with value: 0.8516746411483254 and parameters: {'num_leaves': 26, 'learning_rate': 0.09641739052596739, 'feature_fraction': 0.6521411578342976, 'bagging_fraction': 0.9418752191364126, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 37 with value: 0.923444976076555.
[I 2025-09-17 13:18:58,179] Trial 39 finished with value: 0.7942583732057416 and parameters: {'num_leaves': 40, 'learning_rate': 0.1288770601895837, 'feature_fraction': 0.7201066603334053, 'bagging_fraction': 0.6206035319796338, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 37 with value: 0.923444976076555.
[I 2025-09-17 13:18:58,240] Trial 40 finished with value: 0.84688995215311 and parameters: {'num_leaves': 233, 'learning_rate': 0.06178946038319315, 'feature_fraction': 0.48721815617165154, 'bagging_fraction': 0.9556655056737278, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 37 with value: 0.923444976076555.
[I 2025-09-17 13:18:58,331] Trial 41 finished with value: 0.9234449760765551 and parameters: {'num_leaves': 101, 'learning_rate': 0.16844975938669426, 'feature_fraction': 0.75336938448897, 'bagging_fraction': 0.7243108437215999, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:58,422] Trial 42 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 52, 'learning_rate': 0.16857298265170376, 'feature_fraction': 0.7067525059717326, 'bagging_fraction': 0.7267957273314799, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:58,468] Trial 43 finished with value: 0.861244019138756 and parameters: {'num_leaves': 77, 'learning_rate': 0.20127162145139618, 'feature_fraction': 0.6562915956907089, 'bagging_fraction': 0.6408838722240272, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:58,542] Trial 44 finished with value: 0.861244019138756 and parameters: {'num_leaves': 161, 'learning_rate': 0.13759372265165812, 'feature_fraction': 0.5738505941902261, 'bagging_fraction': 0.7082406935702033, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:58,566] Trial 45 finished with value: 0.8444976076555024 and parameters: {'num_leaves': 100, 'learning_rate': 0.23991174852125585, 'feature_fraction': 0.9204097145191221, 'bagging_fraction': 0.5930803140043115, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:58,608] Trial 46 finished with value: 0.832535885167464 and parameters: {'num_leaves': 281, 'learning_rate': 0.11962301153997712, 'feature_fraction': 0.7389283957452143, 'bagging_fraction': 0.8121141537704188, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:58,672] Trial 47 finished with value: 0.8133971291866029 and parameters: {'num_leaves': 11, 'learning_rate': 0.10283701686497806, 'feature_fraction': 0.794748098424049, 'bagging_fraction': 0.9244308282618431, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:58,688] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 60, 'learning_rate': 0.1659070316392332, 'feature_fraction': 0.8476288501729351, 'bagging_fraction': 0.8532713697613714, 'bagging_freq': 2, 'min_child_samples': 66}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:58,721] Trial 49 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 86, 'learning_rate': 0.15048041570703546, 'feature_fraction': 0.9587024748364155, 'bagging_fraction': 0.6665871702743189, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 41 with value: 0.9234449760765551.
[I 2025-09-17 13:18:59,084] A new study created in memory with name: no-name-ff472236-36e5-4005-ab27-c32d37f04d93
[I 2025-09-17 13:18:59,109] Trial 0 finished with value: 0.8086124401913876 and parameters: {'num_leaves': 43, 'learning_rate': 0.2761796737953203, 'feature_fraction': 0.8137446207864487, 'bagging_fraction': 0.6538321352105005, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 0 with value: 0.8086124401913876.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.515227
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.416963
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.550219
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.467787
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.581451
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.489275
Training model for P056... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.505239
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.50136
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.568538
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.576548
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.525441
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.540919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.528998
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.596523
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.500039
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.453904
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.478102
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.517416
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.500588
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.498544
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.521374
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.551676
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.50617
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.525356
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.405666
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.519858
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.445497
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.471428
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.52291
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.444717
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.473689
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.51471
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.50868
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.508743
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.390712
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.462915
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.503909
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.496913
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.408
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.529404
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.43441
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.449014
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.486301
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.489124
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.511549
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.460033
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.51267
Training until validation scores don't improve for 50 rounds[I 2025-09-17 13:18:59,133] Trial 1 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 233, 'learning_rate': 0.256726655746915, 'feature_fraction': 0.5366234422905432, 'bagging_fraction': 0.5916097178300115, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,142] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 71, 'learning_rate': 0.14349060942049463, 'feature_fraction': 0.7897459896701335, 'bagging_fraction': 0.58641937897166, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,162] Trial 3 finished with value: 0.7703349282296651 and parameters: {'num_leaves': 121, 'learning_rate': 0.10694223466740523, 'feature_fraction': 0.5375378591494022, 'bagging_fraction': 0.9187961433757401, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,171] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 205, 'learning_rate': 0.27576099325507464, 'feature_fraction': 0.4602784817968223, 'bagging_fraction': 0.6285707005593866, 'bagging_freq': 6, 'min_child_samples': 57}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,187] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 226, 'learning_rate': 0.02958503091694681, 'feature_fraction': 0.9173645514332562, 'bagging_fraction': 0.5021463193785647, 'bagging_freq': 5, 'min_child_samples': 68}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,201] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 253, 'learning_rate': 0.2626312576677402, 'feature_fraction': 0.6280814729263844, 'bagging_fraction': 0.808779391533016, 'bagging_freq': 2, 'min_child_samples': 76}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,214] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 90, 'learning_rate': 0.14174493598515822, 'feature_fraction': 0.5558813120644086, 'bagging_fraction': 0.6942930747794571, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,223] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 61, 'learning_rate': 0.2198295102755668, 'feature_fraction': 0.7180534400121885, 'bagging_fraction': 0.9801177166944353, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,235] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.24235404793145168, 'feature_fraction': 0.502375320836961, 'bagging_fraction': 0.8645362142252733, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,292] Trial 10 finished with value: 0.7033492822966507 and parameters: {'num_leaves': 27, 'learning_rate': 0.19752702444012293, 'feature_fraction': 0.9766738728306853, 'bagging_fraction': 0.41689355618275187, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,323] Trial 11 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 292, 'learning_rate': 0.2890190864604227, 'feature_fraction': 0.7888690113072658, 'bagging_fraction': 0.751006539056445, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,349] Trial 12 finished with value: 0.7272727272727273 and parameters: {'num_leaves': 185, 'learning_rate': 0.29436295843279353, 'feature_fraction': 0.41292756334238484, 'bagging_fraction': 0.5842659079669908, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,401] Trial 13 finished with value: 0.7368421052631579 and parameters: {'num_leaves': 11, 'learning_rate': 0.20028410855301684, 'feature_fraction': 0.8520463236938035, 'bagging_fraction': 0.674443863773862, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,427] Trial 14 finished with value: 0.7942583732057417 and parameters: {'num_leaves': 172, 'learning_rate': 0.22482044904964804, 'feature_fraction': 0.6201553612397271, 'bagging_fraction': 0.5066548344516592, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,443] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 264, 'learning_rate': 0.17816792389166983, 'feature_fraction': 0.6803960829134108, 'bagging_fraction': 0.5111488363331249, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,472] Trial 16 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 148, 'learning_rate': 0.07435126435202483, 'feature_fraction': 0.7612270553155598, 'bagging_fraction': 0.7560475114725514, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,495] Trial 17 finished with value: 0.6148325358851675 and parameters: {'num_leaves': 109, 'learning_rate': 0.24769293388829056, 'feature_fraction': 0.8675426163921914, 'bagging_fraction': 0.4005805570240734, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,528] Trial 18 finished with value: 0.7559808612440191 and parameters: {'num_leaves': 222, 'learning_rate': 0.16905887475400438, 'feature_fraction': 0.6252978147251842, 'bagging_fraction': 0.6372606172724993, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,538] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 294, 'learning_rate': 0.263540337559636, 'feature_fraction': 0.9881799680432279, 'bagging_fraction': 0.5560802461994883, 'bagging_freq': 1, 'min_child_samples': 49}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,574] Trial 20 finished with value: 0.7942583732057417 and parameters: {'num_leaves': 44, 'learning_rate': 0.2985370203450365, 'feature_fraction': 0.7043356511965353, 'bagging_fraction': 0.7411205626714465, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,602] Trial 21 finished with value: 0.7607655502392344 and parameters: {'num_leaves': 294, 'learning_rate': 0.2993376375115049, 'feature_fraction': 0.8122893494016235, 'bagging_fraction': 0.7583348775550518, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 0 with value: 0.8086124401913876.
[I 2025-09-17 13:18:59,640] Trial 22 finished with value: 0.8133971291866029 and parameters: {'num_leaves': 246, 'learning_rate': 0.2383673693778567, 'feature_fraction': 0.8861917969799976, 'bagging_fraction': 0.8292190393717812, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 22 with value: 0.8133971291866029.
[I 2025-09-17 13:18:59,664] Trial 23 finished with value: 0.7942583732057416 and parameters: {'num_leaves': 253, 'learning_rate': 0.23355356301103647, 'feature_fraction': 0.9107373569282589, 'bagging_fraction': 0.847538197122118, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 22 with value: 0.8133971291866029.
[I 2025-09-17 13:18:59,692] Trial 24 finished with value: 0.7559808612440192 and parameters: {'num_leaves': 191, 'learning_rate': 0.20712660509654607, 'feature_fraction': 0.9136669257854119, 'bagging_fraction': 0.6460190747840896, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 22 with value: 0.8133971291866029.
[I 2025-09-17 13:18:59,760] Trial 25 finished with value: 0.69377990430622 and parameters: {'num_leaves': 235, 'learning_rate': 0.2591839698688223, 'feature_fraction': 0.8525560013549871, 'bagging_fraction': 0.8143096717398253, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 22 with value: 0.8133971291866029.
[I 2025-09-17 13:18:59,790] Trial 26 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 162, 'learning_rate': 0.2723472189745145, 'feature_fraction': 0.7513830459669695, 'bagging_fraction': 0.9165817480777393, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 22 with value: 0.8133971291866029.
[I 2025-09-17 13:18:59,805] Trial 27 finished with value: 0.7607655502392345 and parameters: {'num_leaves': 268, 'learning_rate': 0.2460202569549505, 'feature_fraction': 0.9399824479817351, 'bagging_fraction': 0.7079460338967672, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 22 with value: 0.8133971291866029.
[I 2025-09-17 13:18:59,837] Trial 28 finished with value: 0.8133971291866029 and parameters: {'num_leaves': 214, 'learning_rate': 0.1148618372293024, 'feature_fraction': 0.671317696320674, 'bagging_fraction': 0.4589301441390503, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 22 with value: 0.8133971291866029.
[I 2025-09-17 13:18:59,863] Trial 29 finished with value: 0.8277511961722488 and parameters: {'num_leaves': 206, 'learning_rate': 0.11453739189541884, 'feature_fraction': 0.661527693264222, 'bagging_fraction': 0.4611806180657097, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:18:59,879] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 212, 'learning_rate': 0.11266705136499933, 'feature_fraction': 0.6671975892251983, 'bagging_fraction': 0.45953105502908637, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:18:59,913] Trial 31 finished with value: 0.7894736842105262 and parameters: {'num_leaves': 194, 'learning_rate': 0.10609461961080771, 'feature_fraction': 0.7273316834863728, 'bagging_fraction': 0.46370224034676, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:18:59,963] Trial 32 finished with value: 0.8133971291866029 and parameters: {'num_leaves': 240, 'learning_rate': 0.05778920485221205, 'feature_fraction': 0.5849038739188972, 'bagging_fraction': 0.5637613133580096, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,020] Trial 33 finished with value: 0.7799043062200958 and parameters: {'num_leaves': 245, 'learning_rate': 0.048780746230850665, 'feature_fraction': 0.5833733466900973, 'bagging_fraction': 0.4595122467382639, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,117] Trial 34 finished with value: 0.8086124401913876 and parameters: {'num_leaves': 211, 'learning_rate': 0.06763121887922394, 'feature_fraction': 0.6580278791296647, 'bagging_fraction': 0.5399343081955441, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,143] Trial 35 finished with value: 0.770334928229665 and parameters: {'num_leaves': 276, 'learning_rate': 0.1269447387024959, 'feature_fraction': 0.580953028793153, 'bagging_fraction': 0.430064859124777, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,191] Trial 36 finished with value: 0.8038277511961722 and parameters: {'num_leaves': 235, 'learning_rate': 0.08396701158866421, 'feature_fraction': 0.49534728677647544, 'bagging_fraction': 0.6010620993260715, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,222] Trial 37 finished with value: 0.7511961722488038 and parameters: {'num_leaves': 176, 'learning_rate': 0.09521307032296164, 'feature_fraction': 0.5941139721373627, 'bagging_fraction': 0.494388679753504, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,250] Trial 38 finished with value: 0.7081339712918661 and parameters: {'num_leaves': 208, 'learning_rate': 0.052634036915770024, 'feature_fraction': 0.6506315793640345, 'bagging_fraction': 0.5398771839821827, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,269] Trial 39 finished with value: 0.5885167464114832 and parameters: {'num_leaves': 225, 'learning_rate': 0.014847712810815122, 'feature_fraction': 0.5391087270816011, 'bagging_fraction': 0.5667190451183576, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,281] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 273, 'learning_rate': 0.14461792319849756, 'feature_fraction': 0.4994949868578138, 'bagging_fraction': 0.44207219772427075, 'bagging_freq': 3, 'min_child_samples': 99}. Best is trial 29 with value: 0.8277511961722488.
[I 2025-09-17 13:19:00,337] Trial 41 finished with value: 0.84688995215311 and parameters: {'num_leaves': 91, 'learning_rate': 0.12459558997258269, 'feature_fraction': 0.8187004172245627, 'bagging_fraction': 0.6152212911351227, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:00,381] Trial 42 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 87, 'learning_rate': 0.15191681838263843, 'feature_fraction': 0.7535286580135823, 'bagging_fraction': 0.48777978819149803, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:00,450] Trial 43 finished with value: 0.8181818181818181 and parameters: {'num_leaves': 122, 'learning_rate': 0.12979411467714688, 'feature_fraction': 0.8744185717968668, 'bagging_fraction': 0.6193815638550256, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:00,536] Trial 44 finished with value: 0.7703349282296651 and parameters: {'num_leaves': 116, 'learning_rate': 0.1309853481394341, 'feature_fraction': 0.8837583638273948, 'bagging_fraction': 0.5991705197413145, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:00,567] Trial 45 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 84, 'learning_rate': 0.168926669172724, 'feature_fraction': 0.8114021029246227, 'bagging_fraction': 0.6718952979923799, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:00,580] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 145, 'learning_rate': 0.12779053179525876, 'feature_fraction': 0.9581687671635227, 'bagging_fraction': 0.7217875861592179, 'bagging_freq': 2, 'min_child_samples': 62}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:00,592] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 130, 'learning_rate': 0.113511016881221, 'feature_fraction': 0.7823404820155422, 'bagging_fraction': 0.6202562016506477, 'bagging_freq': 2, 'min_child_samples': 80}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:00,690] Trial 48 finished with value: 0.8086124401913876 and parameters: {'num_leaves': 69, 'learning_rate': 0.08834898453594897, 'feature_fraction': 0.8352077280983988, 'bagging_fraction': 0.9392741297354277, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:00,722] Trial 49 finished with value: 0.7559808612440192 and parameters: {'num_leaves': 103, 'learning_rate': 0.100249931772299, 'feature_fraction': 0.8921550408293615, 'bagging_fraction': 0.7795187683563314, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 41 with value: 0.84688995215311.
[I 2025-09-17 13:19:01,069] A new study created in memory with name: no-name-ae2dcb36-eb91-422c-8af6-57d58d5b3dc1
[I 2025-09-17 13:19:01,078] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 111, 'learning_rate': 0.24981368334900772, 'feature_fraction': 0.6905491765390346, 'bagging_fraction': 0.6193825074047443, 'bagging_freq': 1, 'min_child_samples': 50}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:01,088] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 129, 'learning_rate': 0.21901526608952537, 'feature_fraction': 0.4748639851760216, 'bagging_fraction': 0.5402285516892008, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:01,092] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 126, 'learning_rate': 0.2392055749000444, 'feature_fraction': 0.41146009135866274, 'bagging_fraction': 0.9939121410862412, 'bagging_freq': 1, 'min_child_samples': 65}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:01,111] Trial 3 finished with value: 0.8194444444444444 and parameters: {'num_leaves': 239, 'learning_rate': 0.12403653085558687, 'feature_fraction': 0.9117286166880029, 'bagging_fraction': 0.9043248155953795, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 3 with value: 0.8194444444444444.
[I 2025-09-17 13:19:01,119] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 35, 'learning_rate': 0.11516962349791575, 'feature_fraction': 0.8126555628322281, 'bagging_fraction': 0.555241152358005, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 3 with value: 0.8194444444444444.
[I 2025-09-17 13:19:01,129] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 232, 'learning_rate': 0.06910929221311363, 'feature_fraction': 0.5869217051260356, 'bagging_fraction': 0.5436628578127447, 'bagging_freq': 7, 'min_child_samples': 66}. Best is trial 3 with value: 0.8194444444444444.
[I 2025-09-17 13:19:01,141] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.03594476484486003, 'feature_fraction': 0.49816799156699904, 'bagging_fraction': 0.5446861971855755, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 3 with value: 0.8194444444444444.
[I 2025-09-17 13:19:01,162] Trial 7 finished with value: 0.6851851851851851 and parameters: {'num_leaves': 239, 'learning_rate': 0.07173416412303614, 'feature_fraction': 0.7062291177880147, 'bagging_fraction': 0.8840265434688495, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 3 with value: 0.8194444444444444.
[I 2025-09-17 13:19:01,301] Trial 8 finished with value: 0.8009259259259259 and parameters: {'num_leaves': 218, 'learning_rate': 0.05631263149054865, 'feature_fraction': 0.40453318752432577, 'bagging_fraction': 0.6704644518918346, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 3 with value: 0.8194444444444444.
[I 2025-09-17 13:19:01,309] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 71, 'learning_rate': 0.2917216110137133, 'feature_fraction': 0.9818126035675734, 'bagging_fraction': 0.6167118148440203, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 3 with value: 0.8194444444444444.

Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.520304
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.559376
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.593959
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.512154
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.531836
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.589283
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.562738
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.542316
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.640426
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.556951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.525749
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.57304
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.517427
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.546668
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.563717
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.659139
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.517758
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.621317
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.515439
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.525281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.525167
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.527902
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.539596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.512585
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.582483
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.518761
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.559869
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.595111
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.657525
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.473565
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.538243
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.48149
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.552665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.527781
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.657997
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.53556
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.544281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.542433
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.611573
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.529949
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:01,337] Trial 10 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 290, 'learning_rate': 0.15149518391636477, 'feature_fraction': 0.9920904896246481, 'bagging_fraction': 0.7960648712009875, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,369] Trial 11 finished with value: 0.7824074074074074 and parameters: {'num_leaves': 298, 'learning_rate': 0.16085084734383936, 'feature_fraction': 0.9807110272924188, 'bagging_fraction': 0.8332088652451091, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,391] Trial 12 finished with value: 0.8148148148148148 and parameters: {'num_leaves': 294, 'learning_rate': 0.15985943487014584, 'feature_fraction': 0.869054958552134, 'bagging_fraction': 0.7723671436012356, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,422] Trial 13 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 263, 'learning_rate': 0.11462515219565683, 'feature_fraction': 0.8766354186029659, 'bagging_fraction': 0.9688894099511817, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,475] Trial 14 finished with value: 0.7592592592592593 and parameters: {'num_leaves': 183, 'learning_rate': 0.1166476085147578, 'feature_fraction': 0.906298886967344, 'bagging_fraction': 0.7608818926428764, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,487] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 266, 'learning_rate': 0.18587605049140313, 'feature_fraction': 0.7697220684720314, 'bagging_fraction': 0.41817421138526273, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,521] Trial 16 finished with value: 0.7685185185185186 and parameters: {'num_leaves': 183, 'learning_rate': 0.19398660850640517, 'feature_fraction': 0.9881978430154429, 'bagging_fraction': 0.8906982639699379, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,541] Trial 17 finished with value: 0.7291666666666666 and parameters: {'num_leaves': 264, 'learning_rate': 0.12608134807895724, 'feature_fraction': 0.9210521169206016, 'bagging_fraction': 0.7802596011179137, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,588] Trial 18 finished with value: 0.7962962962962963 and parameters: {'num_leaves': 209, 'learning_rate': 0.09202007483524811, 'feature_fraction': 0.8158478848353998, 'bagging_fraction': 0.914613015236428, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,614] Trial 19 finished with value: 0.7546296296296297 and parameters: {'num_leaves': 299, 'learning_rate': 0.02700049246972898, 'feature_fraction': 0.6538106363247376, 'bagging_fraction': 0.8278319051497385, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,627] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 156, 'learning_rate': 0.1453792274591093, 'feature_fraction': 0.9256305347256314, 'bagging_fraction': 0.7136635541102824, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,654] Trial 21 finished with value: 0.8009259259259259 and parameters: {'num_leaves': 277, 'learning_rate': 0.164573882685415, 'feature_fraction': 0.8539050457178654, 'bagging_fraction': 0.7998340794495102, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 10 with value: 0.8333333333333333.
[I 2025-09-17 13:19:01,675] Trial 22 finished with value: 0.8425925925925926 and parameters: {'num_leaves': 284, 'learning_rate': 0.18999082853366775, 'feature_fraction': 0.7724633020023035, 'bagging_fraction': 0.726503765832406, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,698] Trial 23 finished with value: 0.7129629629629629 and parameters: {'num_leaves': 240, 'learning_rate': 0.1977261651583702, 'feature_fraction': 0.7552297706373146, 'bagging_fraction': 0.7306544212342894, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,741] Trial 24 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 252, 'learning_rate': 0.14088423237658587, 'feature_fraction': 0.9406158250596766, 'bagging_fraction': 0.9385885638988137, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,753] Trial 25 finished with value: 0.5 and parameters: {'num_leaves': 277, 'learning_rate': 0.1811166747690706, 'feature_fraction': 0.8354881447538625, 'bagging_fraction': 0.8243997865879147, 'bagging_freq': 2, 'min_child_samples': 97}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,776] Trial 26 finished with value: 0.787037037037037 and parameters: {'num_leaves': 213, 'learning_rate': 0.09683287857833216, 'feature_fraction': 0.7713377226588601, 'bagging_fraction': 0.8619399064519527, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,874] Trial 27 finished with value: 0.7870370370370371 and parameters: {'num_leaves': 283, 'learning_rate': 0.21568241156493034, 'feature_fraction': 0.6138510425840911, 'bagging_fraction': 0.6709316284822666, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,893] Trial 28 finished with value: 0.6342592592592593 and parameters: {'num_leaves': 248, 'learning_rate': 0.26438842484326364, 'feature_fraction': 0.9447137421638572, 'bagging_fraction': 0.9487969607995923, 'bagging_freq': 1, 'min_child_samples': 58}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,907] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 72, 'learning_rate': 0.21758507307682212, 'feature_fraction': 0.7073108888493957, 'bagging_fraction': 0.6746095386501632, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,940] Trial 30 finished with value: 0.7175925925925927 and parameters: {'num_leaves': 164, 'learning_rate': 0.1331105016907615, 'feature_fraction': 0.8922955659006787, 'bagging_fraction': 0.6227792348946968, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,964] Trial 31 finished with value: 0.7916666666666666 and parameters: {'num_leaves': 286, 'learning_rate': 0.16205713856114382, 'feature_fraction': 0.864251415213548, 'bagging_fraction': 0.7539269898037009, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:01,995] Trial 32 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 300, 'learning_rate': 0.1730611628273395, 'feature_fraction': 0.798154398171298, 'bagging_fraction': 0.8006070829805279, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,043] Trial 33 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 258, 'learning_rate': 0.23754626050896788, 'feature_fraction': 0.9978585429789709, 'bagging_fraction': 0.8512134535786537, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,058] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.14604231719160216, 'feature_fraction': 0.9567880866411178, 'bagging_fraction': 0.727076670043653, 'bagging_freq': 1, 'min_child_samples': 55}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,076] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 280, 'learning_rate': 0.20407295911200568, 'feature_fraction': 0.7362854251836838, 'bagging_fraction': 0.6110100712527963, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,118] Trial 36 finished with value: 0.7361111111111112 and parameters: {'num_leaves': 200, 'learning_rate': 0.09679822105905528, 'feature_fraction': 0.8491195822072137, 'bagging_fraction': 0.7704087744241083, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,143] Trial 37 finished with value: 0.7685185185185185 and parameters: {'num_leaves': 97, 'learning_rate': 0.23073672118534763, 'feature_fraction': 0.896976134013505, 'bagging_fraction': 0.8866882088721222, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,188] Trial 38 finished with value: 0.8148148148148149 and parameters: {'num_leaves': 137, 'learning_rate': 0.17913814815337986, 'feature_fraction': 0.8057781812014445, 'bagging_fraction': 0.9936526436349978, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,238] Trial 39 finished with value: 0.6666666666666667 and parameters: {'num_leaves': 129, 'learning_rate': 0.2538664348582849, 'feature_fraction': 0.5388791519969268, 'bagging_fraction': 0.984201861892378, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,282] Trial 40 finished with value: 0.7407407407407407 and parameters: {'num_leaves': 134, 'learning_rate': 0.17625679126968596, 'feature_fraction': 0.7972250433456413, 'bagging_fraction': 0.9966442143975697, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,308] Trial 41 finished with value: 0.7546296296296297 and parameters: {'num_leaves': 108, 'learning_rate': 0.15329849747004304, 'feature_fraction': 0.8316344332597135, 'bagging_fraction': 0.9416363160869107, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,332] Trial 42 finished with value: 0.7453703703703703 and parameters: {'num_leaves': 30, 'learning_rate': 0.12911077106335894, 'feature_fraction': 0.8732663932823557, 'bagging_fraction': 0.9142716736772908, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,354] Trial 43 finished with value: 0.6805555555555556 and parameters: {'num_leaves': 10, 'learning_rate': 0.20860677438523348, 'feature_fraction': 0.7278590343489634, 'bagging_fraction': 0.6995188616649963, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,381] Trial 44 finished with value: 0.7777777777777777 and parameters: {'num_leaves': 226, 'learning_rate': 0.10534838047787073, 'feature_fraction': 0.9610101217577868, 'bagging_fraction': 0.8015372393290583, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,403] Trial 45 finished with value: 0.6435185185185185 and parameters: {'num_leaves': 144, 'learning_rate': 0.07725499577665196, 'feature_fraction': 0.809981379035125, 'bagging_fraction': 0.8613143402564575, 'bagging_freq': 3, 'min_child_samples': 52}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,451] Trial 46 finished with value: 0.787037037037037 and parameters: {'num_leaves': 165, 'learning_rate': 0.1876354391590444, 'feature_fraction': 0.6801998341813084, 'bagging_fraction': 0.4990937618798733, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,501] Trial 47 finished with value: 0.7916666666666666 and parameters: {'num_leaves': 289, 'learning_rate': 0.16899914713902228, 'feature_fraction': 0.8938720757312449, 'bagging_fraction': 0.9640469867109901, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,541] Trial 48 finished with value: 0.736111111111111 and parameters: {'num_leaves': 269, 'learning_rate': 0.15296660586159802, 'feature_fraction': 0.7756358375760073, 'bagging_fraction': 0.7467081336305461, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,580] Trial 49 finished with value: 0.736111111111111 and parameters: {'num_leaves': 238, 'learning_rate': 0.12502697332579552, 'feature_fraction': 0.9187086957492521, 'bagging_fraction': 0.9053139295095828, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 22 with value: 0.8425925925925926.
[I 2025-09-17 13:19:02,869] A new study created in memory with name: no-name-65ffe283-ee6a-43bf-ac8a-49db9a55fedb
[I 2025-09-17 13:19:02,880] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 102, 'learning_rate': 0.012021435441743479, 'feature_fraction': 0.8786234797819474, 'bagging_fraction': 0.4767715556930474, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:02,888] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 197, 'learning_rate': 0.04848008463076207, 'feature_fraction': 0.8033682278141105, 'bagging_fraction': 0.9286902843495684, 'bagging_freq': 6, 'min_child_samples': 73}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:02,896] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 13, 'learning_rate': 0.18494360896077705, 'feature_fraction': 0.6075515169834781, 'bagging_fraction': 0.850276637215354, 'bagging_freq': 5, 'min_child_samples': 70}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:02,904] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 76, 'learning_rate': 0.23027661609832217, 'feature_fraction': 0.9824330080436949, 'bagging_fraction': 0.7045508265724503, 'bagging_freq': 2, 'min_child_samples': 75}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:02,912] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.1276307303636925, 'feature_fraction': 0.566858687715759, 'bagging_fraction': 0.505855016022273, 'bagging_freq': 3, 'min_child_samples': 100}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:02,923] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 57, 'learning_rate': 0.19736043477523035, 'feature_fraction': 0.4045511343224307, 'bagging_fraction': 0.8925930787781344, 'bagging_freq': 4, 'min_child_samples': 90}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:02,930] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 152, 'learning_rate': 0.20414206389446282, 'feature_fraction': 0.7169114414431634, 'bagging_fraction': 0.8978173560811588, 'bagging_freq': 6, 'min_child_samples': 90}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:02,954] Trial 7 finished with value: 0.6712962962962963 and parameters: {'num_leaves': 162, 'learning_rate': 0.08403364967330555, 'feature_fraction': 0.519086827806539, 'bagging_fraction': 0.8488503111651728, 'bagging_freq': 1, 'min_child_samples': 43}. Best is trial 7 with value: 0.6712962962962963.
[I 2025-09-17 13:19:02,963] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 234, 'learning_rate': 0.2021592972164756, 'feature_fraction': 0.5560201979521993, 'bagging_fraction': 0.7255984741114048, 'bagging_freq': 5, 'min_child_samples': 85}. Best is trial 7 with value: 0.6712962962962963.
[I 2025-09-17 13:19:02,969] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 129, 'learning_rate': 0.23058809365438038, 'feature_fraction': 0.901172220738962, 'bagging_fraction': 0.634198838554703, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 7 with value: 0.6712962962962963.
[I 2025-09-17 13:19:03,006] Trial 10 finished with value: 0.7962962962962963 and parameters: {'num_leaves': 283, 'learning_rate': 0.10125691255171834, 'feature_fraction': 0.40976878235646924, 'bagging_fraction': 0.993427580005306, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,051] Trial 11 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 299, 'learning_rate': 0.10818086145862374, 'feature_fraction': 0.40101681387538257, 'bagging_fraction': 0.9825649585956275, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,144] Trial 12 finished with value: 0.787037037037037 and parameters: {'num_leaves': 292, 'learning_rate': 0.12330883240685414, 'feature_fraction': 0.40414515842975945, 'bagging_fraction': 0.9857801960548258, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,248] Trial 13 finished with value: 0.7592592592592593 and parameters: {'num_leaves': 295, 'learning_rate': 0.2843046964175348, 'feature_fraction': 0.48705529131669334, 'bagging_fraction': 0.9654268598034922, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,274] Trial 14 finished with value: 0.787037037037037 and parameters: {'num_leaves': 248, 'learning_rate': 0.15105636445214815, 'feature_fraction': 0.6589595243488309, 'bagging_fraction': 0.7999985061796792, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,425] Trial 15 finished with value: 0.7685185185185185 and parameters: {'num_leaves': 253, 'learning_rate': 0.06366419691775914, 'feature_fraction': 0.47276540986550275, 'bagging_fraction': 0.9986598845483015, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,447] Trial 16 finished with value: 0.7037037037037036 and parameters: {'num_leaves': 267, 'learning_rate': 0.11687909710905049, 'feature_fraction': 0.45551072162532036, 'bagging_fraction': 0.6022876407637873, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,478] Trial 17 finished with value: 0.7685185185185186 and parameters: {'num_leaves': 221, 'learning_rate': 0.15260200243239727, 'feature_fraction': 0.7164905514608177, 'bagging_fraction': 0.7873168307018437, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,526] Trial 18 finished with value: 0.775462962962963 and parameters: {'num_leaves': 276, 'learning_rate': 0.08478404390051243, 'feature_fraction': 0.610179788711788, 'bagging_fraction': 0.8131229525061981, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,542] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 208, 'learning_rate': 0.017924112128184094, 'feature_fraction': 0.4432520028010533, 'bagging_fraction': 0.4038482794859353, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 10 with value: 0.7962962962962963.
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.498905
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.553068
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.529365
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.598094
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.596277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.559239
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.583368
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.549451
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.583299
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.531427
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.508126
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.6056
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.552478
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.539179
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.591971
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.614329
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.57396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.546295
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.557431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.603033
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.568993
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.542657
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.516715
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.632771
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.586193
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.568955
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.569559
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.605846
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.555337
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.637194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.537332
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.530692
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.568684
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.585772
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.617947
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.537548
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.562077
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.5287
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.556703
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.532128
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.555668
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.605067
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.561472
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.55148
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.673596
[I 2025-09-17 13:19:03,558] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 280, 'learning_rate': 0.1338893231822425, 'feature_fraction': 0.5153629832234551, 'bagging_fraction': 0.9240254387352171, 'bagging_freq': 3, 'min_child_samples': 60}. Best is trial 10 with value: 0.7962962962962963.
[I 2025-09-17 13:19:03,591] Trial 21 finished with value: 0.8101851851851852 and parameters: {'num_leaves': 245, 'learning_rate': 0.1628252557579444, 'feature_fraction': 0.6763391998812516, 'bagging_fraction': 0.7621851860180235, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 21 with value: 0.8101851851851852.
[I 2025-09-17 13:19:03,626] Trial 22 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 245, 'learning_rate': 0.16728075604417275, 'feature_fraction': 0.8219547707740276, 'bagging_fraction': 0.6045585209760449, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 21 with value: 0.8101851851851852.
[I 2025-09-17 13:19:03,646] Trial 23 finished with value: 0.625 and parameters: {'num_leaves': 239, 'learning_rate': 0.16346975924140741, 'feature_fraction': 0.7840381426007504, 'bagging_fraction': 0.6224963471684541, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 21 with value: 0.8101851851851852.
[I 2025-09-17 13:19:03,686] Trial 24 finished with value: 0.8703703703703703 and parameters: {'num_leaves': 179, 'learning_rate': 0.1744512453051706, 'feature_fraction': 0.7937643139574273, 'bagging_fraction': 0.5662031303000974, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 24 with value: 0.8703703703703703.
[I 2025-09-17 13:19:03,718] Trial 25 finished with value: 0.8101851851851852 and parameters: {'num_leaves': 184, 'learning_rate': 0.24219972819810875, 'feature_fraction': 0.7944726436803329, 'bagging_fraction': 0.5629943766193198, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 24 with value: 0.8703703703703703.
[I 2025-09-17 13:19:03,739] Trial 26 finished with value: 0.7453703703703703 and parameters: {'num_leaves': 175, 'learning_rate': 0.286927298467325, 'feature_fraction': 0.7594025255650971, 'bagging_fraction': 0.5362009429543095, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 24 with value: 0.8703703703703703.
[I 2025-09-17 13:19:03,757] Trial 27 finished with value: 0.650462962962963 and parameters: {'num_leaves': 130, 'learning_rate': 0.2360492583955358, 'feature_fraction': 0.8609632985950895, 'bagging_fraction': 0.6731979109078071, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 24 with value: 0.8703703703703703.
[I 2025-09-17 13:19:03,771] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 208, 'learning_rate': 0.2619607588975869, 'feature_fraction': 0.6806768952811592, 'bagging_fraction': 0.4631761897441152, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 24 with value: 0.8703703703703703.
[I 2025-09-17 13:19:03,816] Trial 29 finished with value: 0.8703703703703705 and parameters: {'num_leaves': 124, 'learning_rate': 0.2519248106932472, 'feature_fraction': 0.9299002623332165, 'bagging_fraction': 0.5518757055924067, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:03,828] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 110, 'learning_rate': 0.1864560407757172, 'feature_fraction': 0.9651793905665494, 'bagging_fraction': 0.4295124197154516, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:03,860] Trial 31 finished with value: 0.7175925925925926 and parameters: {'num_leaves': 138, 'learning_rate': 0.25371931766521294, 'feature_fraction': 0.9079970421140884, 'bagging_fraction': 0.5425456867662531, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:03,882] Trial 32 finished with value: 0.7175925925925926 and parameters: {'num_leaves': 99, 'learning_rate': 0.2537079260682755, 'feature_fraction': 0.834842247680736, 'bagging_fraction': 0.5662348035226216, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:03,920] Trial 33 finished with value: 0.7638888888888888 and parameters: {'num_leaves': 189, 'learning_rate': 0.29946916383154515, 'feature_fraction': 0.7481211079204851, 'bagging_fraction': 0.7453476473353472, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:03,941] Trial 34 finished with value: 0.6990740740740741 and parameters: {'num_leaves': 165, 'learning_rate': 0.20890925879795114, 'feature_fraction': 0.9410696679153276, 'bagging_fraction': 0.6746499185377182, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:03,964] Trial 35 finished with value: 0.6875 and parameters: {'num_leaves': 74, 'learning_rate': 0.2178069341526545, 'feature_fraction': 0.7853800032169767, 'bagging_fraction': 0.485769491579801, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:03,999] Trial 36 finished with value: 0.6018518518518519 and parameters: {'num_leaves': 112, 'learning_rate': 0.2681011747981126, 'feature_fraction': 0.8654093220254069, 'bagging_fraction': 0.5691799244665972, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,012] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 38, 'learning_rate': 0.1828939162660327, 'feature_fraction': 0.6506904251204546, 'bagging_fraction': 0.6579028495501392, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,043] Trial 38 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 201, 'learning_rate': 0.13968000127014477, 'feature_fraction': 0.99163056676727, 'bagging_fraction': 0.5188928032460141, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,064] Trial 39 finished with value: 0.6157407407407407 and parameters: {'num_leaves': 140, 'learning_rate': 0.23928605233320951, 'feature_fraction': 0.7488179873565979, 'bagging_fraction': 0.5739759874116009, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,097] Trial 40 finished with value: 0.8055555555555555 and parameters: {'num_leaves': 154, 'learning_rate': 0.21821559696549506, 'feature_fraction': 0.6266522871140634, 'bagging_fraction': 0.7624244159897817, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,131] Trial 41 finished with value: 0.7731481481481481 and parameters: {'num_leaves': 217, 'learning_rate': 0.16225551134438754, 'feature_fraction': 0.8195370576744454, 'bagging_fraction': 0.5932138320556478, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,163] Trial 42 finished with value: 0.7569444444444444 and parameters: {'num_leaves': 181, 'learning_rate': 0.1720905640078833, 'feature_fraction': 0.8380366603363097, 'bagging_fraction': 0.7036783349281889, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,224] Trial 43 finished with value: 0.7453703703703703 and parameters: {'num_leaves': 228, 'learning_rate': 0.18218636221993245, 'feature_fraction': 0.8998067830880132, 'bagging_fraction': 0.6351860302139565, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,254] Trial 44 finished with value: 0.8101851851851851 and parameters: {'num_leaves': 262, 'learning_rate': 0.19160627259905913, 'feature_fraction': 0.7998241099079226, 'bagging_fraction': 0.4757134591288564, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,277] Trial 45 finished with value: 0.7870370370370371 and parameters: {'num_leaves': 259, 'learning_rate': 0.2204094650831388, 'feature_fraction': 0.6942814834244958, 'bagging_fraction': 0.4986750739578707, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,290] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.19918124968022843, 'feature_fraction': 0.7815205152534194, 'bagging_fraction': 0.46208531667536024, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,308] Trial 47 finished with value: 0.5231481481481481 and parameters: {'num_leaves': 192, 'learning_rate': 0.24849041700274627, 'feature_fraction': 0.9310855963446701, 'bagging_fraction': 0.4356806576949874, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,345] Trial 48 finished with value: 0.7106481481481483 and parameters: {'num_leaves': 170, 'learning_rate': 0.14276018096158927, 'feature_fraction': 0.7228061394697368, 'bagging_fraction': 0.5207953069315429, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,365] Trial 49 finished with value: 0.7453703703703702 and parameters: {'num_leaves': 149, 'learning_rate': 0.267372225802515, 'feature_fraction': 0.8030094667440881, 'bagging_fraction': 0.8464833454759818, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 29 with value: 0.8703703703703705.
[I 2025-09-17 13:19:04,569] A new study created in memory with name: no-name-1d910291-128e-4bf2-bc8e-dda1a1c5384d
[I 2025-09-17 13:19:04,578] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 196, 'learning_rate': 0.14284997631868415, 'feature_fraction': 0.8475499508009698, 'bagging_fraction': 0.5341241312149405, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:04,721] Trial 1 finished with value: 0.8935185185185186 and parameters: {'num_leaves': 70, 'learning_rate': 0.09523622971308848, 'feature_fraction': 0.7931694288973656, 'bagging_fraction': 0.9125137557417294, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,749] Trial 2 finished with value: 0.6527777777777778 and parameters: {'num_leaves': 55, 'learning_rate': 0.07159533852157866, 'feature_fraction': 0.8726337319827169, 'bagging_fraction': 0.5191380429901831, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,762] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 146, 'learning_rate': 0.05477736963138319, 'feature_fraction': 0.43014743123624, 'bagging_fraction': 0.5489764224408288, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,772] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 100, 'learning_rate': 0.21193206872416126, 'feature_fraction': 0.6118251968450812, 'bagging_fraction': 0.46464945479573055, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,780] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 239, 'learning_rate': 0.09885710251361311, 'feature_fraction': 0.47152975254296414, 'bagging_fraction': 0.5981675583278191, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,788] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 49, 'learning_rate': 0.0588990142940268, 'feature_fraction': 0.7948471720592291, 'bagging_fraction': 0.6948784853914142, 'bagging_freq': 4, 'min_child_samples': 89}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,793] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 296, 'learning_rate': 0.14145347837738298, 'feature_fraction': 0.4093616317729362, 'bagging_fraction': 0.9693423555468886, 'bagging_freq': 5, 'min_child_samples': 95}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,803] Trial 8 finished with value: 0.5856481481481481 and parameters: {'num_leaves': 292, 'learning_rate': 0.04163626985387973, 'feature_fraction': 0.5700990757970332, 'bagging_fraction': 0.8993046635489146, 'bagging_freq': 1, 'min_child_samples': 57}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,816] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 133, 'learning_rate': 0.16688420371002136, 'feature_fraction': 0.45017002853705446, 'bagging_fraction': 0.4744464358568157, 'bagging_freq': 5, 'min_child_samples': 92}. Best is trial 1 with value: 0.8935185185185186.
[I 2025-09-17 13:19:04,920] Trial 10 finished with value: 0.9490740740740742 and parameters: {'num_leaves': 22, 'learning_rate': 0.2904791507393939, 'feature_fraction': 0.9982142955648057, 'bagging_fraction': 0.8509341616260888, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:04,985] Trial 11 finished with value: 0.8981481481481481 and parameters: {'num_leaves': 11, 'learning_rate': 0.29363290084621096, 'feature_fraction': 0.9806825986527317, 'bagging_fraction': 0.8372017618134874, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,068] Trial 12 finished with value: 0.9398148148148148 and parameters: {'num_leaves': 12, 'learning_rate': 0.2997431753860233, 'feature_fraction': 0.9666958274748341, 'bagging_fraction': 0.8094410520328859, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,112] Trial 13 finished with value: 0.9027777777777778 and parameters: {'num_leaves': 13, 'learning_rate': 0.2992399169658986, 'feature_fraction': 0.9996537153236237, 'bagging_fraction': 0.7698853259784337, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,152] Trial 14 finished with value: 0.9027777777777778 and parameters: {'num_leaves': 96, 'learning_rate': 0.24338746602070294, 'feature_fraction': 0.938790115942993, 'bagging_fraction': 0.7176606161788491, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,166] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 38, 'learning_rate': 0.24563657731904365, 'feature_fraction': 0.6980349011516087, 'bagging_fraction': 0.8209645359095523, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,220] Trial 16 finished with value: 0.925925925925926 and parameters: {'num_leaves': 98, 'learning_rate': 0.25845373884112255, 'feature_fraction': 0.9092910111135584, 'bagging_fraction': 0.6610790059726082, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,249] Trial 17 finished with value: 0.8240740740740741 and parameters: {'num_leaves': 184, 'learning_rate': 0.1972933553515506, 'feature_fraction': 0.7415023979543315, 'bagging_fraction': 0.9817818327762855, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,271] Trial 18 finished with value: 0.5740740740740742 and parameters: {'num_leaves': 73, 'learning_rate': 0.012800118300897556, 'feature_fraction': 0.9268753070952298, 'bagging_fraction': 0.8064502920618493, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,319] Trial 19 finished with value: 0.9120370370370371 and parameters: {'num_leaves': 30, 'learning_rate': 0.2632370153363941, 'feature_fraction': 0.8363316960709932, 'bagging_fraction': 0.883761350147718, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,346] Trial 20 finished with value: 0.8287037037037037 and parameters: {'num_leaves': 121, 'learning_rate': 0.21731852641439264, 'feature_fraction': 0.6653680020109778, 'bagging_fraction': 0.7582452058684388, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,403] Trial 21 finished with value: 0.9074074074074073 and parameters: {'num_leaves': 91, 'learning_rate': 0.2735628311256558, 'feature_fraction': 0.9206341098256077, 'bagging_fraction': 0.6553724091574773, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,440] Trial 22 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 32, 'learning_rate': 0.2663238409190039, 'feature_fraction': 0.896780659376361, 'bagging_fraction': 0.6359070232743992, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,562] Trial 23 finished with value: 0.9120370370370371 and parameters: {'num_leaves': 67, 'learning_rate': 0.2371479434817273, 'feature_fraction': 0.9638740375247198, 'bagging_fraction': 0.728234556953133, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,615] Trial 24 finished with value: 0.8842592592592593 and parameters: {'num_leaves': 165, 'learning_rate': 0.28601884104593195, 'feature_fraction': 0.9920165432693835, 'bagging_fraction': 0.8652328424330517, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,649] Trial 25 finished with value: 0.8194444444444444 and parameters: {'num_leaves': 111, 'learning_rate': 0.17763193390551457, 'feature_fraction': 0.8868853679405728, 'bagging_fraction': 0.7822089173809953, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,661] Trial 26 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.2599876892467447, 'feature_fraction': 0.8272637058804134, 'bagging_fraction': 0.933423582901465, 'bagging_freq': 7, 'min_child_samples': 68}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,700] Trial 27 finished with value: 0.9027777777777778 and parameters: {'num_leaves': 78, 'learning_rate': 0.29943819262847493, 'feature_fraction': 0.9463162400255472, 'bagging_fraction': 0.6532862735236599, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 10 with value: 0.9490740740740742.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.533639
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.525746
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.628466
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.461936
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.508829
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.593392
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.647864
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.507649
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.603732
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.589764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.592253
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.598294
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.628101
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.662387
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.559605
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.641795
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.519795
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.561234
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.568749
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.59851
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.542034
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.557254
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.665428
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.615059
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.602503
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.381884
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.610594
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.67083
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.278646
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.395035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.330556
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.399143
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.425126
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.361617
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.496878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.653523
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.363152
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.464044
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.427297
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.531051
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.385796
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.427481
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.471844
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.416392
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:05,727] Trial 28 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 48, 'learning_rate': 0.22860369991137675, 'feature_fraction': 0.7574948196961503, 'bagging_fraction': 0.8485032694734735, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,753] Trial 29 finished with value: 0.6712962962962963 and parameters: {'num_leaves': 215, 'learning_rate': 0.2778279795679319, 'feature_fraction': 0.8628589761437842, 'bagging_fraction': 0.5946844023199134, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,774] Trial 30 finished with value: 0.6574074074074074 and parameters: {'num_leaves': 28, 'learning_rate': 0.19591782281901, 'feature_fraction': 0.9545688307350279, 'bagging_fraction': 0.6930924922005925, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,818] Trial 31 finished with value: 0.8287037037037037 and parameters: {'num_leaves': 31, 'learning_rate': 0.25949219844225596, 'feature_fraction': 0.8336652594134747, 'bagging_fraction': 0.8759954465203417, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,920] Trial 32 finished with value: 0.9027777777777779 and parameters: {'num_leaves': 58, 'learning_rate': 0.26245075408383134, 'feature_fraction': 0.9127780583310251, 'bagging_fraction': 0.9432753845311003, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:05,975] Trial 33 finished with value: 0.8842592592592593 and parameters: {'num_leaves': 26, 'learning_rate': 0.1369830525125636, 'feature_fraction': 0.808908852546711, 'bagging_fraction': 0.9017693752780481, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,039] Trial 34 finished with value: 0.8472222222222222 and parameters: {'num_leaves': 84, 'learning_rate': 0.280285473427726, 'feature_fraction': 0.8883232681677806, 'bagging_fraction': 0.7991524004259145, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,082] Trial 35 finished with value: 0.8981481481481481 and parameters: {'num_leaves': 50, 'learning_rate': 0.2544573126196163, 'feature_fraction': 0.9648534020302063, 'bagging_fraction': 0.7313401418998715, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,135] Trial 36 finished with value: 0.8564814814814815 and parameters: {'num_leaves': 151, 'learning_rate': 0.22444710781218666, 'feature_fraction': 0.8594391082927768, 'bagging_fraction': 0.42309983754052694, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,172] Trial 37 finished with value: 0.8564814814814815 and parameters: {'num_leaves': 56, 'learning_rate': 0.2813924022750546, 'feature_fraction': 0.7489463224693306, 'bagging_fraction': 0.8739442810568137, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,232] Trial 38 finished with value: 0.9027777777777779 and parameters: {'num_leaves': 108, 'learning_rate': 0.09971693461025073, 'feature_fraction': 0.8495939426883407, 'bagging_fraction': 0.9323743283494268, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,357] Trial 39 finished with value: 0.8842592592592593 and parameters: {'num_leaves': 43, 'learning_rate': 0.20892434593407475, 'feature_fraction': 0.7768823608336051, 'bagging_fraction': 0.998198584664313, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,376] Trial 40 finished with value: 0.6782407407407407 and parameters: {'num_leaves': 269, 'learning_rate': 0.2434505626712626, 'feature_fraction': 0.9091631256325644, 'bagging_fraction': 0.5655929007525886, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,451] Trial 41 finished with value: 0.9074074074074074 and parameters: {'num_leaves': 68, 'learning_rate': 0.23652055740892036, 'feature_fraction': 0.9620204946927364, 'bagging_fraction': 0.7439632235098343, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,530] Trial 42 finished with value: 0.7175925925925926 and parameters: {'num_leaves': 66, 'learning_rate': 0.2878684209572606, 'feature_fraction': 0.9738188621851933, 'bagging_fraction': 0.7064241802500104, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,576] Trial 43 finished with value: 0.898148148148148 and parameters: {'num_leaves': 22, 'learning_rate': 0.27049781052414784, 'feature_fraction': 0.9971537791351137, 'bagging_fraction': 0.828141136573587, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,628] Trial 44 finished with value: 0.8564814814814815 and parameters: {'num_leaves': 42, 'learning_rate': 0.2507545222813287, 'feature_fraction': 0.9432683358951067, 'bagging_fraction': 0.6886740403152922, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,703] Trial 45 finished with value: 0.8888888888888888 and parameters: {'num_leaves': 22, 'learning_rate': 0.11710333812533899, 'feature_fraction': 0.5658908450472531, 'bagging_fraction': 0.7828039156575805, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,716] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 134, 'learning_rate': 0.23580766683892695, 'feature_fraction': 0.8820972219447447, 'bagging_fraction': 0.6237377854430193, 'bagging_freq': 6, 'min_child_samples': 81}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,749] Trial 47 finished with value: 0.8287037037037036 and parameters: {'num_leaves': 69, 'learning_rate': 0.2941167669247789, 'feature_fraction': 0.9226806171357451, 'bagging_fraction': 0.5079665501215417, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,830] Trial 48 finished with value: 0.925925925925926 and parameters: {'num_leaves': 85, 'learning_rate': 0.19629361464500156, 'feature_fraction': 0.9751851253534566, 'bagging_fraction': 0.6682910614989233, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:06,873] Trial 49 finished with value: 0.8981481481481481 and parameters: {'num_leaves': 170, 'learning_rate': 0.15348346913918304, 'feature_fraction': 0.49078086423456735, 'bagging_fraction': 0.6727411842070182, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 10 with value: 0.9490740740740742.
[I 2025-09-17 13:19:07,092] A new study created in memory with name: no-name-c5246d5f-8b77-4e75-aad6-fcddb5afc3e9
[I 2025-09-17 13:19:07,102] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.045895744652892506, 'feature_fraction': 0.7934694839646106, 'bagging_fraction': 0.7916625004944619, 'bagging_freq': 1, 'min_child_samples': 87}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:07,120] Trial 1 finished with value: 0.625 and parameters: {'num_leaves': 14, 'learning_rate': 0.026770101225129857, 'feature_fraction': 0.627724807505023, 'bagging_fraction': 0.8462077141302289, 'bagging_freq': 3, 'min_child_samples': 46}. Best is trial 1 with value: 0.625.
[I 2025-09-17 13:19:07,137] Trial 2 finished with value: 0.5982142857142857 and parameters: {'num_leaves': 143, 'learning_rate': 0.039856591986549235, 'feature_fraction': 0.4717483781210966, 'bagging_fraction': 0.9424885898151675, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial 1 with value: 0.625.
[I 2025-09-17 13:19:07,149] Trial 3 finished with value: 0.4375 and parameters: {'num_leaves': 261, 'learning_rate': 0.11920543658568433, 'feature_fraction': 0.7604761025324829, 'bagging_fraction': 0.4325234602442876, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 1 with value: 0.625.
[I 2025-09-17 13:19:07,161] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 152, 'learning_rate': 0.1848907956717499, 'feature_fraction': 0.6124631876518873, 'bagging_fraction': 0.5457659530274942, 'bagging_freq': 7, 'min_child_samples': 63}. Best is trial 1 with value: 0.625.
[I 2025-09-17 13:19:07,171] Trial 5 finished with value: 0.75 and parameters: {'num_leaves': 250, 'learning_rate': 0.19630775490296193, 'feature_fraction': 0.752852819926479, 'bagging_fraction': 0.9344521791937849, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 5 with value: 0.75.
[I 2025-09-17 13:19:07,178] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.0759973276182136, 'feature_fraction': 0.6229337842726215, 'bagging_fraction': 0.43445111626394173, 'bagging_freq': 4, 'min_child_samples': 83}. Best is trial 5 with value: 0.75.
[I 2025-09-17 13:19:07,188] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 286, 'learning_rate': 0.14273129681414803, 'feature_fraction': 0.5129869060913588, 'bagging_fraction': 0.8130137136138555, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 5 with value: 0.75.
[I 2025-09-17 13:19:07,194] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 86, 'learning_rate': 0.20935210644421018, 'feature_fraction': 0.7518499334182095, 'bagging_fraction': 0.8427010215912043, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial 5 with value: 0.75.
[I 2025-09-17 13:19:07,300] Trial 9 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 266, 'learning_rate': 0.16112471057417915, 'feature_fraction': 0.5203561069636282, 'bagging_fraction': 0.4629143013503325, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 9 with value: 0.9642857142857143.
[I 2025-09-17 13:19:07,342] Trial 10 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 205, 'learning_rate': 0.2874484977242105, 'feature_fraction': 0.954703122264947, 'bagging_fraction': 0.6230579285900337, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 9 with value: 0.9642857142857143.
[I 2025-09-17 13:19:07,392] Trial 11 finished with value: 0.8392857142857142 and parameters: {'num_leaves': 190, 'learning_rate': 0.2934946513875811, 'feature_fraction': 0.9389307702879367, 'bagging_fraction': 0.6036960349448711, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 9 with value: 0.9642857142857143.
[I 2025-09-17 13:19:07,444] Trial 12 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 299, 'learning_rate': 0.2977966582613777, 'feature_fraction': 0.968473964267071, 'bagging_fraction': 0.628011179887117, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 9 with value: 0.9642857142857143.
[I 2025-09-17 13:19:07,468] Trial 13 finished with value: 0.7678571428571428 and parameters: {'num_leaves': 213, 'learning_rate': 0.2487856928099727, 'feature_fraction': 0.8787527702043647, 'bagging_fraction': 0.5240742206362873, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 9 with value: 0.9642857142857143.
[I 2025-09-17 13:19:07,505] Trial 14 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 106, 'learning_rate': 0.10762833092738736, 'feature_fraction': 0.42399730309229905, 'bagging_fraction': 0.7021206217502024, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 9 with value: 0.9642857142857143.
[I 2025-09-17 13:19:07,586] Trial 15 finished with value: 1.0 and parameters: {'num_leaves': 194, 'learning_rate': 0.24658335046870608, 'feature_fraction': 0.8607658880043102, 'bagging_fraction': 0.701923570156363, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,608] Trial 16 finished with value: 0.7321428571428572 and parameters: {'num_leaves': 254, 'learning_rate': 0.23833516334530686, 'feature_fraction': 0.5216860644476924, 'bagging_fraction': 0.723373236610227, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,690] Trial 17 finished with value: 1.0 and parameters: {'num_leaves': 115, 'learning_rate': 0.1594508880387806, 'feature_fraction': 0.8521675947279916, 'bagging_fraction': 0.5211295836341904, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,705] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 90, 'learning_rate': 0.24736002467116042, 'feature_fraction': 0.8603018349769904, 'bagging_fraction': 0.7518963253648668, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,746] Trial 19 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 54, 'learning_rate': 0.2221267737856817, 'feature_fraction': 0.8524602550956377, 'bagging_fraction': 0.5351209165802414, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,768] Trial 20 finished with value: 0.6785714285714286 and parameters: {'num_leaves': 126, 'learning_rate': 0.16743074254789167, 'feature_fraction': 0.6728684821388232, 'bagging_fraction': 0.6693009260354961, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,849] Trial 21 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 173, 'learning_rate': 0.14712823811580675, 'feature_fraction': 0.8154908772649687, 'bagging_fraction': 0.47715621227844046, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,881] Trial 22 finished with value: 0.75 and parameters: {'num_leaves': 172, 'learning_rate': 0.13178084057698553, 'feature_fraction': 0.8060499090164481, 'bagging_fraction': 0.5109750906150161, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,893] Trial 23 finished with value: 0.5 and parameters: {'num_leaves': 164, 'learning_rate': 0.08775554113893841, 'feature_fraction': 0.9069980791950734, 'bagging_fraction': 0.40589879064364837, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:07,971] Trial 24 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 134, 'learning_rate': 0.1763542567602484, 'feature_fraction': 0.8140764346110191, 'bagging_fraction': 0.5696367153348535, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,010] Trial 25 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 112, 'learning_rate': 0.2702273099789094, 'feature_fraction': 0.6963352960819357, 'bagging_fraction': 0.48048715931505614, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,122] Trial 26 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 181, 'learning_rate': 0.08338220329384093, 'feature_fraction': 0.9079086316459964, 'bagging_fraction': 0.659508403796881, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,151] Trial 27 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 59, 'learning_rate': 0.14319602582102695, 'feature_fraction': 0.9890574120718316, 'bagging_fraction': 0.5804211245755508, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,189] Trial 28 finished with value: 1.0 and parameters: {'num_leaves': 220, 'learning_rate': 0.20652224345148418, 'feature_fraction': 0.8560699693490309, 'bagging_fraction': 0.4956100439263743, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,234] Trial 29 finished with value: 0.9107142857142856 and parameters: {'num_leaves': 219, 'learning_rate': 0.21055369916974384, 'feature_fraction': 0.910588961265451, 'bagging_fraction': 0.7637524365542476, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,257] Trial 30 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 236, 'learning_rate': 0.26160785202590453, 'feature_fraction': 0.8516874227347216, 'bagging_fraction': 0.8919453164229526, 'bagging_freq': 7, 'min_child_samples': 32}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,295] Trial 31 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 199, 'learning_rate': 0.19275925232785307, 'feature_fraction': 0.8103134138453093, 'bagging_fraction': 0.48291574498842504, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,341] Trial 32 finished with value: 0.9107142857142858 and parameters: {'num_leaves': 164, 'learning_rate': 0.22656025339777774, 'feature_fraction': 0.7838813164345824, 'bagging_fraction': 0.4925902516071332, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,370] Trial 33 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 238, 'learning_rate': 0.15310871104476995, 'feature_fraction': 0.8245319558094084, 'bagging_fraction': 0.6695777102940261, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,382] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 145, 'learning_rate': 0.11083310427335943, 'feature_fraction': 0.7267989671860133, 'bagging_fraction': 0.4373799381176167, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,454] Trial 35 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 226, 'learning_rate': 0.20502149898966754, 'feature_fraction': 0.8827207435545573, 'bagging_fraction': 0.5640802853030408, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 15 with value: 1.0.
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.607429
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.611653
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.592206
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.514078
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.375772
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.453989
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.533299
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.404476
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.582263
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.459147
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.42753
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.445213
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.647281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.443106
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.607401
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.379789
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.510324
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.432309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.673596
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.48331
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.421288
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.419319
Training model for P071... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.237771
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.239937
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.252482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.232994
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.164328
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.165583
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.210008
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.159658
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.199671
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.168545
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.0988035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.195852
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.118553
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.138576
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.212879
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.137647
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.179059
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.149962
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.176229
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.135476
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.169649
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.160228
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.174788
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.151757
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.18718
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.190091
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.163566
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.156597
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:08,487] Trial 36 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 122, 'learning_rate': 0.1760037963458308, 'feature_fraction': 0.9279547850375416, 'bagging_fraction': 0.40766877534580825, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,506] Trial 37 finished with value: 0.875 and parameters: {'num_leaves': 154, 'learning_rate': 0.051249453806649706, 'feature_fraction': 0.8381343740102571, 'bagging_fraction': 0.5940007452174112, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,525] Trial 38 finished with value: 0.6071428571428572 and parameters: {'num_leaves': 189, 'learning_rate': 0.1263409727416625, 'feature_fraction': 0.7755147668801031, 'bagging_fraction': 0.9836859181665912, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,540] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.18909124911735534, 'feature_fraction': 0.7195837505430935, 'bagging_fraction': 0.45765564419268456, 'bagging_freq': 4, 'min_child_samples': 74}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,609] Trial 40 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 272, 'learning_rate': 0.22714289909266047, 'feature_fraction': 0.6709242816167121, 'bagging_fraction': 0.8001381237209515, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,674] Trial 41 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 224, 'learning_rate': 0.2035753656420929, 'feature_fraction': 0.8692459928095972, 'bagging_fraction': 0.5424357261607764, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,721] Trial 42 finished with value: 0.75 and parameters: {'num_leaves': 199, 'learning_rate': 0.012134525139425673, 'feature_fraction': 0.8880762828983992, 'bagging_fraction': 0.49384147855702804, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,806] Trial 43 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 238, 'learning_rate': 0.15320883095417445, 'feature_fraction': 0.8910113055325091, 'bagging_fraction': 0.5593990478074913, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,885] Trial 44 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 209, 'learning_rate': 0.20885964972173002, 'feature_fraction': 0.9939295657771058, 'bagging_fraction': 0.6329432554510538, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,915] Trial 45 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 176, 'learning_rate': 0.1770102204085638, 'feature_fraction': 0.7497426670843201, 'bagging_fraction': 0.4541995677159002, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,929] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.2610663939761844, 'feature_fraction': 0.9426706653320743, 'bagging_fraction': 0.5104605507206038, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:08,972] Trial 47 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 248, 'learning_rate': 0.23959497607864544, 'feature_fraction': 0.8359024133505482, 'bagging_fraction': 0.5516226980094637, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:09,009] Trial 48 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 278, 'learning_rate': 0.1404124881341497, 'feature_fraction': 0.8050461765350537, 'bagging_fraction': 0.6048931279556906, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:09,075] Trial 49 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 79, 'learning_rate': 0.22043115001632294, 'feature_fraction': 0.9559921858650622, 'bagging_fraction': 0.7268047100946152, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 15 with value: 1.0.
[I 2025-09-17 13:19:09,241] A new study created in memory with name: no-name-3cfaec2a-d7f8-4743-bedf-adcf2fc104b3
[I 2025-09-17 13:19:09,305] Trial 0 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 54, 'learning_rate': 0.2996545379900259, 'feature_fraction': 0.8768214637728686, 'bagging_fraction': 0.8839163879083463, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 0 with value: 0.9464285714285715.
[I 2025-09-17 13:19:09,354] Trial 1 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 138, 'learning_rate': 0.14928049336215538, 'feature_fraction': 0.5088535038641592, 'bagging_fraction': 0.44416046006343135, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,368] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 94, 'learning_rate': 0.05528567873305282, 'feature_fraction': 0.7383536999554584, 'bagging_fraction': 0.6337716229751652, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,383] Trial 3 finished with value: 0.6607142857142857 and parameters: {'num_leaves': 247, 'learning_rate': 0.240842414564209, 'feature_fraction': 0.8720976546163784, 'bagging_fraction': 0.5022976370630341, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,394] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 65, 'learning_rate': 0.018977584253336593, 'feature_fraction': 0.41530120398482295, 'bagging_fraction': 0.4184136374294468, 'bagging_freq': 2, 'min_child_samples': 55}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,406] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.06027283688606677, 'feature_fraction': 0.5597292259793585, 'bagging_fraction': 0.5318557862247374, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,414] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.10305245633233653, 'feature_fraction': 0.7121155957915901, 'bagging_fraction': 0.7462425269085713, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,420] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.245023812674149, 'feature_fraction': 0.7242872653639427, 'bagging_fraction': 0.6504556639664905, 'bagging_freq': 1, 'min_child_samples': 73}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,445] Trial 8 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 241, 'learning_rate': 0.08406583254917797, 'feature_fraction': 0.42665738481422016, 'bagging_fraction': 0.40551979028066687, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,466] Trial 9 finished with value: 0.9553571428571428 and parameters: {'num_leaves': 102, 'learning_rate': 0.134960984560228, 'feature_fraction': 0.7636975228390313, 'bagging_fraction': 0.47180276817833056, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,500] Trial 10 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 179, 'learning_rate': 0.1790682320850873, 'feature_fraction': 0.5708989206602606, 'bagging_fraction': 0.9776125379233083, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,568] Trial 11 finished with value: 0.9375 and parameters: {'num_leaves': 134, 'learning_rate': 0.14907132182264965, 'feature_fraction': 0.9859407012938245, 'bagging_fraction': 0.5589329517844993, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,597] Trial 12 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 15, 'learning_rate': 0.14777117897476666, 'feature_fraction': 0.5951514962696918, 'bagging_fraction': 0.7610996311116396, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,615] Trial 13 finished with value: 0.9553571428571428 and parameters: {'num_leaves': 139, 'learning_rate': 0.19565613892278583, 'feature_fraction': 0.8364037401476333, 'bagging_fraction': 0.48387657845856435, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,631] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.12104706339181508, 'feature_fraction': 0.6402114989343476, 'bagging_fraction': 0.6021461741005723, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,692] Trial 15 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 109, 'learning_rate': 0.2020545208345826, 'feature_fraction': 0.5044400585987913, 'bagging_fraction': 0.46031109347451715, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 1 with value: 0.9821428571428572.
[I 2025-09-17 13:19:09,720] Trial 16 finished with value: 1.0 and parameters: {'num_leaves': 203, 'learning_rate': 0.12837363471970595, 'feature_fraction': 0.8140660130630182, 'bagging_fraction': 0.7034032018172309, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,752] Trial 17 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 207, 'learning_rate': 0.17437882529247853, 'feature_fraction': 0.9676418483623749, 'bagging_fraction': 0.8022846854846027, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,780] Trial 18 finished with value: 0.6964285714285714 and parameters: {'num_leaves': 215, 'learning_rate': 0.09555974851132165, 'feature_fraction': 0.7988628503214578, 'bagging_fraction': 0.6951373060381363, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,805] Trial 19 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 169, 'learning_rate': 0.22800159339253673, 'feature_fraction': 0.6559812143791119, 'bagging_fraction': 0.8189484235158601, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,819] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 297, 'learning_rate': 0.019908398144954986, 'feature_fraction': 0.47851966226844284, 'bagging_fraction': 0.8918663682360594, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,847] Trial 21 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 161, 'learning_rate': 0.23202254559310428, 'feature_fraction': 0.6575251394969934, 'bagging_fraction': 0.8654525304163159, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,866] Trial 22 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 198, 'learning_rate': 0.28102978021329844, 'feature_fraction': 0.6578385087276681, 'bagging_fraction': 0.8222524856797832, 'bagging_freq': 1, 'min_child_samples': 41}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,887] Trial 23 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 157, 'learning_rate': 0.21244512845279917, 'feature_fraction': 0.5163069194179916, 'bagging_fraction': 0.7039663302457103, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,901] Trial 24 finished with value: 0.5 and parameters: {'num_leaves': 128, 'learning_rate': 0.1711907593351708, 'feature_fraction': 0.6102692070977775, 'bagging_fraction': 0.6973405131031004, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:09,994] Trial 25 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 226, 'learning_rate': 0.12035523615708106, 'feature_fraction': 0.9082526976448567, 'bagging_fraction': 0.9531211938240595, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,019] Trial 26 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 174, 'learning_rate': 0.2740560814854048, 'feature_fraction': 0.7730325860847139, 'bagging_fraction': 0.7771263462801102, 'bagging_freq': 1, 'min_child_samples': 36}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,054] Trial 27 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 150, 'learning_rate': 0.16180373204625614, 'feature_fraction': 0.6945602744040605, 'bagging_fraction': 0.8367776426354321, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,108] Trial 28 finished with value: 0.8839285714285714 and parameters: {'num_leaves': 197, 'learning_rate': 0.21950512454637716, 'feature_fraction': 0.4688462234664663, 'bagging_fraction': 0.5871292834538385, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,178] Trial 29 finished with value: 1.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.29952306164637355, 'feature_fraction': 0.8232796802516604, 'bagging_fraction': 0.7263569182803936, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,330] Trial 30 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 65, 'learning_rate': 0.07056790067809518, 'feature_fraction': 0.8240129883360195, 'bagging_fraction': 0.729200485956837, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,377] Trial 31 finished with value: 0.875 and parameters: {'num_leaves': 111, 'learning_rate': 0.26275491192196143, 'feature_fraction': 0.9156785121234537, 'bagging_fraction': 0.6730218404031075, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,397] Trial 32 finished with value: 0.9821428571428571 and parameters: {'num_leaves': 84, 'learning_rate': 0.2903400151956929, 'feature_fraction': 0.8597013473673408, 'bagging_fraction': 0.6350222419360383, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,420] Trial 33 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 31, 'learning_rate': 0.2631156071597138, 'feature_fraction': 0.9192395479335529, 'bagging_fraction': 0.8760237932963324, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,523] Trial 34 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 79, 'learning_rate': 0.18645051618252537, 'feature_fraction': 0.7831750019904543, 'bagging_fraction': 0.7898910791781645, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,572] Trial 35 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 56, 'learning_rate': 0.1276162138721821, 'feature_fraction': 0.6846214630044173, 'bagging_fraction': 0.9363112338832411, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,609] Trial 36 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 166, 'learning_rate': 0.29983485933573467, 'feature_fraction': 0.8296127785332832, 'bagging_fraction': 0.7319487359713472, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,630] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 128, 'learning_rate': 0.24549571550171748, 'feature_fraction': 0.5390981803269113, 'bagging_fraction': 0.6116363933111459, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,650] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.10623428335944995, 'feature_fraction': 0.7319413045643769, 'bagging_fraction': 0.53610513264851, 'bagging_freq': 5, 'min_child_samples': 93}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,762] Trial 39 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 34, 'learning_rate': 0.04343467353923554, 'feature_fraction': 0.4044899388362023, 'bagging_fraction': 0.6704917673659372, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,808] Trial 40 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 232, 'learning_rate': 0.22274832831716482, 'feature_fraction': 0.8722682021582348, 'bagging_fraction': 0.845933255656528, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,925] Trial 41 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 74, 'learning_rate': 0.06429394170264581, 'feature_fraction': 0.8129196743254398, 'bagging_fraction': 0.7257641877275932, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:10,992] Trial 42 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 50, 'learning_rate': 0.08258551908398351, 'feature_fraction': 0.8488319842094042, 'bagging_fraction': 0.7531675202096061, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:11,132] Trial 43 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 94, 'learning_rate': 0.041281844488636935, 'feature_fraction': 0.7379075714014748, 'bagging_fraction': 0.6604073040284776, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:11,195] Trial 44 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 62, 'learning_rate': 0.14184904449022837, 'feature_fraction': 0.7546263396918653, 'bagging_fraction': 0.728951673392621, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 16 with value: 1.0.
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.161829
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.224759
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.236499
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.127494
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.159625
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.222641
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.158738
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.0984691
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.134536
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.177555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.146725
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.156811
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.136459
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.0960064
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.239463
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.131284
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.18597
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.13906
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.167631
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.137014
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.187904
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.153179
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.134189
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.127207
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.205517
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.120453
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.118325
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.142723
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.12128
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.121102
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.155237
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.123817
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.18535
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.0299507
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.0751817
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.187492
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.135555
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.118189
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.105789
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.127536
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.120783
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.10558
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.137528
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.124154
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.142945
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.118367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.133226
[I 2025-09-17 13:19:11,234] Trial 45 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 147, 'learning_rate': 0.07351392716527641, 'feature_fraction': 0.9534446472318239, 'bagging_fraction': 0.8095192188696165, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:11,248] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 264, 'learning_rate': 0.15703675794867802, 'feature_fraction': 0.8126645094993035, 'bagging_fraction': 0.42753985900234986, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:11,265] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 39, 'learning_rate': 0.10319505177683214, 'feature_fraction': 0.8859330599962871, 'bagging_fraction': 0.7782047675015392, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:11,341] Trial 48 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 117, 'learning_rate': 0.19242070797262678, 'feature_fraction': 0.4355049789987087, 'bagging_fraction': 0.8986823767479715, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:11,361] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 18, 'learning_rate': 0.2536495399256527, 'feature_fraction': 0.5921105924837238, 'bagging_fraction': 0.5720393136873515, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:11,494] A new study created in memory with name: no-name-ba5df4a8-234e-4f8a-b90f-284070e14650
[I 2025-09-17 13:19:11,510] Trial 0 finished with value: 0.7678571428571428 and parameters: {'num_leaves': 90, 'learning_rate': 0.27434074026031474, 'feature_fraction': 0.8919282043961162, 'bagging_fraction': 0.44296714395727077, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 0 with value: 0.7678571428571428.
[I 2025-09-17 13:19:11,520] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 193, 'learning_rate': 0.022917249437374117, 'feature_fraction': 0.644759143948502, 'bagging_fraction': 0.5069722598827389, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 0 with value: 0.7678571428571428.
[I 2025-09-17 13:19:11,624] Trial 2 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 84, 'learning_rate': 0.06658698115766028, 'feature_fraction': 0.4672677774382255, 'bagging_fraction': 0.9645791681664613, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,704] Trial 3 finished with value: 0.875 and parameters: {'num_leaves': 245, 'learning_rate': 0.02829217683177329, 'feature_fraction': 0.6147981608968179, 'bagging_fraction': 0.7865049832661883, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,712] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.22193388153659785, 'feature_fraction': 0.7936603864649019, 'bagging_fraction': 0.79142963947494, 'bagging_freq': 7, 'min_child_samples': 68}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,721] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 279, 'learning_rate': 0.2199387027266678, 'feature_fraction': 0.6762524767929199, 'bagging_fraction': 0.6918726791353746, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,729] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.10041594148755606, 'feature_fraction': 0.5570467586758071, 'bagging_fraction': 0.8335205800285053, 'bagging_freq': 4, 'min_child_samples': 68}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,808] Trial 7 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 206, 'learning_rate': 0.04850548651769835, 'feature_fraction': 0.6196986709758852, 'bagging_fraction': 0.47495167742371003, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,831] Trial 8 finished with value: 0.875 and parameters: {'num_leaves': 94, 'learning_rate': 0.07521590614121709, 'feature_fraction': 0.7955038174856371, 'bagging_fraction': 0.7378225106016506, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,840] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 223, 'learning_rate': 0.11917295087279847, 'feature_fraction': 0.588445572138098, 'bagging_fraction': 0.6840073190489823, 'bagging_freq': 2, 'min_child_samples': 85}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,864] Trial 10 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 13, 'learning_rate': 0.15900296010173703, 'feature_fraction': 0.41432719014765207, 'bagging_fraction': 0.9918219874590174, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,895] Trial 11 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 21, 'learning_rate': 0.16453954498530352, 'feature_fraction': 0.4113935195499941, 'bagging_fraction': 0.9810517483800361, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,927] Trial 12 finished with value: 0.875 and parameters: {'num_leaves': 10, 'learning_rate': 0.15286431547234286, 'feature_fraction': 0.4120187903128055, 'bagging_fraction': 0.9878472029667867, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:11,955] Trial 13 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 89, 'learning_rate': 0.1751971283867909, 'feature_fraction': 0.5001447573379258, 'bagging_fraction': 0.897548766361742, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:12,020] Trial 14 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 57, 'learning_rate': 0.12201717566981302, 'feature_fraction': 0.4828330943559531, 'bagging_fraction': 0.9035438048505896, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:12,143] Trial 15 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 134, 'learning_rate': 0.20992782988115302, 'feature_fraction': 0.4839241588934312, 'bagging_fraction': 0.9172376868357146, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 2 with value: 0.9821428571428572.
[I 2025-09-17 13:19:12,221] Trial 16 finished with value: 1.0 and parameters: {'num_leaves': 133, 'learning_rate': 0.29853342756357604, 'feature_fraction': 0.5213552898861189, 'bagging_fraction': 0.5872607284172974, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,244] Trial 17 finished with value: 0.875 and parameters: {'num_leaves': 148, 'learning_rate': 0.2937675894059433, 'feature_fraction': 0.7382935286647743, 'bagging_fraction': 0.5865010036903668, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,296] Trial 18 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 128, 'learning_rate': 0.24944801859776528, 'feature_fraction': 0.988841380198209, 'bagging_fraction': 0.5926264277998023, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,308] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 54, 'learning_rate': 0.07300591068547756, 'feature_fraction': 0.5429133069481112, 'bagging_fraction': 0.5945045071866387, 'bagging_freq': 5, 'min_child_samples': 63}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,358] Trial 20 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 120, 'learning_rate': 0.18796269289226228, 'feature_fraction': 0.5045625111369759, 'bagging_fraction': 0.5356475379022703, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,428] Trial 21 finished with value: 1.0 and parameters: {'num_leaves': 166, 'learning_rate': 0.2584041207854053, 'feature_fraction': 0.9906017893516492, 'bagging_fraction': 0.6283979400515158, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,451] Trial 22 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 170, 'learning_rate': 0.29756751049723756, 'feature_fraction': 0.888331711479261, 'bagging_fraction': 0.6651216161238603, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,505] Trial 23 finished with value: 1.0 and parameters: {'num_leaves': 113, 'learning_rate': 0.2541297926501537, 'feature_fraction': 0.9884449286035237, 'bagging_fraction': 0.6366301410667474, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,546] Trial 24 finished with value: 1.0 and parameters: {'num_leaves': 152, 'learning_rate': 0.2602823590852685, 'feature_fraction': 0.9914535197443988, 'bagging_fraction': 0.6345184288560736, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,569] Trial 25 finished with value: 0.8214285714285715 and parameters: {'num_leaves': 168, 'learning_rate': 0.2536124859398384, 'feature_fraction': 0.9158318948161825, 'bagging_fraction': 0.5451252222504269, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,581] Trial 26 finished with value: 0.5 and parameters: {'num_leaves': 59, 'learning_rate': 0.2346603004493762, 'feature_fraction': 0.9259390326859396, 'bagging_fraction': 0.416505287906968, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,595] Trial 27 finished with value: 0.23214285714285715 and parameters: {'num_leaves': 120, 'learning_rate': 0.27604600823294406, 'feature_fraction': 0.8522379991019211, 'bagging_fraction': 0.6409302667001142, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,652] Trial 28 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 109, 'learning_rate': 0.2847974795310537, 'feature_fraction': 0.9618206923549462, 'bagging_fraction': 0.7335323852185497, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,681] Trial 29 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 143, 'learning_rate': 0.19700377843368871, 'feature_fraction': 0.8474997161100939, 'bagging_fraction': 0.4645942790406417, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,721] Trial 30 finished with value: 0.9107142857142858 and parameters: {'num_leaves': 170, 'learning_rate': 0.2394346628188013, 'feature_fraction': 0.7418678048008623, 'bagging_fraction': 0.6315957837078867, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,777] Trial 31 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 159, 'learning_rate': 0.26051349605122653, 'feature_fraction': 0.9983411946280063, 'bagging_fraction': 0.6289202799680131, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,835] Trial 32 finished with value: 1.0 and parameters: {'num_leaves': 190, 'learning_rate': 0.27112995569410747, 'feature_fraction': 0.9505815963331382, 'bagging_fraction': 0.5677245111921467, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,893] Trial 33 finished with value: 1.0 and parameters: {'num_leaves': 104, 'learning_rate': 0.2660019010185557, 'feature_fraction': 0.8761743555517589, 'bagging_fraction': 0.5038742215776747, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,918] Trial 34 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 210, 'learning_rate': 0.2385224191851775, 'feature_fraction': 0.967900985407757, 'bagging_fraction': 0.7387170331795977, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,930] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 78, 'learning_rate': 0.2819532039116534, 'feature_fraction': 0.9122461611122626, 'bagging_fraction': 0.6537296409568388, 'bagging_freq': 5, 'min_child_samples': 86}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:12,992] Trial 36 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 146, 'learning_rate': 0.2205820135514339, 'feature_fraction': 0.6671810446317774, 'bagging_fraction': 0.6109244441425375, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,004] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 240, 'learning_rate': 0.25104036576860744, 'feature_fraction': 0.8140126739840677, 'bagging_fraction': 0.5438231762777685, 'bagging_freq': 6, 'min_child_samples': 57}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,021] Trial 38 finished with value: 0.9732142857142857 and parameters: {'num_leaves': 182, 'learning_rate': 0.2998935880211242, 'feature_fraction': 0.9518853442607806, 'bagging_fraction': 0.7154245817998272, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,099] Trial 39 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 76, 'learning_rate': 0.20214572641412654, 'feature_fraction': 0.9923971650579292, 'bagging_fraction': 0.7694993954180142, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,121] Trial 40 finished with value: 0.875 and parameters: {'num_leaves': 291, 'learning_rate': 0.2346313229964047, 'feature_fraction': 0.716635417999919, 'bagging_fraction': 0.5005508630242326, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,164] Trial 41 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 193, 'learning_rate': 0.27039775813809785, 'feature_fraction': 0.9418448487741344, 'bagging_fraction': 0.5703970152534175, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,227] Trial 42 finished with value: 0.875 and parameters: {'num_leaves': 204, 'learning_rate': 0.2805639236176243, 'feature_fraction': 0.9662608650400653, 'bagging_fraction': 0.669883558227401, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,261] Trial 43 finished with value: 0.875 and parameters: {'num_leaves': 183, 'learning_rate': 0.26734565424950796, 'feature_fraction': 0.9289447214402227, 'bagging_fraction': 0.5620851539844949, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,317] Trial 44 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 221, 'learning_rate': 0.28881358003613583, 'feature_fraction': 0.8711011759009238, 'bagging_fraction': 0.6947861435489011, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,372] Trial 45 finished with value: 0.7857142857142858 and parameters: {'num_leaves': 136, 'learning_rate': 0.010902214443502423, 'feature_fraction': 0.9986068152855075, 'bagging_fraction': 0.6207748450946333, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,385] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 157, 'learning_rate': 0.2271725090178697, 'feature_fraction': 0.9013720878627316, 'bagging_fraction': 0.5747951028465136, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,397] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 107, 'learning_rate': 0.25743528480219513, 'feature_fraction': 0.58114906315717, 'bagging_fraction': 0.5200607491786601, 'bagging_freq': 6, 'min_child_samples': 81}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,413] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.14282212954011048, 'feature_fraction': 0.44753273845645003, 'bagging_fraction': 0.6096871433667842, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,442] Trial 49 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 123, 'learning_rate': 0.211756667186337, 'feature_fraction': 0.6253426879113959, 'bagging_fraction': 0.48508736742557645, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 16 with value: 1.0.
[I 2025-09-17 13:19:13,667] A new study created in memory with name: no-name-e0098bf9-ea3d-4f25-b95d-45f231c8a9fe
[I 2025-09-17 13:19:13,675] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 107, 'learning_rate': 0.013113831320265015, 'feature_fraction': 0.7447147820344686, 'bagging_fraction': 0.6852129242111595, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:13,682] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 267, 'learning_rate': 0.18803721056238915, 'feature_fraction': 0.5142071978607751, 'bagging_fraction': 0.502192313948089, 'bagging_freq': 3, 'min_child_samples': 80}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:13,688] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 17, 'learning_rate': 0.05528812145355225, 'feature_fraction': 0.864044482043071, 'bagging_fraction': 0.9143370066979726, 'bagging_freq': 1, 'min_child_samples': 80}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:13,708] Trial 3 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 154, 'learning_rate': 0.12474078800174292, 'feature_fraction': 0.6537431643303884, 'bagging_fraction': 0.41035586349121317, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 3 with value: 0.9642857142857143.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.137761
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.154041
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.244933
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.195359
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.148867
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.201917
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.212191
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.183094
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.156924
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.164146
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.161864
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.187187
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.192938
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.179039
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.145044
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.19904
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.166594
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.180017
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.154532
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.206332
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.123087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.146161
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.211773
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.105553
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.172665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.190887
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.217491
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.107873
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.192321
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.174741
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.199742
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.184185
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.164242
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.212851
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.21789
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.209936
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.198561
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.136972
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.227243
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.213696
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.0960671
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:13,713] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 74, 'learning_rate': 0.15108879641242107, 'feature_fraction': 0.6912075255064696, 'bagging_fraction': 0.9722633818968193, 'bagging_freq': 3, 'min_child_samples': 85}. Best is trial 3 with value: 0.9642857142857143.
[I 2025-09-17 13:19:13,748] Trial 5 finished with value: 1.0 and parameters: {'num_leaves': 280, 'learning_rate': 0.2066984083473327, 'feature_fraction': 0.7645211217065004, 'bagging_fraction': 0.506757898208175, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,754] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 195, 'learning_rate': 0.19161481495133784, 'feature_fraction': 0.7360657277183422, 'bagging_fraction': 0.5641559733104584, 'bagging_freq': 1, 'min_child_samples': 67}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,761] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 234, 'learning_rate': 0.09554753208437679, 'feature_fraction': 0.8626686673914141, 'bagging_fraction': 0.7941214431362202, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,784] Trial 8 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 50, 'learning_rate': 0.2238364997616431, 'feature_fraction': 0.9079204306540012, 'bagging_fraction': 0.9783640017098273, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,792] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.12780060754081074, 'feature_fraction': 0.7082585884434329, 'bagging_fraction': 0.821083097283924, 'bagging_freq': 6, 'min_child_samples': 64}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,858] Trial 10 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 281, 'learning_rate': 0.2697146135881547, 'feature_fraction': 0.500269804687914, 'bagging_fraction': 0.6189638063887684, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,894] Trial 11 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 151, 'learning_rate': 0.2903048802985569, 'feature_fraction': 0.6141589597116175, 'bagging_fraction': 0.4094204664539181, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,914] Trial 12 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 163, 'learning_rate': 0.231841175715429, 'feature_fraction': 0.40903362790111697, 'bagging_fraction': 0.40958185658431384, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,937] Trial 13 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 222, 'learning_rate': 0.10434645551409964, 'feature_fraction': 0.6153004286346018, 'bagging_fraction': 0.5030309983808744, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,959] Trial 14 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 231, 'learning_rate': 0.08192099934591635, 'feature_fraction': 0.9928092204707732, 'bagging_fraction': 0.525873482371549, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:13,979] Trial 15 finished with value: 0.8392857142857143 and parameters: {'num_leaves': 295, 'learning_rate': 0.18083607682162994, 'feature_fraction': 0.5692043606560664, 'bagging_fraction': 0.6391500501532217, 'bagging_freq': 6, 'min_child_samples': 42}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,002] Trial 16 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 243, 'learning_rate': 0.22956625257209046, 'feature_fraction': 0.806851994541633, 'bagging_fraction': 0.5009773625135959, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,025] Trial 17 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 199, 'learning_rate': 0.012255037066402935, 'feature_fraction': 0.7985859078490948, 'bagging_fraction': 0.7569534734183283, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,124] Trial 18 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 205, 'learning_rate': 0.057662983767550594, 'feature_fraction': 0.5785636467142552, 'bagging_fraction': 0.5673017537479843, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,147] Trial 19 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 262, 'learning_rate': 0.15326418948106363, 'feature_fraction': 0.4299930303396444, 'bagging_fraction': 0.46756457007253527, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,274] Trial 20 finished with value: 0.9107142857142858 and parameters: {'num_leaves': 180, 'learning_rate': 0.12077049350149983, 'feature_fraction': 0.6394024945874603, 'bagging_fraction': 0.6158518636440118, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,334] Trial 21 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 219, 'learning_rate': 0.05133758716577321, 'feature_fraction': 0.5642948788246388, 'bagging_fraction': 0.5534671412910444, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,364] Trial 22 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 254, 'learning_rate': 0.05707968824995559, 'feature_fraction': 0.5911099192580642, 'bagging_fraction': 0.467946836462071, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,389] Trial 23 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 208, 'learning_rate': 0.09010986910304837, 'feature_fraction': 0.5093235438129167, 'bagging_fraction': 0.6897046571524947, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,498] Trial 24 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 297, 'learning_rate': 0.07764132640034793, 'feature_fraction': 0.6792960592470196, 'bagging_fraction': 0.5774781389652881, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,518] Trial 25 finished with value: 0.7410714285714285 and parameters: {'num_leaves': 127, 'learning_rate': 0.032411199926513444, 'feature_fraction': 0.7631668211804132, 'bagging_fraction': 0.4884693862189203, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,547] Trial 26 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 183, 'learning_rate': 0.10670508625613255, 'feature_fraction': 0.46017092251774283, 'bagging_fraction': 0.596918675105032, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,563] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 223, 'learning_rate': 0.26170354808588153, 'feature_fraction': 0.5536860538906128, 'bagging_fraction': 0.4517327042784141, 'bagging_freq': 7, 'min_child_samples': 49}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,611] Trial 28 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 280, 'learning_rate': 0.2086283597954961, 'feature_fraction': 0.6172795847469713, 'bagging_fraction': 0.543981031679113, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,638] Trial 29 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 135, 'learning_rate': 0.16873112528684217, 'feature_fraction': 0.7539404865661037, 'bagging_fraction': 0.685669135982712, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,694] Trial 30 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 246, 'learning_rate': 0.14258052340049557, 'feature_fraction': 0.6552360978696293, 'bagging_fraction': 0.6461421812573694, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,746] Trial 31 finished with value: 1.0 and parameters: {'num_leaves': 282, 'learning_rate': 0.2554692518177627, 'feature_fraction': 0.6042552073998456, 'bagging_fraction': 0.5366541561097746, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,771] Trial 32 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 267, 'learning_rate': 0.2738908370077349, 'feature_fraction': 0.5357017145497315, 'bagging_fraction': 0.5279445632999719, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,850] Trial 33 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 283, 'learning_rate': 0.20472873933855482, 'feature_fraction': 0.6047645523990862, 'bagging_fraction': 0.7356292014178172, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,881] Trial 34 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 265, 'learning_rate': 0.03744329581822288, 'feature_fraction': 0.7162718125882047, 'bagging_fraction': 0.4521521489771499, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,901] Trial 35 finished with value: 0.875 and parameters: {'num_leaves': 214, 'learning_rate': 0.23617484633152713, 'feature_fraction': 0.4751674762954904, 'bagging_fraction': 0.5115905687172121, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,913] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 184, 'learning_rate': 0.2523557123487572, 'feature_fraction': 0.6618908103892069, 'bagging_fraction': 0.5816282411935718, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,969] Trial 37 finished with value: 1.0 and parameters: {'num_leaves': 247, 'learning_rate': 0.29162572536253506, 'feature_fraction': 0.7881790767819371, 'bagging_fraction': 0.4490573506611635, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,981] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 241, 'learning_rate': 0.2962232777657549, 'feature_fraction': 0.83802355671736, 'bagging_fraction': 0.4489366956072594, 'bagging_freq': 6, 'min_child_samples': 48}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:14,993] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 274, 'learning_rate': 0.24867066071489297, 'feature_fraction': 0.9147240779165559, 'bagging_fraction': 0.8819715014151293, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,011] Trial 40 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 253, 'learning_rate': 0.2843905538598348, 'feature_fraction': 0.7825433268104087, 'bagging_fraction': 0.4288076254638633, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,076] Trial 41 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 230, 'learning_rate': 0.06976052140694694, 'feature_fraction': 0.7070216728782875, 'bagging_fraction': 0.47992325863801194, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,130] Trial 42 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 293, 'learning_rate': 0.21107230798047685, 'feature_fraction': 0.7346476382569241, 'bagging_fraction': 0.5482650430858571, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,166] Trial 43 finished with value: 1.0 and parameters: {'num_leaves': 199, 'learning_rate': 0.2798333205559598, 'feature_fraction': 0.6802336898177631, 'bagging_fraction': 0.5112808855877673, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,193] Trial 44 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 254, 'learning_rate': 0.2806125702738195, 'feature_fraction': 0.8376020570193882, 'bagging_fraction': 0.5046045686963391, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,213] Trial 45 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 13, 'learning_rate': 0.2994651837625106, 'feature_fraction': 0.6798831191162866, 'bagging_fraction': 0.4232495665024629, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,236] Trial 46 finished with value: 0.9553571428571429 and parameters: {'num_leaves': 230, 'learning_rate': 0.2621424947641585, 'feature_fraction': 0.6229203024158055, 'bagging_fraction': 0.6548366658318454, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,258] Trial 47 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 36, 'learning_rate': 0.2516284193672602, 'feature_fraction': 0.7250973130885998, 'bagging_fraction': 0.5173029094636302, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,290] Trial 48 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 173, 'learning_rate': 0.18752468839917036, 'feature_fraction': 0.897859298692689, 'bagging_fraction': 0.4281367039796126, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,303] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 195, 'learning_rate': 0.2404753323250954, 'feature_fraction': 0.7752333485789903, 'bagging_fraction': 0.6045765721918153, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 5 with value: 1.0.
[I 2025-09-17 13:19:15,439] A new study created in memory with name: no-name-22d564d0-ed6f-43ab-bc66-ef66d128d446
[I 2025-09-17 13:19:15,452] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 46, 'learning_rate': 0.24625591229187468, 'feature_fraction': 0.46309246795140885, 'bagging_fraction': 0.41605103324619813, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:15,459] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 294, 'learning_rate': 0.2837072673730078, 'feature_fraction': 0.6731934612362745, 'bagging_fraction': 0.8101945928918044, 'bagging_freq': 7, 'min_child_samples': 86}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:15,502] Trial 2 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 289, 'learning_rate': 0.2726886439943824, 'feature_fraction': 0.9720825797446146, 'bagging_fraction': 0.9805318793321893, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 2 with value: 0.8928571428571428.
[I 2025-09-17 13:19:15,511] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.14726454618473125, 'feature_fraction': 0.8176528757117923, 'bagging_fraction': 0.6448842242041086, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 2 with value: 0.8928571428571428.
[I 2025-09-17 13:19:15,520] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 197, 'learning_rate': 0.22031654851625876, 'feature_fraction': 0.5495285460504812, 'bagging_fraction': 0.8929598396170652, 'bagging_freq': 5, 'min_child_samples': 96}. Best is trial 2 with value: 0.8928571428571428.
[I 2025-09-17 13:19:15,529] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.28207710025365856, 'feature_fraction': 0.984414714049236, 'bagging_fraction': 0.8845378147593503, 'bagging_freq': 3, 'min_child_samples': 83}. Best is trial 2 with value: 0.8928571428571428.
[I 2025-09-17 13:19:15,547] Trial 6 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 207, 'learning_rate': 0.08799835552563577, 'feature_fraction': 0.7153743627862423, 'bagging_fraction': 0.930252140885659, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,556] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 125, 'learning_rate': 0.1831253557015903, 'feature_fraction': 0.40962850574655957, 'bagging_fraction': 0.5988246465570154, 'bagging_freq': 6, 'min_child_samples': 64}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,566] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 126, 'learning_rate': 0.0763299699290379, 'feature_fraction': 0.43736024088463415, 'bagging_fraction': 0.919049438886728, 'bagging_freq': 2, 'min_child_samples': 70}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,575] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 186, 'learning_rate': 0.20858811398250962, 'feature_fraction': 0.7389913231387932, 'bagging_fraction': 0.6888165671652009, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,602] Trial 10 finished with value: 0.9107142857142858 and parameters: {'num_leaves': 235, 'learning_rate': 0.01236510935644107, 'feature_fraction': 0.6534795900053528, 'bagging_fraction': 0.7657228799179421, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,632] Trial 11 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 237, 'learning_rate': 0.012037697354146101, 'feature_fraction': 0.6032592150881018, 'bagging_fraction': 0.7934092533900269, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,668] Trial 12 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 246, 'learning_rate': 0.01355354852779923, 'feature_fraction': 0.5813663275020877, 'bagging_fraction': 0.8020978876649348, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 6 with value: 0.9642857142857143.
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.0868904
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.143996
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.175328
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.143456
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.171
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.113582
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.14601
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.185857
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.132993
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.209695
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.121149
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.143699
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.176853
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.122596
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.145919
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.143465
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.134761
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.24268
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.137034
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.107965
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.139597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.164277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.0625022
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.120398
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.164569
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.145653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.153463
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.0446895
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.15243
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.132793
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.1526
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.0739529
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.115063
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.176656
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.136051
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.163521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.127055
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.245449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.174747
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.166058
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.217047
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.196607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.192393
[I 2025-09-17 13:19:15,790] Trial 13 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 244, 'learning_rate': 0.08771673616805284, 'feature_fraction': 0.7915766909289451, 'bagging_fraction': 0.9852557368019013, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,813] Trial 14 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 61, 'learning_rate': 0.07394780727414457, 'feature_fraction': 0.5588418796895158, 'bagging_fraction': 0.8333456802939231, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,832] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 249, 'learning_rate': 0.12099941647807301, 'feature_fraction': 0.8277102652253076, 'bagging_fraction': 0.5807123222632252, 'bagging_freq': 3, 'min_child_samples': 50}. Best is trial 6 with value: 0.9642857142857143.
[I 2025-09-17 13:19:15,861] Trial 16 finished with value: 0.9821428571428572 and parameters: {'num_leaves': 208, 'learning_rate': 0.04427118362499934, 'feature_fraction': 0.8972466267954653, 'bagging_fraction': 0.4880438607111793, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:15,876] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 85, 'learning_rate': 0.04642024648706586, 'feature_fraction': 0.878524121087934, 'bagging_fraction': 0.46022874571644945, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:15,901] Trial 18 finished with value: 0.9821428571428571 and parameters: {'num_leaves': 163, 'learning_rate': 0.11997619153299414, 'feature_fraction': 0.7320512997603199, 'bagging_fraction': 0.5259102499416065, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:15,947] Trial 19 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 162, 'learning_rate': 0.12818110872167385, 'feature_fraction': 0.9064786208694533, 'bagging_fraction': 0.5233393861813482, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:15,960] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 95, 'learning_rate': 0.04426661526901195, 'feature_fraction': 0.9094605372434489, 'bagging_fraction': 0.48572738363120427, 'bagging_freq': 2, 'min_child_samples': 58}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,011] Trial 21 finished with value: 0.875 and parameters: {'num_leaves': 11, 'learning_rate': 0.10805417352882184, 'feature_fraction': 0.7427119712878387, 'bagging_fraction': 0.5556135200023722, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,033] Trial 22 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 206, 'learning_rate': 0.16330283645417587, 'feature_fraction': 0.7378699366777661, 'bagging_fraction': 0.6521706359843847, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,135] Trial 23 finished with value: 0.8928571428571428 and parameters: {'num_leaves': 158, 'learning_rate': 0.04868024087085565, 'feature_fraction': 0.6390956562164368, 'bagging_fraction': 0.7346076898467511, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,157] Trial 24 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 167, 'learning_rate': 0.09824479843261458, 'feature_fraction': 0.857647378987989, 'bagging_fraction': 0.4061743549505367, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,177] Trial 25 finished with value: 0.9196428571428572 and parameters: {'num_leaves': 200, 'learning_rate': 0.058473137209915066, 'feature_fraction': 0.7671995407338229, 'bagging_fraction': 0.4909344405128291, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,193] Trial 26 finished with value: 0.5714285714285714 and parameters: {'num_leaves': 213, 'learning_rate': 0.14515644390725116, 'feature_fraction': 0.6867954952693422, 'bagging_fraction': 0.6221576860952099, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,220] Trial 27 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 270, 'learning_rate': 0.10893246346776532, 'feature_fraction': 0.7001875439980144, 'bagging_fraction': 0.5487141063512777, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,233] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.17290123184191383, 'feature_fraction': 0.5202161553907924, 'bagging_fraction': 0.6886752861692695, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,291] Trial 29 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 140, 'learning_rate': 0.033146102509796015, 'feature_fraction': 0.49608224523519706, 'bagging_fraction': 0.44781395265061413, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,305] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 183, 'learning_rate': 0.06762148956390196, 'feature_fraction': 0.9294296900955921, 'bagging_fraction': 0.5195892549009978, 'bagging_freq': 3, 'min_child_samples': 45}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,343] Trial 31 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 265, 'learning_rate': 0.027506547539750514, 'feature_fraction': 0.6105840553519799, 'bagging_fraction': 0.8438901495675926, 'bagging_freq': 1, 'min_child_samples': 27}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,390] Trial 32 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 218, 'learning_rate': 0.08707256751362663, 'feature_fraction': 0.7050962289134708, 'bagging_fraction': 0.9290664160567521, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,444] Trial 33 finished with value: 0.9107142857142857 and parameters: {'num_leaves': 274, 'learning_rate': 0.02629875651980579, 'feature_fraction': 0.5903029694984993, 'bagging_fraction': 0.7419045462116991, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,484] Trial 34 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 296, 'learning_rate': 0.13440452179351556, 'feature_fraction': 0.7970874212316924, 'bagging_fraction': 0.436190952349145, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,512] Trial 35 finished with value: 0.9464285714285715 and parameters: {'num_leaves': 227, 'learning_rate': 0.05798136201416769, 'feature_fraction': 0.6383980396627648, 'bagging_fraction': 0.9480911927236161, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,534] Trial 36 finished with value: 0.7857142857142856 and parameters: {'num_leaves': 173, 'learning_rate': 0.08689096934972265, 'feature_fraction': 0.9561949719091348, 'bagging_fraction': 0.8778907168558172, 'bagging_freq': 7, 'min_child_samples': 40}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,567] Trial 37 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 257, 'learning_rate': 0.03282162481128023, 'feature_fraction': 0.8385957405650588, 'bagging_fraction': 0.8015100662776427, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,625] Trial 38 finished with value: 0.9107142857142858 and parameters: {'num_leaves': 148, 'learning_rate': 0.2966361512000316, 'feature_fraction': 0.5606430241246769, 'bagging_fraction': 0.6573445121248456, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,643] Trial 39 finished with value: 0.9464285714285714 and parameters: {'num_leaves': 113, 'learning_rate': 0.11236086424531208, 'feature_fraction': 0.6657362746566237, 'bagging_fraction': 0.8625829890334327, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,685] Trial 40 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 280, 'learning_rate': 0.18967819269527955, 'feature_fraction': 0.7712930742908585, 'bagging_fraction': 0.9970569203064484, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,727] Trial 41 finished with value: 0.9732142857142857 and parameters: {'num_leaves': 282, 'learning_rate': 0.21267869619393046, 'feature_fraction': 0.7243436154886357, 'bagging_fraction': 0.9619606713435955, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,767] Trial 42 finished with value: 0.9732142857142857 and parameters: {'num_leaves': 280, 'learning_rate': 0.24337823120854887, 'feature_fraction': 0.7222678362100077, 'bagging_fraction': 0.9682576963123971, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,834] Trial 43 finished with value: 0.8035714285714286 and parameters: {'num_leaves': 300, 'learning_rate': 0.2623433406073099, 'feature_fraction': 0.7452858873012558, 'bagging_fraction': 0.9579177145969854, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,875] Trial 44 finished with value: 0.9285714285714286 and parameters: {'num_leaves': 282, 'learning_rate': 0.23794940663918301, 'feature_fraction': 0.7202981816713304, 'bagging_fraction': 0.9135136214017457, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,905] Trial 45 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 184, 'learning_rate': 0.22725042075477858, 'feature_fraction': 0.811239491386738, 'bagging_fraction': 0.9532725047521945, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,931] Trial 46 finished with value: 0.9642857142857143 and parameters: {'num_leaves': 231, 'learning_rate': 0.2059707547467495, 'feature_fraction': 0.7730483150583551, 'bagging_fraction': 0.897844626202178, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,948] Trial 47 finished with value: 0.7321428571428572 and parameters: {'num_leaves': 261, 'learning_rate': 0.25838150437473406, 'feature_fraction': 0.6727328639277915, 'bagging_fraction': 0.9748384127483736, 'bagging_freq': 7, 'min_child_samples': 57}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,962] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.19924529818322964, 'feature_fraction': 0.9974627103805007, 'bagging_fraction': 0.924164568571411, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:16,975] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 250, 'learning_rate': 0.2196578075443531, 'feature_fraction': 0.6236099835353085, 'bagging_fraction': 0.8351896072751348, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 16 with value: 0.9821428571428572.
[I 2025-09-17 13:19:17,356] A new study created in memory with name: no-name-4270ffb7-874f-47ad-8376-7d01f3bb47d1
[I 2025-09-17 13:19:17,366] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 82, 'learning_rate': 0.033098764651754875, 'feature_fraction': 0.61820894487366, 'bagging_fraction': 0.5534940183151196, 'bagging_freq': 6, 'min_child_samples': 47}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:17,423] Trial 1 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 219, 'learning_rate': 0.1033622317729499, 'feature_fraction': 0.8194141636928978, 'bagging_fraction': 0.7035784186597117, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,435] Trial 2 finished with value: 0.35714285714285715 and parameters: {'num_leaves': 247, 'learning_rate': 0.06474546192859111, 'feature_fraction': 0.9299728737925491, 'bagging_fraction': 0.7662917628484298, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,448] Trial 3 finished with value: 0.503968253968254 and parameters: {'num_leaves': 61, 'learning_rate': 0.1769841921129409, 'feature_fraction': 0.6354860119778963, 'bagging_fraction': 0.8770333722793613, 'bagging_freq': 1, 'min_child_samples': 51}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,458] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 125, 'learning_rate': 0.2724908535808791, 'feature_fraction': 0.5158965639871443, 'bagging_fraction': 0.6985672511193897, 'bagging_freq': 3, 'min_child_samples': 54}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,471] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 218, 'learning_rate': 0.2281464036950111, 'feature_fraction': 0.5284903997040692, 'bagging_fraction': 0.4371316340844894, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,510] Trial 6 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 179, 'learning_rate': 0.2082693379089597, 'feature_fraction': 0.7899790502450537, 'bagging_fraction': 0.7585761183769333, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,519] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 241, 'learning_rate': 0.2590490789323304, 'feature_fraction': 0.5901179202366912, 'bagging_fraction': 0.5514263256279772, 'bagging_freq': 2, 'min_child_samples': 72}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,527] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 275, 'learning_rate': 0.03020139894205097, 'feature_fraction': 0.9253778282551189, 'bagging_fraction': 0.5947507461971298, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,546] Trial 9 finished with value: 0.6746031746031746 and parameters: {'num_leaves': 149, 'learning_rate': 0.2657310702500713, 'feature_fraction': 0.8351990773028555, 'bagging_fraction': 0.919961359377693, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,605] Trial 10 finished with value: 0.7361111111111112 and parameters: {'num_leaves': 20, 'learning_rate': 0.11122445215947054, 'feature_fraction': 0.7554068644142625, 'bagging_fraction': 0.6647682328271518, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,671] Trial 11 finished with value: 0.7638888888888887 and parameters: {'num_leaves': 44, 'learning_rate': 0.12205297220031294, 'feature_fraction': 0.755535161111913, 'bagging_fraction': 0.6749726435270195, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,697] Trial 12 finished with value: 0.6587301587301587 and parameters: {'num_leaves': 190, 'learning_rate': 0.12867421608454635, 'feature_fraction': 0.6941719597858618, 'bagging_fraction': 0.8014282471071881, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,709] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 106, 'learning_rate': 0.09475595001261065, 'feature_fraction': 0.8543190898604307, 'bagging_fraction': 0.6442806820534802, 'bagging_freq': 5, 'min_child_samples': 98}. Best is trial 1 with value: 0.7698412698412699.
[I 2025-09-17 13:19:17,795] Trial 14 finished with value: 0.861111111111111 and parameters: {'num_leaves': 14, 'learning_rate': 0.1566811340377459, 'feature_fraction': 0.43565420286831597, 'bagging_fraction': 0.9831928785922968, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:17,840] Trial 15 finished with value: 0.6904761904761906 and parameters: {'num_leaves': 297, 'learning_rate': 0.17266990263638052, 'feature_fraction': 0.42424795644091623, 'bagging_fraction': 0.9850857632186767, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:17,866] Trial 16 finished with value: 0.60515873015873 and parameters: {'num_leaves': 193, 'learning_rate': 0.15113216074107716, 'feature_fraction': 0.4051414322455893, 'bagging_fraction': 0.4101376143319219, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:17,885] Trial 17 finished with value: 0.47023809523809523 and parameters: {'num_leaves': 150, 'learning_rate': 0.09397634627866944, 'feature_fraction': 0.9902878643171118, 'bagging_fraction': 0.9995020901053818, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:17,938] Trial 18 finished with value: 0.742063492063492 and parameters: {'num_leaves': 105, 'learning_rate': 0.07184016348464682, 'feature_fraction': 0.6849273403370022, 'bagging_fraction': 0.856920633086001, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:17,951] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 222, 'learning_rate': 0.21594259493973905, 'feature_fraction': 0.48208745928066205, 'bagging_fraction': 0.513083253053841, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,037] Trial 20 finished with value: 0.761904761904762 and parameters: {'num_leaves': 16, 'learning_rate': 0.14693907756848618, 'feature_fraction': 0.8732372536743276, 'bagging_fraction': 0.9426371241449891, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,087] Trial 21 finished with value: 0.7023809523809523 and parameters: {'num_leaves': 53, 'learning_rate': 0.1282642394067972, 'feature_fraction': 0.7955952209352054, 'bagging_fraction': 0.7321479794630477, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 14 with value: 0.861111111111111.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.219941
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.189684
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.193717
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.179684
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.158717
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.185974
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.186038
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.186883
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.163969
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.199109
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.228722
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.184847
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.155987
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.180298
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.161077
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.174152
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.186968
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.177399
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.21746
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.177563
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.17444
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.188278
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.139717
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.148194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.144208
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.263487
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.189581
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.154275
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.154766
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.221578
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.24493
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.24493
Training model for P094... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.547323
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.660018
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.662612
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.576166
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.609744
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.590634
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.590112
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.60686
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.485304
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.598224
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.643241
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.660688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.562392
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.536522
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.600558
[I 2025-09-17 13:19:18,127] Trial 22 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 60, 'learning_rate': 0.18536113235523846, 'feature_fraction': 0.7380235018108647, 'bagging_fraction': 0.8234847131063994, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,197] Trial 23 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 29, 'learning_rate': 0.058012659774344486, 'feature_fraction': 0.6666201862193722, 'bagging_fraction': 0.6537713846722165, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,219] Trial 24 finished with value: 0.5119047619047619 and parameters: {'num_leaves': 32, 'learning_rate': 0.015772672824960303, 'feature_fraction': 0.5610457637160127, 'bagging_fraction': 0.6099890787439122, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,266] Trial 25 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 10, 'learning_rate': 0.06030087855227872, 'feature_fraction': 0.45453744502129445, 'bagging_fraction': 0.4733530072568706, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,284] Trial 26 finished with value: 0.42460317460317465 and parameters: {'num_leaves': 86, 'learning_rate': 0.09032698124013747, 'feature_fraction': 0.6544099836295494, 'bagging_fraction': 0.6196794082177575, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,335] Trial 27 finished with value: 0.738095238095238 and parameters: {'num_leaves': 79, 'learning_rate': 0.04638144396109438, 'feature_fraction': 0.8870729069196231, 'bagging_fraction': 0.7262467707557015, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,348] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 168, 'learning_rate': 0.0797066479056371, 'feature_fraction': 0.5615363485038857, 'bagging_fraction': 0.8063595494255205, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,364] Trial 29 finished with value: 0.5297619047619048 and parameters: {'num_leaves': 78, 'learning_rate': 0.10829558235600478, 'feature_fraction': 0.8122419865012784, 'bagging_fraction': 0.5653011120871564, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,383] Trial 30 finished with value: 0.38095238095238093 and parameters: {'num_leaves': 122, 'learning_rate': 0.042084130492090366, 'feature_fraction': 0.6076434058179977, 'bagging_fraction': 0.5201485158212118, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,428] Trial 31 finished with value: 0.6845238095238095 and parameters: {'num_leaves': 38, 'learning_rate': 0.12838838449611525, 'feature_fraction': 0.7354098315033805, 'bagging_fraction': 0.680453056567628, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,544] Trial 32 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 39, 'learning_rate': 0.11582796052266028, 'feature_fraction': 0.7548206650096212, 'bagging_fraction': 0.6475121874370635, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,583] Trial 33 finished with value: 0.6984126984126984 and parameters: {'num_leaves': 33, 'learning_rate': 0.1543108142195114, 'feature_fraction': 0.6702127007854356, 'bagging_fraction': 0.6329354644571645, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,626] Trial 34 finished with value: 0.6904761904761906 and parameters: {'num_leaves': 65, 'learning_rate': 0.0649415302214889, 'feature_fraction': 0.9144625293557461, 'bagging_fraction': 0.7246162331601069, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,638] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 27, 'learning_rate': 0.19022605297976686, 'feature_fraction': 0.7197163260592478, 'bagging_fraction': 0.5762137615801305, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,655] Trial 36 finished with value: 0.35714285714285715 and parameters: {'num_leaves': 217, 'learning_rate': 0.16521987756573264, 'feature_fraction': 0.9838067083998061, 'bagging_fraction': 0.7808556562072596, 'bagging_freq': 2, 'min_child_samples': 47}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,713] Trial 37 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 262, 'learning_rate': 0.13893091131400742, 'feature_fraction': 0.5092291312624984, 'bagging_fraction': 0.868586779505653, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,741] Trial 38 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 248, 'learning_rate': 0.24336520086066926, 'feature_fraction': 0.5000750556199467, 'bagging_fraction': 0.8920148809127348, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,810] Trial 39 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 265, 'learning_rate': 0.14142729310550864, 'feature_fraction': 0.47355610847461865, 'bagging_fraction': 0.9504074439465747, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,824] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 283, 'learning_rate': 0.28809836694536517, 'feature_fraction': 0.5555319448313822, 'bagging_fraction': 0.947391733395628, 'bagging_freq': 2, 'min_child_samples': 70}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,877] Trial 41 finished with value: 0.746031746031746 and parameters: {'num_leaves': 261, 'learning_rate': 0.1381718037242417, 'feature_fraction': 0.4609064922387891, 'bagging_fraction': 0.9052478151677226, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,918] Trial 42 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 282, 'learning_rate': 0.19553627647910632, 'feature_fraction': 0.5204622358564759, 'bagging_fraction': 0.9674730422433078, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:18,965] Trial 43 finished with value: 0.7023809523809524 and parameters: {'num_leaves': 229, 'learning_rate': 0.18909689817142813, 'feature_fraction': 0.44836518048856294, 'bagging_fraction': 0.9567752166696669, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:19,038] Trial 44 finished with value: 0.7976190476190477 and parameters: {'num_leaves': 294, 'learning_rate': 0.21538514466134917, 'feature_fraction': 0.5286203185699052, 'bagging_fraction': 0.9637855567178839, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:19,087] Trial 45 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 300, 'learning_rate': 0.21094857479105908, 'feature_fraction': 0.5339183724946432, 'bagging_fraction': 0.9723304634166955, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:19,124] Trial 46 finished with value: 0.7063492063492064 and parameters: {'num_leaves': 297, 'learning_rate': 0.21518016191036965, 'feature_fraction': 0.5276081289240675, 'bagging_fraction': 0.9716378059959385, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:19,140] Trial 47 finished with value: 0.49404761904761896 and parameters: {'num_leaves': 277, 'learning_rate': 0.2009978565145391, 'feature_fraction': 0.4851642221698075, 'bagging_fraction': 0.9222243086370577, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:19,188] Trial 48 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 286, 'learning_rate': 0.23236788379041268, 'feature_fraction': 0.42334603353750405, 'bagging_fraction': 0.8434098045836563, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:19,235] Trial 49 finished with value: 0.7103174603174602 and parameters: {'num_leaves': 288, 'learning_rate': 0.23605204894170886, 'feature_fraction': 0.42819129245975296, 'bagging_fraction': 0.8525965562593404, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 14 with value: 0.861111111111111.
[I 2025-09-17 13:19:19,681] A new study created in memory with name: no-name-31187666-2a7f-42f2-bded-77a29b5c3bc0
[I 2025-09-17 13:19:19,687] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 157, 'learning_rate': 0.12999831328912964, 'feature_fraction': 0.9213763006458451, 'bagging_fraction': 0.7045579559463224, 'bagging_freq': 1, 'min_child_samples': 72}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:19,712] Trial 1 finished with value: 0.7301587301587302 and parameters: {'num_leaves': 61, 'learning_rate': 0.16845496208894323, 'feature_fraction': 0.7895035481996442, 'bagging_fraction': 0.7797391413794783, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 1 with value: 0.7301587301587302.
[I 2025-09-17 13:19:19,739] Trial 2 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 240, 'learning_rate': 0.14543182770941482, 'feature_fraction': 0.6850687072391191, 'bagging_fraction': 0.5919176109155226, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 2 with value: 0.7619047619047619.
[I 2025-09-17 13:19:19,747] Trial 3 finished with value: 0.48214285714285715 and parameters: {'num_leaves': 213, 'learning_rate': 0.11075517399561895, 'feature_fraction': 0.5550010267656736, 'bagging_fraction': 0.5328514775730532, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 2 with value: 0.7619047619047619.
[I 2025-09-17 13:19:19,764] Trial 4 finished with value: 0.6170634920634921 and parameters: {'num_leaves': 168, 'learning_rate': 0.16813307580134515, 'feature_fraction': 0.5033865743188127, 'bagging_fraction': 0.9552492400345032, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 2 with value: 0.7619047619047619.
[I 2025-09-17 13:19:19,830] Trial 5 finished with value: 0.873015873015873 and parameters: {'num_leaves': 42, 'learning_rate': 0.1852082834043674, 'feature_fraction': 0.709640971760975, 'bagging_fraction': 0.8839439410851064, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:19,847] Trial 6 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 133, 'learning_rate': 0.22530073818872962, 'feature_fraction': 0.8526595905507569, 'bagging_fraction': 0.7616215889217963, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:19,857] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 17, 'learning_rate': 0.07698107043912467, 'feature_fraction': 0.7452075820986106, 'bagging_fraction': 0.7631234013728303, 'bagging_freq': 2, 'min_child_samples': 86}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:19,867] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 160, 'learning_rate': 0.061595503784472115, 'feature_fraction': 0.44147329796431556, 'bagging_fraction': 0.6788427880804201, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:19,910] Trial 9 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 83, 'learning_rate': 0.24890875650888208, 'feature_fraction': 0.49592439133571004, 'bagging_fraction': 0.5803571922525166, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:19,927] Trial 10 finished with value: 0.4583333333333333 and parameters: {'num_leaves': 289, 'learning_rate': 0.010512257203629333, 'feature_fraction': 0.6335994492768573, 'bagging_fraction': 0.99726226170543, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:19,989] Trial 11 finished with value: 0.7380952380952381 and parameters: {'num_leaves': 81, 'learning_rate': 0.2787492819501641, 'feature_fraction': 0.5945995459623148, 'bagging_fraction': 0.4415929071468204, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,062] Trial 12 finished with value: 0.865079365079365 and parameters: {'num_leaves': 83, 'learning_rate': 0.22509118649727045, 'feature_fraction': 0.4254884575389266, 'bagging_fraction': 0.8767379438147151, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,131] Trial 13 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 12, 'learning_rate': 0.2230935921272784, 'feature_fraction': 0.6999218024290489, 'bagging_fraction': 0.8817894960196945, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,147] Trial 14 finished with value: 0.33333333333333337 and parameters: {'num_leaves': 116, 'learning_rate': 0.19793291476294692, 'feature_fraction': 0.9952794251587046, 'bagging_fraction': 0.8778143066242197, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,185] Trial 15 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 45, 'learning_rate': 0.2898706475859747, 'feature_fraction': 0.8122598846072898, 'bagging_fraction': 0.8686106266269183, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,227] Trial 16 finished with value: 0.761904761904762 and parameters: {'num_leaves': 108, 'learning_rate': 0.19223766656168323, 'feature_fraction': 0.6322224982865109, 'bagging_fraction': 0.9333539974090308, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,250] Trial 17 finished with value: 0.5714285714285714 and parameters: {'num_leaves': 50, 'learning_rate': 0.2516442568761679, 'feature_fraction': 0.4723991754337048, 'bagging_fraction': 0.8190909187093266, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,291] Trial 18 finished with value: 0.8452380952380951 and parameters: {'num_leaves': 91, 'learning_rate': 0.20123187411467638, 'feature_fraction': 0.4026369415411556, 'bagging_fraction': 0.6887741587609686, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,303] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 36, 'learning_rate': 0.25958499312614924, 'feature_fraction': 0.5485052655886913, 'bagging_fraction': 0.8300616534263925, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,341] Trial 20 finished with value: 0.7658730158730159 and parameters: {'num_leaves': 189, 'learning_rate': 0.10867947908238673, 'feature_fraction': 0.8820440053439975, 'bagging_fraction': 0.9288889352754552, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,394] Trial 21 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 84, 'learning_rate': 0.20485319461003437, 'feature_fraction': 0.42602164427204653, 'bagging_fraction': 0.6739614491912285, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,435] Trial 22 finished with value: 0.7261904761904762 and parameters: {'num_leaves': 110, 'learning_rate': 0.23131836572884074, 'feature_fraction': 0.4128004442149162, 'bagging_fraction': 0.7231158217053272, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,520] Trial 23 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 71, 'learning_rate': 0.18643153922927272, 'feature_fraction': 0.5357809117172897, 'bagging_fraction': 0.6199079193608795, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,581] Trial 24 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 132, 'learning_rate': 0.15810433229926796, 'feature_fraction': 0.4008831517586082, 'bagging_fraction': 0.8279545579607741, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,599] Trial 25 finished with value: 0.8075396825396826 and parameters: {'num_leaves': 31, 'learning_rate': 0.21006990322798508, 'feature_fraction': 0.7543387977145454, 'bagging_fraction': 0.9979755266945384, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,629] Trial 26 finished with value: 0.75 and parameters: {'num_leaves': 97, 'learning_rate': 0.17683048349959268, 'feature_fraction': 0.6516685678894245, 'bagging_fraction': 0.6348849279523581, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,644] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 136, 'learning_rate': 0.14007136494694403, 'feature_fraction': 0.46309962540451555, 'bagging_fraction': 0.4641690702144827, 'bagging_freq': 2, 'min_child_samples': 65}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,676] Trial 28 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 57, 'learning_rate': 0.2658245249084433, 'feature_fraction': 0.5926431251391127, 'bagging_fraction': 0.5241586060856738, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,727] Trial 29 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 30, 'learning_rate': 0.22855854547378798, 'feature_fraction': 0.7368041209063098, 'bagging_fraction': 0.7175991635726611, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,768] Trial 30 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 98, 'learning_rate': 0.12558729472693658, 'feature_fraction': 0.9415029368854164, 'bagging_fraction': 0.9224970041720484, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,836] Trial 31 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 13, 'learning_rate': 0.2220328674527317, 'feature_fraction': 0.7001264928063858, 'bagging_fraction': 0.8850334049228324, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 5 with value: 0.873015873015873.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.58072
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.539394
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.65607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.568166
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.660028
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.557208
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.654321
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659523
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.61836
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.560589
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.62835
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.611597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.668572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.532651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.590415
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.532871
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.655533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.572932
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.490875
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.580308
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.537108
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.514369
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.59251
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657052
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.522735
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.575284
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.598475
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.559471
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.653065
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.611151
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.453514
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.591709
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.551107
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.554424
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.452194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.53403
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.667903
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.593141
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.564264
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.644255
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.474903
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.555956
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.51508
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.581369
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.530457
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.533091
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.612164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.571183
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.582465
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.507118
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.554665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.508604
[I 2025-09-17 13:19:20,884] Trial 32 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 10, 'learning_rate': 0.24357247842697247, 'feature_fraction': 0.6743810811234672, 'bagging_fraction': 0.778119429871994, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,923] Trial 33 finished with value: 0.8214285714285715 and parameters: {'num_leaves': 64, 'learning_rate': 0.20735110446224048, 'feature_fraction': 0.8169326690946823, 'bagging_fraction': 0.852485174675731, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,970] Trial 34 finished with value: 0.75 and parameters: {'num_leaves': 65, 'learning_rate': 0.18000822703222039, 'feature_fraction': 0.8021979322705582, 'bagging_fraction': 0.7983775867616214, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:20,994] Trial 35 finished with value: 0.7460317460317459 and parameters: {'num_leaves': 64, 'learning_rate': 0.15170183358946254, 'feature_fraction': 0.8431598069714659, 'bagging_fraction': 0.8526572991554427, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:21,028] Trial 36 finished with value: 0.6607142857142857 and parameters: {'num_leaves': 91, 'learning_rate': 0.21154740572613911, 'feature_fraction': 0.9008980806752757, 'bagging_fraction': 0.7515992650243503, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:21,061] Trial 37 finished with value: 0.7261904761904763 and parameters: {'num_leaves': 145, 'learning_rate': 0.16421690644720624, 'feature_fraction': 0.7710350508930074, 'bagging_fraction': 0.9573319605735836, 'bagging_freq': 1, 'min_child_samples': 40}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:21,093] Trial 38 finished with value: 0.757936507936508 and parameters: {'num_leaves': 183, 'learning_rate': 0.19248102036858947, 'feature_fraction': 0.5175307005092729, 'bagging_fraction': 0.9039176030219281, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:21,129] Trial 39 finished with value: 0.7023809523809523 and parameters: {'num_leaves': 45, 'learning_rate': 0.2400984378187965, 'feature_fraction': 0.5729204732056228, 'bagging_fraction': 0.6807374548236451, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:21,188] Trial 40 finished with value: 0.8214285714285714 and parameters: {'num_leaves': 244, 'learning_rate': 0.1707102822394836, 'feature_fraction': 0.7261279640880358, 'bagging_fraction': 0.9650940829392155, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 5 with value: 0.873015873015873.
[I 2025-09-17 13:19:21,265] Trial 41 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 22, 'learning_rate': 0.2145220923788637, 'feature_fraction': 0.7099151551207381, 'bagging_fraction': 0.898868545792666, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 41 with value: 0.9166666666666666.
[I 2025-09-17 13:19:21,300] Trial 42 finished with value: 0.8095238095238095 and parameters: {'num_leaves': 28, 'learning_rate': 0.21258112403861915, 'feature_fraction': 0.8228324411518049, 'bagging_fraction': 0.8436684128051364, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 41 with value: 0.9166666666666666.
[I 2025-09-17 13:19:21,388] Trial 43 finished with value: 0.878968253968254 and parameters: {'num_leaves': 74, 'learning_rate': 0.26842135126392686, 'feature_fraction': 0.772182709996729, 'bagging_fraction': 0.7950204684021105, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 41 with value: 0.9166666666666666.
[I 2025-09-17 13:19:21,487] Trial 44 finished with value: 0.871031746031746 and parameters: {'num_leaves': 75, 'learning_rate': 0.27840610643671754, 'feature_fraction': 0.7740470018048838, 'bagging_fraction': 0.8013216070364789, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 41 with value: 0.9166666666666666.
[I 2025-09-17 13:19:21,580] Trial 45 finished with value: 0.873015873015873 and parameters: {'num_leaves': 75, 'learning_rate': 0.27594429095819467, 'feature_fraction': 0.7698731795683645, 'bagging_fraction': 0.7975785618209424, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 41 with value: 0.9166666666666666.
[I 2025-09-17 13:19:21,655] Trial 46 finished with value: 0.9166666666666667 and parameters: {'num_leaves': 73, 'learning_rate': 0.29671510483789, 'feature_fraction': 0.7802855611862186, 'bagging_fraction': 0.8047445468366144, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 46 with value: 0.9166666666666667.
[I 2025-09-17 13:19:21,696] Trial 47 finished with value: 0.6626984126984127 and parameters: {'num_leaves': 46, 'learning_rate': 0.29415286626216897, 'feature_fraction': 0.7135852587729673, 'bagging_fraction': 0.7988258463927085, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 46 with value: 0.9166666666666667.
[I 2025-09-17 13:19:21,709] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 122, 'learning_rate': 0.2727971061261616, 'feature_fraction': 0.6657836325892184, 'bagging_fraction': 0.7444004924534683, 'bagging_freq': 6, 'min_child_samples': 71}. Best is trial 46 with value: 0.9166666666666667.
[I 2025-09-17 13:19:21,786] Trial 49 finished with value: 0.8928571428571429 and parameters: {'num_leaves': 25, 'learning_rate': 0.2958316648002795, 'feature_fraction': 0.7729933826039587, 'bagging_fraction': 0.7787215817495632, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 46 with value: 0.9166666666666667.
[I 2025-09-17 13:19:22,026] A new study created in memory with name: no-name-30c7cc69-dac1-4bdb-8651-bbef26346075
[I 2025-09-17 13:19:22,048] Trial 0 finished with value: 0.7142857142857142 and parameters: {'num_leaves': 176, 'learning_rate': 0.11142913755155115, 'feature_fraction': 0.9694131581402013, 'bagging_fraction': 0.6349049855272041, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,060] Trial 1 finished with value: 0.6547619047619048 and parameters: {'num_leaves': 172, 'learning_rate': 0.17833017782933386, 'feature_fraction': 0.6549847436693916, 'bagging_fraction': 0.812196613852801, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,089] Trial 2 finished with value: 0.6706349206349206 and parameters: {'num_leaves': 295, 'learning_rate': 0.23069509215961484, 'feature_fraction': 0.7472347105141697, 'bagging_fraction': 0.8859102781441586, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,101] Trial 3 finished with value: 0.6309523809523809 and parameters: {'num_leaves': 281, 'learning_rate': 0.242711331171437, 'feature_fraction': 0.7977055285821251, 'bagging_fraction': 0.9491800937809377, 'bagging_freq': 7, 'min_child_samples': 43}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,109] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 237, 'learning_rate': 0.2372281310845916, 'feature_fraction': 0.5732922417783078, 'bagging_fraction': 0.4438872959475594, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,118] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 284, 'learning_rate': 0.047396524099101, 'feature_fraction': 0.5386853024259197, 'bagging_fraction': 0.596480315619144, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,126] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 104, 'learning_rate': 0.24211000735694527, 'feature_fraction': 0.6010262125200343, 'bagging_fraction': 0.6216224050547385, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,137] Trial 7 finished with value: 0.44841269841269843 and parameters: {'num_leaves': 221, 'learning_rate': 0.1901897474269477, 'feature_fraction': 0.9058191512027602, 'bagging_fraction': 0.5192700457885274, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,145] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.04839629018079343, 'feature_fraction': 0.6553129091925038, 'bagging_fraction': 0.874025786876954, 'bagging_freq': 7, 'min_child_samples': 85}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,152] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 151, 'learning_rate': 0.01612662661853858, 'feature_fraction': 0.7159758727570953, 'bagging_fraction': 0.9618102694984503, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,242] Trial 10 finished with value: 0.6904761904761905 and parameters: {'num_leaves': 33, 'learning_rate': 0.1087407757811917, 'feature_fraction': 0.40304119829219165, 'bagging_fraction': 0.7397288510142865, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 0 with value: 0.7142857142857142.
[I 2025-09-17 13:19:22,340] Trial 11 finished with value: 0.8055555555555556 and parameters: {'num_leaves': 19, 'learning_rate': 0.11085942394206891, 'feature_fraction': 0.4196616548916907, 'bagging_fraction': 0.7272705866131509, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,412] Trial 12 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 20, 'learning_rate': 0.11772908026082962, 'feature_fraction': 0.9799338937963686, 'bagging_fraction': 0.7036553205179081, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,525] Trial 13 finished with value: 0.7380952380952381 and parameters: {'num_leaves': 23, 'learning_rate': 0.11219527895942202, 'feature_fraction': 0.4381661913647714, 'bagging_fraction': 0.7382668450732287, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,559] Trial 14 finished with value: 0.7837301587301587 and parameters: {'num_leaves': 71, 'learning_rate': 0.1447569808536514, 'feature_fraction': 0.4044658757907931, 'bagging_fraction': 0.7656010608739319, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,607] Trial 15 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 79, 'learning_rate': 0.15188497407833645, 'feature_fraction': 0.4905608162089461, 'bagging_fraction': 0.8031655502998526, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,642] Trial 16 finished with value: 0.7222222222222222 and parameters: {'num_leaves': 77, 'learning_rate': 0.28385354686831604, 'feature_fraction': 0.4866854369114529, 'bagging_fraction': 0.7989930028960787, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,655] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 62, 'learning_rate': 0.07806293022484467, 'feature_fraction': 0.4698810033602958, 'bagging_fraction': 0.6475318844779012, 'bagging_freq': 3, 'min_child_samples': 69}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,674] Trial 18 finished with value: 0.5238095238095238 and parameters: {'num_leaves': 103, 'learning_rate': 0.14466599307404765, 'feature_fraction': 0.4076189346930273, 'bagging_fraction': 0.5378855876124122, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,722] Trial 19 finished with value: 0.7261904761904763 and parameters: {'num_leaves': 50, 'learning_rate': 0.17741724406555504, 'feature_fraction': 0.528444070638286, 'bagging_fraction': 0.8748324104585956, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,757] Trial 20 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 111, 'learning_rate': 0.20416913648682397, 'feature_fraction': 0.8240551821876306, 'bagging_fraction': 0.70707925798068, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,785] Trial 21 finished with value: 0.7837301587301586 and parameters: {'num_leaves': 114, 'learning_rate': 0.2008056626769631, 'feature_fraction': 0.8823654130720056, 'bagging_fraction': 0.685546573532845, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,802] Trial 22 finished with value: 0.47023809523809523 and parameters: {'num_leaves': 51, 'learning_rate': 0.14250689195725771, 'feature_fraction': 0.8802826751948012, 'bagging_fraction': 0.7685131237833784, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,829] Trial 23 finished with value: 0.753968253968254 and parameters: {'num_leaves': 128, 'learning_rate': 0.08604575550375841, 'feature_fraction': 0.6230527727752236, 'bagging_fraction': 0.6770655218994391, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,858] Trial 24 finished with value: 0.7559523809523809 and parameters: {'num_leaves': 11, 'learning_rate': 0.20593101095817135, 'feature_fraction': 0.7935113572034892, 'bagging_fraction': 0.5671818704246768, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 11 with value: 0.8055555555555556.
[I 2025-09-17 13:19:22,882] Trial 25 finished with value: 0.8432539682539683 and parameters: {'num_leaves': 81, 'learning_rate': 0.27582298236131714, 'feature_fraction': 0.8881110631328236, 'bagging_fraction': 0.8392369951310328, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:22,910] Trial 26 finished with value: 0.759920634920635 and parameters: {'num_leaves': 83, 'learning_rate': 0.29940495463688926, 'feature_fraction': 0.5365854447226022, 'bagging_fraction': 0.8421840829883047, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:22,928] Trial 27 finished with value: 0.6666666666666667 and parameters: {'num_leaves': 40, 'learning_rate': 0.08420166697784992, 'feature_fraction': 0.4418429367774625, 'bagging_fraction': 0.9037068109751356, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:22,999] Trial 28 finished with value: 0.75 and parameters: {'num_leaves': 64, 'learning_rate': 0.1301924622793806, 'feature_fraction': 0.7411241563038555, 'bagging_fraction': 0.7654525186072084, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,029] Trial 29 finished with value: 0.6805555555555556 and parameters: {'num_leaves': 91, 'learning_rate': 0.16463382802298962, 'feature_fraction': 0.9329363962245663, 'bagging_fraction': 0.9196047627481365, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,041] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 180, 'learning_rate': 0.26897062314422654, 'feature_fraction': 0.8415735024294694, 'bagging_fraction': 0.8253879926113491, 'bagging_freq': 3, 'min_child_samples': 75}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,076] Trial 31 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 110, 'learning_rate': 0.2615436097614764, 'feature_fraction': 0.9978736107781869, 'bagging_fraction': 0.6677296162621372, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,102] Trial 32 finished with value: 0.7083333333333334 and parameters: {'num_leaves': 123, 'learning_rate': 0.22042768047639705, 'feature_fraction': 0.8635087839939256, 'bagging_fraction': 0.7329151075607858, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,129] Trial 33 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 179, 'learning_rate': 0.16761193282296458, 'feature_fraction': 0.933914500860136, 'bagging_fraction': 0.998585385345018, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,171] Trial 34 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 58, 'learning_rate': 0.19245443526638079, 'feature_fraction': 0.7923786457877838, 'bagging_fraction': 0.7781310994584627, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,186] Trial 35 finished with value: 0.6547619047619048 and parameters: {'num_leaves': 33, 'learning_rate': 0.09894151156228628, 'feature_fraction': 0.9442864139651522, 'bagging_fraction': 0.8431630290406054, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,203] Trial 36 finished with value: 0.3591269841269842 and parameters: {'num_leaves': 165, 'learning_rate': 0.12561611397185424, 'feature_fraction': 0.6541161943644375, 'bagging_fraction': 0.6183398906032842, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,218] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.22449827344398715, 'feature_fraction': 0.8857733593032378, 'bagging_fraction': 0.6821081224504187, 'bagging_freq': 2, 'min_child_samples': 56}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,234] Trial 38 finished with value: 0.45238095238095233 and parameters: {'num_leaves': 72, 'learning_rate': 0.25096973814478957, 'feature_fraction': 0.7506975661198431, 'bagging_fraction': 0.48809010855384916, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,256] Trial 39 finished with value: 0.5873015873015873 and parameters: {'num_leaves': 94, 'learning_rate': 0.06714534780612008, 'feature_fraction': 0.5745518970015291, 'bagging_fraction': 0.5901468716070014, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,288] Trial 40 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 204, 'learning_rate': 0.13365680720598996, 'feature_fraction': 0.679109025904984, 'bagging_fraction': 0.4050140616647345, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,327] Trial 41 finished with value: 0.6825396825396826 and parameters: {'num_leaves': 208, 'learning_rate': 0.1356516771576849, 'feature_fraction': 0.6912903590880061, 'bagging_fraction': 0.4995252081144673, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 25 with value: 0.8432539682539683.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.517341
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.533111
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.590886
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.595935
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.61974
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.604549
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.563502
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.610875
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.496579
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.389456
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.520699
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.466177
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.465826
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.457947
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.426003
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.613653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.487118
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.588589
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.642916
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.61191
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.651268
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.590601
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.498572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.581489
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.572054
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.559412
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.601756
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.563754
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.654738
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.56382
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.545583
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.558831
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.664837
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.581131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.585119
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.536723
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.557396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.63853
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.570674
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.60652
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.551289
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.600628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.594408
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.542726
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.64146
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.670354
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.644683
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.547917
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.591262
[I 2025-09-17 13:19:23,349] Trial 42 finished with value: 0.5575396825396824 and parameters: {'num_leaves': 235, 'learning_rate': 0.16432781702290788, 'feature_fraction': 0.44385626805074724, 'bagging_fraction': 0.4065246787592958, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,393] Trial 43 finished with value: 0.7698412698412698 and parameters: {'num_leaves': 255, 'learning_rate': 0.18474178792867615, 'feature_fraction': 0.5091507562400234, 'bagging_fraction': 0.40810459381238345, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 25 with value: 0.8432539682539683.
[I 2025-09-17 13:19:23,472] Trial 44 finished with value: 0.8452380952380952 and parameters: {'num_leaves': 153, 'learning_rate': 0.1016315306566559, 'feature_fraction': 0.7615641255628627, 'bagging_fraction': 0.7222857870278574, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 44 with value: 0.8452380952380952.
[I 2025-09-17 13:19:23,553] Trial 45 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 216, 'learning_rate': 0.09521547759312687, 'feature_fraction': 0.7641208518530159, 'bagging_fraction': 0.7265215574518024, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 44 with value: 0.8452380952380952.
[I 2025-09-17 13:19:23,623] Trial 46 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 151, 'learning_rate': 0.05630284720465097, 'feature_fraction': 0.6895196896365616, 'bagging_fraction': 0.7887723811480027, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 44 with value: 0.8452380952380952.
[I 2025-09-17 13:19:23,687] Trial 47 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 189, 'learning_rate': 0.028578359552243582, 'feature_fraction': 0.6002609736590855, 'bagging_fraction': 0.8256638653941683, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 44 with value: 0.8452380952380952.
[I 2025-09-17 13:19:23,734] Trial 48 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 200, 'learning_rate': 0.11640867097810786, 'feature_fraction': 0.4092516972076851, 'bagging_fraction': 0.7537778875097143, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 44 with value: 0.8452380952380952.
[I 2025-09-17 13:19:23,750] Trial 49 finished with value: 0.4226190476190476 and parameters: {'num_leaves': 160, 'learning_rate': 0.10378242371726878, 'feature_fraction': 0.8275001206985642, 'bagging_fraction': 0.6473756501742627, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 44 with value: 0.8452380952380952.
[I 2025-09-17 13:19:24,274] A new study created in memory with name: no-name-d8ac9706-b207-42ff-a047-659a8d39a2ad
[I 2025-09-17 13:19:24,320] Trial 0 finished with value: 0.7023809523809523 and parameters: {'num_leaves': 207, 'learning_rate': 0.10440613209142904, 'feature_fraction': 0.7479618670336508, 'bagging_fraction': 0.7008218437824447, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 0 with value: 0.7023809523809523.
[I 2025-09-17 13:19:24,337] Trial 1 finished with value: 0.6865079365079364 and parameters: {'num_leaves': 200, 'learning_rate': 0.11925648979038465, 'feature_fraction': 0.4708348559585548, 'bagging_fraction': 0.9918706156465593, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 0 with value: 0.7023809523809523.
[I 2025-09-17 13:19:24,345] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 223, 'learning_rate': 0.19709102875599702, 'feature_fraction': 0.848436993281896, 'bagging_fraction': 0.6862599602033885, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 0 with value: 0.7023809523809523.
[I 2025-09-17 13:19:24,373] Trial 3 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 43, 'learning_rate': 0.02169997325202739, 'feature_fraction': 0.6468888937987115, 'bagging_fraction': 0.4128985414713068, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 3 with value: 0.7301587301587301.
[I 2025-09-17 13:19:24,405] Trial 4 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 44, 'learning_rate': 0.1281479319066233, 'feature_fraction': 0.8800691141925379, 'bagging_fraction': 0.7484272745646909, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,446] Trial 5 finished with value: 0.761904761904762 and parameters: {'num_leaves': 122, 'learning_rate': 0.09194744248778665, 'feature_fraction': 0.4951098153726679, 'bagging_fraction': 0.8133767202765813, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,469] Trial 6 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 14, 'learning_rate': 0.1456553151267579, 'feature_fraction': 0.4446653403993106, 'bagging_fraction': 0.9202606502191627, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,480] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 289, 'learning_rate': 0.20128865124903267, 'feature_fraction': 0.4952323473441754, 'bagging_fraction': 0.5602539177884258, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,493] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 149, 'learning_rate': 0.23866255763347474, 'feature_fraction': 0.8013191527693742, 'bagging_fraction': 0.41147890911205875, 'bagging_freq': 2, 'min_child_samples': 67}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,503] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 280, 'learning_rate': 0.11184634325369323, 'feature_fraction': 0.958027421350892, 'bagging_fraction': 0.44033954799191855, 'bagging_freq': 1, 'min_child_samples': 76}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,539] Trial 10 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 80, 'learning_rate': 0.2898252420760314, 'feature_fraction': 0.9775798442486717, 'bagging_fraction': 0.776375368940932, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,575] Trial 11 finished with value: 0.7698412698412699 and parameters: {'num_leaves': 92, 'learning_rate': 0.05591745407409186, 'feature_fraction': 0.6321862365602218, 'bagging_fraction': 0.8319125871854295, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,712] Trial 12 finished with value: 0.7738095238095237 and parameters: {'num_leaves': 83, 'learning_rate': 0.03496451082055024, 'feature_fraction': 0.6378965430255034, 'bagging_fraction': 0.8512142928328865, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,850] Trial 13 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 60, 'learning_rate': 0.014315561370367935, 'feature_fraction': 0.586221893539984, 'bagging_fraction': 0.6533952187963843, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 4 with value: 0.7896825396825397.
[I 2025-09-17 13:19:24,965] Trial 14 finished with value: 0.8531746031746031 and parameters: {'num_leaves': 34, 'learning_rate': 0.0637883062223164, 'feature_fraction': 0.8671284134225933, 'bagging_fraction': 0.6078105249652763, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:24,992] Trial 15 finished with value: 0.5158730158730158 and parameters: {'num_leaves': 12, 'learning_rate': 0.07032931197260402, 'feature_fraction': 0.8864830976760437, 'bagging_fraction': 0.5658591697649298, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,019] Trial 16 finished with value: 0.6924603174603174 and parameters: {'num_leaves': 123, 'learning_rate': 0.15245628021136357, 'feature_fraction': 0.9059767552164023, 'bagging_fraction': 0.5623749349112457, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,034] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 42, 'learning_rate': 0.1769807528521524, 'feature_fraction': 0.7723077224684728, 'bagging_fraction': 0.6184558278817573, 'bagging_freq': 7, 'min_child_samples': 53}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,068] Trial 18 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 168, 'learning_rate': 0.05579805519028565, 'feature_fraction': 0.8273685798827936, 'bagging_fraction': 0.7518239986447623, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,112] Trial 19 finished with value: 0.7896825396825398 and parameters: {'num_leaves': 109, 'learning_rate': 0.07573570296241429, 'feature_fraction': 0.7139029944783298, 'bagging_fraction': 0.7336654945497911, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,123] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 111, 'learning_rate': 0.0757513664242655, 'feature_fraction': 0.7226464774698919, 'bagging_fraction': 0.5049262927831197, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,164] Trial 21 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 51, 'learning_rate': 0.14088864182123156, 'feature_fraction': 0.9083203745540892, 'bagging_fraction': 0.7419315909033167, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,213] Trial 22 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 62, 'learning_rate': 0.08806156117809164, 'feature_fraction': 0.9561681223820957, 'bagging_fraction': 0.6267420916757724, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,265] Trial 23 finished with value: 0.7896825396825397 and parameters: {'num_leaves': 27, 'learning_rate': 0.057564578472835984, 'feature_fraction': 0.6869499873261157, 'bagging_fraction': 0.7034539481352314, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,282] Trial 24 finished with value: 0.5376984126984127 and parameters: {'num_leaves': 151, 'learning_rate': 0.13426219475201231, 'feature_fraction': 0.9172468269381834, 'bagging_fraction': 0.5084410707888168, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,431] Trial 25 finished with value: 0.8373015873015873 and parameters: {'num_leaves': 101, 'learning_rate': 0.045789734547350566, 'feature_fraction': 0.7986206006467707, 'bagging_fraction': 0.8827326195723795, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,573] Trial 26 finished with value: 0.8492063492063492 and parameters: {'num_leaves': 69, 'learning_rate': 0.038542038530171296, 'feature_fraction': 0.8049571018415732, 'bagging_fraction': 0.9216471956925865, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,748] Trial 27 finished with value: 0.8055555555555555 and parameters: {'num_leaves': 72, 'learning_rate': 0.040081958889417395, 'feature_fraction': 0.795924601441912, 'bagging_fraction': 0.9362879585371511, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,781] Trial 28 finished with value: 0.623015873015873 and parameters: {'num_leaves': 96, 'learning_rate': 0.040135635810953786, 'feature_fraction': 0.8455283889759808, 'bagging_fraction': 0.8914614637422426, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,859] Trial 29 finished with value: 0.8174603174603174 and parameters: {'num_leaves': 175, 'learning_rate': 0.09800291744346873, 'feature_fraction': 0.7605911071015611, 'bagging_fraction': 0.9978224457610383, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,883] Trial 30 finished with value: 0.6547619047619048 and parameters: {'num_leaves': 130, 'learning_rate': 0.026839947813754626, 'feature_fraction': 0.7468237435701938, 'bagging_fraction': 0.8725201133741255, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,927] Trial 31 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 57, 'learning_rate': 0.17258281885320062, 'feature_fraction': 0.8243046550935252, 'bagging_fraction': 0.9349385093859478, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:25,973] Trial 32 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 28, 'learning_rate': 0.24320432105461398, 'feature_fraction': 0.9320585874285968, 'bagging_fraction': 0.7998980226086605, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,022] Trial 33 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 73, 'learning_rate': 0.011298866966775824, 'feature_fraction': 0.8577333230313322, 'bagging_fraction': 0.9711675464591146, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,078] Trial 34 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 40, 'learning_rate': 0.10766800083019776, 'feature_fraction': 0.7910155280085998, 'bagging_fraction': 0.8905342286501008, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,113] Trial 35 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 248, 'learning_rate': 0.05084681395327942, 'feature_fraction': 0.9977041968924962, 'bagging_fraction': 0.7113123482103553, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,179] Trial 36 finished with value: 0.7638888888888888 and parameters: {'num_leaves': 99, 'learning_rate': 0.12158317429167219, 'feature_fraction': 0.869801616663197, 'bagging_fraction': 0.675907267370269, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,196] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 53, 'learning_rate': 0.0846762695555825, 'feature_fraction': 0.8950188037468241, 'bagging_fraction': 0.9552289312215373, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,229] Trial 38 finished with value: 0.8253968253968255 and parameters: {'num_leaves': 29, 'learning_rate': 0.21908933291721627, 'feature_fraction': 0.823669265422426, 'bagging_fraction': 0.7811550732536655, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,244] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 23, 'learning_rate': 0.29087018851202645, 'feature_fraction': 0.678652897637108, 'bagging_fraction': 0.7916302362846838, 'bagging_freq': 7, 'min_child_samples': 61}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,275] Trial 40 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 31, 'learning_rate': 0.24134996471593234, 'feature_fraction': 0.8114761121766619, 'bagging_fraction': 0.840381823977525, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,312] Trial 41 finished with value: 0.75 and parameters: {'num_leaves': 43, 'learning_rate': 0.1849685390006701, 'feature_fraction': 0.8437171691397308, 'bagging_fraction': 0.8719309094250648, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,369] Trial 42 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 10, 'learning_rate': 0.21088164827526, 'feature_fraction': 0.9420607822844385, 'bagging_fraction': 0.7760390985345329, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,400] Trial 43 finished with value: 0.7638888888888888 and parameters: {'num_leaves': 70, 'learning_rate': 0.22289768322868034, 'feature_fraction': 0.8701774601396801, 'bagging_fraction': 0.9041005613442115, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,428] Trial 44 finished with value: 0.6309523809523809 and parameters: {'num_leaves': 85, 'learning_rate': 0.022832182178864662, 'feature_fraction': 0.7445724033795558, 'bagging_fraction': 0.6008272989047502, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,478] Trial 45 finished with value: 0.751984126984127 and parameters: {'num_leaves': 56, 'learning_rate': 0.27593673384620787, 'feature_fraction': 0.7812309674970274, 'bagging_fraction': 0.8269682137991557, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,515] Trial 46 finished with value: 0.76984126984127 and parameters: {'num_leaves': 132, 'learning_rate': 0.1380492017402622, 'feature_fraction': 0.8297195779946749, 'bagging_fraction': 0.6686992653721933, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,610] Trial 47 finished with value: 0.7996031746031745 and parameters: {'num_leaves': 200, 'learning_rate': 0.2722623706173205, 'feature_fraction': 0.5546811505491228, 'bagging_fraction': 0.7298385544443803, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,647] Trial 48 finished with value: 0.7817460317460317 and parameters: {'num_leaves': 36, 'learning_rate': 0.15874927878809633, 'feature_fraction': 0.9023582875473903, 'bagging_fraction': 0.7508457622685455, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:26,689] Trial 49 finished with value: 0.75 and parameters: {'num_leaves': 24, 'learning_rate': 0.06747188690749192, 'feature_fraction': 0.40406137656700203, 'bagging_fraction': 0.8666243788003004, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 14 with value: 0.8531746031746031.
[I 2025-09-17 13:19:27,381] A new study created in memory with name: no-name-f9312185-1ec2-4a43-b58c-b078e8d4f772
[I 2025-09-17 13:19:27,389] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 208, 'learning_rate': 0.1297323844954774, 'feature_fraction': 0.9944066263904335, 'bagging_fraction': 0.8332046914417042, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 0 with value: 0.5.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.647661
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.543222
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.521097
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.542194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.558604
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.581904
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.586785
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.659425
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.599343
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.594756
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.603912
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.550514
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.550992
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.586173
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.605829
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.541314
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.549887
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.562703
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.484118
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.65075
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.620483
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.578802
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.537341
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.499679
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.571225
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.544144
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.652829
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.474371
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.460249
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.499649
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.628587
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.511839
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.626621
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.562834
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.549592
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.594811
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.535901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.610981
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.525546
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.546872
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.655607
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.559024
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.573665
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.547104
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.54874
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.630023
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.5716
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.570703
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.489054
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.54983
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.560405
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655482
[I 2025-09-17 13:19:27,397] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 13, 'learning_rate': 0.23873902501027072, 'feature_fraction': 0.8025700802742364, 'bagging_fraction': 0.4155062466093368, 'bagging_freq': 5, 'min_child_samples': 39}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:27,404] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 66, 'learning_rate': 0.1736588301664333, 'feature_fraction': 0.5984925821054756, 'bagging_fraction': 0.8008331596190732, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:27,412] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 211, 'learning_rate': 0.06150371085209257, 'feature_fraction': 0.5402883388583648, 'bagging_fraction': 0.4919980087170091, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:27,420] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 22, 'learning_rate': 0.24602325464730318, 'feature_fraction': 0.513279851243584, 'bagging_fraction': 0.5411524171612048, 'bagging_freq': 7, 'min_child_samples': 59}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:27,428] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 150, 'learning_rate': 0.26733277186811394, 'feature_fraction': 0.7321897248863652, 'bagging_fraction': 0.747548058940093, 'bagging_freq': 6, 'min_child_samples': 61}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:27,435] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 240, 'learning_rate': 0.0370144463619904, 'feature_fraction': 0.40141471789166794, 'bagging_fraction': 0.4335872621930723, 'bagging_freq': 1, 'min_child_samples': 81}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:27,442] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 91, 'learning_rate': 0.05064041675026173, 'feature_fraction': 0.45888684184473494, 'bagging_fraction': 0.8391130574340515, 'bagging_freq': 5, 'min_child_samples': 80}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:27,448] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 41, 'learning_rate': 0.24512020012859148, 'feature_fraction': 0.6088028331334001, 'bagging_fraction': 0.6627606201733542, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:27,479] Trial 9 finished with value: 0.7142857142857142 and parameters: {'num_leaves': 88, 'learning_rate': 0.2875040320349993, 'feature_fraction': 0.5258860319698431, 'bagging_fraction': 0.8464691300614253, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 9 with value: 0.7142857142857142.
[I 2025-09-17 13:19:27,552] Trial 10 finished with value: 0.7103174603174602 and parameters: {'num_leaves': 123, 'learning_rate': 0.1681518034349891, 'feature_fraction': 0.860449057931691, 'bagging_fraction': 0.9800890325615532, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 9 with value: 0.7142857142857142.
[I 2025-09-17 13:19:27,651] Trial 11 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 126, 'learning_rate': 0.17431091334798712, 'feature_fraction': 0.8861900306476964, 'bagging_fraction': 0.9813940047394863, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:27,742] Trial 12 finished with value: 0.75 and parameters: {'num_leaves': 109, 'learning_rate': 0.29269107578608045, 'feature_fraction': 0.9591920929640367, 'bagging_fraction': 0.9964951333256196, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:27,900] Trial 13 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 150, 'learning_rate': 0.11609651087499775, 'feature_fraction': 0.9776179158762252, 'bagging_fraction': 0.9516606022031668, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:27,945] Trial 14 finished with value: 0.6825396825396826 and parameters: {'num_leaves': 291, 'learning_rate': 0.13454685175547823, 'feature_fraction': 0.8898156441378197, 'bagging_fraction': 0.9253732451145678, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:27,993] Trial 15 finished with value: 0.6944444444444444 and parameters: {'num_leaves': 169, 'learning_rate': 0.09497176380998336, 'feature_fraction': 0.9107639242906573, 'bagging_fraction': 0.9024367178631814, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,018] Trial 16 finished with value: 0.6666666666666667 and parameters: {'num_leaves': 162, 'learning_rate': 0.20225173115292827, 'feature_fraction': 0.8099455580959842, 'bagging_fraction': 0.6666998558776768, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,066] Trial 17 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 132, 'learning_rate': 0.09843021932164145, 'feature_fraction': 0.7437124457211628, 'bagging_fraction': 0.920750059413527, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,089] Trial 18 finished with value: 0.6666666666666666 and parameters: {'num_leaves': 198, 'learning_rate': 0.1980330215492809, 'feature_fraction': 0.9432012187662321, 'bagging_fraction': 0.7417573010386782, 'bagging_freq': 2, 'min_child_samples': 44}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,130] Trial 19 finished with value: 0.7341269841269841 and parameters: {'num_leaves': 265, 'learning_rate': 0.0886410806522901, 'feature_fraction': 0.8450635334333206, 'bagging_fraction': 0.5893250867730514, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,157] Trial 20 finished with value: 0.6706349206349207 and parameters: {'num_leaves': 184, 'learning_rate': 0.12812083411733638, 'feature_fraction': 0.9990900628128956, 'bagging_fraction': 0.9410696680205219, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,210] Trial 21 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 139, 'learning_rate': 0.0964051132583856, 'feature_fraction': 0.7282754191527352, 'bagging_fraction': 0.8990028009187865, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,359] Trial 22 finished with value: 0.7619047619047619 and parameters: {'num_leaves': 126, 'learning_rate': 0.016681093855215712, 'feature_fraction': 0.7818386060672833, 'bagging_fraction': 0.962567671321026, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,487] Trial 23 finished with value: 0.753968253968254 and parameters: {'num_leaves': 94, 'learning_rate': 0.01350753804521404, 'feature_fraction': 0.7910936298238883, 'bagging_fraction': 0.9849444926858648, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,525] Trial 24 finished with value: 0.7857142857142858 and parameters: {'num_leaves': 63, 'learning_rate': 0.15025539246650382, 'feature_fraction': 0.6441782959325097, 'bagging_fraction': 0.8795428725030622, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,564] Trial 25 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 58, 'learning_rate': 0.20952993660027996, 'feature_fraction': 0.6571156853238354, 'bagging_fraction': 0.8802294793706607, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,615] Trial 26 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 75, 'learning_rate': 0.15533701978198072, 'feature_fraction': 0.6523562570595378, 'bagging_fraction': 0.7856107257400777, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,653] Trial 27 finished with value: 0.7103174603174603 and parameters: {'num_leaves': 117, 'learning_rate': 0.18246838048102604, 'feature_fraction': 0.6600269453498693, 'bagging_fraction': 0.8736532691311086, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,689] Trial 28 finished with value: 0.7261904761904763 and parameters: {'num_leaves': 43, 'learning_rate': 0.2221084684395799, 'feature_fraction': 0.7560581708628553, 'bagging_fraction': 0.954292782536686, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,716] Trial 29 finished with value: 0.6150793650793651 and parameters: {'num_leaves': 102, 'learning_rate': 0.012446552060263183, 'feature_fraction': 0.8526032919854275, 'bagging_fraction': 0.8107777565028319, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,770] Trial 30 finished with value: 0.6825396825396826 and parameters: {'num_leaves': 228, 'learning_rate': 0.14655938588853912, 'feature_fraction': 0.6888122107636652, 'bagging_fraction': 0.8704200727501087, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,900] Trial 31 finished with value: 0.75 and parameters: {'num_leaves': 173, 'learning_rate': 0.12029863153147043, 'feature_fraction': 0.9563469162722504, 'bagging_fraction': 0.9540356101201721, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:28,951] Trial 32 finished with value: 0.6626984126984127 and parameters: {'num_leaves': 139, 'learning_rate': 0.06969113709547183, 'feature_fraction': 0.9106927827546892, 'bagging_fraction': 0.9924730697412869, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,018] Trial 33 finished with value: 0.7658730158730158 and parameters: {'num_leaves': 150, 'learning_rate': 0.11192162709157318, 'feature_fraction': 0.7892642295933928, 'bagging_fraction': 0.9339943971179531, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,081] Trial 34 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 75, 'learning_rate': 0.15731952123619988, 'feature_fraction': 0.7985875476537687, 'bagging_fraction': 0.9332801568483652, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,107] Trial 35 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 10, 'learning_rate': 0.18182753307649757, 'feature_fraction': 0.7736550680469043, 'bagging_fraction': 0.7788191909796709, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,150] Trial 36 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 194, 'learning_rate': 0.14143298564826545, 'feature_fraction': 0.7009788290155698, 'bagging_fraction': 0.8476714088521308, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,235] Trial 37 finished with value: 0.746031746031746 and parameters: {'num_leaves': 47, 'learning_rate': 0.08038354254830847, 'feature_fraction': 0.5851320532945826, 'bagging_fraction': 0.9052406477836376, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,260] Trial 38 finished with value: 0.6626984126984127 and parameters: {'num_leaves': 123, 'learning_rate': 0.031115748260341164, 'feature_fraction': 0.8304332381798396, 'bagging_fraction': 0.9694207651954349, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,283] Trial 39 finished with value: 0.6150793650793651 and parameters: {'num_leaves': 29, 'learning_rate': 0.11169979706675758, 'feature_fraction': 0.6171973339762328, 'bagging_fraction': 0.8172112295652577, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,312] Trial 40 finished with value: 0.7301587301587301 and parameters: {'num_leaves': 152, 'learning_rate': 0.23106839280115138, 'feature_fraction': 0.7067174504197863, 'bagging_fraction': 0.69836962192795, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,383] Trial 41 finished with value: 0.8134920634920635 and parameters: {'num_leaves': 151, 'learning_rate': 0.11489482201763276, 'feature_fraction': 0.8758979555119475, 'bagging_fraction': 0.950494961378415, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,460] Trial 42 finished with value: 0.7341269841269842 and parameters: {'num_leaves': 182, 'learning_rate': 0.05121589616123482, 'feature_fraction': 0.8799244202241414, 'bagging_fraction': 0.8798074367691703, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,503] Trial 43 finished with value: 0.7936507936507937 and parameters: {'num_leaves': 211, 'learning_rate': 0.16520101323788208, 'feature_fraction': 0.8181205883509989, 'bagging_fraction': 0.9657793789490523, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,540] Trial 44 finished with value: 0.7817460317460316 and parameters: {'num_leaves': 210, 'learning_rate': 0.16944832595206966, 'feature_fraction': 0.9190116040959244, 'bagging_fraction': 0.9976616885500567, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,584] Trial 45 finished with value: 0.7738095238095238 and parameters: {'num_leaves': 223, 'learning_rate': 0.1686472365050848, 'feature_fraction': 0.9242140172416332, 'bagging_fraction': 0.994475430939068, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,593] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 241, 'learning_rate': 0.18659159217754995, 'feature_fraction': 0.8809500749882416, 'bagging_fraction': 0.9997179779690794, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,617] Trial 47 finished with value: 0.7579365079365079 and parameters: {'num_leaves': 210, 'learning_rate': 0.16566578007499397, 'feature_fraction': 0.8288631626333244, 'bagging_fraction': 0.5683438250796718, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,672] Trial 48 finished with value: 0.6706349206349206 and parameters: {'num_leaves': 240, 'learning_rate': 0.14239482760846603, 'feature_fraction': 0.9329546305208664, 'bagging_fraction': 0.9116694227958029, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:29,704] Trial 49 finished with value: 0.6984126984126984 and parameters: {'num_leaves': 193, 'learning_rate': 0.1936373598337724, 'feature_fraction': 0.573241575123135, 'bagging_fraction': 0.9640280771670203, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 11 with value: 0.8134920634920635.
[I 2025-09-17 13:19:30,087] A new study created in memory with name: no-name-b7606bb0-49b1-4888-95cf-30ca262ab2d7
[I 2025-09-17 13:19:30,096] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 138, 'learning_rate': 0.12467574853317692, 'feature_fraction': 0.5585880010986382, 'bagging_fraction': 0.6446258943834169, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:30,105] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 217, 'learning_rate': 0.1116836035249004, 'feature_fraction': 0.4455541996765634, 'bagging_fraction': 0.7281258183075277, 'bagging_freq': 6, 'min_child_samples': 63}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:30,113] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 99, 'learning_rate': 0.15175822756744517, 'feature_fraction': 0.49124421719508776, 'bagging_fraction': 0.7790395783271619, 'bagging_freq': 6, 'min_child_samples': 99}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:30,130] Trial 3 finished with value: 0.6811145510835913 and parameters: {'num_leaves': 297, 'learning_rate': 0.05166632179361493, 'feature_fraction': 0.545130217063606, 'bagging_fraction': 0.8690907473593765, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 3 with value: 0.6811145510835913.
[I 2025-09-17 13:19:30,138] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 241, 'learning_rate': 0.2282290605434277, 'feature_fraction': 0.9450241659359103, 'bagging_fraction': 0.48673527943318035, 'bagging_freq': 6, 'min_child_samples': 42}. Best is trial 3 with value: 0.6811145510835913.
[I 2025-09-17 13:19:30,143] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 126, 'learning_rate': 0.08002896188307326, 'feature_fraction': 0.7565961637532242, 'bagging_fraction': 0.7289827473163175, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 3 with value: 0.6811145510835913.
[I 2025-09-17 13:19:30,162] Trial 6 finished with value: 0.7306501547987616 and parameters: {'num_leaves': 188, 'learning_rate': 0.1968105826140639, 'feature_fraction': 0.4519698568188454, 'bagging_fraction': 0.6077435472173933, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 6 with value: 0.7306501547987616.
[I 2025-09-17 13:19:30,182] Trial 7 finished with value: 0.7678018575851393 and parameters: {'num_leaves': 111, 'learning_rate': 0.11502214865855782, 'feature_fraction': 0.7186735710974885, 'bagging_fraction': 0.9001370400019896, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,190] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 122, 'learning_rate': 0.1708664233788107, 'feature_fraction': 0.4881456764586749, 'bagging_fraction': 0.6859260759356598, 'bagging_freq': 7, 'min_child_samples': 92}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,208] Trial 9 finished with value: 0.7461300309597524 and parameters: {'num_leaves': 76, 'learning_rate': 0.27462266498397525, 'feature_fraction': 0.49186867715892907, 'bagging_fraction': 0.8779087048125842, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 7 with value: 0.7678018575851393.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.578023
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.546725
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.492085
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.565259
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.523069
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.584222
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.570094
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.581991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.508172
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.60098
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.544918
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.609731
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.541752
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.522799
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.533783
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.523714
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.537572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.5505
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.567879
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.599043
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.638835
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.550085
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.534383
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.581688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.505465
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.52104
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.577275
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.540142
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.524154
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.621812
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.620122
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.542757
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.502043
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.536126
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.503285
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.503133
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.503476
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.655482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.55704
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.573919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.586544
Training model for P105... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.619974
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.613979
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.600427
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.599162
[I 2025-09-17 13:19:30,296] Trial 10 finished with value: 0.7585139318885449 and parameters: {'num_leaves': 12, 'learning_rate': 0.03930474674802746, 'feature_fraction': 0.7372587309617932, 'bagging_fraction': 0.98938528085038, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,437] Trial 11 finished with value: 0.696594427244582 and parameters: {'num_leaves': 17, 'learning_rate': 0.014446533011393637, 'feature_fraction': 0.729614849358368, 'bagging_fraction': 0.9934277234026897, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,573] Trial 12 finished with value: 0.6965944272445821 and parameters: {'num_leaves': 25, 'learning_rate': 0.013519837453034662, 'feature_fraction': 0.8438674946187525, 'bagging_fraction': 0.9974983037522402, 'bagging_freq': 5, 'min_child_samples': 7}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,600] Trial 13 finished with value: 0.7229102167182663 and parameters: {'num_leaves': 72, 'learning_rate': 0.07221398513979371, 'feature_fraction': 0.6530362891986046, 'bagging_fraction': 0.8895146011808961, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,622] Trial 14 finished with value: 0.585139318885449 and parameters: {'num_leaves': 49, 'learning_rate': 0.11607456316918817, 'feature_fraction': 0.8229206265930644, 'bagging_fraction': 0.938406777262518, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,647] Trial 15 finished with value: 0.7136222910216719 and parameters: {'num_leaves': 161, 'learning_rate': 0.06524777359504713, 'feature_fraction': 0.6352133409297875, 'bagging_fraction': 0.8133848206199032, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,659] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 10, 'learning_rate': 0.03775169858061672, 'feature_fraction': 0.8329635061306941, 'bagging_fraction': 0.40521788431606093, 'bagging_freq': 3, 'min_child_samples': 74}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,698] Trial 17 finished with value: 0.7275541795665635 and parameters: {'num_leaves': 51, 'learning_rate': 0.09890780799510829, 'feature_fraction': 0.9991665596407169, 'bagging_fraction': 0.8164349262896407, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,721] Trial 18 finished with value: 0.7027863777089783 and parameters: {'num_leaves': 179, 'learning_rate': 0.15342522138865478, 'feature_fraction': 0.6585520110454659, 'bagging_fraction': 0.936602036207671, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,736] Trial 19 finished with value: 0.7461300309597523 and parameters: {'num_leaves': 98, 'learning_rate': 0.2232172467878109, 'feature_fraction': 0.762059355574091, 'bagging_fraction': 0.9412545600113059, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,747] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 297, 'learning_rate': 0.2960016888614606, 'feature_fraction': 0.594905428402117, 'bagging_fraction': 0.5829155010839531, 'bagging_freq': 2, 'min_child_samples': 78}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,767] Trial 21 finished with value: 0.7260061919504645 and parameters: {'num_leaves': 71, 'learning_rate': 0.2906527546653499, 'feature_fraction': 0.7052233178037659, 'bagging_fraction': 0.8701616305795176, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,798] Trial 22 finished with value: 0.7430340557275542 and parameters: {'num_leaves': 92, 'learning_rate': 0.24349631905401947, 'feature_fraction': 0.7961086646645701, 'bagging_fraction': 0.9035500392423702, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,818] Trial 23 finished with value: 0.7507739938080495 and parameters: {'num_leaves': 50, 'learning_rate': 0.26436949963399003, 'feature_fraction': 0.40128278156917846, 'bagging_fraction': 0.9864575289706511, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,834] Trial 24 finished with value: 0.7430340557275541 and parameters: {'num_leaves': 42, 'learning_rate': 0.18442525173575217, 'feature_fraction': 0.8929879540235681, 'bagging_fraction': 0.9844042750024504, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,856] Trial 25 finished with value: 0.7430340557275543 and parameters: {'num_leaves': 36, 'learning_rate': 0.13948251287119917, 'feature_fraction': 0.6876402594385937, 'bagging_fraction': 0.952850164261605, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,881] Trial 26 finished with value: 0.718266253869969 and parameters: {'num_leaves': 61, 'learning_rate': 0.26012079284564327, 'feature_fraction': 0.4033090807791851, 'bagging_fraction': 0.8155821141533556, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,900] Trial 27 finished with value: 0.7430340557275542 and parameters: {'num_leaves': 109, 'learning_rate': 0.09509812061451225, 'feature_fraction': 0.6086006854974406, 'bagging_fraction': 0.9188169628921865, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,921] Trial 28 finished with value: 0.7616099071207431 and parameters: {'num_leaves': 29, 'learning_rate': 0.2051066619328776, 'feature_fraction': 0.8734198286014533, 'bagging_fraction': 0.9697952062791733, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,940] Trial 29 finished with value: 0.7213622291021672 and parameters: {'num_leaves': 146, 'learning_rate': 0.20297560548912508, 'feature_fraction': 0.8867754125130176, 'bagging_fraction': 0.848213436209008, 'bagging_freq': 3, 'min_child_samples': 49}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,951] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 10, 'learning_rate': 0.0367899880711766, 'feature_fraction': 0.8933927839678889, 'bagging_fraction': 0.9594315313317767, 'bagging_freq': 1, 'min_child_samples': 83}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,975] Trial 31 finished with value: 0.7414860681114551 and parameters: {'num_leaves': 38, 'learning_rate': 0.21737495755760472, 'feature_fraction': 0.7759769237695946, 'bagging_fraction': 0.9978573464864569, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:30,997] Trial 32 finished with value: 0.7337461300309598 and parameters: {'num_leaves': 28, 'learning_rate': 0.12787088050087653, 'feature_fraction': 0.5672983104384289, 'bagging_fraction': 0.9653321346113828, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,017] Trial 33 finished with value: 0.7012383900928792 and parameters: {'num_leaves': 83, 'learning_rate': 0.25556479917242947, 'feature_fraction': 0.7299386261375483, 'bagging_fraction': 0.9185000797053609, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,029] Trial 34 finished with value: 0.5 and parameters: {'num_leaves': 52, 'learning_rate': 0.167339169743979, 'feature_fraction': 0.6871029098705811, 'bagging_fraction': 0.7347610206963149, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,045] Trial 35 finished with value: 0.7275541795665634 and parameters: {'num_leaves': 249, 'learning_rate': 0.2431577223031114, 'feature_fraction': 0.9921963992122287, 'bagging_fraction': 0.845800377544713, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,092] Trial 36 finished with value: 0.7430340557275542 and parameters: {'num_leaves': 109, 'learning_rate': 0.19018887700170123, 'feature_fraction': 0.8032584819587585, 'bagging_fraction': 0.9032354612915098, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,110] Trial 37 finished with value: 0.7198142414860682 and parameters: {'num_leaves': 60, 'learning_rate': 0.1408381176769964, 'feature_fraction': 0.9359440448937557, 'bagging_fraction': 0.7613696008969687, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,131] Trial 38 finished with value: 0.7151702786377709 and parameters: {'num_leaves': 30, 'learning_rate': 0.20661445745229018, 'feature_fraction': 0.522797898746439, 'bagging_fraction': 0.9651790787300069, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,158] Trial 39 finished with value: 0.7383900928792569 and parameters: {'num_leaves': 132, 'learning_rate': 0.16876915363031902, 'feature_fraction': 0.8586388821594522, 'bagging_fraction': 0.6801369201494785, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,180] Trial 40 finished with value: 0.7430340557275541 and parameters: {'num_leaves': 222, 'learning_rate': 0.2826828973030363, 'feature_fraction': 0.7340746250723446, 'bagging_fraction': 0.5280636327974051, 'bagging_freq': 5, 'min_child_samples': 36}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,202] Trial 41 finished with value: 0.7414860681114551 and parameters: {'num_leaves': 80, 'learning_rate': 0.268377562008105, 'feature_fraction': 0.4041611434558745, 'bagging_fraction': 0.8713182070844883, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,221] Trial 42 finished with value: 0.7538699690402475 and parameters: {'num_leaves': 66, 'learning_rate': 0.270741507658505, 'feature_fraction': 0.47138792538478536, 'bagging_fraction': 0.9675344893512621, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,239] Trial 43 finished with value: 0.7476780185758513 and parameters: {'num_leaves': 22, 'learning_rate': 0.2372407850771307, 'feature_fraction': 0.44239135105836913, 'bagging_fraction': 0.9749373839084974, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 7 with value: 0.7678018575851393.
[I 2025-09-17 13:19:31,265] Trial 44 finished with value: 0.7739938080495355 and parameters: {'num_leaves': 61, 'learning_rate': 0.08894181747705487, 'feature_fraction': 0.4503370632537739, 'bagging_fraction': 0.9246115453060844, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 44 with value: 0.7739938080495355.
[I 2025-09-17 13:19:31,294] Trial 45 finished with value: 0.7678018575851393 and parameters: {'num_leaves': 115, 'learning_rate': 0.04949675280373047, 'feature_fraction': 0.5063759049169471, 'bagging_fraction': 0.9210228905231407, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 44 with value: 0.7739938080495355.
[I 2025-09-17 13:19:31,330] Trial 46 finished with value: 0.7461300309597523 and parameters: {'num_leaves': 116, 'learning_rate': 0.057200690255717807, 'feature_fraction': 0.5431572428886556, 'bagging_fraction': 0.7889212117031337, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 44 with value: 0.7739938080495355.
[I 2025-09-17 13:19:31,353] Trial 47 finished with value: 0.6996904024767802 and parameters: {'num_leaves': 150, 'learning_rate': 0.08413375405691631, 'feature_fraction': 0.5093561697758011, 'bagging_fraction': 0.8412586484487803, 'bagging_freq': 2, 'min_child_samples': 61}. Best is trial 44 with value: 0.7739938080495355.
[I 2025-09-17 13:19:31,375] Trial 48 finished with value: 0.5758513931888545 and parameters: {'num_leaves': 162, 'learning_rate': 0.036983160975127535, 'feature_fraction': 0.6219747916380646, 'bagging_fraction': 0.9318384217664801, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 44 with value: 0.7739938080495355.
[I 2025-09-17 13:19:31,402] Trial 49 finished with value: 0.7012383900928792 and parameters: {'num_leaves': 87, 'learning_rate': 0.023223143557537466, 'feature_fraction': 0.5785464563194911, 'bagging_fraction': 0.9129427597472622, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 44 with value: 0.7739938080495355.
[I 2025-09-17 13:19:31,738] A new study created in memory with name: no-name-80690011-a5e8-4704-a800-df6c1082f187
[I 2025-09-17 13:19:31,756] Trial 0 finished with value: 0.6904024767801857 and parameters: {'num_leaves': 266, 'learning_rate': 0.09141821341572609, 'feature_fraction': 0.8157343581413603, 'bagging_fraction': 0.725615635663831, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 0 with value: 0.6904024767801857.
[I 2025-09-17 13:19:31,774] Trial 1 finished with value: 0.71671826625387 and parameters: {'num_leaves': 86, 'learning_rate': 0.02753625841995365, 'feature_fraction': 0.6176355439366321, 'bagging_fraction': 0.7208406605981577, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,795] Trial 2 finished with value: 0.6795665634674923 and parameters: {'num_leaves': 232, 'learning_rate': 0.2973119102139152, 'feature_fraction': 0.5985535384671224, 'bagging_fraction': 0.7192999814155235, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,810] Trial 3 finished with value: 0.7058823529411764 and parameters: {'num_leaves': 169, 'learning_rate': 0.2667330626838075, 'feature_fraction': 0.8373548980337944, 'bagging_fraction': 0.5712527269698301, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,818] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 125, 'learning_rate': 0.2657974205788556, 'feature_fraction': 0.7483253527065622, 'bagging_fraction': 0.7104130178881634, 'bagging_freq': 6, 'min_child_samples': 69}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,826] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 292, 'learning_rate': 0.2536759939919947, 'feature_fraction': 0.7471808396954072, 'bagging_fraction': 0.49428308800089177, 'bagging_freq': 6, 'min_child_samples': 69}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,833] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 68, 'learning_rate': 0.0567642277180733, 'feature_fraction': 0.48171713216866063, 'bagging_fraction': 0.9096606301888885, 'bagging_freq': 6, 'min_child_samples': 77}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,853] Trial 7 finished with value: 0.6857585139318886 and parameters: {'num_leaves': 215, 'learning_rate': 0.038907147950958315, 'feature_fraction': 0.9843306355451288, 'bagging_fraction': 0.9385906240778952, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,862] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 134, 'learning_rate': 0.026156512188080204, 'feature_fraction': 0.48767198000289425, 'bagging_fraction': 0.6091551278048828, 'bagging_freq': 7, 'min_child_samples': 59}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,876] Trial 9 finished with value: 0.6764705882352942 and parameters: {'num_leaves': 24, 'learning_rate': 0.057319950422968266, 'feature_fraction': 0.5659029925996184, 'bagging_fraction': 0.8898878246923516, 'bagging_freq': 7, 'min_child_samples': 68}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,886] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 76, 'learning_rate': 0.15324326339326372, 'feature_fraction': 0.6489539160136961, 'bagging_fraction': 0.40106959938543313, 'bagging_freq': 4, 'min_child_samples': 96}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,906] Trial 11 finished with value: 0.7089783281733746 and parameters: {'num_leaves': 178, 'learning_rate': 0.18579808528630642, 'feature_fraction': 0.8964932980113949, 'bagging_fraction': 0.5874260030776719, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,922] Trial 12 finished with value: 0.6934984520123839 and parameters: {'num_leaves': 178, 'learning_rate': 0.19003175735755756, 'feature_fraction': 0.9854628656052181, 'bagging_fraction': 0.612436809505485, 'bagging_freq': 4, 'min_child_samples': 43}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,939] Trial 13 finished with value: 0.6981424148606812 and parameters: {'num_leaves': 90, 'learning_rate': 0.14780529394486383, 'feature_fraction': 0.8908723592199954, 'bagging_fraction': 0.8333067700909657, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,956] Trial 14 finished with value: 0.71671826625387 and parameters: {'num_leaves': 18, 'learning_rate': 0.19172529838104058, 'feature_fraction': 0.6767089805876836, 'bagging_fraction': 0.8009256435669861, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 1 with value: 0.71671826625387.
[I 2025-09-17 13:19:31,978] Trial 15 finished with value: 0.7724458204334365 and parameters: {'num_leaves': 15, 'learning_rate': 0.10841998323096659, 'feature_fraction': 0.6659518281204942, 'bagging_fraction': 0.8120225254435817, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:31,996] Trial 16 finished with value: 0.7554179566563467 and parameters: {'num_leaves': 47, 'learning_rate': 0.1081729643959635, 'feature_fraction': 0.4308644667806103, 'bagging_fraction': 0.7927217272364601, 'bagging_freq': 5, 'min_child_samples': 53}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,014] Trial 17 finished with value: 0.7105263157894737 and parameters: {'num_leaves': 52, 'learning_rate': 0.11569836090146024, 'feature_fraction': 0.4173735795089517, 'bagging_fraction': 0.9798801353163096, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,025] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 41, 'learning_rate': 0.0931833427769464, 'feature_fraction': 0.5239542266819375, 'bagging_fraction': 0.7934318608518053, 'bagging_freq': 5, 'min_child_samples': 89}. Best is trial 15 with value: 0.7724458204334365.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.597213
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.625855
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.635171
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.620249
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.658157
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.615602
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.620943
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.627312
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.602054
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.624628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.599031
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.599529
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.61136
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.606616
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.606709
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.606887
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.603328
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.610886
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.603924
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.609244
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.64169
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.60918
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.617292
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.612333
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.61457
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.614507
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.60018
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.617887
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.601505
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.597253
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.595537
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.603486
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.610896
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.630485
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.673274
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.614783
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.626923
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.608809
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.622459
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.614931
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.633859
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.679372
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.610921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.626823
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.616121
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.613557
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.577087
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.615405
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.608635
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:32,044] Trial 19 finished with value: 0.7693498452012384 and parameters: {'num_leaves': 119, 'learning_rate': 0.12061865906345418, 'feature_fraction': 0.731779358365553, 'bagging_fraction': 0.8464183896869948, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,059] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 108, 'learning_rate': 0.12960139311605598, 'feature_fraction': 0.7292072649834066, 'bagging_fraction': 0.8703459941807282, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,082] Trial 21 finished with value: 0.7244582043343653 and parameters: {'num_leaves': 44, 'learning_rate': 0.10877207651642368, 'feature_fraction': 0.40534650441158493, 'bagging_fraction': 0.7808349487762825, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,107] Trial 22 finished with value: 0.65015479876161 and parameters: {'num_leaves': 11, 'learning_rate': 0.07463831026649571, 'feature_fraction': 0.8004775951177401, 'bagging_fraction': 0.8455267330328473, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,131] Trial 23 finished with value: 0.5526315789473684 and parameters: {'num_leaves': 141, 'learning_rate': 0.13321367363650594, 'feature_fraction': 0.6722351810755121, 'bagging_fraction': 0.6563812098622241, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,217] Trial 24 finished with value: 0.7089783281733747 and parameters: {'num_leaves': 106, 'learning_rate': 0.17105132614163668, 'feature_fraction': 0.561414945919408, 'bagging_fraction': 0.7678389053482805, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,237] Trial 25 finished with value: 0.7012383900928792 and parameters: {'num_leaves': 57, 'learning_rate': 0.21372298879946777, 'feature_fraction': 0.7106813441336487, 'bagging_fraction': 0.97366588714935, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,254] Trial 26 finished with value: 0.71671826625387 and parameters: {'num_leaves': 34, 'learning_rate': 0.08550784088000514, 'feature_fraction': 0.46931644171207343, 'bagging_fraction': 0.8328654574191002, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,278] Trial 27 finished with value: 0.6656346749226005 and parameters: {'num_leaves': 61, 'learning_rate': 0.1126737466576895, 'feature_fraction': 0.7779079533772691, 'bagging_fraction': 0.9172744519655441, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,289] Trial 28 finished with value: 0.5 and parameters: {'num_leaves': 110, 'learning_rate': 0.06696184033433014, 'feature_fraction': 0.8641606896896236, 'bagging_fraction': 0.66039333954125, 'bagging_freq': 5, 'min_child_samples': 77}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,308] Trial 29 finished with value: 0.760061919504644 and parameters: {'num_leaves': 204, 'learning_rate': 0.09727377122878876, 'feature_fraction': 0.6275766896230608, 'bagging_fraction': 0.7426745392535299, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,330] Trial 30 finished with value: 0.6888544891640866 and parameters: {'num_leaves': 204, 'learning_rate': 0.13597065339988412, 'feature_fraction': 0.641526001318619, 'bagging_fraction': 0.7579724356725263, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,351] Trial 31 finished with value: 0.6455108359133127 and parameters: {'num_leaves': 231, 'learning_rate': 0.09651632738989206, 'feature_fraction': 0.6961149354086131, 'bagging_fraction': 0.6729661841033385, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,370] Trial 32 finished with value: 0.6795665634674922 and parameters: {'num_leaves': 197, 'learning_rate': 0.1142201899239707, 'feature_fraction': 0.5863327132045975, 'bagging_fraction': 0.7398596549194546, 'bagging_freq': 6, 'min_child_samples': 57}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,393] Trial 33 finished with value: 0.7151702786377709 and parameters: {'num_leaves': 272, 'learning_rate': 0.012573749550944105, 'feature_fraction': 0.6328412142005507, 'bagging_fraction': 0.8142849782817437, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,414] Trial 34 finished with value: 0.6470588235294118 and parameters: {'num_leaves': 152, 'learning_rate': 0.08541409134466299, 'feature_fraction': 0.5245461585907006, 'bagging_fraction': 0.8604279334539694, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,429] Trial 35 finished with value: 0.7027863777089783 and parameters: {'num_leaves': 81, 'learning_rate': 0.16727446979837632, 'feature_fraction': 0.7740224824529729, 'bagging_fraction': 0.7122350362538741, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,447] Trial 36 finished with value: 0.7306501547987615 and parameters: {'num_leaves': 261, 'learning_rate': 0.09968286561248695, 'feature_fraction': 0.5995178726139373, 'bagging_fraction': 0.7596306148838288, 'bagging_freq': 6, 'min_child_samples': 46}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,459] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 245, 'learning_rate': 0.13095276508668524, 'feature_fraction': 0.4449644828137237, 'bagging_fraction': 0.6987149426244105, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,493] Trial 38 finished with value: 0.7244582043343653 and parameters: {'num_leaves': 163, 'learning_rate': 0.043637098631471, 'feature_fraction': 0.8333710494393871, 'bagging_fraction': 0.9491697578514818, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,514] Trial 39 finished with value: 0.7554179566563467 and parameters: {'num_leaves': 97, 'learning_rate': 0.07146197148702414, 'feature_fraction': 0.5364887975281234, 'bagging_fraction': 0.8828590730329045, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,535] Trial 40 finished with value: 0.6888544891640868 and parameters: {'num_leaves': 122, 'learning_rate': 0.14446001926416618, 'feature_fraction': 0.7466021219076692, 'bagging_fraction': 0.7334553435015895, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,558] Trial 41 finished with value: 0.7291021671826625 and parameters: {'num_leaves': 91, 'learning_rate': 0.06871805636208862, 'feature_fraction': 0.5241915783868988, 'bagging_fraction': 0.878477649482757, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,578] Trial 42 finished with value: 0.6671826625386996 and parameters: {'num_leaves': 66, 'learning_rate': 0.08026273533470851, 'feature_fraction': 0.6157055261447, 'bagging_fraction': 0.9105484942614228, 'bagging_freq': 6, 'min_child_samples': 68}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,602] Trial 43 finished with value: 0.7430340557275541 and parameters: {'num_leaves': 35, 'learning_rate': 0.05022088276265687, 'feature_fraction': 0.5546137464800496, 'bagging_fraction': 0.8331218712336986, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,615] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 148, 'learning_rate': 0.10270696861537101, 'feature_fraction': 0.49744341449767815, 'bagging_fraction': 0.7982671691716532, 'bagging_freq': 6, 'min_child_samples': 64}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,631] Trial 45 finished with value: 0.6981424148606812 and parameters: {'num_leaves': 126, 'learning_rate': 0.11839350361438765, 'feature_fraction': 0.6780936387756711, 'bagging_fraction': 0.8952336119436298, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,644] Trial 46 finished with value: 0.5 and parameters: {'num_leaves': 26, 'learning_rate': 0.05644122702527535, 'feature_fraction': 0.4364065326978819, 'bagging_fraction': 0.5273984082721468, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,656] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 97, 'learning_rate': 0.030580395258430676, 'feature_fraction': 0.7138740723385801, 'bagging_fraction': 0.8197861095695421, 'bagging_freq': 5, 'min_child_samples': 82}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,668] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 77, 'learning_rate': 0.06864350006279926, 'feature_fraction': 0.6634625475863063, 'bagging_fraction': 0.854592689963266, 'bagging_freq': 6, 'min_child_samples': 70}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,686] Trial 49 finished with value: 0.6873065015479876 and parameters: {'num_leaves': 182, 'learning_rate': 0.09396905530617027, 'feature_fraction': 0.6126124160857573, 'bagging_fraction': 0.9392487629378888, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 15 with value: 0.7724458204334365.
[I 2025-09-17 13:19:32,828] A new study created in memory with name: no-name-e10612f0-ffdc-406c-9a24-2530081aff6a
[I 2025-09-17 13:19:32,843] Trial 0 finished with value: 0.8 and parameters: {'num_leaves': 105, 'learning_rate': 0.22944311698159736, 'feature_fraction': 0.46975348802734485, 'bagging_fraction': 0.5806809526701124, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 0 with value: 0.8.
[I 2025-09-17 13:19:32,850] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 11, 'learning_rate': 0.2780929050110463, 'feature_fraction': 0.4717754978478996, 'bagging_fraction': 0.5186899341405784, 'bagging_freq': 6, 'min_child_samples': 94}. Best is trial 0 with value: 0.8.
[I 2025-09-17 13:19:32,886] Trial 2 finished with value: 0.753125 and parameters: {'num_leaves': 298, 'learning_rate': 0.018806884956933254, 'feature_fraction': 0.41911703225625596, 'bagging_fraction': 0.9469243267689949, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 0 with value: 0.8.
[I 2025-09-17 13:19:32,918] Trial 3 finished with value: 0.796875 and parameters: {'num_leaves': 43, 'learning_rate': 0.191651428400989, 'feature_fraction': 0.40978606335321294, 'bagging_fraction': 0.6499545655617902, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 0 with value: 0.8.
[I 2025-09-17 13:19:32,925] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 29, 'learning_rate': 0.26066309733405374, 'feature_fraction': 0.7276280838212819, 'bagging_fraction': 0.5128167813117152, 'bagging_freq': 7, 'min_child_samples': 86}. Best is trial 0 with value: 0.8.
[I 2025-09-17 13:19:32,978] Trial 5 finished with value: 0.8625 and parameters: {'num_leaves': 188, 'learning_rate': 0.07676532173931212, 'feature_fraction': 0.8180030795861788, 'bagging_fraction': 0.9191370608103645, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 5 with value: 0.8625.
[I 2025-09-17 13:19:32,986] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 232, 'learning_rate': 0.2886360130464726, 'feature_fraction': 0.5009217772015666, 'bagging_fraction': 0.4816886057629465, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 5 with value: 0.8625.
[I 2025-09-17 13:19:32,992] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 93, 'learning_rate': 0.14923020397285822, 'feature_fraction': 0.49007880056993913, 'bagging_fraction': 0.8896163057241303, 'bagging_freq': 1, 'min_child_samples': 87}. Best is trial 5 with value: 0.8625.
[I 2025-09-17 13:19:33,114] Trial 8 finished with value: 0.865625 and parameters: {'num_leaves': 156, 'learning_rate': 0.24362915348074685, 'feature_fraction': 0.7734708849620804, 'bagging_fraction': 0.8981308552704748, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,146] Trial 9 finished with value: 0.784375 and parameters: {'num_leaves': 261, 'learning_rate': 0.06795597534855483, 'feature_fraction': 0.5047954387373538, 'bagging_fraction': 0.8075231299641095, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,160] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 163, 'learning_rate': 0.1774359034892786, 'feature_fraction': 0.9369823985647858, 'bagging_fraction': 0.759537485267287, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,270] Trial 11 finished with value: 0.834375 and parameters: {'num_leaves': 188, 'learning_rate': 0.10930056633821997, 'feature_fraction': 0.8252730887339144, 'bagging_fraction': 0.8647379544434617, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,393] Trial 12 finished with value: 0.7906249999999999 and parameters: {'num_leaves': 211, 'learning_rate': 0.10550709658822197, 'feature_fraction': 0.6877498966014666, 'bagging_fraction': 0.9937152429121554, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,421] Trial 13 finished with value: 0.7281249999999999 and parameters: {'num_leaves': 126, 'learning_rate': 0.05645811925324057, 'feature_fraction': 0.8349310118158523, 'bagging_fraction': 0.7140152750952333, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,438] Trial 14 finished with value: 0.7609375 and parameters: {'num_leaves': 147, 'learning_rate': 0.22328067596624784, 'feature_fraction': 0.6735020873423113, 'bagging_fraction': 0.8604945478801777, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,471] Trial 15 finished with value: 0.81875 and parameters: {'num_leaves': 181, 'learning_rate': 0.13669964268026447, 'feature_fraction': 0.9679377382447704, 'bagging_fraction': 0.9511984448888058, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,483] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 229, 'learning_rate': 0.011426167662705378, 'feature_fraction': 0.822913291140391, 'bagging_fraction': 0.8028156381652606, 'bagging_freq': 5, 'min_child_samples': 66}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,541] Trial 17 finished with value: 0.78125 and parameters: {'num_leaves': 64, 'learning_rate': 0.07347555274840255, 'feature_fraction': 0.5996043012003893, 'bagging_fraction': 0.6430556995320105, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,564] Trial 18 finished with value: 0.7640625000000001 and parameters: {'num_leaves': 140, 'learning_rate': 0.22669885499426776, 'feature_fraction': 0.8951452430489141, 'bagging_fraction': 0.913143969180574, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,596] Trial 19 finished with value: 0.83125 and parameters: {'num_leaves': 192, 'learning_rate': 0.18646095417418296, 'feature_fraction': 0.7531996607849346, 'bagging_fraction': 0.817656486898398, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,613] Trial 20 finished with value: 0.6234375 and parameters: {'num_leaves': 269, 'learning_rate': 0.10475254785582822, 'feature_fraction': 0.6022023871673724, 'bagging_fraction': 0.9799019446697295, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,737] Trial 21 finished with value: 0.8125 and parameters: {'num_leaves': 174, 'learning_rate': 0.11297405795373738, 'feature_fraction': 0.8102044215315479, 'bagging_fraction': 0.8662373038095074, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,779] Trial 22 finished with value: 0.784375 and parameters: {'num_leaves': 205, 'learning_rate': 0.0842329365717865, 'feature_fraction': 0.8723607343644758, 'bagging_fraction': 0.40018243340184373, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,947] Trial 23 finished with value: 0.8531249999999999 and parameters: {'num_leaves': 117, 'learning_rate': 0.047822423300126676, 'feature_fraction': 0.7701694526486255, 'bagging_fraction': 0.9127322030993639, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:33,994] Trial 24 finished with value: 0.803125 and parameters: {'num_leaves': 111, 'learning_rate': 0.0380269788829081, 'feature_fraction': 0.7688898906069903, 'bagging_fraction': 0.9368975809792819, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,028] Trial 25 finished with value: 0.7375 and parameters: {'num_leaves': 78, 'learning_rate': 0.03306178254744504, 'feature_fraction': 0.6666886967707704, 'bagging_fraction': 0.7402880366476836, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,055] Trial 26 finished with value: 0.73125 and parameters: {'num_leaves': 129, 'learning_rate': 0.04733339522368408, 'feature_fraction': 0.7723886863074628, 'bagging_fraction': 0.9968856061929955, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,120] Trial 27 finished with value: 0.846875 and parameters: {'num_leaves': 159, 'learning_rate': 0.14166628996631214, 'feature_fraction': 0.6206350094345224, 'bagging_fraction': 0.8311009828236754, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 8 with value: 0.865625.
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.59536
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.614728
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.639845
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.638828
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.628574
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.615979
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.608127
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.636552
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.603011
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.620307
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.640323
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.636868
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.61089
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.652997
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.61172
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.604246
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.631437
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.604161
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.613778
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.615926
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.658351
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.593688
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.617504
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691991
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.615526
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.552083
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.581397
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.548214
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.456305
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.498628
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.535269
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.507922
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.536244
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.58403
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.582369
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.502791
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.543953
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.550082
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.485482
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.674358
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.531216
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.517727
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.48282
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[75]	valid_0's binary_logloss: 0.530822
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.574643
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.607585
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.476258
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:34,160] Trial 28 finished with value: 0.765625 and parameters: {'num_leaves': 119, 'learning_rate': 0.08470456469940855, 'feature_fraction': 0.8715876264249413, 'bagging_fraction': 0.7740673462953691, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,182] Trial 29 finished with value: 0.7374999999999999 and parameters: {'num_leaves': 92, 'learning_rate': 0.20187572366104573, 'feature_fraction': 0.9236785598247426, 'bagging_fraction': 0.9083357061985695, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,275] Trial 30 finished with value: 0.8375 and parameters: {'num_leaves': 147, 'learning_rate': 0.24969026387369594, 'feature_fraction': 0.7219481899514044, 'bagging_fraction': 0.6748706039027845, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,339] Trial 31 finished with value: 0.846875 and parameters: {'num_leaves': 164, 'learning_rate': 0.13503045832067684, 'feature_fraction': 0.6225089204239407, 'bagging_fraction': 0.8468584619485657, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,394] Trial 32 finished with value: 0.8515625 and parameters: {'num_leaves': 157, 'learning_rate': 0.16691432546447973, 'feature_fraction': 0.7881045802103785, 'bagging_fraction': 0.9018842494065931, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,434] Trial 33 finished with value: 0.8374999999999999 and parameters: {'num_leaves': 105, 'learning_rate': 0.16605259325960234, 'feature_fraction': 0.8003730824925529, 'bagging_fraction': 0.9449258344323752, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,465] Trial 34 finished with value: 0.7421875 and parameters: {'num_leaves': 210, 'learning_rate': 0.21178727047586957, 'feature_fraction': 0.8615121818144839, 'bagging_fraction': 0.881847199534291, 'bagging_freq': 6, 'min_child_samples': 30}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,533] Trial 35 finished with value: 0.828125 and parameters: {'num_leaves': 139, 'learning_rate': 0.25147737379287427, 'feature_fraction': 0.7489825801326689, 'bagging_fraction': 0.9161233588833102, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,553] Trial 36 finished with value: 0.7734375 and parameters: {'num_leaves': 65, 'learning_rate': 0.26603663637125885, 'feature_fraction': 0.9990966463995448, 'bagging_fraction': 0.9580100954487906, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,581] Trial 37 finished with value: 0.734375 and parameters: {'num_leaves': 243, 'learning_rate': 0.024979565759954477, 'feature_fraction': 0.7089450397485206, 'bagging_fraction': 0.6119961581432447, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,623] Trial 38 finished with value: 0.840625 and parameters: {'num_leaves': 173, 'learning_rate': 0.12225789192220263, 'feature_fraction': 0.786368068749458, 'bagging_fraction': 0.7872703743779704, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,637] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 192, 'learning_rate': 0.29318158491530244, 'feature_fraction': 0.8509753888459539, 'bagging_fraction': 0.9004837056074024, 'bagging_freq': 7, 'min_child_samples': 74}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,680] Trial 40 finished with value: 0.84375 and parameters: {'num_leaves': 26, 'learning_rate': 0.16793732870446043, 'feature_fraction': 0.7334881959483313, 'bagging_fraction': 0.7373082098447937, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,771] Trial 41 finished with value: 0.828125 and parameters: {'num_leaves': 163, 'learning_rate': 0.058424399268060034, 'feature_fraction': 0.6296339227292752, 'bagging_fraction': 0.8396801645899613, 'bagging_freq': 7, 'min_child_samples': 9}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,799] Trial 42 finished with value: 0.78125 and parameters: {'num_leaves': 155, 'learning_rate': 0.14962445155866622, 'feature_fraction': 0.5254921807302905, 'bagging_fraction': 0.841158771271932, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,819] Trial 43 finished with value: 0.5 and parameters: {'num_leaves': 138, 'learning_rate': 0.08399609915421796, 'feature_fraction': 0.6539945545083596, 'bagging_fraction': 0.9295187253488167, 'bagging_freq': 7, 'min_child_samples': 96}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,885] Trial 44 finished with value: 0.796875 and parameters: {'num_leaves': 91, 'learning_rate': 0.2397003824630139, 'feature_fraction': 0.7992869224294971, 'bagging_fraction': 0.8267185267793609, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,911] Trial 45 finished with value: 0.76875 and parameters: {'num_leaves': 201, 'learning_rate': 0.09393934348708115, 'feature_fraction': 0.5382057917047198, 'bagging_fraction': 0.9667181005097218, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:34,956] Trial 46 finished with value: 0.8374999999999999 and parameters: {'num_leaves': 120, 'learning_rate': 0.2786018060029149, 'feature_fraction': 0.7094031632079696, 'bagging_fraction': 0.8785654005161816, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:35,101] Trial 47 finished with value: 0.775 and parameters: {'num_leaves': 152, 'learning_rate': 0.12934806115294323, 'feature_fraction': 0.4372178740909226, 'bagging_fraction': 0.8882564134015815, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:35,129] Trial 48 finished with value: 0.7531249999999999 and parameters: {'num_leaves': 175, 'learning_rate': 0.21340248709469223, 'feature_fraction': 0.7509567017916848, 'bagging_fraction': 0.5392351533804819, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:35,160] Trial 49 finished with value: 0.7468750000000001 and parameters: {'num_leaves': 226, 'learning_rate': 0.06323123714914712, 'feature_fraction': 0.9006517625833828, 'bagging_fraction': 0.9303099444866405, 'bagging_freq': 5, 'min_child_samples': 32}. Best is trial 8 with value: 0.865625.
[I 2025-09-17 13:19:35,556] A new study created in memory with name: no-name-d1bf2032-d4b0-4a61-853b-1d9c4c8570ab
[I 2025-09-17 13:19:35,564] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 210, 'learning_rate': 0.24308755427982737, 'feature_fraction': 0.8054892006274751, 'bagging_fraction': 0.6037362973978881, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:35,572] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 255, 'learning_rate': 0.19808076142233086, 'feature_fraction': 0.5683438861947043, 'bagging_fraction': 0.6780745899938913, 'bagging_freq': 2, 'min_child_samples': 76}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:35,589] Trial 2 finished with value: 0.715625 and parameters: {'num_leaves': 23, 'learning_rate': 0.08473734044758073, 'feature_fraction': 0.9719419272144799, 'bagging_fraction': 0.594225171613251, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 2 with value: 0.715625.
[I 2025-09-17 13:19:35,608] Trial 3 finished with value: 0.7281249999999999 and parameters: {'num_leaves': 222, 'learning_rate': 0.1034810943272483, 'feature_fraction': 0.7753882228259144, 'bagging_fraction': 0.6284227054790987, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 3 with value: 0.7281249999999999.
[I 2025-09-17 13:19:35,628] Trial 4 finished with value: 0.734375 and parameters: {'num_leaves': 233, 'learning_rate': 0.1474391088861093, 'feature_fraction': 0.8968750417851549, 'bagging_fraction': 0.9908052576252003, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 4 with value: 0.734375.
[I 2025-09-17 13:19:35,637] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 20, 'learning_rate': 0.12885147336853645, 'feature_fraction': 0.779755718800156, 'bagging_fraction': 0.8192692411925155, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 4 with value: 0.734375.
[I 2025-09-17 13:19:35,653] Trial 6 finished with value: 0.715625 and parameters: {'num_leaves': 273, 'learning_rate': 0.12676400157338588, 'feature_fraction': 0.7898960856268649, 'bagging_fraction': 0.6174717249940863, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 4 with value: 0.734375.
[I 2025-09-17 13:19:35,669] Trial 7 finished with value: 0.71875 and parameters: {'num_leaves': 183, 'learning_rate': 0.1358558778099894, 'feature_fraction': 0.7409844329064815, 'bagging_fraction': 0.609961395913959, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 4 with value: 0.734375.
[I 2025-09-17 13:19:35,677] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.18608885022662755, 'feature_fraction': 0.5400381866119374, 'bagging_fraction': 0.8930976746908905, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 4 with value: 0.734375.
[I 2025-09-17 13:19:35,689] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 283, 'learning_rate': 0.26897351826984633, 'feature_fraction': 0.6790818015013431, 'bagging_fraction': 0.7980668241924693, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 4 with value: 0.734375.
[I 2025-09-17 13:19:35,703] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 125, 'learning_rate': 0.024707826853859832, 'feature_fraction': 0.9915415376502272, 'bagging_fraction': 0.4158327294145233, 'bagging_freq': 1, 'min_child_samples': 54}. Best is trial 4 with value: 0.734375.
[I 2025-09-17 13:19:35,761] Trial 11 finished with value: 0.6734375 and parameters: {'num_leaves': 222, 'learning_rate': 0.061993176457201024, 'feature_fraction': 0.897121900044175, 'bagging_fraction': 0.9761507567653759, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 4 with value: 0.734375.
[I 2025-09-17 13:19:35,827] Trial 12 finished with value: 0.759375 and parameters: {'num_leaves': 151, 'learning_rate': 0.08343483910997972, 'feature_fraction': 0.8806371834740628, 'bagging_fraction': 0.4321412371950999, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 12 with value: 0.759375.
[I 2025-09-17 13:19:35,893] Trial 13 finished with value: 0.7812499999999999 and parameters: {'num_leaves': 148, 'learning_rate': 0.03879255178823238, 'feature_fraction': 0.8933632530148551, 'bagging_fraction': 0.43236121931087873, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:35,980] Trial 14 finished with value: 0.746875 and parameters: {'num_leaves': 132, 'learning_rate': 0.016230514814014513, 'feature_fraction': 0.4119099108809555, 'bagging_fraction': 0.4006898425393157, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,010] Trial 15 finished with value: 0.7484375000000001 and parameters: {'num_leaves': 85, 'learning_rate': 0.05764593578831431, 'feature_fraction': 0.8991384660262893, 'bagging_fraction': 0.49958108939978607, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,123] Trial 16 finished with value: 0.7625 and parameters: {'num_leaves': 170, 'learning_rate': 0.056201309443048325, 'feature_fraction': 0.670717112015029, 'bagging_fraction': 0.5017195960842098, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,150] Trial 17 finished with value: 0.690625 and parameters: {'num_leaves': 187, 'learning_rate': 0.03857021583262395, 'feature_fraction': 0.637550920284425, 'bagging_fraction': 0.532567740839484, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,165] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 96, 'learning_rate': 0.01007602324963816, 'feature_fraction': 0.5948232535783581, 'bagging_fraction': 0.5198740521059797, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,191] Trial 19 finished with value: 0.6953125 and parameters: {'num_leaves': 172, 'learning_rate': 0.18310058326987935, 'feature_fraction': 0.691718958601119, 'bagging_fraction': 0.475768508442573, 'bagging_freq': 3, 'min_child_samples': 14}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,201] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 47, 'learning_rate': 0.05131437962440878, 'feature_fraction': 0.4534367651951295, 'bagging_fraction': 0.7296330974176708, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,262] Trial 21 finished with value: 0.684375 and parameters: {'num_leaves': 145, 'learning_rate': 0.08589048798256081, 'feature_fraction': 0.8354479476792809, 'bagging_fraction': 0.44969301066910733, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,332] Trial 22 finished with value: 0.7218749999999999 and parameters: {'num_leaves': 115, 'learning_rate': 0.09036769531124042, 'feature_fraction': 0.9281109771086633, 'bagging_fraction': 0.5485141074083661, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,365] Trial 23 finished with value: 0.74375 and parameters: {'num_leaves': 156, 'learning_rate': 0.06993748861833324, 'feature_fraction': 0.850612821606394, 'bagging_fraction': 0.4588094155981164, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,396] Trial 24 finished with value: 0.6515625 and parameters: {'num_leaves': 161, 'learning_rate': 0.03907605312812914, 'feature_fraction': 0.6541187878701292, 'bagging_fraction': 0.4207129657393476, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,438] Trial 25 finished with value: 0.73125 and parameters: {'num_leaves': 201, 'learning_rate': 0.10400097563506405, 'feature_fraction': 0.7371180506821217, 'bagging_fraction': 0.5539703250779874, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,461] Trial 26 finished with value: 0.721875 and parameters: {'num_leaves': 113, 'learning_rate': 0.10911681218801092, 'feature_fraction': 0.8521115647253847, 'bagging_fraction': 0.48703850405541455, 'bagging_freq': 4, 'min_child_samples': 20}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,481] Trial 27 finished with value: 0.6953125 and parameters: {'num_leaves': 142, 'learning_rate': 0.03421109446911468, 'feature_fraction': 0.9427251417873725, 'bagging_fraction': 0.4496900513384292, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,532] Trial 28 finished with value: 0.7218749999999999 and parameters: {'num_leaves': 60, 'learning_rate': 0.07146510472831802, 'feature_fraction': 0.5118004928474316, 'bagging_fraction': 0.5677353558864261, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,550] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 200, 'learning_rate': 0.16669949525706426, 'feature_fraction': 0.6086015553459616, 'bagging_fraction': 0.5062145771819104, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,581] Trial 30 finished with value: 0.7234374999999998 and parameters: {'num_leaves': 171, 'learning_rate': 0.22237385667014548, 'feature_fraction': 0.7358861243915283, 'bagging_fraction': 0.6764847388865896, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,611] Trial 31 finished with value: 0.68125 and parameters: {'num_leaves': 81, 'learning_rate': 0.05327856910914599, 'feature_fraction': 0.8717834998052723, 'bagging_fraction': 0.4982135814427938, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,667] Trial 32 finished with value: 0.753125 and parameters: {'num_leaves': 100, 'learning_rate': 0.052420144173955935, 'feature_fraction': 0.8209092798350447, 'bagging_fraction': 0.4389026923246102, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,732] Trial 33 finished with value: 0.7468750000000001 and parameters: {'num_leaves': 107, 'learning_rate': 0.07695004107207128, 'feature_fraction': 0.827602838814401, 'bagging_fraction': 0.4394846627090246, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,774] Trial 34 finished with value: 0.7250000000000001 and parameters: {'num_leaves': 66, 'learning_rate': 0.04683913698489984, 'feature_fraction': 0.7959710083932849, 'bagging_fraction': 0.4027498243803568, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,800] Trial 35 finished with value: 0.7218749999999999 and parameters: {'num_leaves': 137, 'learning_rate': 0.029394841764949782, 'feature_fraction': 0.9588183142129884, 'bagging_fraction': 0.5775392494980086, 'bagging_freq': 6, 'min_child_samples': 23}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,821] Trial 36 finished with value: 0.7140624999999999 and parameters: {'num_leaves': 155, 'learning_rate': 0.09461943933126182, 'feature_fraction': 0.9276350653990124, 'bagging_fraction': 0.6554156661295738, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,852] Trial 37 finished with value: 0.7359375 and parameters: {'num_leaves': 185, 'learning_rate': 0.11431581346923397, 'feature_fraction': 0.7510082699543983, 'bagging_fraction': 0.7237653856568991, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 13 with value: 0.7812499999999999.
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.551844
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.589973
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.503992
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.478605
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.484259
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.490594
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.564205
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.525523
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.570782
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.587525
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.49617
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.466048
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.497209
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.538649
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.528207
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.571104
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.488961
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.57988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.572899
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.563944
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.618035
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.618641
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.605601
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.611289
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.611438
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.645067
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.629986
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.588002
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.606081
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.614075
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.587106
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.635881
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.635207
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.629329
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.615017
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.591071
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.637368
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.627165
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.619163
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.660378
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.603938
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.599266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.643642
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.602698
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.646263
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.614488
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.62041
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.618946
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.61563
[I 2025-09-17 13:19:36,918] Trial 38 finished with value: 0.778125 and parameters: {'num_leaves': 239, 'learning_rate': 0.28728314121067716, 'feature_fraction': 0.8068914794348148, 'bagging_fraction': 0.4338142344546311, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,931] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 242, 'learning_rate': 0.29780558159864023, 'feature_fraction': 0.874899793168215, 'bagging_fraction': 0.47833994081294995, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,945] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 262, 'learning_rate': 0.23032664026789848, 'feature_fraction': 0.7677395579712079, 'bagging_fraction': 0.528254671744005, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:36,977] Trial 41 finished with value: 0.625 and parameters: {'num_leaves': 220, 'learning_rate': 0.28233220836329503, 'feature_fraction': 0.8196999094888591, 'bagging_fraction': 0.43533564665118407, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:37,035] Trial 42 finished with value: 0.6484375 and parameters: {'num_leaves': 295, 'learning_rate': 0.153536375245371, 'feature_fraction': 0.8099884567448732, 'bagging_fraction': 0.4628972945972352, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:37,063] Trial 43 finished with value: 0.7359375 and parameters: {'num_leaves': 245, 'learning_rate': 0.1404192925076963, 'feature_fraction': 0.9947360774596248, 'bagging_fraction': 0.4374664209731705, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:37,082] Trial 44 finished with value: 0.7015625 and parameters: {'num_leaves': 31, 'learning_rate': 0.25613180891824405, 'feature_fraction': 0.9002290474992183, 'bagging_fraction': 0.40187727884030455, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:37,124] Trial 45 finished with value: 0.721875 and parameters: {'num_leaves': 120, 'learning_rate': 0.21223259018727136, 'feature_fraction': 0.7084279359023501, 'bagging_fraction': 0.5948240356459393, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:37,140] Trial 46 finished with value: 0.7296874999999999 and parameters: {'num_leaves': 101, 'learning_rate': 0.12148165540089453, 'feature_fraction': 0.7824496202167874, 'bagging_fraction': 0.47607390282170425, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:37,170] Trial 47 finished with value: 0.65625 and parameters: {'num_leaves': 208, 'learning_rate': 0.021457093075912204, 'feature_fraction': 0.7092389673890143, 'bagging_fraction': 0.42491717728419, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:37,183] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 169, 'learning_rate': 0.07683609755692322, 'feature_fraction': 0.8703976409221194, 'bagging_fraction': 0.8448363970646527, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:37,217] Trial 49 finished with value: 0.746875 and parameters: {'num_leaves': 135, 'learning_rate': 0.05776945116383742, 'feature_fraction': 0.6664842442155202, 'bagging_fraction': 0.5083181187247635, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 13 with value: 0.7812499999999999.
[I 2025-09-17 13:19:38,087] A new study created in memory with name: no-name-5ad7139e-498e-4f4d-a833-9565ad2c626b
[I 2025-09-17 13:19:38,108] Trial 0 finished with value: 0.6953125 and parameters: {'num_leaves': 162, 'learning_rate': 0.03726648621354102, 'feature_fraction': 0.6040400362635576, 'bagging_fraction': 0.7973024160856292, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 0 with value: 0.6953125.
[I 2025-09-17 13:19:38,128] Trial 1 finished with value: 0.709375 and parameters: {'num_leaves': 165, 'learning_rate': 0.1181995421124256, 'feature_fraction': 0.5562890747245046, 'bagging_fraction': 0.6849483361709705, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 1 with value: 0.709375.
[I 2025-09-17 13:19:38,147] Trial 2 finished with value: 0.7374999999999999 and parameters: {'num_leaves': 243, 'learning_rate': 0.06795102959799296, 'feature_fraction': 0.7351138167095529, 'bagging_fraction': 0.46721383905740366, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,162] Trial 3 finished with value: 0.7140624999999999 and parameters: {'num_leaves': 67, 'learning_rate': 0.18102290073397567, 'feature_fraction': 0.9798562542600319, 'bagging_fraction': 0.5198286845415041, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,174] Trial 4 finished with value: 0.7078125000000001 and parameters: {'num_leaves': 81, 'learning_rate': 0.17078376967440073, 'feature_fraction': 0.4041793616932916, 'bagging_fraction': 0.6076963585246664, 'bagging_freq': 6, 'min_child_samples': 42}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,196] Trial 5 finished with value: 0.6890625 and parameters: {'num_leaves': 136, 'learning_rate': 0.01877984760534325, 'feature_fraction': 0.899940123096084, 'bagging_fraction': 0.8746889362054222, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,205] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 55, 'learning_rate': 0.04450651075577787, 'feature_fraction': 0.947242636094822, 'bagging_fraction': 0.47256503348335044, 'bagging_freq': 2, 'min_child_samples': 67}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,208] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 115, 'learning_rate': 0.20214162949355835, 'feature_fraction': 0.7625801348601929, 'bagging_fraction': 0.9935372329427037, 'bagging_freq': 6, 'min_child_samples': 91}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,221] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 228, 'learning_rate': 0.26524951767788646, 'feature_fraction': 0.8012425179829139, 'bagging_fraction': 0.47291228242384076, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,264] Trial 9 finished with value: 0.675 and parameters: {'num_leaves': 48, 'learning_rate': 0.25288043402960736, 'feature_fraction': 0.7075302384799039, 'bagging_fraction': 0.8269765096140472, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,276] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 294, 'learning_rate': 0.10247921204311325, 'feature_fraction': 0.5668798389021441, 'bagging_fraction': 0.4179189081735232, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,318] Trial 11 finished with value: 0.709375 and parameters: {'num_leaves': 219, 'learning_rate': 0.10332077835023835, 'feature_fraction': 0.9843563642837716, 'bagging_fraction': 0.5750235492560521, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,335] Trial 12 finished with value: 0.690625 and parameters: {'num_leaves': 15, 'learning_rate': 0.1981252187004255, 'feature_fraction': 0.8536514623467047, 'bagging_fraction': 0.5566764487122828, 'bagging_freq': 7, 'min_child_samples': 32}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,347] Trial 13 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.14209378247934043, 'feature_fraction': 0.6612986888520995, 'bagging_fraction': 0.4035746747831416, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,421] Trial 14 finished with value: 0.553125 and parameters: {'num_leaves': 219, 'learning_rate': 0.0716826676559566, 'feature_fraction': 0.4785185668177673, 'bagging_fraction': 0.6610551908240274, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,438] Trial 15 finished with value: 0.69375 and parameters: {'num_leaves': 253, 'learning_rate': 0.19864656117209042, 'feature_fraction': 0.7989261617347018, 'bagging_fraction': 0.5014836041057003, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,455] Trial 16 finished with value: 0.7171875000000001 and parameters: {'num_leaves': 188, 'learning_rate': 0.2988699676626131, 'feature_fraction': 0.8938716289749239, 'bagging_fraction': 0.5312098688818593, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,471] Trial 17 finished with value: 0.6156250000000001 and parameters: {'num_leaves': 192, 'learning_rate': 0.28280199401235373, 'feature_fraction': 0.8867327490399866, 'bagging_fraction': 0.622314530851589, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,489] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 258, 'learning_rate': 0.2339966097333102, 'feature_fraction': 0.7150443179788843, 'bagging_fraction': 0.756733508018196, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,510] Trial 19 finished with value: 0.6656250000000001 and parameters: {'num_leaves': 199, 'learning_rate': 0.06766423006199485, 'feature_fraction': 0.8526211153628481, 'bagging_fraction': 0.7317920609069286, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,523] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 255, 'learning_rate': 0.2987600258354793, 'feature_fraction': 0.7637861301416913, 'bagging_fraction': 0.4479482828843681, 'bagging_freq': 5, 'min_child_samples': 52}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,544] Trial 21 finished with value: 0.66875 and parameters: {'num_leaves': 102, 'learning_rate': 0.15198177456401574, 'feature_fraction': 0.9918956905756611, 'bagging_fraction': 0.5306083924724484, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,561] Trial 22 finished with value: 0.69375 and parameters: {'num_leaves': 179, 'learning_rate': 0.22599093930506398, 'feature_fraction': 0.914559060798924, 'bagging_fraction': 0.512796413238363, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,578] Trial 23 finished with value: 0.69375 and parameters: {'num_leaves': 128, 'learning_rate': 0.17335237498947695, 'feature_fraction': 0.956521640125767, 'bagging_fraction': 0.6254277664541977, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,589] Trial 24 finished with value: 0.5 and parameters: {'num_leaves': 90, 'learning_rate': 0.12223247862099877, 'feature_fraction': 0.8488300997982421, 'bagging_fraction': 0.5606452009864012, 'bagging_freq': 4, 'min_child_samples': 52}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,610] Trial 25 finished with value: 0.6859375000000001 and parameters: {'num_leaves': 24, 'learning_rate': 0.07737079818527155, 'feature_fraction': 0.6604640418606802, 'bagging_fraction': 0.46526929107848225, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,629] Trial 26 finished with value: 0.69375 and parameters: {'num_leaves': 140, 'learning_rate': 0.23410370840041603, 'feature_fraction': 0.9366084340951842, 'bagging_fraction': 0.5225172837134793, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,643] Trial 27 finished with value: 0.5 and parameters: {'num_leaves': 273, 'learning_rate': 0.17546466750231246, 'feature_fraction': 0.9963351915309941, 'bagging_fraction': 0.4234300956553199, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,674] Trial 28 finished with value: 0.6687500000000002 and parameters: {'num_leaves': 238, 'learning_rate': 0.1369563330114471, 'feature_fraction': 0.8076073450068907, 'bagging_fraction': 0.5897184451829341, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,704] Trial 29 finished with value: 0.6749999999999999 and parameters: {'num_leaves': 155, 'learning_rate': 0.010422045605148575, 'feature_fraction': 0.6622204091309016, 'bagging_fraction': 0.65563641396044, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,720] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 203, 'learning_rate': 0.03821858369904727, 'feature_fraction': 0.6124162125139456, 'bagging_fraction': 0.5440458377932378, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,756] Trial 31 finished with value: 0.7218749999999999 and parameters: {'num_leaves': 167, 'learning_rate': 0.10540294423329843, 'feature_fraction': 0.5416946246435034, 'bagging_fraction': 0.7098764870315403, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,792] Trial 32 finished with value: 0.7093750000000001 and parameters: {'num_leaves': 174, 'learning_rate': 0.08758142442768604, 'feature_fraction': 0.486582817919361, 'bagging_fraction': 0.7096856122309457, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,812] Trial 33 finished with value: 0.684375 and parameters: {'num_leaves': 154, 'learning_rate': 0.1048336948321788, 'feature_fraction': 0.49634149762006885, 'bagging_fraction': 0.8399869481503464, 'bagging_freq': 2, 'min_child_samples': 46}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,836] Trial 34 finished with value: 0.7046874999999999 and parameters: {'num_leaves': 69, 'learning_rate': 0.05372244278458782, 'feature_fraction': 0.6061718091810473, 'bagging_fraction': 0.7771083518509728, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,874] Trial 35 finished with value: 0.7250000000000001 and parameters: {'num_leaves': 183, 'learning_rate': 0.12997415644875243, 'feature_fraction': 0.5327338373777756, 'bagging_fraction': 0.684684767598353, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,893] Trial 36 finished with value: 0.6265624999999999 and parameters: {'num_leaves': 165, 'learning_rate': 0.13105711124765906, 'feature_fraction': 0.5393809197616533, 'bagging_fraction': 0.9047174255515007, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,912] Trial 37 finished with value: 0.6499999999999999 and parameters: {'num_leaves': 192, 'learning_rate': 0.08814288525736799, 'feature_fraction': 0.43093435982693395, 'bagging_fraction': 0.6774465999469403, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,925] Trial 38 finished with value: 0.475 and parameters: {'num_leaves': 211, 'learning_rate': 0.12038929404363483, 'feature_fraction': 0.5296843852871264, 'bagging_fraction': 0.7297360487274506, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,952] Trial 39 finished with value: 0.6874999999999999 and parameters: {'num_leaves': 181, 'learning_rate': 0.1556729799680555, 'feature_fraction': 0.4426450636146803, 'bagging_fraction': 0.6312318641541133, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:38,973] Trial 40 finished with value: 0.690625 and parameters: {'num_leaves': 237, 'learning_rate': 0.053947672942592374, 'feature_fraction': 0.5646141242883546, 'bagging_fraction': 0.7922262481113072, 'bagging_freq': 3, 'min_child_samples': 48}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,008] Trial 41 finished with value: 0.703125 and parameters: {'num_leaves': 141, 'learning_rate': 0.10615598388647318, 'feature_fraction': 0.7556471379710531, 'bagging_fraction': 0.5930717993253357, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,029] Trial 42 finished with value: 0.709375 and parameters: {'num_leaves': 109, 'learning_rate': 0.18744050525480532, 'feature_fraction': 0.9581207241331372, 'bagging_fraction': 0.4817954575236082, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,109] Trial 43 finished with value: 0.6171875 and parameters: {'num_leaves': 126, 'learning_rate': 0.1579094734823584, 'feature_fraction': 0.6355582774994908, 'bagging_fraction': 0.9292493091630725, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,129] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.21779154178485877, 'feature_fraction': 0.5846205400622114, 'bagging_fraction': 0.4488664123302591, 'bagging_freq': 6, 'min_child_samples': 40}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,158] Trial 45 finished with value: 0.734375 and parameters: {'num_leaves': 159, 'learning_rate': 0.2577436274505635, 'feature_fraction': 0.5195991029275974, 'bagging_fraction': 0.6990772050351262, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,185] Trial 46 finished with value: 0.6609375000000001 and parameters: {'num_leaves': 153, 'learning_rate': 0.2674468950560086, 'feature_fraction': 0.4532173788728383, 'bagging_fraction': 0.6974527663482978, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,236] Trial 47 finished with value: 0.6734375 and parameters: {'num_leaves': 167, 'learning_rate': 0.29254026677992967, 'feature_fraction': 0.5158496796260164, 'bagging_fraction': 0.7541673492299613, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 2 with value: 0.7374999999999999.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.589266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.667236
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.6511
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.614017
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.623549
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.604064
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.628313
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.639069
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.60488
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.628719
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.605279
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.601464
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.606094
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.623145
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.624346
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.647529
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.626766
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.618876
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.675184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.612472
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.628608
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.647835
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.61767
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.633254
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.613921
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.614294
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.633424
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.613321
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.64342
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.627181
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.610105
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.608553
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.621812
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.616355
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.595591
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.638139
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.63184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.629524
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.614462
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.621445
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.615091
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.653547
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.687351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.610967
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.615814
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.647002
[I 2025-09-17 13:19:39,260] Trial 48 finished with value: 0.7093750000000001 and parameters: {'num_leaves': 185, 'learning_rate': 0.2738687253398834, 'feature_fraction': 0.40537476674336376, 'bagging_fraction': 0.6550010374688154, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,273] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 231, 'learning_rate': 0.24233071955748667, 'feature_fraction': 0.5817673608933215, 'bagging_fraction': 0.7126128070905028, 'bagging_freq': 4, 'min_child_samples': 66}. Best is trial 2 with value: 0.7374999999999999.
[I 2025-09-17 13:19:39,439] A new study created in memory with name: no-name-6227c450-a55e-42fb-a879-939a502845b6
[I 2025-09-17 13:19:39,459] Trial 0 finished with value: 0.8833333333333333 and parameters: {'num_leaves': 175, 'learning_rate': 0.06951329547049138, 'feature_fraction': 0.7814200816642167, 'bagging_fraction': 0.6876941537647815, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 0 with value: 0.8833333333333333.
[I 2025-09-17 13:19:39,500] Trial 1 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 172, 'learning_rate': 0.2965607682902244, 'feature_fraction': 0.8428447281126289, 'bagging_fraction': 0.9220903768026609, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,513] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.18854055447713608, 'feature_fraction': 0.9944263914141838, 'bagging_fraction': 0.6270788950897513, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,528] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 263, 'learning_rate': 0.09611177015293057, 'feature_fraction': 0.49169328134981616, 'bagging_fraction': 0.9634727563335976, 'bagging_freq': 6, 'min_child_samples': 66}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,540] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 294, 'learning_rate': 0.16874809143790284, 'feature_fraction': 0.8027255016979249, 'bagging_fraction': 0.4968930961650387, 'bagging_freq': 1, 'min_child_samples': 73}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,603] Trial 5 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 57, 'learning_rate': 0.09543576140995086, 'feature_fraction': 0.83968165634758, 'bagging_fraction': 0.8510473490761223, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,616] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 174, 'learning_rate': 0.09346533825436679, 'feature_fraction': 0.8282981174656205, 'bagging_fraction': 0.42600995462362, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,645] Trial 7 finished with value: 0.9625 and parameters: {'num_leaves': 91, 'learning_rate': 0.2195244652213796, 'feature_fraction': 0.9841591632299557, 'bagging_fraction': 0.9815782509249196, 'bagging_freq': 7, 'min_child_samples': 33}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,656] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 285, 'learning_rate': 0.15226611775888016, 'feature_fraction': 0.4245403299156575, 'bagging_fraction': 0.6755943351283966, 'bagging_freq': 7, 'min_child_samples': 58}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,720] Trial 9 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 43, 'learning_rate': 0.09179857822147257, 'feature_fraction': 0.4118114704459197, 'bagging_fraction': 0.7108901707624691, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,735] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 119, 'learning_rate': 0.2881026426745107, 'feature_fraction': 0.5892273267786795, 'bagging_fraction': 0.8747499379528227, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,776] Trial 11 finished with value: 0.9541666666666667 and parameters: {'num_leaves': 106, 'learning_rate': 0.2963725787581656, 'feature_fraction': 0.9896378239642004, 'bagging_fraction': 0.9916488372149579, 'bagging_freq': 5, 'min_child_samples': 29}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,807] Trial 12 finished with value: 0.9583333333333334 and parameters: {'num_leaves': 220, 'learning_rate': 0.23449491623671467, 'feature_fraction': 0.9199793829116651, 'bagging_fraction': 0.8385034249034877, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,829] Trial 13 finished with value: 0.8916666666666666 and parameters: {'num_leaves': 103, 'learning_rate': 0.24085356902973024, 'feature_fraction': 0.6807801135728313, 'bagging_fraction': 0.9177863532389583, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,863] Trial 14 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 14, 'learning_rate': 0.2483050121670104, 'feature_fraction': 0.9051085539361174, 'bagging_fraction': 0.7699094130761981, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:39,893] Trial 15 finished with value: 0.9583333333333333 and parameters: {'num_leaves': 221, 'learning_rate': 0.2041387580803097, 'feature_fraction': 0.6748684397092711, 'bagging_fraction': 0.9873568538141585, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,018] Trial 16 finished with value: 0.9291666666666666 and parameters: {'num_leaves': 144, 'learning_rate': 0.019552906406623716, 'feature_fraction': 0.9236519638118729, 'bagging_fraction': 0.7733454746438615, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,034] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 75, 'learning_rate': 0.25970589990759374, 'feature_fraction': 0.7357615549066651, 'bagging_fraction': 0.5858837049473208, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,085] Trial 18 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 219, 'learning_rate': 0.21866052520909598, 'feature_fraction': 0.878541892751974, 'bagging_fraction': 0.9131187863540381, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,102] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 150, 'learning_rate': 0.2744941842065999, 'feature_fraction': 0.9659451795170692, 'bagging_fraction': 0.8081442819365847, 'bagging_freq': 6, 'min_child_samples': 78}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,153] Trial 20 finished with value: 0.9291666666666667 and parameters: {'num_leaves': 81, 'learning_rate': 0.14253323144660543, 'feature_fraction': 0.7455887753299533, 'bagging_fraction': 0.9126127520605701, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,192] Trial 21 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 218, 'learning_rate': 0.2269031043170191, 'feature_fraction': 0.9313538384270615, 'bagging_fraction': 0.8378299105200945, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,224] Trial 22 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 203, 'learning_rate': 0.2678194252089431, 'feature_fraction': 0.8660708076086729, 'bagging_fraction': 0.942561586418562, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,258] Trial 23 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 241, 'learning_rate': 0.1882297191253915, 'feature_fraction': 0.9363474435118989, 'bagging_fraction': 0.8809621230142919, 'bagging_freq': 7, 'min_child_samples': 21}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,278] Trial 24 finished with value: 0.9 and parameters: {'num_leaves': 132, 'learning_rate': 0.29945655322277936, 'feature_fraction': 0.8809711471587685, 'bagging_fraction': 0.7932966727706232, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,297] Trial 25 finished with value: 0.8875 and parameters: {'num_leaves': 191, 'learning_rate': 0.23385378828705225, 'feature_fraction': 0.6037201166254857, 'bagging_fraction': 0.9463356903503384, 'bagging_freq': 7, 'min_child_samples': 53}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,332] Trial 26 finished with value: 0.9375 and parameters: {'num_leaves': 247, 'learning_rate': 0.21135238980708973, 'feature_fraction': 0.9535919260306127, 'bagging_fraction': 0.7487683968910291, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,423] Trial 27 finished with value: 0.9041666666666667 and parameters: {'num_leaves': 153, 'learning_rate': 0.2700666688885301, 'feature_fraction': 0.7699483246456544, 'bagging_fraction': 0.9981050411223813, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,463] Trial 28 finished with value: 0.925 and parameters: {'num_leaves': 266, 'learning_rate': 0.1842780985594463, 'feature_fraction': 0.84253545857776, 'bagging_fraction': 0.8262947543926537, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,486] Trial 29 finished with value: 0.9125 and parameters: {'num_leaves': 170, 'learning_rate': 0.24778491204670094, 'feature_fraction': 0.9974928709416124, 'bagging_fraction': 0.8787356653443986, 'bagging_freq': 4, 'min_child_samples': 43}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,513] Trial 30 finished with value: 0.8958333333333333 and parameters: {'num_leaves': 201, 'learning_rate': 0.13639553883318845, 'feature_fraction': 0.893514397708117, 'bagging_fraction': 0.7195963912398953, 'bagging_freq': 6, 'min_child_samples': 39}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,545] Trial 31 finished with value: 0.9375 and parameters: {'num_leaves': 225, 'learning_rate': 0.20914458347528297, 'feature_fraction': 0.6792459956840392, 'bagging_fraction': 0.9676835197702913, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,576] Trial 32 finished with value: 0.9624999999999999 and parameters: {'num_leaves': 184, 'learning_rate': 0.20143705361967873, 'feature_fraction': 0.6243879021333811, 'bagging_fraction': 0.9979972685050371, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,613] Trial 33 finished with value: 0.9500000000000001 and parameters: {'num_leaves': 170, 'learning_rate': 0.16584112021880243, 'feature_fraction': 0.6053527407106996, 'bagging_fraction': 0.9373004331104401, 'bagging_freq': 7, 'min_child_samples': 29}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,655] Trial 34 finished with value: 0.9291666666666667 and parameters: {'num_leaves': 187, 'learning_rate': 0.20117061972931313, 'feature_fraction': 0.5154747791441032, 'bagging_fraction': 0.8997444022429486, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,686] Trial 35 finished with value: 0.9541666666666667 and parameters: {'num_leaves': 129, 'learning_rate': 0.1294565023896497, 'feature_fraction': 0.5461773501261223, 'bagging_fraction': 0.9604528544945451, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,728] Trial 36 finished with value: 0.9708333333333334 and parameters: {'num_leaves': 164, 'learning_rate': 0.1796417095002802, 'feature_fraction': 0.6411089090345351, 'bagging_fraction': 0.8680644361607653, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,752] Trial 37 finished with value: 0.8958333333333333 and parameters: {'num_leaves': 167, 'learning_rate': 0.11702905999342729, 'feature_fraction': 0.6558768978850281, 'bagging_fraction': 0.9693278244912243, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,777] Trial 38 finished with value: 0.9125 and parameters: {'num_leaves': 90, 'learning_rate': 0.17268559406361375, 'feature_fraction': 0.6283369298263263, 'bagging_fraction': 0.8720719305973317, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,796] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.16176131712012964, 'feature_fraction': 0.7855154495958067, 'bagging_fraction': 0.5122933346346392, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,836] Trial 40 finished with value: 0.9208333333333334 and parameters: {'num_leaves': 113, 'learning_rate': 0.1819030474567414, 'feature_fraction': 0.7343101329026229, 'bagging_fraction': 0.607381299121684, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,865] Trial 41 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 203, 'learning_rate': 0.2276542522855334, 'feature_fraction': 0.5535513049159526, 'bagging_fraction': 0.8615315113463852, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,890] Trial 42 finished with value: 0.9041666666666667 and parameters: {'num_leaves': 191, 'learning_rate': 0.2807547073705151, 'feature_fraction': 0.6364507523061806, 'bagging_fraction': 0.658738637843639, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,916] Trial 43 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 161, 'learning_rate': 0.19754201177086222, 'feature_fraction': 0.9601759283890393, 'bagging_fraction': 0.9349369690032392, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,930] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 46, 'learning_rate': 0.25438877999917825, 'feature_fraction': 0.7056584070472791, 'bagging_fraction': 0.8429944484274632, 'bagging_freq': 6, 'min_child_samples': 71}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:40,974] Trial 45 finished with value: 0.9583333333333333 and parameters: {'num_leaves': 177, 'learning_rate': 0.15271310022582904, 'feature_fraction': 0.46843265007434753, 'bagging_fraction': 0.8993417913521542, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:41,038] Trial 46 finished with value: 0.9249999999999999 and parameters: {'num_leaves': 17, 'learning_rate': 0.21625693591111406, 'feature_fraction': 0.8129604700970317, 'bagging_fraction': 0.9804196668539201, 'bagging_freq': 7, 'min_child_samples': 11}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:41,072] Trial 47 finished with value: 0.9416666666666668 and parameters: {'num_leaves': 239, 'learning_rate': 0.24205449887186642, 'feature_fraction': 0.9149684060564848, 'bagging_fraction': 0.8110430816705034, 'bagging_freq': 1, 'min_child_samples': 32}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:41,140] Trial 48 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 283, 'learning_rate': 0.03349333565773961, 'feature_fraction': 0.5668261282633708, 'bagging_fraction': 0.9974340934955157, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:41,155] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.1747786802397554, 'feature_fraction': 0.8586314322750749, 'bagging_fraction': 0.9299051320929906, 'bagging_freq': 6, 'min_child_samples': 83}. Best is trial 1 with value: 0.9791666666666666.
[I 2025-09-17 13:19:41,337] A new study created in memory with name: no-name-fb5bcd8e-20df-4c14-82be-5ca6c4fcae1c
[I 2025-09-17 13:19:41,357] Trial 0 finished with value: 0.9374999999999999 and parameters: {'num_leaves': 282, 'learning_rate': 0.13752498116661444, 'feature_fraction': 0.5676984983355153, 'bagging_fraction': 0.8846742328353605, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 0 with value: 0.9374999999999999.
[I 2025-09-17 13:19:41,367] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 39, 'learning_rate': 0.05157875921351442, 'feature_fraction': 0.6390880850620453, 'bagging_fraction': 0.5006187619665897, 'bagging_freq': 6, 'min_child_samples': 85}. Best is trial 0 with value: 0.9374999999999999.
[I 2025-09-17 13:19:41,380] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 269, 'learning_rate': 0.18386078762637248, 'feature_fraction': 0.547534747246183, 'bagging_fraction': 0.5658037667204479, 'bagging_freq': 7, 'min_child_samples': 97}. Best is trial 0 with value: 0.9374999999999999.
[I 2025-09-17 13:19:41,421] Trial 3 finished with value: 0.9791666666666667 and parameters: {'num_leaves': 291, 'learning_rate': 0.05041618403919182, 'feature_fraction': 0.8108030375711544, 'bagging_fraction': 0.7689755927958033, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 3 with value: 0.9791666666666667.
[I 2025-09-17 13:19:41,478] Trial 4 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 168, 'learning_rate': 0.2678623252641453, 'feature_fraction': 0.5887636566597493, 'bagging_fraction': 0.8406321210138746, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 4 with value: 0.9874999999999999.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.640098
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.687351
Training model for P124... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.399162
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.217608
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.266615
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.239435
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.270897
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.296221
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.243775
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.387662
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.239093
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.260428
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.304995
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.30241
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.283396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.236924
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.27077
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.295653
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.370757
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.391634
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.268164
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.323121
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.314184
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.365663
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.383936
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.276937
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.243313
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.278239
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.300853
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.269399
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.209935
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.385396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.364634
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.297615
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.269068
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.301773
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.297905
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.266767
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.280434
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.289427
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.300334
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.272131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.199739
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.123102
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:41,495] Trial 5 finished with value: 0.8916666666666667 and parameters: {'num_leaves': 127, 'learning_rate': 0.1454798049181641, 'feature_fraction': 0.5013356826658054, 'bagging_fraction': 0.6829460606872246, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 4 with value: 0.9874999999999999.
[I 2025-09-17 13:19:41,514] Trial 6 finished with value: 0.8875 and parameters: {'num_leaves': 221, 'learning_rate': 0.21333744723820583, 'feature_fraction': 0.5771068407389595, 'bagging_fraction': 0.8620723284346503, 'bagging_freq': 1, 'min_child_samples': 50}. Best is trial 4 with value: 0.9874999999999999.
[I 2025-09-17 13:19:41,524] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 197, 'learning_rate': 0.06860098236130413, 'feature_fraction': 0.48234959025143215, 'bagging_fraction': 0.5745338495696519, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 4 with value: 0.9874999999999999.
[I 2025-09-17 13:19:41,532] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 264, 'learning_rate': 0.16435910775696955, 'feature_fraction': 0.561084949051854, 'bagging_fraction': 0.8504926631481704, 'bagging_freq': 5, 'min_child_samples': 63}. Best is trial 4 with value: 0.9874999999999999.
[I 2025-09-17 13:19:41,578] Trial 9 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 183, 'learning_rate': 0.1791272116705674, 'feature_fraction': 0.6741310942921657, 'bagging_fraction': 0.8764514810025887, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 4 with value: 0.9874999999999999.
[I 2025-09-17 13:19:41,631] Trial 10 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 93, 'learning_rate': 0.29835007750292963, 'feature_fraction': 0.975113048040725, 'bagging_fraction': 0.9947950661694139, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 10 with value: 0.9916666666666667.
[I 2025-09-17 13:19:41,707] Trial 11 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 87, 'learning_rate': 0.29144769709440693, 'feature_fraction': 0.9811237691762233, 'bagging_fraction': 0.9987384051838141, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 10 with value: 0.9916666666666667.
[I 2025-09-17 13:19:41,752] Trial 12 finished with value: 1.0 and parameters: {'num_leaves': 120, 'learning_rate': 0.27077044026659425, 'feature_fraction': 0.804811947944939, 'bagging_fraction': 0.9697646406022752, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:41,792] Trial 13 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 114, 'learning_rate': 0.24193839268261694, 'feature_fraction': 0.859957726361512, 'bagging_fraction': 0.9871973562202272, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:41,833] Trial 14 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 43, 'learning_rate': 0.29636000411206237, 'feature_fraction': 0.9835282698609822, 'bagging_fraction': 0.9403523270709148, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:41,918] Trial 15 finished with value: 0.9625 and parameters: {'num_leaves': 71, 'learning_rate': 0.2401809415743158, 'feature_fraction': 0.8015033338360209, 'bagging_fraction': 0.7406095084593082, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:41,954] Trial 16 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 11, 'learning_rate': 0.0925012460197236, 'feature_fraction': 0.8934660929682816, 'bagging_fraction': 0.9428887787069499, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:41,968] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 137, 'learning_rate': 0.2527488306122786, 'feature_fraction': 0.7264930565927071, 'bagging_fraction': 0.6711152336119206, 'bagging_freq': 2, 'min_child_samples': 58}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,000] Trial 18 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 91, 'learning_rate': 0.20688899261573584, 'feature_fraction': 0.9132607152226798, 'bagging_fraction': 0.42438953628554577, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,023] Trial 19 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 147, 'learning_rate': 0.27518250914978737, 'feature_fraction': 0.40256033345186903, 'bagging_fraction': 0.7933026720364155, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,120] Trial 20 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 106, 'learning_rate': 0.010882473589556296, 'feature_fraction': 0.7707165861624443, 'bagging_fraction': 0.9491397520357807, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,169] Trial 21 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 163, 'learning_rate': 0.2562847144814592, 'feature_fraction': 0.6350259471526991, 'bagging_fraction': 0.8127199034872128, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,220] Trial 22 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 168, 'learning_rate': 0.27045256829342956, 'feature_fraction': 0.7421860174101289, 'bagging_fraction': 0.9131762853372065, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,282] Trial 23 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 202, 'learning_rate': 0.21805221223147842, 'feature_fraction': 0.9131168004162783, 'bagging_fraction': 0.9727634552961546, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,325] Trial 24 finished with value: 1.0 and parameters: {'num_leaves': 232, 'learning_rate': 0.298561210260898, 'feature_fraction': 0.8484715570419233, 'bagging_fraction': 0.8367374223231105, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,363] Trial 25 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 235, 'learning_rate': 0.29850455543168963, 'feature_fraction': 0.8608726383088335, 'bagging_fraction': 0.9081419914977013, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,393] Trial 26 finished with value: 0.9583333333333333 and parameters: {'num_leaves': 59, 'learning_rate': 0.23433552579280548, 'feature_fraction': 0.9520746874645991, 'bagging_fraction': 0.7260969343520267, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,415] Trial 27 finished with value: 0.8916666666666667 and parameters: {'num_leaves': 246, 'learning_rate': 0.27825767869100204, 'feature_fraction': 0.8145356145734468, 'bagging_fraction': 0.9231182138622646, 'bagging_freq': 2, 'min_child_samples': 52}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,456] Trial 28 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 117, 'learning_rate': 0.2999728048287757, 'feature_fraction': 0.9432291387818059, 'bagging_fraction': 0.9961389702769499, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,480] Trial 29 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 93, 'learning_rate': 0.10913752700201954, 'feature_fraction': 0.851213405655397, 'bagging_fraction': 0.8912046203151524, 'bagging_freq': 3, 'min_child_samples': 41}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,496] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 148, 'learning_rate': 0.2290686036278792, 'feature_fraction': 0.8866363144595245, 'bagging_fraction': 0.6340454154744417, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,534] Trial 31 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 71, 'learning_rate': 0.2989468047597994, 'feature_fraction': 0.9467987239308934, 'bagging_fraction': 0.9981347959700303, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,565] Trial 32 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 126, 'learning_rate': 0.28257822327320775, 'feature_fraction': 0.9423257640206617, 'bagging_fraction': 0.9561388739802205, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,603] Trial 33 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 110, 'learning_rate': 0.2588918851868, 'feature_fraction': 0.8382914324908175, 'bagging_fraction': 0.8272615309966589, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,664] Trial 34 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 125, 'learning_rate': 0.2738890934212864, 'feature_fraction': 0.992615447250738, 'bagging_fraction': 0.8887979629081166, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,760] Trial 35 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 19, 'learning_rate': 0.19022560552314507, 'feature_fraction': 0.7796220843715002, 'bagging_fraction': 0.9638800124872385, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,782] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 49, 'learning_rate': 0.25589257864963244, 'feature_fraction': 0.9328632002479836, 'bagging_fraction': 0.9195591449219281, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,795] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 73, 'learning_rate': 0.28322860942726114, 'feature_fraction': 0.8926949401404748, 'bagging_fraction': 0.7736378883986709, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,881] Trial 38 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 187, 'learning_rate': 0.12035105724680904, 'feature_fraction': 0.82018290216953, 'bagging_fraction': 0.8590822159233504, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,942] Trial 39 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 286, 'learning_rate': 0.29983582821741905, 'feature_fraction': 0.7016232804479753, 'bagging_fraction': 0.9700521327869632, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:42,967] Trial 40 finished with value: 0.9125 and parameters: {'num_leaves': 299, 'learning_rate': 0.2646385996933025, 'feature_fraction': 0.7768167952195899, 'bagging_fraction': 0.8242662794141704, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,008] Trial 41 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 74, 'learning_rate': 0.28376243694437087, 'feature_fraction': 0.9594766513645857, 'bagging_fraction': 0.9969336845305125, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,059] Trial 42 finished with value: 1.0 and parameters: {'num_leaves': 100, 'learning_rate': 0.2977996292443671, 'feature_fraction': 0.9629495497095328, 'bagging_fraction': 0.9924655694627038, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,155] Trial 43 finished with value: 0.9541666666666667 and parameters: {'num_leaves': 100, 'learning_rate': 0.24794421351171994, 'feature_fraction': 0.9152709863404354, 'bagging_fraction': 0.9473368230540051, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,212] Trial 44 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 137, 'learning_rate': 0.2853693727251053, 'feature_fraction': 0.9684114584555463, 'bagging_fraction': 0.8810819650948332, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,269] Trial 45 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 117, 'learning_rate': 0.268566308089948, 'feature_fraction': 0.8761929387277098, 'bagging_fraction': 0.9716420544561338, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,307] Trial 46 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 264, 'learning_rate': 0.22456842976845193, 'feature_fraction': 0.9929187688614383, 'bagging_fraction': 0.9328436210389066, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,346] Trial 47 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 270, 'learning_rate': 0.19777931177519414, 'feature_fraction': 0.9960012692048587, 'bagging_fraction': 0.9237376678752376, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,383] Trial 48 finished with value: 0.9958333333333333 and parameters: {'num_leaves': 227, 'learning_rate': 0.2361284672708145, 'feature_fraction': 0.9962287453638703, 'bagging_fraction': 0.8563269681327953, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,420] Trial 49 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 222, 'learning_rate': 0.16707983552407646, 'feature_fraction': 0.9137317844357086, 'bagging_fraction': 0.8531716441561096, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 12 with value: 1.0.
[I 2025-09-17 13:19:43,652] A new study created in memory with name: no-name-0cb63cc0-e4c2-4e81-9975-e6ccc91427b6
[I 2025-09-17 13:19:43,677] Trial 0 finished with value: 0.8958333333333334 and parameters: {'num_leaves': 22, 'learning_rate': 0.06990552480942035, 'feature_fraction': 0.6658681154223584, 'bagging_fraction': 0.6733299191810664, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 0 with value: 0.8958333333333334.
[I 2025-09-17 13:19:43,685] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 117, 'learning_rate': 0.15332442297884724, 'feature_fraction': 0.7599687232221704, 'bagging_fraction': 0.580166833036516, 'bagging_freq': 3, 'min_child_samples': 91}. Best is trial 0 with value: 0.8958333333333334.
[I 2025-09-17 13:19:43,703] Trial 2 finished with value: 0.9583333333333334 and parameters: {'num_leaves': 168, 'learning_rate': 0.19972549074621007, 'feature_fraction': 0.982408965918969, 'bagging_fraction': 0.6670213960820777, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,735] Trial 3 finished with value: 0.9291666666666667 and parameters: {'num_leaves': 14, 'learning_rate': 0.2307054672053953, 'feature_fraction': 0.5087964817127295, 'bagging_fraction': 0.9125975557300569, 'bagging_freq': 1, 'min_child_samples': 25}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,774] Trial 4 finished with value: 0.9458333333333334 and parameters: {'num_leaves': 99, 'learning_rate': 0.2058541995725627, 'feature_fraction': 0.8206312151438211, 'bagging_fraction': 0.7531972335866364, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,782] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 50, 'learning_rate': 0.2102247466628753, 'feature_fraction': 0.5765073177796641, 'bagging_fraction': 0.8382870698123055, 'bagging_freq': 2, 'min_child_samples': 91}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,790] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.014593806014058686, 'feature_fraction': 0.7033130998547106, 'bagging_fraction': 0.47740599888133256, 'bagging_freq': 5, 'min_child_samples': 68}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,799] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 225, 'learning_rate': 0.2247653921418473, 'feature_fraction': 0.6141314797767403, 'bagging_fraction': 0.9251859521058415, 'bagging_freq': 4, 'min_child_samples': 73}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,813] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 31, 'learning_rate': 0.2850572838754818, 'feature_fraction': 0.6557773705409555, 'bagging_fraction': 0.798825277663848, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,832] Trial 9 finished with value: 0.9083333333333333 and parameters: {'num_leaves': 227, 'learning_rate': 0.13205526730444536, 'feature_fraction': 0.6991326187597134, 'bagging_fraction': 0.871732299967902, 'bagging_freq': 3, 'min_child_samples': 42}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,872] Trial 10 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 298, 'learning_rate': 0.297414855890854, 'feature_fraction': 0.9757842507759784, 'bagging_fraction': 0.41574511653558943, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,960] Trial 11 finished with value: 0.9249999999999999 and parameters: {'num_leaves': 122, 'learning_rate': 0.18748167805879884, 'feature_fraction': 0.9391771959451566, 'bagging_fraction': 0.6860881808102889, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:43,998] Trial 12 finished with value: 0.8750000000000001 and parameters: {'num_leaves': 162, 'learning_rate': 0.13038407194700372, 'feature_fraction': 0.8585813222932255, 'bagging_fraction': 0.7719543862419705, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,027] Trial 13 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 82, 'learning_rate': 0.25548119704108513, 'feature_fraction': 0.8355562020456466, 'bagging_fraction': 0.5903181779934867, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 2 with value: 0.9583333333333334.
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.387816
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.38297
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.182183
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.12238
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.171509
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.091008
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.149202
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.134926
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.202199
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.169433
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.250796
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.308663
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.318194
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.168103
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.189774
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.156367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.0835725
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.154962
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.286597
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.39626
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.117982
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.283022
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.121955
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.147131
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.13486
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.145848
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.183177
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.661878
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.1774
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.12188
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.336305
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.178703
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.130367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.230679
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.14778
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.134274
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.12945
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.162111
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.107061
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.148481
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.401374
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.287135
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.285141
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.272859
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.404203
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.310966
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.337078
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.29856
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.311311
[I 2025-09-17 13:19:44,041] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 169, 'learning_rate': 0.18104557430589724, 'feature_fraction': 0.8898674534461326, 'bagging_fraction': 0.6013169482606227, 'bagging_freq': 7, 'min_child_samples': 50}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,075] Trial 15 finished with value: 0.8875 and parameters: {'num_leaves': 112, 'learning_rate': 0.09294543203953569, 'feature_fraction': 0.4073171121064185, 'bagging_fraction': 0.9837266287277537, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,109] Trial 16 finished with value: 0.9541666666666667 and parameters: {'num_leaves': 78, 'learning_rate': 0.2614803301129115, 'feature_fraction': 0.7970533178466814, 'bagging_fraction': 0.7422002929299728, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,120] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 71, 'learning_rate': 0.2584364443540124, 'feature_fraction': 0.9313961841082065, 'bagging_fraction': 0.6360346384053162, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,133] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.26194404430508383, 'feature_fraction': 0.7747062455341452, 'bagging_fraction': 0.5251313254180748, 'bagging_freq': 3, 'min_child_samples': 51}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,156] Trial 19 finished with value: 0.8708333333333332 and parameters: {'num_leaves': 261, 'learning_rate': 0.17034900253397162, 'feature_fraction': 0.9857863408976213, 'bagging_fraction': 0.7460038283245094, 'bagging_freq': 6, 'min_child_samples': 32}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,194] Trial 20 finished with value: 0.95 and parameters: {'num_leaves': 136, 'learning_rate': 0.24336883266614473, 'feature_fraction': 0.7817577918076191, 'bagging_fraction': 0.7287100721258111, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,246] Trial 21 finished with value: 0.95 and parameters: {'num_leaves': 137, 'learning_rate': 0.25581336492179657, 'feature_fraction': 0.7816210047951722, 'bagging_fraction': 0.6978182400119448, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,270] Trial 22 finished with value: 0.9083333333333332 and parameters: {'num_leaves': 70, 'learning_rate': 0.22232496196060064, 'feature_fraction': 0.8890155196685741, 'bagging_fraction': 0.7456916976914866, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,292] Trial 23 finished with value: 0.8916666666666667 and parameters: {'num_leaves': 144, 'learning_rate': 0.2769752703844158, 'feature_fraction': 0.7271569696812957, 'bagging_fraction': 0.643959725645238, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,331] Trial 24 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 186, 'learning_rate': 0.23906076412873392, 'feature_fraction': 0.8146316580813912, 'bagging_fraction': 0.8022703838736652, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,435] Trial 25 finished with value: 0.8916666666666667 and parameters: {'num_leaves': 90, 'learning_rate': 0.19805449378327836, 'feature_fraction': 0.919218719936812, 'bagging_fraction': 0.7203172574932314, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,467] Trial 26 finished with value: 0.8833333333333334 and parameters: {'num_leaves': 142, 'learning_rate': 0.24337001764500985, 'feature_fraction': 0.5588347005516301, 'bagging_fraction': 0.5407333931014908, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,490] Trial 27 finished with value: 0.9 and parameters: {'num_leaves': 47, 'learning_rate': 0.1619547683284872, 'feature_fraction': 0.8678804938073338, 'bagging_fraction': 0.6431674042801976, 'bagging_freq': 4, 'min_child_samples': 38}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,520] Trial 28 finished with value: 0.9041666666666667 and parameters: {'num_leaves': 194, 'learning_rate': 0.2800475811714319, 'feature_fraction': 0.7580737331652886, 'bagging_fraction': 0.832712979502191, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,584] Trial 29 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 158, 'learning_rate': 0.14116578593784723, 'feature_fraction': 0.8112287503609498, 'bagging_fraction': 0.7046169214567191, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,604] Trial 30 finished with value: 0.8083333333333333 and parameters: {'num_leaves': 126, 'learning_rate': 0.2986896146934355, 'feature_fraction': 0.6521641805302949, 'bagging_fraction': 0.6431344177008763, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,636] Trial 31 finished with value: 0.9416666666666668 and parameters: {'num_leaves': 138, 'learning_rate': 0.2478747313382626, 'feature_fraction': 0.7887119420589384, 'bagging_fraction': 0.6911554697882348, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,682] Trial 32 finished with value: 0.9041666666666666 and parameters: {'num_leaves': 97, 'learning_rate': 0.26881320918372403, 'feature_fraction': 0.7304597558348671, 'bagging_fraction': 0.7233287694269505, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,708] Trial 33 finished with value: 0.8958333333333334 and parameters: {'num_leaves': 169, 'learning_rate': 0.2209549496314182, 'feature_fraction': 0.7692934364395791, 'bagging_fraction': 0.6668163554693868, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,734] Trial 34 finished with value: 0.9041666666666667 and parameters: {'num_leaves': 116, 'learning_rate': 0.23689516697238833, 'feature_fraction': 0.6870292527485038, 'bagging_fraction': 0.7859811506918958, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,774] Trial 35 finished with value: 0.8916666666666667 and parameters: {'num_leaves': 136, 'learning_rate': 0.20698094578869108, 'feature_fraction': 0.84118015683768, 'bagging_fraction': 0.6102418072779721, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,813] Trial 36 finished with value: 0.9125 and parameters: {'num_leaves': 104, 'learning_rate': 0.19014347374984994, 'feature_fraction': 0.732793391371283, 'bagging_fraction': 0.8419337635692279, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,825] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 51, 'learning_rate': 0.21772253525653024, 'feature_fraction': 0.6297506755888229, 'bagging_fraction': 0.5647629199705491, 'bagging_freq': 2, 'min_child_samples': 84}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,838] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 208, 'learning_rate': 0.04958569676685817, 'feature_fraction': 0.5054822431007854, 'bagging_fraction': 0.6779572317319263, 'bagging_freq': 3, 'min_child_samples': 57}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,858] Trial 39 finished with value: 0.8833333333333333 and parameters: {'num_leaves': 235, 'learning_rate': 0.27409439505954947, 'feature_fraction': 0.8938997881336983, 'bagging_fraction': 0.8887471781370667, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,870] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 19, 'learning_rate': 0.23202422258009447, 'feature_fraction': 0.9622748480420441, 'bagging_fraction': 0.7374214023661279, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,935] Trial 41 finished with value: 0.9208333333333333 and parameters: {'num_leaves': 149, 'learning_rate': 0.20703574772334124, 'feature_fraction': 0.8066730903790097, 'bagging_fraction': 0.7734398922557364, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:44,975] Trial 42 finished with value: 0.9291666666666667 and parameters: {'num_leaves': 83, 'learning_rate': 0.24858229759557857, 'feature_fraction': 0.7427808006108817, 'bagging_fraction': 0.8175910319188326, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:45,011] Trial 43 finished with value: 0.925 and parameters: {'num_leaves': 128, 'learning_rate': 0.20107224804160026, 'feature_fraction': 0.8430159145874059, 'bagging_fraction': 0.7617285784461799, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:45,040] Trial 44 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 104, 'learning_rate': 0.29034176513988996, 'feature_fraction': 0.697763763097837, 'bagging_fraction': 0.7119447312405203, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:45,102] Trial 45 finished with value: 0.925 and parameters: {'num_leaves': 46, 'learning_rate': 0.22834571290857342, 'feature_fraction': 0.794160212703368, 'bagging_fraction': 0.8618637054258861, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:45,138] Trial 46 finished with value: 0.9458333333333332 and parameters: {'num_leaves': 74, 'learning_rate': 0.17624757086382498, 'feature_fraction': 0.8278207605716742, 'bagging_fraction': 0.6668243957099406, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:45,169] Trial 47 finished with value: 0.8833333333333333 and parameters: {'num_leaves': 163, 'learning_rate': 0.11702060710642063, 'feature_fraction': 0.8719078702357186, 'bagging_fraction': 0.6186710552445879, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:45,284] Trial 48 finished with value: 0.95 and parameters: {'num_leaves': 60, 'learning_rate': 0.2528464675050485, 'feature_fraction': 0.9478627939779299, 'bagging_fraction': 0.935975514797722, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:45,384] Trial 49 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 59, 'learning_rate': 0.2634604596177048, 'feature_fraction': 0.9542053293762592, 'bagging_fraction': 0.9561101323887072, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 2 with value: 0.9583333333333334.
[I 2025-09-17 13:19:45,565] A new study created in memory with name: no-name-d53d78b5-3bf6-404b-a636-93cf17816590
[I 2025-09-17 13:19:45,573] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 291, 'learning_rate': 0.19848979795856425, 'feature_fraction': 0.5166065637692215, 'bagging_fraction': 0.6999762878291989, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:45,649] Trial 1 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 12, 'learning_rate': 0.06103721515617057, 'feature_fraction': 0.5070385161090075, 'bagging_fraction': 0.49893661138546713, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,654] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 247, 'learning_rate': 0.18262892893362362, 'feature_fraction': 0.7268537153895263, 'bagging_fraction': 0.9965671587822166, 'bagging_freq': 7, 'min_child_samples': 66}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,659] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 122, 'learning_rate': 0.18305037293767992, 'feature_fraction': 0.5274932961246612, 'bagging_fraction': 0.9993366333439716, 'bagging_freq': 7, 'min_child_samples': 76}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,668] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 16, 'learning_rate': 0.14903934734732677, 'feature_fraction': 0.9822809932439616, 'bagging_fraction': 0.4655701848804748, 'bagging_freq': 7, 'min_child_samples': 55}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,676] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 164, 'learning_rate': 0.15781615586082368, 'feature_fraction': 0.4332036082495482, 'bagging_fraction': 0.9376756858566562, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,688] Trial 6 finished with value: 0.9125 and parameters: {'num_leaves': 294, 'learning_rate': 0.2767689013979957, 'feature_fraction': 0.45198397730009865, 'bagging_fraction': 0.6640773984948962, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,697] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 300, 'learning_rate': 0.209046016419523, 'feature_fraction': 0.5889766379925114, 'bagging_fraction': 0.4576839683872759, 'bagging_freq': 5, 'min_child_samples': 48}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,705] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 146, 'learning_rate': 0.14574212760959043, 'feature_fraction': 0.7520158402017032, 'bagging_fraction': 0.5088774863893281, 'bagging_freq': 5, 'min_child_samples': 76}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,713] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 172, 'learning_rate': 0.05283391624581361, 'feature_fraction': 0.7242087244092474, 'bagging_fraction': 0.8130378876242126, 'bagging_freq': 4, 'min_child_samples': 93}. Best is trial 1 with value: 0.9750000000000001.
[I 2025-09-17 13:19:45,816] Trial 10 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 11, 'learning_rate': 0.011262774235669855, 'feature_fraction': 0.8763204141216832, 'bagging_fraction': 0.5846978526471658, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 10 with value: 0.9791666666666666.
[I 2025-09-17 13:19:45,908] Trial 11 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 10, 'learning_rate': 0.014952678212533151, 'feature_fraction': 0.8870311769379658, 'bagging_fraction': 0.5887860748574621, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 10 with value: 0.9791666666666666.
[I 2025-09-17 13:19:46,006] Trial 12 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 70, 'learning_rate': 0.07242035581734393, 'feature_fraction': 0.8357141670005167, 'bagging_fraction': 0.5728621514907629, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 10 with value: 0.9791666666666666.
[I 2025-09-17 13:19:46,030] Trial 13 finished with value: 0.9166666666666667 and parameters: {'num_leaves': 76, 'learning_rate': 0.08869557414400164, 'feature_fraction': 0.6287720433429431, 'bagging_fraction': 0.40511232218774124, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 10 with value: 0.9791666666666666.
[I 2025-09-17 13:19:46,059] Trial 14 finished with value: 0.9458333333333332 and parameters: {'num_leaves': 58, 'learning_rate': 0.018434096724958465, 'feature_fraction': 0.9974733206309893, 'bagging_fraction': 0.600001765738874, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 10 with value: 0.9791666666666666.
[I 2025-09-17 13:19:46,100] Trial 15 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 45, 'learning_rate': 0.10496217462221989, 'feature_fraction': 0.8279531972981533, 'bagging_fraction': 0.7840554554715179, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 10 with value: 0.9791666666666666.
[I 2025-09-17 13:19:46,138] Trial 16 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 114, 'learning_rate': 0.10601862195105027, 'feature_fraction': 0.8668060870873499, 'bagging_fraction': 0.8511080334582448, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 10 with value: 0.9791666666666666.
[I 2025-09-17 13:19:46,163] Trial 17 finished with value: 0.9000000000000001 and parameters: {'num_leaves': 48, 'learning_rate': 0.10847443586843326, 'feature_fraction': 0.7947687756531857, 'bagging_fraction': 0.7921722867158975, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 10 with value: 0.9791666666666666.
[I 2025-09-17 13:19:46,195] Trial 18 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 205, 'learning_rate': 0.2388027041644243, 'feature_fraction': 0.9184903256700032, 'bagging_fraction': 0.758362350073738, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 18 with value: 0.9833333333333334.
[I 2025-09-17 13:19:46,212] Trial 19 finished with value: 0.9125 and parameters: {'num_leaves': 207, 'learning_rate': 0.2520495678527305, 'feature_fraction': 0.9309008720526886, 'bagging_fraction': 0.6555664163417707, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 18 with value: 0.9833333333333334.
[I 2025-09-17 13:19:46,259] Trial 20 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 213, 'learning_rate': 0.23660508234786515, 'feature_fraction': 0.9221452620917449, 'bagging_fraction': 0.7311228733827067, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,304] Trial 21 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 212, 'learning_rate': 0.22956844994600514, 'feature_fraction': 0.941876090247387, 'bagging_fraction': 0.7535725551413436, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,343] Trial 22 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 217, 'learning_rate': 0.2433808268472007, 'feature_fraction': 0.9371753921766846, 'bagging_fraction': 0.7401979863133809, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 20 with value: 0.9874999999999999.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.343257
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.285415
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.391019
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.272534
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.259031
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.307321
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.40159
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.269113
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.342437
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.336886
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.362958
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.335875
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.267754
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.544931
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.266582
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.30431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.329325
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.319902
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.305252
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.29067
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.36228
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.30928
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.269125
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.319561
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.288546
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.254583
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.269611
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.309047
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.300081
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.215392
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.21644
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.395448
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.320788
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.272621
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.222915
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.347582
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.310791
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.211449
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.217407
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.355241
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.198515
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.382964
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.177315
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.189467
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.139328
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:46,368] Trial 23 finished with value: 0.9625 and parameters: {'num_leaves': 232, 'learning_rate': 0.2692491089867378, 'feature_fraction': 0.9359680333935679, 'bagging_fraction': 0.8698215817376904, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,407] Trial 24 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 260, 'learning_rate': 0.2421697961290621, 'feature_fraction': 0.7884069208842284, 'bagging_fraction': 0.7293343754990299, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,429] Trial 25 finished with value: 0.8791666666666667 and parameters: {'num_leaves': 195, 'learning_rate': 0.28864628350194427, 'feature_fraction': 0.6797903656094699, 'bagging_fraction': 0.6823840880580384, 'bagging_freq': 3, 'min_child_samples': 44}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,469] Trial 26 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 185, 'learning_rate': 0.2268364287098451, 'feature_fraction': 0.9072567877353279, 'bagging_fraction': 0.864353367535906, 'bagging_freq': 5, 'min_child_samples': 14}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,494] Trial 27 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 233, 'learning_rate': 0.2603420137529595, 'feature_fraction': 0.958613436220944, 'bagging_fraction': 0.7394559587252905, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,525] Trial 28 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 271, 'learning_rate': 0.29676875538324926, 'feature_fraction': 0.9952399374660328, 'bagging_fraction': 0.8265891847540817, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,536] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 215, 'learning_rate': 0.20959460943131006, 'feature_fraction': 0.810554449312883, 'bagging_fraction': 0.637002613486527, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,592] Trial 30 finished with value: 0.9791666666666667 and parameters: {'num_leaves': 141, 'learning_rate': 0.18845729793238541, 'feature_fraction': 0.8471209641392305, 'bagging_fraction': 0.9162988661174777, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 20 with value: 0.9874999999999999.
[I 2025-09-17 13:19:46,632] Trial 31 finished with value: 1.0 and parameters: {'num_leaves': 220, 'learning_rate': 0.23348984887116941, 'feature_fraction': 0.9187048020548709, 'bagging_fraction': 0.7444519315793935, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,686] Trial 32 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 233, 'learning_rate': 0.2309938180872901, 'feature_fraction': 0.9123274246056527, 'bagging_fraction': 0.7248710426114157, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,715] Trial 33 finished with value: 0.9375 and parameters: {'num_leaves': 271, 'learning_rate': 0.2080447634666734, 'feature_fraction': 0.9596625368561773, 'bagging_fraction': 0.7593589430053203, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,744] Trial 34 finished with value: 0.9708333333333334 and parameters: {'num_leaves': 182, 'learning_rate': 0.2507171062276203, 'feature_fraction': 0.8913499513255743, 'bagging_fraction': 0.6892752723140729, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,807] Trial 35 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 254, 'learning_rate': 0.16913968682157732, 'feature_fraction': 0.7622068735570164, 'bagging_fraction': 0.7128139865190469, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,866] Trial 36 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 244, 'learning_rate': 0.16050573473720203, 'feature_fraction': 0.7586110614930591, 'bagging_fraction': 0.7066975019146827, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,937] Trial 37 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 261, 'learning_rate': 0.1633416149935198, 'feature_fraction': 0.6653290411390247, 'bagging_fraction': 0.6357709561835093, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,952] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 239, 'learning_rate': 0.13967264248293643, 'feature_fraction': 0.7704282696272858, 'bagging_fraction': 0.6978387937050206, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,967] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 275, 'learning_rate': 0.17603886429961105, 'feature_fraction': 0.7323349956225477, 'bagging_fraction': 0.7079914774639047, 'bagging_freq': 6, 'min_child_samples': 84}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:46,979] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 251, 'learning_rate': 0.12512555184589694, 'feature_fraction': 0.5690981279799215, 'bagging_fraction': 0.7866290279011551, 'bagging_freq': 5, 'min_child_samples': 69}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,047] Trial 41 finished with value: 0.9708333333333334 and parameters: {'num_leaves': 222, 'learning_rate': 0.19760888446156552, 'feature_fraction': 0.8593306774769924, 'bagging_fraction': 0.662740817602599, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,086] Trial 42 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 247, 'learning_rate': 0.16981585862829973, 'feature_fraction': 0.6880794471799448, 'bagging_fraction': 0.7090170400160518, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,131] Trial 43 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 289, 'learning_rate': 0.21695679046287886, 'feature_fraction': 0.7501884501717073, 'bagging_fraction': 0.618374668758243, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,195] Trial 44 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 281, 'learning_rate': 0.21957614380603932, 'feature_fraction': 0.7526430873647143, 'bagging_fraction': 0.6186153017951108, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,282] Trial 45 finished with value: 0.9208333333333333 and parameters: {'num_leaves': 289, 'learning_rate': 0.19346167073099674, 'feature_fraction': 0.7157582007689793, 'bagging_fraction': 0.5429918308053799, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,304] Trial 46 finished with value: 0.9291666666666666 and parameters: {'num_leaves': 300, 'learning_rate': 0.14029369751540213, 'feature_fraction': 0.6445348665033317, 'bagging_fraction': 0.5554412199346404, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,324] Trial 47 finished with value: 0.9166666666666667 and parameters: {'num_leaves': 252, 'learning_rate': 0.15466657626851882, 'feature_fraction': 0.8143782457457306, 'bagging_fraction': 0.6709550713406247, 'bagging_freq': 4, 'min_child_samples': 37}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,345] Trial 48 finished with value: 0.9333333333333332 and parameters: {'num_leaves': 287, 'learning_rate': 0.21373951582661904, 'feature_fraction': 0.505025610944603, 'bagging_fraction': 0.8130208498927465, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,423] Trial 49 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 159, 'learning_rate': 0.18054924805694195, 'feature_fraction': 0.764284974499315, 'bagging_fraction': 0.5140099462644802, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 31 with value: 1.0.
[I 2025-09-17 13:19:47,586] A new study created in memory with name: no-name-602858c3-202e-4dc8-983f-59c261a897bd
[I 2025-09-17 13:19:47,594] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 74, 'learning_rate': 0.1155615472930026, 'feature_fraction': 0.9199647710799125, 'bagging_fraction': 0.941175108771323, 'bagging_freq': 3, 'min_child_samples': 80}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:19:47,609] Trial 1 finished with value: 0.9104166666666667 and parameters: {'num_leaves': 43, 'learning_rate': 0.21333587992917807, 'feature_fraction': 0.8029879173681553, 'bagging_fraction': 0.6119278258501473, 'bagging_freq': 6, 'min_child_samples': 44}. Best is trial 1 with value: 0.9104166666666667.
[I 2025-09-17 13:19:47,638] Trial 2 finished with value: 0.9416666666666665 and parameters: {'num_leaves': 96, 'learning_rate': 0.29784778610960866, 'feature_fraction': 0.5828417734513135, 'bagging_fraction': 0.9819555151144169, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 2 with value: 0.9416666666666665.
[I 2025-09-17 13:19:47,722] Trial 3 finished with value: 0.9666666666666666 and parameters: {'num_leaves': 100, 'learning_rate': 0.19517004398897936, 'feature_fraction': 0.535733504414637, 'bagging_fraction': 0.7796257408021934, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 3 with value: 0.9666666666666666.
[I 2025-09-17 13:19:47,737] Trial 4 finished with value: 0.9041666666666667 and parameters: {'num_leaves': 289, 'learning_rate': 0.26619739580599083, 'feature_fraction': 0.7405955541368852, 'bagging_fraction': 0.7681238777282964, 'bagging_freq': 7, 'min_child_samples': 40}. Best is trial 3 with value: 0.9666666666666666.
[I 2025-09-17 13:19:47,782] Trial 5 finished with value: 0.9583333333333333 and parameters: {'num_leaves': 208, 'learning_rate': 0.15842885982327623, 'feature_fraction': 0.5122130243443072, 'bagging_fraction': 0.9801061536362222, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 3 with value: 0.9666666666666666.
[I 2025-09-17 13:19:47,813] Trial 6 finished with value: 0.9291666666666667 and parameters: {'num_leaves': 298, 'learning_rate': 0.0831799179169018, 'feature_fraction': 0.5659450126350896, 'bagging_fraction': 0.6022602958337585, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 3 with value: 0.9666666666666666.
[I 2025-09-17 13:19:47,823] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 243, 'learning_rate': 0.0411494528692641, 'feature_fraction': 0.65351898209364, 'bagging_fraction': 0.4165510166145974, 'bagging_freq': 3, 'min_child_samples': 89}. Best is trial 3 with value: 0.9666666666666666.
[I 2025-09-17 13:19:47,833] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 190, 'learning_rate': 0.29360366507300933, 'feature_fraction': 0.9945067126709423, 'bagging_fraction': 0.5512268118870635, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 3 with value: 0.9666666666666666.
[I 2025-09-17 13:19:47,848] Trial 9 finished with value: 0.9125 and parameters: {'num_leaves': 247, 'learning_rate': 0.25612747912912426, 'feature_fraction': 0.6917030930797399, 'bagging_fraction': 0.825478654174673, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 3 with value: 0.9666666666666666.
[I 2025-09-17 13:19:47,946] Trial 10 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 125, 'learning_rate': 0.18818766275956816, 'feature_fraction': 0.41121275748716135, 'bagging_fraction': 0.8277955585481712, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 10 with value: 0.9833333333333334.
[I 2025-09-17 13:19:48,033] Trial 11 finished with value: 0.9916666666666667 and parameters: {'num_leaves': 153, 'learning_rate': 0.18152701500641266, 'feature_fraction': 0.41027758280674653, 'bagging_fraction': 0.8447426546380346, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,195] Trial 12 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 132, 'learning_rate': 0.1642557842743263, 'feature_fraction': 0.4039477216139269, 'bagging_fraction': 0.8654633081521171, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,246] Trial 13 finished with value: 0.9625 and parameters: {'num_leaves': 157, 'learning_rate': 0.21399056479786016, 'feature_fraction': 0.41092847069153887, 'bagging_fraction': 0.69881403943069, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,259] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 16, 'learning_rate': 0.10289741068757634, 'feature_fraction': 0.4654794498046932, 'bagging_fraction': 0.8773177008343132, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,272] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 145, 'learning_rate': 0.18104226150187597, 'feature_fraction': 0.482024733621093, 'bagging_fraction': 0.7065787524089061, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,328] Trial 16 finished with value: 0.9708333333333333 and parameters: {'num_leaves': 179, 'learning_rate': 0.12234657181016961, 'feature_fraction': 0.6326230461971306, 'bagging_fraction': 0.9031690446903393, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,422] Trial 17 finished with value: 0.9666666666666667 and parameters: {'num_leaves': 112, 'learning_rate': 0.24170524154041534, 'feature_fraction': 0.7888299449647816, 'bagging_fraction': 0.7818625416304135, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,458] Trial 18 finished with value: 0.9166666666666666 and parameters: {'num_leaves': 61, 'learning_rate': 0.14013867074907344, 'feature_fraction': 0.44605850714492296, 'bagging_fraction': 0.6829671701700382, 'bagging_freq': 4, 'min_child_samples': 23}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,469] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 165, 'learning_rate': 0.06524323513554599, 'feature_fraction': 0.5957928761795012, 'bagging_fraction': 0.8366440856433893, 'bagging_freq': 2, 'min_child_samples': 68}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,494] Trial 20 finished with value: 0.8833333333333332 and parameters: {'num_leaves': 127, 'learning_rate': 0.22729523373364943, 'feature_fraction': 0.5014846478500236, 'bagging_fraction': 0.47219172522669395, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,556] Trial 21 finished with value: 0.9624999999999999 and parameters: {'num_leaves': 186, 'learning_rate': 0.1267165265367624, 'feature_fraction': 0.6252843715238253, 'bagging_fraction': 0.929832361486677, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,613] Trial 22 finished with value: 0.9833333333333333 and parameters: {'num_leaves': 225, 'learning_rate': 0.17830890146149303, 'feature_fraction': 0.8399553763588642, 'bagging_fraction': 0.9039174554206735, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,677] Trial 23 finished with value: 0.9875 and parameters: {'num_leaves': 219, 'learning_rate': 0.18097138625818932, 'feature_fraction': 0.9030990844263826, 'bagging_fraction': 0.822282289114718, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,735] Trial 24 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 216, 'learning_rate': 0.202641290805876, 'feature_fraction': 0.9061198782725584, 'bagging_fraction': 0.7349024015339126, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,757] Trial 25 finished with value: 0.925 and parameters: {'num_leaves': 260, 'learning_rate': 0.15165463591435152, 'feature_fraction': 0.9868004629735212, 'bagging_fraction': 0.8258088290857726, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,769] Trial 26 finished with value: 0.5 and parameters: {'num_leaves': 141, 'learning_rate': 0.1840570212094476, 'feature_fraction': 0.8918152302022416, 'bagging_fraction': 0.655719444890155, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,873] Trial 27 finished with value: 0.9750000000000001 and parameters: {'num_leaves': 169, 'learning_rate': 0.22803402675695747, 'feature_fraction': 0.732448511577384, 'bagging_fraction': 0.8008173286806612, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,922] Trial 28 finished with value: 0.9500000000000001 and parameters: {'num_leaves': 202, 'learning_rate': 0.1720322962062968, 'feature_fraction': 0.42462814564599843, 'bagging_fraction': 0.7424002366155725, 'bagging_freq': 2, 'min_child_samples': 20}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:48,954] Trial 29 finished with value: 0.9458333333333333 and parameters: {'num_leaves': 71, 'learning_rate': 0.13934728275171418, 'feature_fraction': 0.8563163579661284, 'bagging_fraction': 0.9398586890488877, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:49,021] Trial 30 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 108, 'learning_rate': 0.09868720086778875, 'feature_fraction': 0.955626067290313, 'bagging_fraction': 0.8683626140599828, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:49,094] Trial 31 finished with value: 0.9791666666666666 and parameters: {'num_leaves': 113, 'learning_rate': 0.07974792161220329, 'feature_fraction': 0.9455415027518006, 'bagging_fraction': 0.8636740278356712, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 11 with value: 0.9916666666666667.
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.205996
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.20516
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.383112
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.180985
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.272613
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.244022
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.188809
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.185082
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.187919
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.313679
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.222148
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.121726
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.153002
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.157605
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.199261
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.175134
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.186683
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.190884
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.268032
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.33786
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.367967
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.287857
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.230977
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.472865
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.260913
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.188
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.366342
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.217857
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.281331
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.372982
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.146419
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.166198
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.176557
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.218895
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.185941
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.18274
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.287296
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.380166
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.212032
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.169733
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.152915
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.184384
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.281959
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.194431
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.243323
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.239441
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.179643
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.164728
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:49,110] Trial 32 finished with value: 0.5 and parameters: {'num_leaves': 90, 'learning_rate': 0.014249601074579982, 'feature_fraction': 0.9488490393417022, 'bagging_fraction': 0.8977807111261733, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:49,205] Trial 33 finished with value: 0.9875 and parameters: {'num_leaves': 52, 'learning_rate': 0.09803724099431099, 'feature_fraction': 0.8609981583643108, 'bagging_fraction': 0.8344492572242266, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:49,280] Trial 34 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 39, 'learning_rate': 0.19702262357517203, 'feature_fraction': 0.8028464437606571, 'bagging_fraction': 0.8125128967611127, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:49,311] Trial 35 finished with value: 0.9541666666666666 and parameters: {'num_leaves': 14, 'learning_rate': 0.13638122298796396, 'feature_fraction': 0.8699113370879913, 'bagging_fraction': 0.7619023112624371, 'bagging_freq': 1, 'min_child_samples': 26}. Best is trial 11 with value: 0.9916666666666667.
[I 2025-09-17 13:19:49,425] Trial 36 finished with value: 1.0 and parameters: {'num_leaves': 39, 'learning_rate': 0.10904994416933839, 'feature_fraction': 0.5415565534873386, 'bagging_fraction': 0.9811296059301233, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:49,474] Trial 37 finished with value: 0.9708333333333332 and parameters: {'num_leaves': 48, 'learning_rate': 0.10518121356194153, 'feature_fraction': 0.7557068657853588, 'bagging_fraction': 0.9955356355580747, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:49,516] Trial 38 finished with value: 0.9416666666666667 and parameters: {'num_leaves': 31, 'learning_rate': 0.05936087033001977, 'feature_fraction': 0.6690666143061599, 'bagging_fraction': 0.9571926161543572, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:49,599] Trial 39 finished with value: 0.9875 and parameters: {'num_leaves': 83, 'learning_rate': 0.08337220932590947, 'feature_fraction': 0.8242737056792586, 'bagging_fraction': 0.9717085720559488, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:49,624] Trial 40 finished with value: 0.9104166666666667 and parameters: {'num_leaves': 280, 'learning_rate': 0.043034147079095114, 'feature_fraction': 0.5343685996043601, 'bagging_fraction': 0.919342334805062, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:49,710] Trial 41 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 78, 'learning_rate': 0.08584420173731273, 'feature_fraction': 0.8284265090354707, 'bagging_fraction': 0.9605881866463851, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:49,816] Trial 42 finished with value: 0.9833333333333334 and parameters: {'num_leaves': 48, 'learning_rate': 0.11462259442690004, 'feature_fraction': 0.7770229905517997, 'bagging_fraction': 0.998262369981949, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:49,869] Trial 43 finished with value: 0.9749999999999999 and parameters: {'num_leaves': 87, 'learning_rate': 0.15249686817092678, 'feature_fraction': 0.7097758973555024, 'bagging_fraction': 0.9672546031359932, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:49,972] Trial 44 finished with value: 0.9791666666666667 and parameters: {'num_leaves': 58, 'learning_rate': 0.08617007755817173, 'feature_fraction': 0.8779784584554772, 'bagging_fraction': 0.8480114251681937, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:50,027] Trial 45 finished with value: 0.9625 and parameters: {'num_leaves': 26, 'learning_rate': 0.0701595313631914, 'feature_fraction': 0.912932571994961, 'bagging_fraction': 0.7945776813252226, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:50,062] Trial 46 finished with value: 0.9083333333333333 and parameters: {'num_leaves': 67, 'learning_rate': 0.047460908703824085, 'feature_fraction': 0.5756587778795359, 'bagging_fraction': 0.6037567545248231, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:50,075] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 82, 'learning_rate': 0.16698077029568947, 'feature_fraction': 0.8293754442320543, 'bagging_fraction': 0.8943789934163235, 'bagging_freq': 6, 'min_child_samples': 73}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:50,160] Trial 48 finished with value: 0.9791666666666667 and parameters: {'num_leaves': 27, 'learning_rate': 0.10365293409388363, 'feature_fraction': 0.5352211168262876, 'bagging_fraction': 0.9421514739039889, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:50,271] Trial 49 finished with value: 0.9874999999999999 and parameters: {'num_leaves': 99, 'learning_rate': 0.20710026515036523, 'feature_fraction': 0.9325456511850096, 'bagging_fraction': 0.5592776061596295, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 36 with value: 1.0.
[I 2025-09-17 13:19:50,700] A new study created in memory with name: no-name-d53b2560-0ca1-4d18-ae9c-64ef619acb2a
[I 2025-09-17 13:19:50,720] Trial 0 finished with value: 0.6353383458646616 and parameters: {'num_leaves': 138, 'learning_rate': 0.014174859550701873, 'feature_fraction': 0.9219338172228264, 'bagging_fraction': 0.6211694336447502, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 0 with value: 0.6353383458646616.
[I 2025-09-17 13:19:50,726] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 146, 'learning_rate': 0.057251230100987455, 'feature_fraction': 0.41481223265841727, 'bagging_fraction': 0.5284427881837116, 'bagging_freq': 1, 'min_child_samples': 41}. Best is trial 0 with value: 0.6353383458646616.
[I 2025-09-17 13:19:50,740] Trial 2 finished with value: 0.7406015037593985 and parameters: {'num_leaves': 134, 'learning_rate': 0.27351920021054454, 'feature_fraction': 0.4218311797942036, 'bagging_fraction': 0.633788720599264, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 2 with value: 0.7406015037593985.
[I 2025-09-17 13:19:50,748] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 143, 'learning_rate': 0.20825005186670406, 'feature_fraction': 0.5752861969331338, 'bagging_fraction': 0.6921882807218935, 'bagging_freq': 5, 'min_child_samples': 70}. Best is trial 2 with value: 0.7406015037593985.
[I 2025-09-17 13:19:50,765] Trial 4 finished with value: 0.7218045112781956 and parameters: {'num_leaves': 25, 'learning_rate': 0.24861905322318606, 'feature_fraction': 0.4503646502561007, 'bagging_fraction': 0.7475412385669922, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 2 with value: 0.7406015037593985.
[I 2025-09-17 13:19:50,773] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 157, 'learning_rate': 0.20806465979101496, 'feature_fraction': 0.7119524090823288, 'bagging_fraction': 0.5878262816891584, 'bagging_freq': 3, 'min_child_samples': 70}. Best is trial 2 with value: 0.7406015037593985.
[I 2025-09-17 13:19:50,782] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 145, 'learning_rate': 0.29848559732473107, 'feature_fraction': 0.8880291804582139, 'bagging_fraction': 0.794992624667224, 'bagging_freq': 1, 'min_child_samples': 87}. Best is trial 2 with value: 0.7406015037593985.
[I 2025-09-17 13:19:50,799] Trial 7 finished with value: 0.6165413533834586 and parameters: {'num_leaves': 57, 'learning_rate': 0.057518187329744376, 'feature_fraction': 0.8138193237059623, 'bagging_fraction': 0.9894425398571423, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 2 with value: 0.7406015037593985.
[I 2025-09-17 13:19:50,826] Trial 8 finished with value: 0.6992481203007519 and parameters: {'num_leaves': 31, 'learning_rate': 0.11618342398180559, 'feature_fraction': 0.9632371502536008, 'bagging_fraction': 0.8805905725063904, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 2 with value: 0.7406015037593985.
[I 2025-09-17 13:19:50,847] Trial 9 finished with value: 0.7518796992481204 and parameters: {'num_leaves': 127, 'learning_rate': 0.29657025063060094, 'feature_fraction': 0.59195784708274, 'bagging_fraction': 0.9794917148439699, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 9 with value: 0.7518796992481204.
[I 2025-09-17 13:19:50,861] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 270, 'learning_rate': 0.16463560463020857, 'feature_fraction': 0.5993717597969811, 'bagging_fraction': 0.4250672843855353, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial 9 with value: 0.7518796992481204.
[I 2025-09-17 13:19:50,960] Trial 11 finished with value: 0.8195488721804511 and parameters: {'num_leaves': 218, 'learning_rate': 0.2888919267376571, 'feature_fraction': 0.5380687614879642, 'bagging_fraction': 0.9764448449982969, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:19:51,004] Trial 12 finished with value: 0.6860902255639098 and parameters: {'num_leaves': 231, 'learning_rate': 0.22825162246607317, 'feature_fraction': 0.5911861560539059, 'bagging_fraction': 0.993851397948593, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 11 with value: 0.8195488721804511.
[I 2025-09-17 13:19:51,099] Trial 13 finished with value: 0.8458646616541353 and parameters: {'num_leaves': 211, 'learning_rate': 0.2945549927344665, 'feature_fraction': 0.5262684258611396, 'bagging_fraction': 0.8763687475465354, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 13 with value: 0.8458646616541353.
[I 2025-09-17 13:19:51,202] Trial 14 finished with value: 0.8458646616541354 and parameters: {'num_leaves': 209, 'learning_rate': 0.17679929852408294, 'feature_fraction': 0.49413972306287035, 'bagging_fraction': 0.870872523694405, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,237] Trial 15 finished with value: 0.7518796992481203 and parameters: {'num_leaves': 198, 'learning_rate': 0.15027243046274516, 'feature_fraction': 0.6881730474884878, 'bagging_fraction': 0.8594092794292232, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,342] Trial 16 finished with value: 0.763157894736842 and parameters: {'num_leaves': 293, 'learning_rate': 0.16947220530443674, 'feature_fraction': 0.5024157537995029, 'bagging_fraction': 0.8811912173391885, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,382] Trial 17 finished with value: 0.7706766917293233 and parameters: {'num_leaves': 186, 'learning_rate': 0.10898224553428268, 'feature_fraction': 0.6786040293583506, 'bagging_fraction': 0.7972123418005341, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,408] Trial 18 finished with value: 0.706766917293233 and parameters: {'num_leaves': 257, 'learning_rate': 0.2541229813505532, 'feature_fraction': 0.4968955170869802, 'bagging_fraction': 0.9147799396292156, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,421] Trial 19 finished with value: 0.5 and parameters: {'num_leaves': 92, 'learning_rate': 0.1985155000413864, 'feature_fraction': 0.7639170244656086, 'bagging_fraction': 0.8176431745532754, 'bagging_freq': 3, 'min_child_samples': 88}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,476] Trial 20 finished with value: 0.8007518796992481 and parameters: {'num_leaves': 190, 'learning_rate': 0.10658799100896327, 'feature_fraction': 0.6411144792315684, 'bagging_fraction': 0.7188609646394402, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,593] Trial 21 finished with value: 0.7631578947368421 and parameters: {'num_leaves': 224, 'learning_rate': 0.26700644942631085, 'feature_fraction': 0.5049472004178517, 'bagging_fraction': 0.9289220143588015, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,669] Trial 22 finished with value: 0.7706766917293232 and parameters: {'num_leaves': 218, 'learning_rate': 0.23293705773875162, 'feature_fraction': 0.5451064222416786, 'bagging_fraction': 0.9373439647350379, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,694] Trial 23 finished with value: 0.7105263157894737 and parameters: {'num_leaves': 251, 'learning_rate': 0.2773356804797419, 'feature_fraction': 0.4695674221042875, 'bagging_fraction': 0.8417747450980668, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,749] Trial 24 finished with value: 0.7406015037593985 and parameters: {'num_leaves': 178, 'learning_rate': 0.23012816925273458, 'feature_fraction': 0.5240411951638491, 'bagging_fraction': 0.9403005722282237, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,857] Trial 25 finished with value: 0.7556390977443609 and parameters: {'num_leaves': 205, 'learning_rate': 0.19290229161488218, 'feature_fraction': 0.5449376556251385, 'bagging_fraction': 0.7484167422954425, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,899] Trial 26 finished with value: 0.7518796992481204 and parameters: {'num_leaves': 293, 'learning_rate': 0.1417186978464095, 'feature_fraction': 0.6364986200698365, 'bagging_fraction': 0.889584235015622, 'bagging_freq': 6, 'min_child_samples': 18}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,920] Trial 27 finished with value: 0.7180451127819549 and parameters: {'num_leaves': 170, 'learning_rate': 0.285341851788643, 'feature_fraction': 0.4011418900631288, 'bagging_fraction': 0.9518472840434172, 'bagging_freq': 7, 'min_child_samples': 32}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,938] Trial 28 finished with value: 0.7330827067669173 and parameters: {'num_leaves': 240, 'learning_rate': 0.2591849741119191, 'feature_fraction': 0.4551215035368348, 'bagging_fraction': 0.8306317389445065, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:51,958] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 213, 'learning_rate': 0.017307890254940422, 'feature_fraction': 0.6315060225003306, 'bagging_fraction': 0.900656638512901, 'bagging_freq': 2, 'min_child_samples': 95}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,035] Trial 30 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 118, 'learning_rate': 0.0804495842105735, 'feature_fraction': 0.5600029320742237, 'bagging_fraction': 0.7771800380407757, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,085] Trial 31 finished with value: 0.7706766917293233 and parameters: {'num_leaves': 198, 'learning_rate': 0.11495188638919922, 'feature_fraction': 0.6378909576474356, 'bagging_fraction': 0.6699624176879307, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,109] Trial 32 finished with value: 0.6578947368421053 and parameters: {'num_leaves': 167, 'learning_rate': 0.09236130792818356, 'feature_fraction': 0.7520306296047814, 'bagging_fraction': 0.5848284848065702, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,172] Trial 33 finished with value: 0.7518796992481204 and parameters: {'num_leaves': 187, 'learning_rate': 0.06149309696254615, 'feature_fraction': 0.4743800768942809, 'bagging_fraction': 0.7232807382284694, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,194] Trial 34 finished with value: 0.6578947368421053 and parameters: {'num_leaves': 274, 'learning_rate': 0.13444350000538793, 'feature_fraction': 0.42978077823029814, 'bagging_fraction': 0.6648877103573393, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,221] Trial 35 finished with value: 0.6240601503759398 and parameters: {'num_leaves': 235, 'learning_rate': 0.031206690711364712, 'feature_fraction': 0.5287095052544063, 'bagging_fraction': 0.5335169700986829, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,238] Trial 36 finished with value: 0.5 and parameters: {'num_leaves': 104, 'learning_rate': 0.16998828856170362, 'feature_fraction': 0.6197949849143568, 'bagging_fraction': 0.42472994672370584, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,279] Trial 37 finished with value: 0.7030075187969925 and parameters: {'num_leaves': 210, 'learning_rate': 0.18573183303629806, 'feature_fraction': 0.5688616094289739, 'bagging_fraction': 0.7539109655031035, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,368] Trial 38 finished with value: 0.8082706766917294 and parameters: {'num_leaves': 155, 'learning_rate': 0.08821092322749964, 'feature_fraction': 0.6665554088193362, 'bagging_fraction': 0.9675776067153664, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,440] Trial 39 finished with value: 0.8007518796992481 and parameters: {'num_leaves': 156, 'learning_rate': 0.21912489019547884, 'feature_fraction': 0.8690435507779459, 'bagging_fraction': 0.9682281178095848, 'bagging_freq': 6, 'min_child_samples': 9}. Best is trial 14 with value: 0.8458646616541354.
Early stopping, best iteration is:
[49]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.158733
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.170962
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.238216
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.137421
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.184423
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.231836
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.158601
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.372734
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.165924
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[53]	valid_0's binary_logloss: 0.155219
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.169089
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.158695
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.20556
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.366332
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.661598
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.166351
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.1278
Training model for P133... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.643042
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.593595
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.613822
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.656152
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.581727
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[88]	valid_0's binary_logloss: 0.585475
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[31]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.50515
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.603495
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.520009
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.467281
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.553424
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.517512
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.539175
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.605937
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.539466
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.558367
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.546737
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.619802
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.560396
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.573519
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.549646
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.591065
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.594333
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.554914
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.569604
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.625381
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.556448
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.626554
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.629548
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.595018
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.503435
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[12]	valid_0's binary_logloss: 0.517202
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:19:52,467] Trial 40 finished with value: 0.68796992481203 and parameters: {'num_leaves': 76, 'learning_rate': 0.2843657719926022, 'feature_fraction': 0.43623075001763784, 'bagging_fraction': 0.8577114992904775, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,555] Trial 41 finished with value: 0.8007518796992482 and parameters: {'num_leaves': 184, 'learning_rate': 0.08995925774306829, 'feature_fraction': 0.6587716308420958, 'bagging_fraction': 0.9548011216234225, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,647] Trial 42 finished with value: 0.8045112781954887 and parameters: {'num_leaves': 164, 'learning_rate': 0.07285442765457793, 'feature_fraction': 0.7386687599332312, 'bagging_fraction': 0.9986112126008339, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,815] Trial 43 finished with value: 0.8195488721804511 and parameters: {'num_leaves': 138, 'learning_rate': 0.0372181977924606, 'feature_fraction': 0.759476096117141, 'bagging_fraction': 0.9784455194463842, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:52,960] Trial 44 finished with value: 0.8045112781954888 and parameters: {'num_leaves': 137, 'learning_rate': 0.040219987160612786, 'feature_fraction': 0.8256828015487361, 'bagging_fraction': 0.9058616896324732, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:53,012] Trial 45 finished with value: 0.7556390977443609 and parameters: {'num_leaves': 147, 'learning_rate': 0.04732374865127728, 'feature_fraction': 0.8113781443103628, 'bagging_fraction': 0.9696329461320032, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:53,033] Trial 46 finished with value: 0.7067669172932332 and parameters: {'num_leaves': 121, 'learning_rate': 0.2423087558565844, 'feature_fraction': 0.7194330491034677, 'bagging_fraction': 0.8660647603267347, 'bagging_freq': 6, 'min_child_samples': 58}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:53,045] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 148, 'learning_rate': 0.014690126803226213, 'feature_fraction': 0.6029545817062484, 'bagging_fraction': 0.917787524976585, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:53,094] Trial 48 finished with value: 0.7857142857142858 and parameters: {'num_leaves': 107, 'learning_rate': 0.1259569850255921, 'feature_fraction': 0.8061495242277799, 'bagging_fraction': 0.9978848983935873, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:53,129] Trial 49 finished with value: 0.7180451127819549 and parameters: {'num_leaves': 248, 'learning_rate': 0.06979471529103415, 'feature_fraction': 0.782656178394999, 'bagging_fraction': 0.9567569296090682, 'bagging_freq': 6, 'min_child_samples': 28}. Best is trial 14 with value: 0.8458646616541354.
[I 2025-09-17 13:19:53,553] A new study created in memory with name: no-name-748ff6db-d809-4ff9-adaa-37f9d3eb9d73
[I 2025-09-17 13:19:53,607] Trial 0 finished with value: 0.8270676691729324 and parameters: {'num_leaves': 66, 'learning_rate': 0.12539024398703794, 'feature_fraction': 0.8889167671492687, 'bagging_fraction': 0.8329811350787106, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 0 with value: 0.8270676691729324.
[I 2025-09-17 13:19:53,700] Trial 1 finished with value: 0.8195488721804512 and parameters: {'num_leaves': 235, 'learning_rate': 0.0525480882357685, 'feature_fraction': 0.42193179329658426, 'bagging_fraction': 0.8988651537044348, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 0 with value: 0.8270676691729324.
[I 2025-09-17 13:19:53,742] Trial 2 finished with value: 0.7857142857142856 and parameters: {'num_leaves': 122, 'learning_rate': 0.0461881502246824, 'feature_fraction': 0.8086677604895887, 'bagging_fraction': 0.5447080708371721, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 0 with value: 0.8270676691729324.
[I 2025-09-17 13:19:53,752] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 240, 'learning_rate': 0.21836574634448422, 'feature_fraction': 0.43282076712688644, 'bagging_fraction': 0.7596680068474506, 'bagging_freq': 3, 'min_child_samples': 56}. Best is trial 0 with value: 0.8270676691729324.
[I 2025-09-17 13:19:53,760] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 243, 'learning_rate': 0.03844911827389838, 'feature_fraction': 0.7205505201738547, 'bagging_fraction': 0.4948393291348706, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial 0 with value: 0.8270676691729324.
[I 2025-09-17 13:19:53,798] Trial 5 finished with value: 0.7481203007518797 and parameters: {'num_leaves': 277, 'learning_rate': 0.0894940402318364, 'feature_fraction': 0.7225498213082027, 'bagging_fraction': 0.9815027818384938, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 0 with value: 0.8270676691729324.
[I 2025-09-17 13:19:53,916] Trial 6 finished with value: 0.8533834586466166 and parameters: {'num_leaves': 116, 'learning_rate': 0.04335391526463626, 'feature_fraction': 0.5278053573762482, 'bagging_fraction': 0.6643996946680022, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 6 with value: 0.8533834586466166.
[I 2025-09-17 13:19:53,967] Trial 7 finished with value: 0.7894736842105263 and parameters: {'num_leaves': 102, 'learning_rate': 0.039167708786464576, 'feature_fraction': 0.7301127127943335, 'bagging_fraction': 0.6893476346047578, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 6 with value: 0.8533834586466166.
[I 2025-09-17 13:19:54,116] Trial 8 finished with value: 0.8609022556390978 and parameters: {'num_leaves': 81, 'learning_rate': 0.08077016467756092, 'feature_fraction': 0.4477386717808866, 'bagging_fraction': 0.7268658204087888, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 8 with value: 0.8609022556390978.
[I 2025-09-17 13:19:54,165] Trial 9 finished with value: 0.7518796992481203 and parameters: {'num_leaves': 219, 'learning_rate': 0.12059483980492977, 'feature_fraction': 0.942799019883277, 'bagging_fraction': 0.9196851652943747, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 8 with value: 0.8609022556390978.
[I 2025-09-17 13:19:54,185] Trial 10 finished with value: 0.6954887218045113 and parameters: {'num_leaves': 18, 'learning_rate': 0.2017047705474751, 'feature_fraction': 0.5351522170345374, 'bagging_fraction': 0.6008795897244813, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 8 with value: 0.8609022556390978.
[I 2025-09-17 13:19:54,205] Trial 11 finished with value: 0.7293233082706767 and parameters: {'num_leaves': 163, 'learning_rate': 0.29913773102184793, 'feature_fraction': 0.565078849258993, 'bagging_fraction': 0.6708529922276392, 'bagging_freq': 4, 'min_child_samples': 41}. Best is trial 8 with value: 0.8609022556390978.
[I 2025-09-17 13:19:54,217] Trial 12 finished with value: 0.5 and parameters: {'num_leaves': 161, 'learning_rate': 0.08922169764604312, 'feature_fraction': 0.5412834023360907, 'bagging_fraction': 0.4149830308788356, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 8 with value: 0.8609022556390978.
[I 2025-09-17 13:19:54,241] Trial 13 finished with value: 0.6898496240601504 and parameters: {'num_leaves': 46, 'learning_rate': 0.012404156841004436, 'feature_fraction': 0.6144735906659512, 'bagging_fraction': 0.7718440828686937, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 8 with value: 0.8609022556390978.
[I 2025-09-17 13:19:54,252] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 112, 'learning_rate': 0.17234234418574537, 'feature_fraction': 0.4652083438381544, 'bagging_fraction': 0.6081128037597368, 'bagging_freq': 7, 'min_child_samples': 63}. Best is trial 8 with value: 0.8609022556390978.
[I 2025-09-17 13:19:54,278] Trial 15 finished with value: 0.6954887218045112 and parameters: {'num_leaves': 75, 'learning_rate': 0.08246902370276721, 'feature_fraction': 0.6351006860005485, 'bagging_fraction': 0.7915165196640707, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 8 with value: 0.8609022556390978.
[I 2025-09-17 13:19:54,388] Trial 16 finished with value: 0.8834586466165414 and parameters: {'num_leaves': 144, 'learning_rate': 0.13505486501761502, 'feature_fraction': 0.4937895974599268, 'bagging_fraction': 0.6457457913361762, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 16 with value: 0.8834586466165414.
[I 2025-09-17 13:19:54,404] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 188, 'learning_rate': 0.1532966929675027, 'feature_fraction': 0.400355665128247, 'bagging_fraction': 0.6012903598396123, 'bagging_freq': 5, 'min_child_samples': 73}. Best is trial 16 with value: 0.8834586466165414.
[I 2025-09-17 13:19:54,430] Trial 18 finished with value: 0.7293233082706767 and parameters: {'num_leaves': 194, 'learning_rate': 0.2434131398453661, 'feature_fraction': 0.49053545301358126, 'bagging_fraction': 0.7247487243079546, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 16 with value: 0.8834586466165414.
[I 2025-09-17 13:19:54,453] Trial 19 finished with value: 0.7330827067669174 and parameters: {'num_leaves': 144, 'learning_rate': 0.12798139720968574, 'feature_fraction': 0.6155722098325189, 'bagging_fraction': 0.8384831373176322, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 16 with value: 0.8834586466165414.
[I 2025-09-17 13:19:54,520] Trial 20 finished with value: 0.8421052631578948 and parameters: {'num_leaves': 74, 'learning_rate': 0.18205352776433686, 'feature_fraction': 0.6549229190154833, 'bagging_fraction': 0.4960037606602813, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 16 with value: 0.8834586466165414.
[I 2025-09-17 13:19:54,626] Trial 21 finished with value: 0.8759398496240601 and parameters: {'num_leaves': 133, 'learning_rate': 0.07471470229965982, 'feature_fraction': 0.4916384668884614, 'bagging_fraction': 0.6588486922399417, 'bagging_freq': 6, 'min_child_samples': 6}. Best is trial 16 with value: 0.8834586466165414.
[I 2025-09-17 13:19:54,742] Trial 22 finished with value: 0.887218045112782 and parameters: {'num_leaves': 142, 'learning_rate': 0.10233303756333939, 'feature_fraction': 0.48108632380249894, 'bagging_fraction': 0.6367728177639636, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:54,785] Trial 23 finished with value: 0.7819548872180452 and parameters: {'num_leaves': 184, 'learning_rate': 0.10779776849066061, 'feature_fraction': 0.49761025242161705, 'bagging_fraction': 0.6387308099324429, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:54,805] Trial 24 finished with value: 0.7142857142857143 and parameters: {'num_leaves': 137, 'learning_rate': 0.15472789338286852, 'feature_fraction': 0.5838525930275404, 'bagging_fraction': 0.5479112776176814, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:54,832] Trial 25 finished with value: 0.7218045112781956 and parameters: {'num_leaves': 166, 'learning_rate': 0.1373666207613438, 'feature_fraction': 0.49151277794680054, 'bagging_fraction': 0.5582081752095883, 'bagging_freq': 5, 'min_child_samples': 34}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:54,883] Trial 26 finished with value: 0.8157894736842104 and parameters: {'num_leaves': 133, 'learning_rate': 0.06818670363513414, 'feature_fraction': 0.809257473041528, 'bagging_fraction': 0.6401544918031787, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:54,918] Trial 27 finished with value: 0.7744360902255639 and parameters: {'num_leaves': 103, 'learning_rate': 0.1061415242882321, 'feature_fraction': 0.6722114605155491, 'bagging_fraction': 0.7130512236359854, 'bagging_freq': 4, 'min_child_samples': 17}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:55,059] Trial 28 finished with value: 0.849624060150376 and parameters: {'num_leaves': 200, 'learning_rate': 0.10188824882554467, 'feature_fraction': 0.5676049197641131, 'bagging_fraction': 0.5756401293513685, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:55,095] Trial 29 finished with value: 0.7819548872180452 and parameters: {'num_leaves': 44, 'learning_rate': 0.1445916114808778, 'feature_fraction': 0.7866672355570319, 'bagging_fraction': 0.4768826407894293, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:55,118] Trial 30 finished with value: 0.7368421052631579 and parameters: {'num_leaves': 90, 'learning_rate': 0.01215810997362142, 'feature_fraction': 0.47188059016959566, 'bagging_fraction': 0.8413618449951964, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 22 with value: 0.887218045112782.
[I 2025-09-17 13:19:55,248] Trial 31 finished with value: 0.8909774436090225 and parameters: {'num_leaves': 147, 'learning_rate': 0.06962514083010686, 'feature_fraction': 0.4494405189105385, 'bagging_fraction': 0.7201964204451776, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,340] Trial 32 finished with value: 0.868421052631579 and parameters: {'num_leaves': 144, 'learning_rate': 0.06284636553650359, 'feature_fraction': 0.40020016666419667, 'bagging_fraction': 0.6471520235731582, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,400] Trial 33 finished with value: 0.7180451127819549 and parameters: {'num_leaves': 170, 'learning_rate': 0.11648090284450209, 'feature_fraction': 0.5034339857545197, 'bagging_fraction': 0.8012105813353415, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,429] Trial 34 finished with value: 0.7819548872180452 and parameters: {'num_leaves': 126, 'learning_rate': 0.06409769184947661, 'feature_fraction': 0.42371192436935795, 'bagging_fraction': 0.7435035385914556, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,482] Trial 35 finished with value: 0.8458646616541353 and parameters: {'num_leaves': 209, 'learning_rate': 0.09756035028592529, 'feature_fraction': 0.450718223653672, 'bagging_fraction': 0.7043551205358243, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,536] Trial 36 finished with value: 0.763157894736842 and parameters: {'num_leaves': 151, 'learning_rate': 0.02570845893181739, 'feature_fraction': 0.5841148709051358, 'bagging_fraction': 0.620853437104088, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,603] Trial 37 finished with value: 0.7819548872180452 and parameters: {'num_leaves': 180, 'learning_rate': 0.1743819772104564, 'feature_fraction': 0.5415520430829504, 'bagging_fraction': 0.6818737633208662, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,639] Trial 38 finished with value: 0.8007518796992481 and parameters: {'num_leaves': 274, 'learning_rate': 0.07167745924393457, 'feature_fraction': 0.9983044669531569, 'bagging_fraction': 0.5844555881676456, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,651] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 120, 'learning_rate': 0.05188567081970415, 'feature_fraction': 0.4355282374524225, 'bagging_fraction': 0.5080722633709136, 'bagging_freq': 3, 'min_child_samples': 89}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,680] Trial 40 finished with value: 0.7105263157894737 and parameters: {'num_leaves': 97, 'learning_rate': 0.052475848492227674, 'feature_fraction': 0.5091259210099824, 'bagging_fraction': 0.5289121204403633, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,761] Trial 41 finished with value: 0.8571428571428572 and parameters: {'num_leaves': 148, 'learning_rate': 0.07492355426574748, 'feature_fraction': 0.4072611427959446, 'bagging_fraction': 0.633988260802604, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,846] Trial 42 finished with value: 0.8383458646616542 and parameters: {'num_leaves': 136, 'learning_rate': 0.06390395140959465, 'feature_fraction': 0.46590618150901725, 'bagging_fraction': 0.6589999382180605, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:55,947] Trial 43 finished with value: 0.8345864661654135 and parameters: {'num_leaves': 152, 'learning_rate': 0.1318935098521165, 'feature_fraction': 0.4377236894892334, 'bagging_fraction': 0.6912822155664575, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:56,008] Trial 44 finished with value: 0.8157894736842106 and parameters: {'num_leaves': 115, 'learning_rate': 0.029623134600413194, 'feature_fraction': 0.4022166915051859, 'bagging_fraction': 0.7437336049699201, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:56,081] Trial 45 finished with value: 0.7857142857142857 and parameters: {'num_leaves': 172, 'learning_rate': 0.0896139699456213, 'feature_fraction': 0.5197429046034954, 'bagging_fraction': 0.6557124746007004, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:56,138] Trial 46 finished with value: 0.8157894736842105 and parameters: {'num_leaves': 128, 'learning_rate': 0.11755609391213259, 'feature_fraction': 0.4730690956304815, 'bagging_fraction': 0.8869162929574337, 'bagging_freq': 3, 'min_child_samples': 22}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:56,281] Trial 47 finished with value: 0.8270676691729323 and parameters: {'num_leaves': 220, 'learning_rate': 0.09130010329490114, 'feature_fraction': 0.43491566070986204, 'bagging_fraction': 0.7742756249332284, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 31 with value: 0.8909774436090225.
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.58185
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.525865
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.528502
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.482718
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.526951
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.548401
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.611912
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.54415
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.580202
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.499929
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.519831
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.548192
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.562972
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.460436
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.551862
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.442482
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.569722
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.611319
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.594314
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.626342
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.601885
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.446892
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.620446
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.586136
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.511275
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.449754
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.413659
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.569381
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.61861
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.57488
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.514204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.555933
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.541428
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.583626
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.635806
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.419857
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.457762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.588907
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.57307
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.500666
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.562127
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.557811
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.545125
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.59805
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[37]	valid_0's binary_logloss: 0.492034
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.477765
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.455951
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.537361
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.529604
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.54213
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.476674
[I 2025-09-17 13:19:56,299] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 109, 'learning_rate': 0.039867258606666095, 'feature_fraction': 0.5453852416063645, 'bagging_fraction': 0.6728834957779183, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:56,356] Trial 49 finished with value: 0.8270676691729324 and parameters: {'num_leaves': 87, 'learning_rate': 0.05795137267333057, 'feature_fraction': 0.45650706942416247, 'bagging_fraction': 0.5809070901145719, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 31 with value: 0.8909774436090225.
[I 2025-09-17 13:19:57,044] A new study created in memory with name: no-name-fd38cd33-f638-4a1b-a439-22a748bbb6ab
[I 2025-09-17 13:19:57,073] Trial 0 finished with value: 0.8082706766917294 and parameters: {'num_leaves': 74, 'learning_rate': 0.12533149643363636, 'feature_fraction': 0.970479136021819, 'bagging_fraction': 0.6847749199997062, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 0 with value: 0.8082706766917294.
[I 2025-09-17 13:19:57,083] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 126, 'learning_rate': 0.061156997564522315, 'feature_fraction': 0.4416738728257832, 'bagging_fraction': 0.4630195943741203, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 0 with value: 0.8082706766917294.
[I 2025-09-17 13:19:57,095] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 122, 'learning_rate': 0.25079344549561705, 'feature_fraction': 0.9885764492744704, 'bagging_fraction': 0.4498409747115982, 'bagging_freq': 2, 'min_child_samples': 44}. Best is trial 0 with value: 0.8082706766917294.
[I 2025-09-17 13:19:57,124] Trial 3 finished with value: 0.868421052631579 and parameters: {'num_leaves': 72, 'learning_rate': 0.14170032939347443, 'feature_fraction': 0.8750819364699698, 'bagging_fraction': 0.8137667602839487, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 3 with value: 0.868421052631579.
[I 2025-09-17 13:19:57,135] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 288, 'learning_rate': 0.28995016125555223, 'feature_fraction': 0.74390438613825, 'bagging_fraction': 0.4816749553110101, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 3 with value: 0.868421052631579.
[I 2025-09-17 13:19:57,188] Trial 5 finished with value: 0.8646616541353384 and parameters: {'num_leaves': 33, 'learning_rate': 0.25154807196789025, 'feature_fraction': 0.8102268261199905, 'bagging_fraction': 0.6328350425967668, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 3 with value: 0.868421052631579.
[I 2025-09-17 13:19:57,200] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 256, 'learning_rate': 0.14007676039333664, 'feature_fraction': 0.8372159043369652, 'bagging_fraction': 0.6806112934135973, 'bagging_freq': 7, 'min_child_samples': 58}. Best is trial 3 with value: 0.868421052631579.
[I 2025-09-17 13:19:57,209] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 211, 'learning_rate': 0.07490719453943216, 'feature_fraction': 0.9406447920458958, 'bagging_fraction': 0.7327960599707639, 'bagging_freq': 3, 'min_child_samples': 96}. Best is trial 3 with value: 0.868421052631579.
[I 2025-09-17 13:19:57,259] Trial 8 finished with value: 0.8609022556390977 and parameters: {'num_leaves': 290, 'learning_rate': 0.02492478973146653, 'feature_fraction': 0.861852509107022, 'bagging_fraction': 0.6934432293351426, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 3 with value: 0.868421052631579.
[I 2025-09-17 13:19:57,369] Trial 9 finished with value: 0.8796992481203008 and parameters: {'num_leaves': 288, 'learning_rate': 0.08351387547727648, 'feature_fraction': 0.8346938106630779, 'bagging_fraction': 0.7227471121136552, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 9 with value: 0.8796992481203008.
[I 2025-09-17 13:19:57,388] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 199, 'learning_rate': 0.1978387433136099, 'feature_fraction': 0.5795913860758222, 'bagging_fraction': 0.9552932331715931, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 9 with value: 0.8796992481203008.
[I 2025-09-17 13:19:57,422] Trial 11 finished with value: 0.8759398496240602 and parameters: {'num_leaves': 81, 'learning_rate': 0.1003117488550682, 'feature_fraction': 0.6612123962415533, 'bagging_fraction': 0.8608833627999752, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 9 with value: 0.8796992481203008.
[I 2025-09-17 13:19:57,458] Trial 12 finished with value: 0.8721804511278195 and parameters: {'num_leaves': 165, 'learning_rate': 0.08973667382939213, 'feature_fraction': 0.6431125980890624, 'bagging_fraction': 0.8934361753902827, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 9 with value: 0.8796992481203008.
[I 2025-09-17 13:19:57,602] Trial 13 finished with value: 0.8984962406015038 and parameters: {'num_leaves': 15, 'learning_rate': 0.02207409559698087, 'feature_fraction': 0.7096867586265391, 'bagging_fraction': 0.8443787685230585, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 13 with value: 0.8984962406015038.
[I 2025-09-17 13:19:57,730] Trial 14 finished with value: 0.8834586466165413 and parameters: {'num_leaves': 32, 'learning_rate': 0.014093180536755096, 'feature_fraction': 0.7411219650600918, 'bagging_fraction': 0.7966087893869462, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 13 with value: 0.8984962406015038.
[I 2025-09-17 13:19:57,739] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 14, 'learning_rate': 0.021431922933255777, 'feature_fraction': 0.5570703876416758, 'bagging_fraction': 0.9852413471531795, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 13 with value: 0.8984962406015038.
[I 2025-09-17 13:19:57,783] Trial 16 finished with value: 0.7593984962406015 and parameters: {'num_leaves': 42, 'learning_rate': 0.013200353404943983, 'feature_fraction': 0.7267976045524405, 'bagging_fraction': 0.8025756125540424, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 13 with value: 0.8984962406015038.
[I 2025-09-17 13:19:57,808] Trial 17 finished with value: 0.7612781954887218 and parameters: {'num_leaves': 11, 'learning_rate': 0.04355031163912457, 'feature_fraction': 0.7731973397617772, 'bagging_fraction': 0.5805130104827205, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 13 with value: 0.8984962406015038.
[I 2025-09-17 13:19:57,911] Trial 18 finished with value: 0.9135338345864662 and parameters: {'num_leaves': 110, 'learning_rate': 0.19607268983465515, 'feature_fraction': 0.5506463535362431, 'bagging_fraction': 0.9128368967552754, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:57,970] Trial 19 finished with value: 0.8609022556390977 and parameters: {'num_leaves': 105, 'learning_rate': 0.1945542038461406, 'feature_fraction': 0.4456124012629343, 'bagging_fraction': 0.917615863120955, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:57,981] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 146, 'learning_rate': 0.18947414911345353, 'feature_fraction': 0.5212156697708765, 'bagging_fraction': 0.8599180990761315, 'bagging_freq': 4, 'min_child_samples': 68}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,093] Trial 21 finished with value: 0.8984962406015037 and parameters: {'num_leaves': 52, 'learning_rate': 0.2239593325575681, 'feature_fraction': 0.6520189696757033, 'bagging_fraction': 0.7907828065331903, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,152] Trial 22 finished with value: 0.9022556390977443 and parameters: {'num_leaves': 56, 'learning_rate': 0.2308402771839703, 'feature_fraction': 0.6289254421575419, 'bagging_fraction': 0.7833407226740059, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,211] Trial 23 finished with value: 0.8721804511278195 and parameters: {'num_leaves': 95, 'learning_rate': 0.1694368342402468, 'feature_fraction': 0.6055920896825957, 'bagging_fraction': 0.9089080807986818, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,254] Trial 24 finished with value: 0.9097744360902256 and parameters: {'num_leaves': 58, 'learning_rate': 0.22806181108061013, 'feature_fraction': 0.5142762688773519, 'bagging_fraction': 0.8527657990091312, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,285] Trial 25 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 58, 'learning_rate': 0.231010683824692, 'feature_fraction': 0.5023856839390658, 'bagging_fraction': 0.7616900894278527, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,321] Trial 26 finished with value: 0.9135338345864662 and parameters: {'num_leaves': 106, 'learning_rate': 0.2831887803058716, 'feature_fraction': 0.4923333193520931, 'bagging_fraction': 0.9527367490826679, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,368] Trial 27 finished with value: 0.9097744360902256 and parameters: {'num_leaves': 158, 'learning_rate': 0.2877437427309506, 'feature_fraction': 0.4882508723467308, 'bagging_fraction': 0.9772131913554684, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,415] Trial 28 finished with value: 0.8759398496240601 and parameters: {'num_leaves': 109, 'learning_rate': 0.26467938149316184, 'feature_fraction': 0.5391849361256708, 'bagging_fraction': 0.9301819158026231, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,439] Trial 29 finished with value: 0.8571428571428571 and parameters: {'num_leaves': 84, 'learning_rate': 0.26725559565793966, 'feature_fraction': 0.4041641027498567, 'bagging_fraction': 0.954717325675931, 'bagging_freq': 3, 'min_child_samples': 45}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,503] Trial 30 finished with value: 0.9060150375939849 and parameters: {'num_leaves': 136, 'learning_rate': 0.21602264713255398, 'feature_fraction': 0.4769659981188008, 'bagging_fraction': 0.8664287345583973, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,528] Trial 31 finished with value: 0.8834586466165413 and parameters: {'num_leaves': 160, 'learning_rate': 0.29923427211459847, 'feature_fraction': 0.48828409662701533, 'bagging_fraction': 0.9831544149190126, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,565] Trial 32 finished with value: 0.8646616541353385 and parameters: {'num_leaves': 185, 'learning_rate': 0.27782773965145313, 'feature_fraction': 0.41108658077197335, 'bagging_fraction': 0.9431307581136814, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,602] Trial 33 finished with value: 0.8646616541353384 and parameters: {'num_leaves': 122, 'learning_rate': 0.2493501370482272, 'feature_fraction': 0.4510035806929556, 'bagging_fraction': 0.9994121660934723, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,628] Trial 34 finished with value: 0.8646616541353382 and parameters: {'num_leaves': 172, 'learning_rate': 0.2860468608469282, 'feature_fraction': 0.5810900814929033, 'bagging_fraction': 0.8980096407482551, 'bagging_freq': 2, 'min_child_samples': 41}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,653] Trial 35 finished with value: 0.8609022556390977 and parameters: {'num_leaves': 118, 'learning_rate': 0.17385010095675793, 'feature_fraction': 0.4662604570455282, 'bagging_fraction': 0.9543443370763668, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,718] Trial 36 finished with value: 0.887218045112782 and parameters: {'num_leaves': 141, 'learning_rate': 0.2457727779253515, 'feature_fraction': 0.5222064499531, 'bagging_fraction': 0.838496332691107, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,783] Trial 37 finished with value: 0.9060150375939849 and parameters: {'num_leaves': 227, 'learning_rate': 0.2139207676847954, 'feature_fraction': 0.5646093449855103, 'bagging_fraction': 0.8870955568182061, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,806] Trial 38 finished with value: 0.8796992481203008 and parameters: {'num_leaves': 72, 'learning_rate': 0.26726679650965673, 'feature_fraction': 0.5059604572166826, 'bagging_fraction': 0.49703791170503575, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,817] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 101, 'learning_rate': 0.12127298709630233, 'feature_fraction': 0.6055076605364691, 'bagging_fraction': 0.6453031938436115, 'bagging_freq': 1, 'min_child_samples': 61}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,912] Trial 40 finished with value: 0.8947368421052632 and parameters: {'num_leaves': 130, 'learning_rate': 0.1548630560234084, 'feature_fraction': 0.42155820891537876, 'bagging_fraction': 0.9762376289582985, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:58,981] Trial 41 finished with value: 0.9135338345864662 and parameters: {'num_leaves': 137, 'learning_rate': 0.21099478319575443, 'feature_fraction': 0.48335508922136095, 'bagging_fraction': 0.8687289784280524, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,039] Trial 42 finished with value: 0.8984962406015037 and parameters: {'num_leaves': 152, 'learning_rate': 0.244512761079697, 'feature_fraction': 0.5381795129627831, 'bagging_fraction': 0.8241423063466121, 'bagging_freq': 7, 'min_child_samples': 20}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,073] Trial 43 finished with value: 0.849624060150376 and parameters: {'num_leaves': 176, 'learning_rate': 0.20840168168442316, 'feature_fraction': 0.47699138061997554, 'bagging_fraction': 0.8765680024767238, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,116] Trial 44 finished with value: 0.8345864661654137 and parameters: {'num_leaves': 90, 'learning_rate': 0.1828832045105765, 'feature_fraction': 0.4315124525205327, 'bagging_fraction': 0.4153233231136756, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,153] Trial 45 finished with value: 0.887218045112782 and parameters: {'num_leaves': 71, 'learning_rate': 0.29515383175298276, 'feature_fraction': 0.9315700833614169, 'bagging_fraction': 0.9274836026252427, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,224] Trial 46 finished with value: 0.9022556390977444 and parameters: {'num_leaves': 113, 'learning_rate': 0.2753930382126295, 'feature_fraction': 0.6873280913426283, 'bagging_fraction': 0.752966274844398, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,248] Trial 47 finished with value: 0.8421052631578947 and parameters: {'num_leaves': 196, 'learning_rate': 0.2387754206801037, 'feature_fraction': 0.45677079105979745, 'bagging_fraction': 0.9090026489550395, 'bagging_freq': 7, 'min_child_samples': 54}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,283] Trial 48 finished with value: 0.9135338345864662 and parameters: {'num_leaves': 153, 'learning_rate': 0.20292327725087042, 'feature_fraction': 0.5490507728907865, 'bagging_fraction': 0.9640768397667815, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,315] Trial 49 finished with value: 0.8909774436090226 and parameters: {'num_leaves': 129, 'learning_rate': 0.20373490103271752, 'feature_fraction': 0.5510630116335032, 'bagging_fraction': 0.8262917812019667, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 18 with value: 0.9135338345864662.
[I 2025-09-17 13:19:59,642] A new study created in memory with name: no-name-7ed9d396-b86d-47c8-9064-f1089d1a7d5c
[I 2025-09-17 13:19:59,658] Trial 0 finished with value: 0.6710526315789473 and parameters: {'num_leaves': 282, 'learning_rate': 0.22824314993039344, 'feature_fraction': 0.9133043670450757, 'bagging_fraction': 0.7914946731022845, 'bagging_freq': 2, 'min_child_samples': 28}. Best is trial 0 with value: 0.6710526315789473.
[I 2025-09-17 13:19:59,667] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 257, 'learning_rate': 0.2801341292325104, 'feature_fraction': 0.5342715468643473, 'bagging_fraction': 0.44505735298603566, 'bagging_freq': 2, 'min_child_samples': 71}. Best is trial 0 with value: 0.6710526315789473.
[I 2025-09-17 13:19:59,687] Trial 2 finished with value: 0.6015037593984963 and parameters: {'num_leaves': 131, 'learning_rate': 0.09660053806668609, 'feature_fraction': 0.9812031638923012, 'bagging_fraction': 0.433713427041737, 'bagging_freq': 5, 'min_child_samples': 15}. Best is trial 0 with value: 0.6710526315789473.
[I 2025-09-17 13:19:59,700] Trial 3 finished with value: 0.618421052631579 and parameters: {'num_leaves': 139, 'learning_rate': 0.26482169513445064, 'feature_fraction': 0.44015669588199224, 'bagging_fraction': 0.8026422422063245, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 0 with value: 0.6710526315789473.
[I 2025-09-17 13:19:59,711] Trial 4 finished with value: 0.5977443609022557 and parameters: {'num_leaves': 186, 'learning_rate': 0.14318412268370412, 'feature_fraction': 0.7658719647897497, 'bagging_fraction': 0.5102828750400036, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 0 with value: 0.6710526315789473.
[I 2025-09-17 13:19:59,724] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 275, 'learning_rate': 0.13363534225471718, 'feature_fraction': 0.6532069599037942, 'bagging_fraction': 0.5583202307821289, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 0 with value: 0.6710526315789473.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.533914
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.528363
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.453378
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.445833
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.491407
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.40515
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.456391
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.460304
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.426557
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.472341
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.553475
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.593604
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.375787
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.436913
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.437691
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.395028
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.426073
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.420264
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.477019
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.404946
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.370725
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.430465
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.480031
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.395757
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.450901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.457428
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.442035
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.474937
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[81]	valid_0's binary_logloss: 0.483974
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.420051
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.386384
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.472984
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.682256
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.38861
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.395347
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.395356
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.458188
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.50266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.401832
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.426861
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.4771
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.42152
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.440792
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.641521
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.650841
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.657611
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.664029
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.682036
[I 2025-09-17 13:19:59,734] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 24, 'learning_rate': 0.21209240624286568, 'feature_fraction': 0.7172000269729315, 'bagging_fraction': 0.8793168014075237, 'bagging_freq': 2, 'min_child_samples': 90}. Best is trial 0 with value: 0.6710526315789473.
[I 2025-09-17 13:19:59,751] Trial 7 finished with value: 0.7030075187969924 and parameters: {'num_leaves': 24, 'learning_rate': 0.2495873674220136, 'feature_fraction': 0.7382876307150141, 'bagging_fraction': 0.8244168872030473, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:19:59,842] Trial 8 finished with value: 0.68796992481203 and parameters: {'num_leaves': 264, 'learning_rate': 0.11213800582322442, 'feature_fraction': 0.7183193318571247, 'bagging_fraction': 0.7943105132083699, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:19:59,850] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 224, 'learning_rate': 0.09864766558166634, 'feature_fraction': 0.955385532542111, 'bagging_fraction': 0.5828499766381781, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:19:59,859] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 17, 'learning_rate': 0.03375728695292664, 'feature_fraction': 0.8296697966201281, 'bagging_fraction': 0.9835986703686532, 'bagging_freq': 6, 'min_child_samples': 98}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:19:59,895] Trial 11 finished with value: 0.6146616541353384 and parameters: {'num_leaves': 96, 'learning_rate': 0.2013065468660326, 'feature_fraction': 0.6208632132610682, 'bagging_fraction': 0.6858578511033349, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:19:59,973] Trial 12 finished with value: 0.6165413533834586 and parameters: {'num_leaves': 58, 'learning_rate': 0.03635775613799681, 'feature_fraction': 0.7995455714910064, 'bagging_fraction': 0.7060159576982882, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:19:59,997] Trial 13 finished with value: 0.6240601503759399 and parameters: {'num_leaves': 199, 'learning_rate': 0.17818706876362211, 'feature_fraction': 0.5710804405544829, 'bagging_fraction': 0.9077936316365447, 'bagging_freq': 1, 'min_child_samples': 29}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,061] Trial 14 finished with value: 0.6541353383458647 and parameters: {'num_leaves': 80, 'learning_rate': 0.09005937114577005, 'feature_fraction': 0.8802420773683902, 'bagging_fraction': 0.7234359335504037, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,076] Trial 15 finished with value: 0.618421052631579 and parameters: {'num_leaves': 232, 'learning_rate': 0.25022420913579585, 'feature_fraction': 0.698433427471108, 'bagging_fraction': 0.8255701549876436, 'bagging_freq': 5, 'min_child_samples': 43}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,108] Trial 16 finished with value: 0.5827067669172932 and parameters: {'num_leaves': 163, 'learning_rate': 0.16614543355520883, 'feature_fraction': 0.7420177164137116, 'bagging_fraction': 0.9971878089188774, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,124] Trial 17 finished with value: 0.4605263157894737 and parameters: {'num_leaves': 108, 'learning_rate': 0.2903036234336531, 'feature_fraction': 0.4900631976945772, 'bagging_fraction': 0.6427176756445855, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,133] Trial 18 finished with value: 0.41541353383458646 and parameters: {'num_leaves': 299, 'learning_rate': 0.057250844851002465, 'feature_fraction': 0.648432544469704, 'bagging_fraction': 0.896771880519578, 'bagging_freq': 1, 'min_child_samples': 61}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,162] Trial 19 finished with value: 0.6635338345864662 and parameters: {'num_leaves': 51, 'learning_rate': 0.12371397533253845, 'feature_fraction': 0.8390583357503134, 'bagging_fraction': 0.7621877941492305, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,175] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 171, 'learning_rate': 0.18627735046182775, 'feature_fraction': 0.5881062698075632, 'bagging_fraction': 0.8340721667601059, 'bagging_freq': 4, 'min_child_samples': 73}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,194] Trial 21 finished with value: 0.637218045112782 and parameters: {'num_leaves': 298, 'learning_rate': 0.23246594736938006, 'feature_fraction': 0.9024587684525944, 'bagging_fraction': 0.7638239278851753, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,308] Trial 22 finished with value: 0.680451127819549 and parameters: {'num_leaves': 256, 'learning_rate': 0.2247253142592978, 'feature_fraction': 0.899152879042545, 'bagging_fraction': 0.9352953577016815, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,364] Trial 23 finished with value: 0.5733082706766918 and parameters: {'num_leaves': 243, 'learning_rate': 0.24535631212456152, 'feature_fraction': 0.7856119508051791, 'bagging_fraction': 0.9337901778221246, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,395] Trial 24 finished with value: 0.6748120300751881 and parameters: {'num_leaves': 223, 'learning_rate': 0.20700961243504237, 'feature_fraction': 0.695261368721502, 'bagging_fraction': 0.8615212032875661, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,498] Trial 25 finished with value: 0.5958646616541354 and parameters: {'num_leaves': 201, 'learning_rate': 0.156614911008891, 'feature_fraction': 0.8281847743058571, 'bagging_fraction': 0.9547206267154036, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,533] Trial 26 finished with value: 0.650375939849624 and parameters: {'num_leaves': 264, 'learning_rate': 0.2984477513211014, 'feature_fraction': 0.9489726958076016, 'bagging_fraction': 0.8440635154750211, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,652] Trial 27 finished with value: 0.6165413533834586 and parameters: {'num_leaves': 248, 'learning_rate': 0.06756593515065593, 'feature_fraction': 0.8675593684582815, 'bagging_fraction': 0.9282560198526987, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,667] Trial 28 finished with value: 0.47744360902255634 and parameters: {'num_leaves': 141, 'learning_rate': 0.2696098067562538, 'feature_fraction': 0.7495430805371732, 'bagging_fraction': 0.6498849098709981, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,687] Trial 29 finished with value: 0.6748120300751881 and parameters: {'num_leaves': 277, 'learning_rate': 0.22697781491175345, 'feature_fraction': 0.6625116674871415, 'bagging_fraction': 0.7640177970156039, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,712] Trial 30 finished with value: 0.6541353383458647 and parameters: {'num_leaves': 212, 'learning_rate': 0.12269038654943101, 'feature_fraction': 0.9320110767234818, 'bagging_fraction': 0.8009937381413169, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,745] Trial 31 finished with value: 0.6578947368421053 and parameters: {'num_leaves': 225, 'learning_rate': 0.20884426155338626, 'feature_fraction': 0.7009929045005932, 'bagging_fraction': 0.8619775951543316, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,788] Trial 32 finished with value: 0.5488721804511278 and parameters: {'num_leaves': 258, 'learning_rate': 0.22825845618256788, 'feature_fraction': 0.6786722537586627, 'bagging_fraction': 0.8775398014508444, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,816] Trial 33 finished with value: 0.6954887218045113 and parameters: {'num_leaves': 182, 'learning_rate': 0.1902416575302237, 'feature_fraction': 0.730266811945714, 'bagging_fraction': 0.9511399684033102, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,858] Trial 34 finished with value: 0.6259398496240601 and parameters: {'num_leaves': 179, 'learning_rate': 0.1887115399287066, 'feature_fraction': 0.9972485346590647, 'bagging_fraction': 0.9604650185074162, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,882] Trial 35 finished with value: 0.6353383458646616 and parameters: {'num_leaves': 118, 'learning_rate': 0.2563414180609865, 'feature_fraction': 0.7758998781180428, 'bagging_fraction': 0.920969746911891, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,933] Trial 36 finished with value: 0.6109022556390977 and parameters: {'num_leaves': 149, 'learning_rate': 0.279065886114242, 'feature_fraction': 0.6140140151861142, 'bagging_fraction': 0.8062493709943226, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,942] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 286, 'learning_rate': 0.17121494697917222, 'feature_fraction': 0.7278318680885089, 'bagging_fraction': 0.961510783460515, 'bagging_freq': 3, 'min_child_samples': 68}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,961] Trial 38 finished with value: 0.5733082706766917 and parameters: {'num_leaves': 245, 'learning_rate': 0.1448113769159297, 'feature_fraction': 0.8035991959077124, 'bagging_fraction': 0.7412525014698172, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:00,992] Trial 39 finished with value: 0.6654135338345865 and parameters: {'num_leaves': 197, 'learning_rate': 0.10092686119583733, 'feature_fraction': 0.4145395525131223, 'bagging_fraction': 0.884350630550567, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:01,006] Trial 40 finished with value: 0.5 and parameters: {'num_leaves': 46, 'learning_rate': 0.2390085889375536, 'feature_fraction': 0.5318440058777941, 'bagging_fraction': 0.4705786373771319, 'bagging_freq': 2, 'min_child_samples': 53}. Best is trial 7 with value: 0.7030075187969924.
[I 2025-09-17 13:20:01,036] Trial 41 finished with value: 0.8045112781954886 and parameters: {'num_leaves': 220, 'learning_rate': 0.19538725470061663, 'feature_fraction': 0.685089654065385, 'bagging_fraction': 0.8513447961305023, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,059] Trial 42 finished with value: 0.6503759398496242 and parameters: {'num_leaves': 265, 'learning_rate': 0.21798396477317217, 'feature_fraction': 0.6354821416016662, 'bagging_fraction': 0.8204565512391205, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,094] Trial 43 finished with value: 0.6484962406015038 and parameters: {'num_leaves': 185, 'learning_rate': 0.19344732997450514, 'feature_fraction': 0.7557537644664089, 'bagging_fraction': 0.7831172606667441, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,113] Trial 44 finished with value: 0.6578947368421053 and parameters: {'num_leaves': 211, 'learning_rate': 0.15888902586319914, 'feature_fraction': 0.7313311544580696, 'bagging_fraction': 0.8542505683704212, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,137] Trial 45 finished with value: 0.6710526315789473 and parameters: {'num_leaves': 239, 'learning_rate': 0.26026184948242925, 'feature_fraction': 0.6777936698928706, 'bagging_fraction': 0.9034183159678841, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,194] Trial 46 finished with value: 0.6165413533834586 and parameters: {'num_leaves': 283, 'learning_rate': 0.1989069795713223, 'feature_fraction': 0.5877713366550061, 'bagging_fraction': 0.9456874771574242, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,228] Trial 47 finished with value: 0.7030075187969926 and parameters: {'num_leaves': 86, 'learning_rate': 0.17671294811621185, 'feature_fraction': 0.8596428416980274, 'bagging_fraction': 0.9764358542780021, 'bagging_freq': 2, 'min_child_samples': 24}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,250] Trial 48 finished with value: 0.6071428571428572 and parameters: {'num_leaves': 80, 'learning_rate': 0.13756194604886038, 'feature_fraction': 0.8090707262184098, 'bagging_fraction': 0.9947631416684835, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,267] Trial 49 finished with value: 0.5 and parameters: {'num_leaves': 33, 'learning_rate': 0.11057227620811569, 'feature_fraction': 0.8551510582537455, 'bagging_fraction': 0.7107948308925239, 'bagging_freq': 3, 'min_child_samples': 81}. Best is trial 41 with value: 0.8045112781954886.
[I 2025-09-17 13:20:01,579] A new study created in memory with name: no-name-04c28a43-324a-4a92-84bb-638ae2d54a64
[I 2025-09-17 13:20:01,586] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 187, 'learning_rate': 0.23203205660324308, 'feature_fraction': 0.7787651286841315, 'bagging_fraction': 0.823569808121327, 'bagging_freq': 1, 'min_child_samples': 77}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:20:01,593] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 35, 'learning_rate': 0.1564045555880475, 'feature_fraction': 0.650473352937682, 'bagging_fraction': 0.9403211788814915, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:20:01,601] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 278, 'learning_rate': 0.2826801424676017, 'feature_fraction': 0.5652347833829462, 'bagging_fraction': 0.5465518107475287, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:20:01,615] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 29, 'learning_rate': 0.09299064738617542, 'feature_fraction': 0.6911298216360064, 'bagging_fraction': 0.6875031387448236, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:20:01,639] Trial 4 finished with value: 0.825925925925926 and parameters: {'num_leaves': 214, 'learning_rate': 0.1424297188170301, 'feature_fraction': 0.6454972444108751, 'bagging_fraction': 0.7964461490167865, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 4 with value: 0.825925925925926.
[I 2025-09-17 13:20:01,651] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 162, 'learning_rate': 0.11847255702400734, 'feature_fraction': 0.4363884381603139, 'bagging_fraction': 0.6680826274191913, 'bagging_freq': 4, 'min_child_samples': 81}. Best is trial 4 with value: 0.825925925925926.
[I 2025-09-17 13:20:01,668] Trial 6 finished with value: 0.7462962962962963 and parameters: {'num_leaves': 142, 'learning_rate': 0.24790714418677787, 'feature_fraction': 0.6840457048785735, 'bagging_fraction': 0.9879872662939778, 'bagging_freq': 4, 'min_child_samples': 29}. Best is trial 4 with value: 0.825925925925926.
[I 2025-09-17 13:20:01,678] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.2570976650080094, 'feature_fraction': 0.41282249930566495, 'bagging_fraction': 0.7472853426141695, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 4 with value: 0.825925925925926.
[I 2025-09-17 13:20:01,686] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 269, 'learning_rate': 0.08500180706273636, 'feature_fraction': 0.8001770346388106, 'bagging_fraction': 0.8819433481607939, 'bagging_freq': 5, 'min_child_samples': 63}. Best is trial 4 with value: 0.825925925925926.
[I 2025-09-17 13:20:01,733] Trial 9 finished with value: 0.8 and parameters: {'num_leaves': 64, 'learning_rate': 0.17160550040277778, 'feature_fraction': 0.5111281772047346, 'bagging_fraction': 0.40603660966680105, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 4 with value: 0.825925925925926.
[I 2025-09-17 13:20:01,751] Trial 10 finished with value: 0.7425925925925926 and parameters: {'num_leaves': 120, 'learning_rate': 0.012214444169702854, 'feature_fraction': 0.9542180250973225, 'bagging_fraction': 0.5639526871588892, 'bagging_freq': 2, 'min_child_samples': 40}. Best is trial 4 with value: 0.825925925925926.
[I 2025-09-17 13:20:01,788] Trial 11 finished with value: 0.8296296296296296 and parameters: {'num_leaves': 90, 'learning_rate': 0.18007339303673603, 'feature_fraction': 0.5471353255376226, 'bagging_fraction': 0.4010175765966862, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 11 with value: 0.8296296296296296.
[I 2025-09-17 13:20:01,889] Trial 12 finished with value: 0.7888888888888889 and parameters: {'num_leaves': 94, 'learning_rate': 0.19756438065843954, 'feature_fraction': 0.572890779677371, 'bagging_fraction': 0.4107593945165848, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 11 with value: 0.8296296296296296.
[I 2025-09-17 13:20:01,920] Trial 13 finished with value: 0.8037037037037037 and parameters: {'num_leaves': 228, 'learning_rate': 0.1998804354961137, 'feature_fraction': 0.8052393546172932, 'bagging_fraction': 0.7780186589806761, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 11 with value: 0.8296296296296296.
[I 2025-09-17 13:20:01,936] Trial 14 finished with value: 0.5 and parameters: {'num_leaves': 91, 'learning_rate': 0.1232909221420003, 'feature_fraction': 0.6052371903238457, 'bagging_fraction': 0.5866181238759376, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 11 with value: 0.8296296296296296.
[I 2025-09-17 13:20:01,992] Trial 15 finished with value: 0.7888888888888889 and parameters: {'num_leaves': 231, 'learning_rate': 0.056718325426906954, 'feature_fraction': 0.4834597797838304, 'bagging_fraction': 0.8561298154580865, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 11 with value: 0.8296296296296296.
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.607647
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.604283
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.637113
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.633322
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.630319
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.618034
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.658207
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.624599
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.707451
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.610763
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.651915
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.645658
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.65755
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.611513
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.6677
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.613616
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.667253
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.617277
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.639797
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[7]	valid_0's binary_logloss: 0.611279
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.646104
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.575614
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.634823
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.635856
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.634178
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.664671
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.633551
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.571287
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.609061
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.596304
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.646488
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.651343
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.636211
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.601226
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.671073
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.682036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[5]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.521153
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.546059
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.556166
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.666717
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.509383
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.528107
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[19]	valid_0's binary_logloss: 0.537698
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.540649
[I 2025-09-17 13:20:02,014] Trial 16 finished with value: 0.6555555555555556 and parameters: {'num_leaves': 166, 'learning_rate': 0.192608265970318, 'feature_fraction': 0.8964355979616271, 'bagging_fraction': 0.46825410938417555, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 11 with value: 0.8296296296296296.
[I 2025-09-17 13:20:02,031] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.13396995888282992, 'feature_fraction': 0.7368047454506583, 'bagging_fraction': 0.6405806648028849, 'bagging_freq': 1, 'min_child_samples': 55}. Best is trial 11 with value: 0.8296296296296296.
[I 2025-09-17 13:20:02,073] Trial 18 finished with value: 0.8333333333333333 and parameters: {'num_leaves': 124, 'learning_rate': 0.1686693922004196, 'feature_fraction': 0.5233499259641172, 'bagging_fraction': 0.7525483452334518, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,110] Trial 19 finished with value: 0.8240740740740741 and parameters: {'num_leaves': 118, 'learning_rate': 0.21890001920193042, 'feature_fraction': 0.504983668354271, 'bagging_fraction': 0.49896691224352885, 'bagging_freq': 2, 'min_child_samples': 14}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,150] Trial 20 finished with value: 0.7814814814814816 and parameters: {'num_leaves': 60, 'learning_rate': 0.2925415556854264, 'feature_fraction': 0.5411697867738293, 'bagging_fraction': 0.7147083519576705, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,172] Trial 21 finished with value: 0.8222222222222223 and parameters: {'num_leaves': 134, 'learning_rate': 0.16402833483304374, 'feature_fraction': 0.5870168868812449, 'bagging_fraction': 0.8016407018669418, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,190] Trial 22 finished with value: 0.7148148148148149 and parameters: {'num_leaves': 94, 'learning_rate': 0.14670062344759455, 'feature_fraction': 0.45938007004787484, 'bagging_fraction': 0.6249423118538499, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,234] Trial 23 finished with value: 0.7222222222222223 and parameters: {'num_leaves': 190, 'learning_rate': 0.18066176433288136, 'feature_fraction': 0.6320677036531078, 'bagging_fraction': 0.733784660494283, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,269] Trial 24 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 65, 'learning_rate': 0.09524415212139506, 'feature_fraction': 0.6417373089507775, 'bagging_fraction': 0.9046068537654048, 'bagging_freq': 1, 'min_child_samples': 24}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,286] Trial 25 finished with value: 0.7462962962962962 and parameters: {'num_leaves': 236, 'learning_rate': 0.22048482924916527, 'feature_fraction': 0.5299648972051845, 'bagging_fraction': 0.8204896580294431, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,315] Trial 26 finished with value: 0.8296296296296297 and parameters: {'num_leaves': 112, 'learning_rate': 0.1446589262285863, 'feature_fraction': 0.7414270685932947, 'bagging_fraction': 0.7721569672918673, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,342] Trial 27 finished with value: 0.8185185185185185 and parameters: {'num_leaves': 110, 'learning_rate': 0.11345795419410652, 'feature_fraction': 0.8559701350297664, 'bagging_fraction': 0.7523650088001809, 'bagging_freq': 3, 'min_child_samples': 31}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,384] Trial 28 finished with value: 0.8074074074074076 and parameters: {'num_leaves': 78, 'learning_rate': 0.06147228640629279, 'feature_fraction': 0.7258897237608977, 'bagging_fraction': 0.6222603578531283, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,407] Trial 29 finished with value: 0.7888888888888889 and parameters: {'num_leaves': 148, 'learning_rate': 0.24018946044800804, 'feature_fraction': 0.7597989954118773, 'bagging_fraction': 0.8434322536487583, 'bagging_freq': 1, 'min_child_samples': 28}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,449] Trial 30 finished with value: 0.7592592592592592 and parameters: {'num_leaves': 177, 'learning_rate': 0.18187538272392462, 'feature_fraction': 0.8585019379206814, 'bagging_fraction': 0.6766630334819661, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,473] Trial 31 finished with value: 0.8222222222222222 and parameters: {'num_leaves': 127, 'learning_rate': 0.13922676350768262, 'feature_fraction': 0.6835146679353771, 'bagging_fraction': 0.7738468423246684, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,492] Trial 32 finished with value: 0.8222222222222223 and parameters: {'num_leaves': 10, 'learning_rate': 0.1600990874803076, 'feature_fraction': 0.6148361482765051, 'bagging_fraction': 0.8013933162609445, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,526] Trial 33 finished with value: 0.7777777777777778 and parameters: {'num_leaves': 199, 'learning_rate': 0.15214849800636612, 'feature_fraction': 0.660307503252964, 'bagging_fraction': 0.9521256719582423, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,548] Trial 34 finished with value: 0.8111111111111111 and parameters: {'num_leaves': 39, 'learning_rate': 0.21175441196893768, 'feature_fraction': 0.5511504309682647, 'bagging_fraction': 0.8818108157202904, 'bagging_freq': 3, 'min_child_samples': 52}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,624] Trial 35 finished with value: 0.762962962962963 and parameters: {'num_leaves': 100, 'learning_rate': 0.10325522341118061, 'feature_fraction': 0.5961848692176088, 'bagging_fraction': 0.7093360642663236, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,647] Trial 36 finished with value: 0.8111111111111111 and parameters: {'num_leaves': 160, 'learning_rate': 0.1300999962343972, 'feature_fraction': 0.7208351632404321, 'bagging_fraction': 0.5028110773712833, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,660] Trial 37 finished with value: 0.5 and parameters: {'num_leaves': 143, 'learning_rate': 0.17363718840230352, 'feature_fraction': 0.4777901751208613, 'bagging_fraction': 0.6578455195805759, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,677] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 252, 'learning_rate': 0.07862993847577888, 'feature_fraction': 0.41016060731836, 'bagging_fraction': 0.7771270370306855, 'bagging_freq': 2, 'min_child_samples': 65}. Best is trial 18 with value: 0.8333333333333333.
[I 2025-09-17 13:20:02,703] Trial 39 finished with value: 0.8481481481481482 and parameters: {'num_leaves': 178, 'learning_rate': 0.1476208681222903, 'feature_fraction': 0.6651576158198597, 'bagging_fraction': 0.9124385352179742, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 39 with value: 0.8481481481481482.
[I 2025-09-17 13:20:02,747] Trial 40 finished with value: 0.8074074074074075 and parameters: {'num_leaves': 178, 'learning_rate': 0.15732250959479757, 'feature_fraction': 0.7835031835146642, 'bagging_fraction': 0.989006164133784, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 39 with value: 0.8481481481481482.
[I 2025-09-17 13:20:02,778] Trial 41 finished with value: 0.8481481481481481 and parameters: {'num_leaves': 215, 'learning_rate': 0.14447746284329044, 'feature_fraction': 0.6603483048659704, 'bagging_fraction': 0.9065390853011753, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 39 with value: 0.8481481481481482.
[I 2025-09-17 13:20:02,807] Trial 42 finished with value: 0.8296296296296296 and parameters: {'num_leaves': 216, 'learning_rate': 0.1132662129768865, 'feature_fraction': 0.6711179682903268, 'bagging_fraction': 0.9263283619497211, 'bagging_freq': 6, 'min_child_samples': 34}. Best is trial 39 with value: 0.8481481481481482.
[I 2025-09-17 13:20:02,834] Trial 43 finished with value: 0.8148148148148148 and parameters: {'num_leaves': 79, 'learning_rate': 0.19151963548213755, 'feature_fraction': 0.7082108056165978, 'bagging_fraction': 0.9582869617559865, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 39 with value: 0.8481481481481482.
[I 2025-09-17 13:20:02,858] Trial 44 finished with value: 0.8 and parameters: {'num_leaves': 108, 'learning_rate': 0.14470162661972574, 'feature_fraction': 0.7609371143811666, 'bagging_fraction': 0.868540708211647, 'bagging_freq': 6, 'min_child_samples': 41}. Best is trial 39 with value: 0.8481481481481482.
[I 2025-09-17 13:20:02,884] Trial 45 finished with value: 0.737037037037037 and parameters: {'num_leaves': 153, 'learning_rate': 0.25942667094952565, 'feature_fraction': 0.6222451258194344, 'bagging_fraction': 0.9184351641796062, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 39 with value: 0.8481481481481482.
[I 2025-09-17 13:20:03,007] Trial 46 finished with value: 0.8518518518518519 and parameters: {'num_leaves': 134, 'learning_rate': 0.20841070826358216, 'feature_fraction': 0.8207981161881712, 'bagging_fraction': 0.8326859647662964, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 46 with value: 0.8518518518518519.
[I 2025-09-17 13:20:03,151] Trial 47 finished with value: 0.8148148148148149 and parameters: {'num_leaves': 137, 'learning_rate': 0.16903043311139682, 'feature_fraction': 0.8460349121111669, 'bagging_fraction': 0.8452666838700519, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 46 with value: 0.8518518518518519.
[I 2025-09-17 13:20:03,193] Trial 48 finished with value: 0.7925925925925926 and parameters: {'num_leaves': 171, 'learning_rate': 0.20753380110145495, 'feature_fraction': 0.991726826749807, 'bagging_fraction': 0.89798280779676, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 46 with value: 0.8518518518518519.
[I 2025-09-17 13:20:03,218] Trial 49 finished with value: 0.8333333333333335 and parameters: {'num_leaves': 185, 'learning_rate': 0.23064680655277225, 'feature_fraction': 0.8307878595515572, 'bagging_fraction': 0.8259847634844517, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 46 with value: 0.8518518518518519.
[I 2025-09-17 13:20:03,519] A new study created in memory with name: no-name-7c85b4a0-9482-43d0-a6f2-f52241fdb921
[I 2025-09-17 13:20:03,566] Trial 0 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 192, 'learning_rate': 0.12180706355993208, 'feature_fraction': 0.4630653290472848, 'bagging_fraction': 0.9353697101038106, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,574] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 259, 'learning_rate': 0.07226335599733091, 'feature_fraction': 0.810330678903288, 'bagging_fraction': 0.4941641932839256, 'bagging_freq': 5, 'min_child_samples': 85}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,581] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 32, 'learning_rate': 0.10298146312193755, 'feature_fraction': 0.8920171590555684, 'bagging_fraction': 0.42231675830369636, 'bagging_freq': 4, 'min_child_samples': 90}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,588] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 191, 'learning_rate': 0.16981261227360347, 'feature_fraction': 0.45509899622427596, 'bagging_fraction': 0.6849239710668368, 'bagging_freq': 6, 'min_child_samples': 77}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,596] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 246, 'learning_rate': 0.20048898735635476, 'feature_fraction': 0.8339787628714858, 'bagging_fraction': 0.5122827116742021, 'bagging_freq': 2, 'min_child_samples': 71}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,604] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 137, 'learning_rate': 0.229278076380528, 'feature_fraction': 0.7570641003920957, 'bagging_fraction': 0.5823998763908163, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,613] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 98, 'learning_rate': 0.24644462617192311, 'feature_fraction': 0.6140849052072079, 'bagging_fraction': 0.6119506980324625, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,625] Trial 7 finished with value: 0.8862745098039215 and parameters: {'num_leaves': 174, 'learning_rate': 0.22219036391266947, 'feature_fraction': 0.7376080918044231, 'bagging_fraction': 0.6619851514490416, 'bagging_freq': 1, 'min_child_samples': 44}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,633] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 43, 'learning_rate': 0.020806408079242604, 'feature_fraction': 0.50996374123252, 'bagging_fraction': 0.5117538464495829, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,638] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 264, 'learning_rate': 0.12804411214016304, 'feature_fraction': 0.9650259958428079, 'bagging_fraction': 0.9024547931438135, 'bagging_freq': 1, 'min_child_samples': 86}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,675] Trial 10 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 211, 'learning_rate': 0.2924722856287175, 'feature_fraction': 0.5977172096602015, 'bagging_fraction': 0.9909416507814369, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 0 with value: 0.9411764705882353.
[I 2025-09-17 13:20:03,766] Trial 11 finished with value: 0.9450980392156862 and parameters: {'num_leaves': 210, 'learning_rate': 0.2791574853863943, 'feature_fraction': 0.5959064015971185, 'bagging_fraction': 0.9963300135047961, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 11 with value: 0.9450980392156862.
[I 2025-09-17 13:20:03,832] Trial 12 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 297, 'learning_rate': 0.2885584818133763, 'feature_fraction': 0.4190403685401489, 'bagging_fraction': 0.8509656320904911, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:03,929] Trial 13 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 297, 'learning_rate': 0.29583049819168006, 'feature_fraction': 0.401137334904703, 'bagging_fraction': 0.8045617221590746, 'bagging_freq': 3, 'min_child_samples': 6}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:03,968] Trial 14 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 296, 'learning_rate': 0.26618581732317886, 'feature_fraction': 0.40592303913518774, 'bagging_fraction': 0.7995077770894911, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,001] Trial 15 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 300, 'learning_rate': 0.2997640997960091, 'feature_fraction': 0.5192559516371408, 'bagging_fraction': 0.8049382628887182, 'bagging_freq': 4, 'min_child_samples': 30}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,100] Trial 16 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 121, 'learning_rate': 0.18749583504128237, 'feature_fraction': 0.6672523365586653, 'bagging_fraction': 0.7771905330420906, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,134] Trial 17 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 237, 'learning_rate': 0.25446894091909517, 'feature_fraction': 0.4050906709980857, 'bagging_fraction': 0.860527290949717, 'bagging_freq': 7, 'min_child_samples': 30}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,147] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 281, 'learning_rate': 0.2159234808053718, 'feature_fraction': 0.5350723787870463, 'bagging_fraction': 0.7500997039409772, 'bagging_freq': 4, 'min_child_samples': 100}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,192] Trial 19 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 76, 'learning_rate': 0.1561597011311965, 'feature_fraction': 0.46591451931618716, 'bagging_fraction': 0.853732959870507, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,235] Trial 20 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 69, 'learning_rate': 0.03150176884644483, 'feature_fraction': 0.6697693079522262, 'bagging_fraction': 0.8861370609220164, 'bagging_freq': 5, 'min_child_samples': 20}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,275] Trial 21 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 90, 'learning_rate': 0.15928142869017056, 'feature_fraction': 0.45985432169913265, 'bagging_fraction': 0.8363744445161903, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,360] Trial 22 finished with value: 0.9450980392156864 and parameters: {'num_leaves': 157, 'learning_rate': 0.05367175967702005, 'feature_fraction': 0.41333806757058056, 'bagging_fraction': 0.7327456324474035, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,388] Trial 23 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 229, 'learning_rate': 0.2526904982758491, 'feature_fraction': 0.5374263919052807, 'bagging_fraction': 0.9319448203420979, 'bagging_freq': 3, 'min_child_samples': 39}. Best is trial 12 with value: 0.9568627450980393.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.660572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.49532
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.518473
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.541887
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[26]	valid_0's binary_logloss: 0.531058
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.6401
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[11]	valid_0's binary_logloss: 0.574209
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.542754
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.618939
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.522504
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.527923
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.535198
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.543738
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	valid_0's binary_logloss: 0.545769
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.532803
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.54735
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.540234
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.52988
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[36]	valid_0's binary_logloss: 0.558464
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.540952
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.689533
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.497278
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.524062
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.505176
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.531866
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.517854
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.550309
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.56805
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.494662
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.474079
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	valid_0's binary_logloss: 0.5372
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[18]	valid_0's binary_logloss: 0.509921
Training model for P135... (normalize_per_user=True)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.284513
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.481863
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.290649
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[8]	valid_0's binary_logloss: 0.293781
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.282224
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.245447
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.26698
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.283603
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.287741
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.235711
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.25085
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.316336
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.269645
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.259749
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.268537
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:20:04,413] Trial 24 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 19, 'learning_rate': 0.2763649859790201, 'feature_fraction': 0.47171288247957144, 'bagging_fraction': 0.8516803198348516, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:04,478] Trial 25 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 276, 'learning_rate': 0.18373828948997298, 'feature_fraction': 0.49210157804364324, 'bagging_fraction': 0.723627286510507, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 25 with value: 0.9607843137254902.
[I 2025-09-17 13:20:04,507] Trial 26 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 269, 'learning_rate': 0.13442359139045024, 'feature_fraction': 0.5686864016525361, 'bagging_fraction': 0.7231971401574534, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 25 with value: 0.9607843137254902.
[I 2025-09-17 13:20:04,569] Trial 27 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 80, 'learning_rate': 0.177982233688429, 'feature_fraction': 0.4854481778058961, 'bagging_fraction': 0.6419322323517925, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,621] Trial 28 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 120, 'learning_rate': 0.18993287183177535, 'feature_fraction': 0.6307695477133954, 'bagging_fraction': 0.6436868688146393, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,684] Trial 29 finished with value: 0.9450980392156862 and parameters: {'num_leaves': 170, 'learning_rate': 0.10051740931781462, 'feature_fraction': 0.4831299589217466, 'bagging_fraction': 0.5743822705930252, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,698] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 49, 'learning_rate': 0.17182314683192718, 'feature_fraction': 0.5632872804525477, 'bagging_fraction': 0.7058085208176137, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,742] Trial 31 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 66, 'learning_rate': 0.14179798371602934, 'feature_fraction': 0.4447592296768527, 'bagging_fraction': 0.9361584661323287, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,793] Trial 32 finished with value: 0.9450980392156864 and parameters: {'num_leaves': 95, 'learning_rate': 0.10187587003506343, 'feature_fraction': 0.4891348082786796, 'bagging_fraction': 0.7652326268597709, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,837] Trial 33 finished with value: 0.9450980392156862 and parameters: {'num_leaves': 117, 'learning_rate': 0.15403707337773354, 'feature_fraction': 0.4482332440803016, 'bagging_fraction': 0.633842576074059, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,904] Trial 34 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 12, 'learning_rate': 0.08345044814883738, 'feature_fraction': 0.5065460047061751, 'bagging_fraction': 0.6889853955444671, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,921] Trial 35 finished with value: 0.5 and parameters: {'num_leaves': 80, 'learning_rate': 0.18366479335441258, 'feature_fraction': 0.5572816134129707, 'bagging_fraction': 0.4350164607539848, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:04,958] Trial 36 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 252, 'learning_rate': 0.20663050882886516, 'feature_fraction': 0.437828136039339, 'bagging_fraction': 0.5794279682174609, 'bagging_freq': 1, 'min_child_samples': 21}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:05,010] Trial 37 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 137, 'learning_rate': 0.14720199919039378, 'feature_fraction': 0.4918166927333402, 'bagging_fraction': 0.53846205286678, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:05,022] Trial 38 finished with value: 0.5 and parameters: {'num_leaves': 281, 'learning_rate': 0.17103815973815853, 'feature_fraction': 0.809946833676001, 'bagging_fraction': 0.6656935515531575, 'bagging_freq': 2, 'min_child_samples': 72}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:05,048] Trial 39 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 58, 'learning_rate': 0.1144179904672003, 'feature_fraction': 0.43176421586620795, 'bagging_fraction': 0.9443045724322133, 'bagging_freq': 2, 'min_child_samples': 43}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:05,106] Trial 40 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 34, 'learning_rate': 0.2268811390114107, 'feature_fraction': 0.994996160324979, 'bagging_fraction': 0.8302632095829802, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 27 with value: 0.9647058823529412.
[I 2025-09-17 13:20:05,168] Trial 41 finished with value: 0.9686274509803922 and parameters: {'num_leaves': 113, 'learning_rate': 0.197072619485758, 'feature_fraction': 0.6377237349469083, 'bagging_fraction': 0.6083245410379622, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 41 with value: 0.9686274509803922.
[I 2025-09-17 13:20:05,206] Trial 42 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 111, 'learning_rate': 0.20284142140779973, 'feature_fraction': 0.7761510040422063, 'bagging_fraction': 0.623372814483433, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 41 with value: 0.9686274509803922.
[I 2025-09-17 13:20:05,301] Trial 43 finished with value: 0.9215686274509804 and parameters: {'num_leaves': 133, 'learning_rate': 0.23774520103582264, 'feature_fraction': 0.697926214816627, 'bagging_fraction': 0.6100108945649809, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 41 with value: 0.9686274509803922.
[I 2025-09-17 13:20:05,342] Trial 44 finished with value: 0.9647058823529412 and parameters: {'num_leaves': 82, 'learning_rate': 0.16321994987793054, 'feature_fraction': 0.8616493480712935, 'bagging_fraction': 0.47545709465831665, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 41 with value: 0.9686274509803922.
[I 2025-09-17 13:20:05,387] Trial 45 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 105, 'learning_rate': 0.17493617194988728, 'feature_fraction': 0.9286041558489431, 'bagging_fraction': 0.46970957298520766, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 41 with value: 0.9686274509803922.
[I 2025-09-17 13:20:05,421] Trial 46 finished with value: 0.9450980392156862 and parameters: {'num_leaves': 87, 'learning_rate': 0.12172331775696163, 'feature_fraction': 0.8847959849461016, 'bagging_fraction': 0.5420741729226686, 'bagging_freq': 1, 'min_child_samples': 14}. Best is trial 41 with value: 0.9686274509803922.
[I 2025-09-17 13:20:05,486] Trial 47 finished with value: 0.9686274509803923 and parameters: {'num_leaves': 151, 'learning_rate': 0.21186589375186926, 'feature_fraction': 0.733233934737286, 'bagging_fraction': 0.456371054116056, 'bagging_freq': 2, 'min_child_samples': 8}. Best is trial 47 with value: 0.9686274509803923.
[I 2025-09-17 13:20:05,500] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 185, 'learning_rate': 0.19600527104156407, 'feature_fraction': 0.7474515232162533, 'bagging_fraction': 0.44684872145799026, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 47 with value: 0.9686274509803923.
[I 2025-09-17 13:20:05,530] Trial 49 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 152, 'learning_rate': 0.21284721945685114, 'feature_fraction': 0.8675211739862568, 'bagging_fraction': 0.40106366524220766, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 47 with value: 0.9686274509803923.
[I 2025-09-17 13:20:05,745] A new study created in memory with name: no-name-fb1fb4a7-42aa-4be0-98d1-48dcc43edc11
[I 2025-09-17 13:20:05,846] Trial 0 finished with value: 0.9490196078431373 and parameters: {'num_leaves': 136, 'learning_rate': 0.22332307019722467, 'feature_fraction': 0.823635831525953, 'bagging_fraction': 0.8485199249699726, 'bagging_freq': 2, 'min_child_samples': 6}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:05,853] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 139, 'learning_rate': 0.15237391639547174, 'feature_fraction': 0.41713716977808646, 'bagging_fraction': 0.6743537263925083, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:05,861] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 299, 'learning_rate': 0.26026573859289376, 'feature_fraction': 0.8943956563606668, 'bagging_fraction': 0.734474994400216, 'bagging_freq': 4, 'min_child_samples': 65}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:05,942] Trial 3 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 97, 'learning_rate': 0.0797810396939278, 'feature_fraction': 0.9001870180892365, 'bagging_fraction': 0.7421377904882647, 'bagging_freq': 1, 'min_child_samples': 9}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:05,950] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 204, 'learning_rate': 0.0590898280464219, 'feature_fraction': 0.6594487895917076, 'bagging_fraction': 0.8314272279545452, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:05,958] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 285, 'learning_rate': 0.154263955098876, 'feature_fraction': 0.8316635259047435, 'bagging_fraction': 0.5509429518575405, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:05,966] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 260, 'learning_rate': 0.19311984573573268, 'feature_fraction': 0.7519420609749254, 'bagging_fraction': 0.4486567657812788, 'bagging_freq': 2, 'min_child_samples': 37}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:05,993] Trial 7 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 195, 'learning_rate': 0.2451813668600285, 'feature_fraction': 0.8387717679127153, 'bagging_fraction': 0.6174911864877517, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:06,025] Trial 8 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 299, 'learning_rate': 0.2647504676147874, 'feature_fraction': 0.7233006857608353, 'bagging_fraction': 0.8602184458712796, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:06,047] Trial 9 finished with value: 0.9176470588235295 and parameters: {'num_leaves': 57, 'learning_rate': 0.2668778411850401, 'feature_fraction': 0.43776828662492945, 'bagging_fraction': 0.7883392634341623, 'bagging_freq': 2, 'min_child_samples': 49}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:06,058] Trial 10 finished with value: 0.5 and parameters: {'num_leaves': 20, 'learning_rate': 0.19462152772194494, 'feature_fraction': 0.9873690149317261, 'bagging_fraction': 0.9697532039374637, 'bagging_freq': 7, 'min_child_samples': 90}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:06,123] Trial 11 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 173, 'learning_rate': 0.2110878674800445, 'feature_fraction': 0.5821678034873573, 'bagging_fraction': 0.6075581735745482, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 0 with value: 0.9490196078431373.
[I 2025-09-17 13:20:06,249] Trial 12 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 138, 'learning_rate': 0.209484511785573, 'feature_fraction': 0.595048291853706, 'bagging_fraction': 0.9538286819278307, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,291] Trial 13 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 130, 'learning_rate': 0.11981384263243303, 'feature_fraction': 0.5612722979538868, 'bagging_fraction': 0.9788943022444363, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,411] Trial 14 finished with value: 0.9176470588235295 and parameters: {'num_leaves': 95, 'learning_rate': 0.22237270405689144, 'feature_fraction': 0.6092531605868307, 'bagging_fraction': 0.9192105336002911, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,463] Trial 15 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 228, 'learning_rate': 0.11943908075596513, 'feature_fraction': 0.5203134968449696, 'bagging_fraction': 0.8751100909708148, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,492] Trial 16 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 100, 'learning_rate': 0.29891187339363057, 'feature_fraction': 0.777936322004625, 'bagging_fraction': 0.9317027766968485, 'bagging_freq': 2, 'min_child_samples': 37}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,504] Trial 17 finished with value: 0.5 and parameters: {'num_leaves': 157, 'learning_rate': 0.016696972007781308, 'feature_fraction': 0.6797554045000741, 'bagging_fraction': 0.8057717323488354, 'bagging_freq': 1, 'min_child_samples': 62}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,555] Trial 18 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 57, 'learning_rate': 0.17437449179931538, 'feature_fraction': 0.5110237786783818, 'bagging_fraction': 0.9014268169008793, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,591] Trial 19 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 120, 'learning_rate': 0.22369845198093968, 'feature_fraction': 0.6490415115211848, 'bagging_fraction': 0.9770953179138118, 'bagging_freq': 2, 'min_child_samples': 30}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,603] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 179, 'learning_rate': 0.29541159800816186, 'feature_fraction': 0.9994517239255607, 'bagging_fraction': 0.40778019382446795, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,663] Trial 21 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 166, 'learning_rate': 0.21632183130481517, 'feature_fraction': 0.592494997328008, 'bagging_fraction': 0.5721834370401517, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,764] Trial 22 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 225, 'learning_rate': 0.193300784543256, 'feature_fraction': 0.4864350968432969, 'bagging_fraction': 0.6530546029800738, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,790] Trial 23 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 145, 'learning_rate': 0.24237858786525757, 'feature_fraction': 0.6130824729703512, 'bagging_fraction': 0.5234093661772765, 'bagging_freq': 1, 'min_child_samples': 19}. Best is trial 12 with value: 0.9568627450980393.
[I 2025-09-17 13:20:06,950] Trial 24 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 190, 'learning_rate': 0.1740565961978599, 'feature_fraction': 0.5565783282070799, 'bagging_fraction': 0.7478451777073206, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,096] Trial 25 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 219, 'learning_rate': 0.11761533379663416, 'feature_fraction': 0.7933704409075161, 'bagging_fraction': 0.7589970076493365, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,138] Trial 26 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 117, 'learning_rate': 0.17329030935231954, 'feature_fraction': 0.48120284458424645, 'bagging_fraction': 0.8395623215240557, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,167] Trial 27 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 68, 'learning_rate': 0.17325130772338962, 'feature_fraction': 0.7117987631011885, 'bagging_fraction': 0.7120849388666, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,238] Trial 28 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 252, 'learning_rate': 0.14838766686467858, 'feature_fraction': 0.5519537338626105, 'bagging_fraction': 0.7927710893904678, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,250] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 145, 'learning_rate': 0.1385121384527686, 'feature_fraction': 0.40593626945216976, 'bagging_fraction': 0.6956844935738856, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,274] Trial 30 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 189, 'learning_rate': 0.20430096361236688, 'feature_fraction': 0.9189215703733441, 'bagging_fraction': 0.8945395452037566, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,343] Trial 31 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 170, 'learning_rate': 0.23109528702080756, 'feature_fraction': 0.5620432566964035, 'bagging_fraction': 0.6543907176826818, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 24 with value: 0.9803921568627452.
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.276204
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.254826
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.334123
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[43]	valid_0's binary_logloss: 0.210358
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.232505
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.259618
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.275369
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.261848
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.277327
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.27092
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.252894
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.303576
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.364108
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[17]	valid_0's binary_logloss: 0.344357
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	valid_0's binary_logloss: 0.207934
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.285775
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[23]	valid_0's binary_logloss: 0.312395
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[21]	valid_0's binary_logloss: 0.262873
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[22]	valid_0's binary_logloss: 0.256157
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.277824
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.20036
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.280901
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[41]	valid_0's binary_logloss: 0.281658
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[3]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.290764
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[73]	valid_0's binary_logloss: 0.289115
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.258335
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.362817
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[67]	valid_0's binary_logloss: 0.245124
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[28]	valid_0's binary_logloss: 0.259277
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.274059
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[13]	valid_0's binary_logloss: 0.312644
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.260687
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.285622
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[4]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.289062
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.285126
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.277672
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.292347
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[24]	valid_0's binary_logloss: 0.320711
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.204869
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.256061
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.32693
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[35]	valid_0's binary_logloss: 0.31266
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[48]	valid_0's binary_logloss: 0.223661
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.295834
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.289229
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:20:07,413] Trial 32 finished with value: 0.9490196078431373 and parameters: {'num_leaves': 158, 'learning_rate': 0.20586938925535436, 'feature_fraction': 0.6180159927078746, 'bagging_fraction': 0.5984395871337097, 'bagging_freq': 1, 'min_child_samples': 10}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,473] Trial 33 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 135, 'learning_rate': 0.1760569205022063, 'feature_fraction': 0.6401236369632072, 'bagging_fraction': 0.4926064374598821, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,579] Trial 34 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 208, 'learning_rate': 0.2478734869336411, 'feature_fraction': 0.6252391584248588, 'bagging_fraction': 0.7555383238376725, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,619] Trial 35 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 105, 'learning_rate': 0.2807726857956836, 'feature_fraction': 0.6727276374689148, 'bagging_fraction': 0.9345232963697877, 'bagging_freq': 2, 'min_child_samples': 19}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,672] Trial 36 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 79, 'learning_rate': 0.09659048600831334, 'feature_fraction': 0.8574742956853735, 'bagging_fraction': 0.7147376461357265, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,722] Trial 37 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 152, 'learning_rate': 0.1615936495631513, 'feature_fraction': 0.452508456447232, 'bagging_fraction': 0.8335936108078508, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,795] Trial 38 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 186, 'learning_rate': 0.20221843383742785, 'feature_fraction': 0.5301863067543816, 'bagging_fraction': 0.6094358529737782, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,819] Trial 39 finished with value: 0.8431372549019608 and parameters: {'num_leaves': 189, 'learning_rate': 0.23858434476982612, 'feature_fraction': 0.5330483872674252, 'bagging_fraction': 0.6597074176562733, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,839] Trial 40 finished with value: 0.7019607843137254 and parameters: {'num_leaves': 249, 'learning_rate': 0.18548294279433455, 'feature_fraction': 0.9371001983058891, 'bagging_fraction': 0.8602363901667607, 'bagging_freq': 6, 'min_child_samples': 58}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,918] Trial 41 finished with value: 0.9647058823529413 and parameters: {'num_leaves': 204, 'learning_rate': 0.2027240274193117, 'feature_fraction': 0.584707914564463, 'bagging_fraction': 0.6055064506287707, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:07,945] Trial 42 finished with value: 0.9215686274509804 and parameters: {'num_leaves': 200, 'learning_rate': 0.25589402540161166, 'feature_fraction': 0.4803986782014003, 'bagging_fraction': 0.5537675968023963, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:08,018] Trial 43 finished with value: 0.9450980392156864 and parameters: {'num_leaves': 214, 'learning_rate': 0.19978115906409902, 'feature_fraction': 0.7415529343890572, 'bagging_fraction': 0.6281129418087676, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:08,132] Trial 44 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 237, 'learning_rate': 0.15733976996124704, 'feature_fraction': 0.576387376309764, 'bagging_fraction': 0.998583322204862, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:08,169] Trial 45 finished with value: 0.9176470588235295 and parameters: {'num_leaves': 181, 'learning_rate': 0.18558718582778916, 'feature_fraction': 0.5381884896846614, 'bagging_fraction': 0.5194764246498476, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:08,201] Trial 46 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 127, 'learning_rate': 0.21682382747537218, 'feature_fraction': 0.6922027040774024, 'bagging_fraction': 0.6913176740627615, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:08,213] Trial 47 finished with value: 0.5 and parameters: {'num_leaves': 270, 'learning_rate': 0.1380536354077172, 'feature_fraction': 0.44639974406204896, 'bagging_fraction': 0.7731335479693612, 'bagging_freq': 6, 'min_child_samples': 82}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:08,225] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 194, 'learning_rate': 0.23013481755908, 'feature_fraction': 0.5873470302026241, 'bagging_fraction': 0.5849633798950443, 'bagging_freq': 3, 'min_child_samples': 52}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:08,285] Trial 49 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 161, 'learning_rate': 0.27600036077641976, 'feature_fraction': 0.5055331517738405, 'bagging_fraction': 0.7351319636038205, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 24 with value: 0.9803921568627452.
[I 2025-09-17 13:20:08,632] A new study created in memory with name: no-name-d8fdd781-93f0-47a2-85c2-1f6241927263
[I 2025-09-17 13:20:08,699] Trial 0 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 217, 'learning_rate': 0.18125661049514116, 'feature_fraction': 0.7852285040797669, 'bagging_fraction': 0.7279998485789092, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 0 with value: 0.9254901960784314.
[I 2025-09-17 13:20:08,731] Trial 1 finished with value: 0.9490196078431372 and parameters: {'num_leaves': 134, 'learning_rate': 0.19719339620996573, 'feature_fraction': 0.8074251731505251, 'bagging_fraction': 0.5230374567762901, 'bagging_freq': 7, 'min_child_samples': 18}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,736] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 14, 'learning_rate': 0.24728996566734915, 'feature_fraction': 0.40128361956358793, 'bagging_fraction': 0.9807271018226917, 'bagging_freq': 2, 'min_child_samples': 83}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,744] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 223, 'learning_rate': 0.2713332619430378, 'feature_fraction': 0.8998069078790427, 'bagging_fraction': 0.8681032994964599, 'bagging_freq': 2, 'min_child_samples': 86}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,751] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 276, 'learning_rate': 0.1799622157292875, 'feature_fraction': 0.7158866915872831, 'bagging_fraction': 0.41237504846849593, 'bagging_freq': 3, 'min_child_samples': 94}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,759] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 231, 'learning_rate': 0.09708164811285896, 'feature_fraction': 0.5751251879005745, 'bagging_fraction': 0.8848121036021743, 'bagging_freq': 4, 'min_child_samples': 74}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,766] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 261, 'learning_rate': 0.17082238331728916, 'feature_fraction': 0.8948166185226112, 'bagging_fraction': 0.7336771807179701, 'bagging_freq': 6, 'min_child_samples': 65}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,773] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.03527593343251428, 'feature_fraction': 0.6246161705707112, 'bagging_fraction': 0.6463480357569591, 'bagging_freq': 7, 'min_child_samples': 87}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,780] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 268, 'learning_rate': 0.23810294303975643, 'feature_fraction': 0.545870924378782, 'bagging_fraction': 0.8195534802035713, 'bagging_freq': 6, 'min_child_samples': 80}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,786] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 206, 'learning_rate': 0.057493087962156526, 'feature_fraction': 0.5407379866877116, 'bagging_fraction': 0.6591908965453877, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,808] Trial 10 finished with value: 0.8352941176470589 and parameters: {'num_leaves': 101, 'learning_rate': 0.11486734011557924, 'feature_fraction': 0.9599684405784413, 'bagging_fraction': 0.448042417467463, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,888] Trial 11 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 130, 'learning_rate': 0.20533065057243513, 'feature_fraction': 0.77419519804184, 'bagging_fraction': 0.5668862457990695, 'bagging_freq': 5, 'min_child_samples': 6}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:08,910] Trial 12 finished with value: 0.8274509803921568 and parameters: {'num_leaves': 162, 'learning_rate': 0.12843763565791466, 'feature_fraction': 0.8005851610021877, 'bagging_fraction': 0.5327922271787575, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:09,000] Trial 13 finished with value: 0.8470588235294118 and parameters: {'num_leaves': 69, 'learning_rate': 0.2086085771372351, 'feature_fraction': 0.816407070093209, 'bagging_fraction': 0.717138460560524, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:09,023] Trial 14 finished with value: 0.6784313725490196 and parameters: {'num_leaves': 166, 'learning_rate': 0.1419502376443109, 'feature_fraction': 0.6941185080004796, 'bagging_fraction': 0.5468812638830624, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:09,056] Trial 15 finished with value: 0.9058823529411766 and parameters: {'num_leaves': 130, 'learning_rate': 0.1986164810693424, 'feature_fraction': 0.8987419710701515, 'bagging_fraction': 0.776540240368076, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:09,068] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 67, 'learning_rate': 0.2916263007474351, 'feature_fraction': 0.9996701120368279, 'bagging_fraction': 0.6148733690617079, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 1 with value: 0.9490196078431372.
[I 2025-09-17 13:20:09,110] Trial 17 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 179, 'learning_rate': 0.15740590045594383, 'feature_fraction': 0.7020005798716877, 'bagging_fraction': 0.4648624771865457, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 17 with value: 0.9529411764705883.
[I 2025-09-17 13:20:09,124] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 184, 'learning_rate': 0.14673319827559048, 'feature_fraction': 0.6679482768356948, 'bagging_fraction': 0.4683589509882804, 'bagging_freq': 1, 'min_child_samples': 58}. Best is trial 17 with value: 0.9529411764705883.
[I 2025-09-17 13:20:09,150] Trial 19 finished with value: 0.9450980392156862 and parameters: {'num_leaves': 127, 'learning_rate': 0.08261121543171412, 'feature_fraction': 0.7396623419989792, 'bagging_fraction': 0.4943460438814207, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 17 with value: 0.9529411764705883.
[I 2025-09-17 13:20:09,163] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 87, 'learning_rate': 0.22766196007263081, 'feature_fraction': 0.45385351850846944, 'bagging_fraction': 0.41702210255434013, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 17 with value: 0.9529411764705883.
[I 2025-09-17 13:20:09,195] Trial 21 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 126, 'learning_rate': 0.08508632031870138, 'feature_fraction': 0.7365524646772366, 'bagging_fraction': 0.48595654055165244, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 17 with value: 0.9529411764705883.
[I 2025-09-17 13:20:09,223] Trial 22 finished with value: 0.884313725490196 and parameters: {'num_leaves': 143, 'learning_rate': 0.01749102940268485, 'feature_fraction': 0.8523148754240281, 'bagging_fraction': 0.5052329462564986, 'bagging_freq': 7, 'min_child_samples': 27}. Best is trial 17 with value: 0.9529411764705883.
[I 2025-09-17 13:20:09,260] Trial 23 finished with value: 0.9411764705882354 and parameters: {'num_leaves': 171, 'learning_rate': 0.08001938584245122, 'feature_fraction': 0.6416548358697818, 'bagging_fraction': 0.5907430908691333, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 17 with value: 0.9529411764705883.
[I 2025-09-17 13:20:09,301] Trial 24 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 106, 'learning_rate': 0.10755507519788352, 'feature_fraction': 0.7475594644908703, 'bagging_fraction': 0.5202274503990619, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,356] Trial 25 finished with value: 0.9490196078431373 and parameters: {'num_leaves': 35, 'learning_rate': 0.16148102290450722, 'feature_fraction': 0.6031765469001706, 'bagging_fraction': 0.5364818775063733, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,418] Trial 26 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 15, 'learning_rate': 0.11492302621068098, 'feature_fraction': 0.6002253564676424, 'bagging_fraction': 0.6139432498392644, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,443] Trial 27 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 40, 'learning_rate': 0.1596312494644765, 'feature_fraction': 0.6565219366035667, 'bagging_fraction': 0.6635635393533124, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,469] Trial 28 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 45, 'learning_rate': 0.12361208632980714, 'feature_fraction': 0.6759827577300075, 'bagging_fraction': 0.6624242608453883, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,482] Trial 29 finished with value: 0.5 and parameters: {'num_leaves': 105, 'learning_rate': 0.1527343295228693, 'feature_fraction': 0.5009519579658953, 'bagging_fraction': 0.4378167807870271, 'bagging_freq': 1, 'min_child_samples': 49}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,502] Trial 30 finished with value: 0.6549019607843137 and parameters: {'num_leaves': 56, 'learning_rate': 0.10458845647018983, 'feature_fraction': 0.6601623526981031, 'bagging_fraction': 0.5792764172839178, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,551] Trial 31 finished with value: 0.9490196078431373 and parameters: {'num_leaves': 40, 'learning_rate': 0.16923973570064238, 'feature_fraction': 0.7449781000133355, 'bagging_fraction': 0.47513558766019587, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,599] Trial 32 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 39, 'learning_rate': 0.1629423915509723, 'feature_fraction': 0.6137604422940774, 'bagging_fraction': 0.5360018929447332, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,648] Trial 33 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 88, 'learning_rate': 0.13545007645277993, 'feature_fraction': 0.6929813550075867, 'bagging_fraction': 0.5201238960841117, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,676] Trial 34 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 18, 'learning_rate': 0.19038606003105227, 'feature_fraction': 0.7633199594375535, 'bagging_fraction': 0.6784240533427757, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,718] Trial 35 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 107, 'learning_rate': 0.17983506043617628, 'feature_fraction': 0.7127472383206095, 'bagging_fraction': 0.6022971894554958, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,828] Trial 36 finished with value: 0.9176470588235294 and parameters: {'num_leaves': 78, 'learning_rate': 0.2211087859255871, 'feature_fraction': 0.6316258951179141, 'bagging_fraction': 0.9692623714915121, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,848] Trial 37 finished with value: 0.8490196078431372 and parameters: {'num_leaves': 243, 'learning_rate': 0.2541140399586118, 'feature_fraction': 0.8328474132737677, 'bagging_fraction': 0.4059206228975828, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,870] Trial 38 finished with value: 0.5764705882352941 and parameters: {'num_leaves': 298, 'learning_rate': 0.1591660403420079, 'feature_fraction': 0.5834012146500223, 'bagging_fraction': 0.4512532985668503, 'bagging_freq': 3, 'min_child_samples': 33}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,897] Trial 39 finished with value: 0.8156862745098039 and parameters: {'num_leaves': 34, 'learning_rate': 0.05702231367661442, 'feature_fraction': 0.5538332993368871, 'bagging_fraction': 0.7557041761434953, 'bagging_freq': 2, 'min_child_samples': 44}. Best is trial 24 with value: 0.9568627450980393.
Early stopping, best iteration is:
[44]	valid_0's binary_logloss: 0.260893
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.310937
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[25]	valid_0's binary_logloss: 0.260247
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[20]	valid_0's binary_logloss: 0.289984
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[59]	valid_0's binary_logloss: 0.275749
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.309532
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[30]	valid_0's binary_logloss: 0.260551
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.449362
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[63]	valid_0's binary_logloss: 0.606915
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.238956
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.356323
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.25507
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.315235
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.335453
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[40]	valid_0's binary_logloss: 0.323232
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[10]	valid_0's binary_logloss: 0.291102
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.361524
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[50]	valid_0's binary_logloss: 0.315777
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[29]	valid_0's binary_logloss: 0.501875
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	valid_0's binary_logloss: 0.381872
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.506394
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[9]	valid_0's binary_logloss: 0.480004
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.5978
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[33]	valid_0's binary_logloss: 0.375718
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[45]	valid_0's binary_logloss: 0.330644
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[2]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[66]	valid_0's binary_logloss: 0.365009
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.354368
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.535732
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[79]	valid_0's binary_logloss: 0.317649
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.2959
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.329738
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.334542
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.336702
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[55]	valid_0's binary_logloss: 0.375922
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.62262
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[74]	valid_0's binary_logloss: 0.296899
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.277098
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.36464
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[68]	valid_0's binary_logloss: 0.333479
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	valid_0's binary_logloss: 0.317762
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[14]	valid_0's binary_logloss: 0.377064
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[16]	valid_0's binary_logloss: 0.485445
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[69]	valid_0's binary_logloss: 0.679711
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.557323
Training until validation scores don't improve for 50 rounds
[I 2025-09-17 13:20:09,932] Trial 40 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 186, 'learning_rate': 0.17736494035590408, 'feature_fraction': 0.5174777958142897, 'bagging_fraction': 0.6249998841382223, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 24 with value: 0.9568627450980393.
[I 2025-09-17 13:20:09,971] Trial 41 finished with value: 0.9647058823529413 and parameters: {'num_leaves': 181, 'learning_rate': 0.1884811359679317, 'feature_fraction': 0.4742569460676646, 'bagging_fraction': 0.6369439842010425, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,014] Trial 42 finished with value: 0.9294117647058824 and parameters: {'num_leaves': 187, 'learning_rate': 0.184292624489555, 'feature_fraction': 0.45428746477529186, 'bagging_fraction': 0.6973588119469641, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,045] Trial 43 finished with value: 0.9333333333333333 and parameters: {'num_leaves': 197, 'learning_rate': 0.1774079180527516, 'feature_fraction': 0.42677366362548586, 'bagging_fraction': 0.6372496197434284, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,058] Trial 44 finished with value: 0.5 and parameters: {'num_leaves': 150, 'learning_rate': 0.2185732686137907, 'feature_fraction': 0.44054710666008257, 'bagging_fraction': 0.6318512558605273, 'bagging_freq': 6, 'min_child_samples': 56}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,079] Trial 45 finished with value: 0.6392156862745098 and parameters: {'num_leaves': 222, 'learning_rate': 0.15138231324462878, 'feature_fraction': 0.496975411264756, 'bagging_fraction': 0.5678941956509911, 'bagging_freq': 7, 'min_child_samples': 42}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,177] Trial 46 finished with value: 0.9215686274509804 and parameters: {'num_leaves': 175, 'learning_rate': 0.19145722715153551, 'feature_fraction': 0.48546144466111985, 'bagging_fraction': 0.6978174713506026, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,204] Trial 47 finished with value: 0.9137254901960785 and parameters: {'num_leaves': 239, 'learning_rate': 0.13406031385581793, 'feature_fraction': 0.4016695406850941, 'bagging_fraction': 0.7889991784313924, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,219] Trial 48 finished with value: 0.5 and parameters: {'num_leaves': 207, 'learning_rate': 0.20757943133410023, 'feature_fraction': 0.5373660668254518, 'bagging_fraction': 0.7345277827310996, 'bagging_freq': 5, 'min_child_samples': 71}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,252] Trial 49 finished with value: 0.9254901960784314 and parameters: {'num_leaves': 157, 'learning_rate': 0.24860705641237468, 'feature_fraction': 0.8551521069391537, 'bagging_fraction': 0.6768031647292755, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 41 with value: 0.9647058823529413.
[I 2025-09-17 13:20:10,427] A new study created in memory with name: no-name-78d423ea-c89b-41d6-92d3-471b967e2352
[I 2025-09-17 13:20:10,435] Trial 0 finished with value: 0.5 and parameters: {'num_leaves': 29, 'learning_rate': 0.037207778623040096, 'feature_fraction': 0.44735348817948944, 'bagging_fraction': 0.517500216659023, 'bagging_freq': 5, 'min_child_samples': 65}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:20:10,443] Trial 1 finished with value: 0.5 and parameters: {'num_leaves': 14, 'learning_rate': 0.25174031164764704, 'feature_fraction': 0.8148424934011469, 'bagging_fraction': 0.5558189292025505, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:20:10,449] Trial 2 finished with value: 0.5 and parameters: {'num_leaves': 126, 'learning_rate': 0.16289615773220176, 'feature_fraction': 0.7259823332880155, 'bagging_fraction': 0.5416746551144356, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 0 with value: 0.5.
[I 2025-09-17 13:20:10,501] Trial 3 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 209, 'learning_rate': 0.24833758972202483, 'feature_fraction': 0.9409718550081771, 'bagging_fraction': 0.9629556685058814, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 3 with value: 0.9882352941176471.
[I 2025-09-17 13:20:10,509] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 235, 'learning_rate': 0.0854764970837925, 'feature_fraction': 0.9667955231146866, 'bagging_fraction': 0.4805699367037757, 'bagging_freq': 7, 'min_child_samples': 95}. Best is trial 3 with value: 0.9882352941176471.
[I 2025-09-17 13:20:10,516] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 108, 'learning_rate': 0.26382848429313926, 'feature_fraction': 0.44185002485857083, 'bagging_fraction': 0.665867272490853, 'bagging_freq': 2, 'min_child_samples': 79}. Best is trial 3 with value: 0.9882352941176471.
[I 2025-09-17 13:20:10,543] Trial 6 finished with value: 0.996078431372549 and parameters: {'num_leaves': 202, 'learning_rate': 0.1639822675584299, 'feature_fraction': 0.8941109539307981, 'bagging_fraction': 0.8278436495953511, 'bagging_freq': 1, 'min_child_samples': 30}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,551] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 124, 'learning_rate': 0.2804116122951709, 'feature_fraction': 0.5928765100490523, 'bagging_fraction': 0.9357424605278652, 'bagging_freq': 6, 'min_child_samples': 83}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,580] Trial 8 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 50, 'learning_rate': 0.2406646359302171, 'feature_fraction': 0.77257933081608, 'bagging_fraction': 0.9920847109925673, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,590] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 135, 'learning_rate': 0.24537329727384163, 'feature_fraction': 0.6119057808361797, 'bagging_fraction': 0.5113868907207028, 'bagging_freq': 6, 'min_child_samples': 87}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,707] Trial 10 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 291, 'learning_rate': 0.15088678462989027, 'feature_fraction': 0.868817599853687, 'bagging_fraction': 0.8056364493429168, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,774] Trial 11 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 222, 'learning_rate': 0.1776630299193592, 'feature_fraction': 0.9944753782849056, 'bagging_fraction': 0.8527039783051623, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,812] Trial 12 finished with value: 0.996078431372549 and parameters: {'num_leaves': 196, 'learning_rate': 0.19640585631344082, 'feature_fraction': 0.8978137907030275, 'bagging_fraction': 0.8190483560756242, 'bagging_freq': 3, 'min_child_samples': 25}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,841] Trial 13 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 177, 'learning_rate': 0.1977197262043312, 'feature_fraction': 0.8679345545967371, 'bagging_fraction': 0.7556376190924624, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,874] Trial 14 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 275, 'learning_rate': 0.12184924549866906, 'feature_fraction': 0.8881338781828494, 'bagging_fraction': 0.6627368206143064, 'bagging_freq': 2, 'min_child_samples': 26}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,890] Trial 15 finished with value: 0.5 and parameters: {'num_leaves': 183, 'learning_rate': 0.20421057251309638, 'feature_fraction': 0.6512209117679796, 'bagging_fraction': 0.8617174240549614, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,930] Trial 16 finished with value: 0.996078431372549 and parameters: {'num_leaves': 246, 'learning_rate': 0.10340691565978323, 'feature_fraction': 0.7801532640547356, 'bagging_fraction': 0.7390164128805492, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,957] Trial 17 finished with value: 0.9941176470588236 and parameters: {'num_leaves': 171, 'learning_rate': 0.13838493774222121, 'feature_fraction': 0.903571965078577, 'bagging_fraction': 0.8877008067341681, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:10,970] Trial 18 finished with value: 0.5 and parameters: {'num_leaves': 69, 'learning_rate': 0.06878943368499904, 'feature_fraction': 0.5210173677335661, 'bagging_fraction': 0.6112723742197184, 'bagging_freq': 2, 'min_child_samples': 55}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:11,005] Trial 19 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 255, 'learning_rate': 0.2117095235219491, 'feature_fraction': 0.8226799127256101, 'bagging_fraction': 0.7833004794847831, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:11,017] Trial 20 finished with value: 0.5 and parameters: {'num_leaves': 191, 'learning_rate': 0.17875374389405047, 'feature_fraction': 0.7169817198874202, 'bagging_fraction': 0.41382464328545115, 'bagging_freq': 4, 'min_child_samples': 40}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:11,056] Trial 21 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 240, 'learning_rate': 0.10781976211575675, 'feature_fraction': 0.7911753846972412, 'bagging_fraction': 0.7400826096005865, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:11,100] Trial 22 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 210, 'learning_rate': 0.011809803687239676, 'feature_fraction': 0.923715378248721, 'bagging_fraction': 0.7017365778748937, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:11,281] Trial 23 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 255, 'learning_rate': 0.09321119693248006, 'feature_fraction': 0.8471623619884735, 'bagging_fraction': 0.8864471902463974, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 6 with value: 0.996078431372549.
[I 2025-09-17 13:20:11,312] Trial 24 finished with value: 1.0 and parameters: {'num_leaves': 206, 'learning_rate': 0.12813500241055467, 'feature_fraction': 0.7616273459570239, 'bagging_fraction': 0.8293931762916077, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,339] Trial 25 finished with value: 1.0 and parameters: {'num_leaves': 151, 'learning_rate': 0.13405562681485117, 'feature_fraction': 0.7466071893207782, 'bagging_fraction': 0.8271896067622091, 'bagging_freq': 2, 'min_child_samples': 33}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,373] Trial 26 finished with value: 0.996078431372549 and parameters: {'num_leaves': 164, 'learning_rate': 0.13768029342327473, 'feature_fraction': 0.6548015681752205, 'bagging_fraction': 0.9021847360604179, 'bagging_freq': 1, 'min_child_samples': 34}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,399] Trial 27 finished with value: 0.7607843137254902 and parameters: {'num_leaves': 93, 'learning_rate': 0.07513858157077327, 'feature_fraction': 0.7544463272956179, 'bagging_fraction': 0.8280967983067815, 'bagging_freq': 2, 'min_child_samples': 50}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,426] Trial 28 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 149, 'learning_rate': 0.13370195604759477, 'feature_fraction': 0.680150628518107, 'bagging_fraction': 0.7745668233249322, 'bagging_freq': 1, 'min_child_samples': 39}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,451] Trial 29 finished with value: 0.7980392156862745 and parameters: {'num_leaves': 143, 'learning_rate': 0.06246539366990289, 'feature_fraction': 0.49636172211275376, 'bagging_fraction': 0.9264993299243508, 'bagging_freq': 2, 'min_child_samples': 56}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,460] Trial 30 finished with value: 0.5 and parameters: {'num_leaves': 158, 'learning_rate': 0.04495924683181643, 'feature_fraction': 0.7460044030782675, 'bagging_fraction': 0.8462488772822053, 'bagging_freq': 1, 'min_child_samples': 71}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,494] Trial 31 finished with value: 1.0 and parameters: {'num_leaves': 201, 'learning_rate': 0.16662592720388486, 'feature_fraction': 0.8226149050164328, 'bagging_fraction': 0.8244743551684978, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,521] Trial 32 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 216, 'learning_rate': 0.16106143017617414, 'feature_fraction': 0.8278427472457729, 'bagging_fraction': 0.7139321122792402, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,545] Trial 33 finished with value: 0.8784313725490196 and parameters: {'num_leaves': 198, 'learning_rate': 0.11824422480298438, 'feature_fraction': 0.8114398826222209, 'bagging_fraction': 0.7991090022296663, 'bagging_freq': 3, 'min_child_samples': 45}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,574] Trial 34 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 229, 'learning_rate': 0.17481073019565324, 'feature_fraction': 0.708722812845482, 'bagging_fraction': 0.6595576855765246, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,600] Trial 35 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 113, 'learning_rate': 0.22586076052154788, 'feature_fraction': 0.9444120937012923, 'bagging_fraction': 0.9386580112301702, 'bagging_freq': 2, 'min_child_samples': 45}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,633] Trial 36 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 204, 'learning_rate': 0.15466280439002858, 'feature_fraction': 0.7378129753700422, 'bagging_fraction': 0.8732465154724471, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,686] Trial 37 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 181, 'learning_rate': 0.1865384629366012, 'feature_fraction': 0.8499957269002967, 'bagging_fraction': 0.830694433481105, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,710] Trial 38 finished with value: 0.9117647058823529 and parameters: {'num_leaves': 157, 'learning_rate': 0.14549382608568917, 'feature_fraction': 0.795063930149552, 'bagging_fraction': 0.9966216363740884, 'bagging_freq': 1, 'min_child_samples': 50}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,722] Trial 39 finished with value: 0.5 and parameters: {'num_leaves': 269, 'learning_rate': 0.2980223039681493, 'feature_fraction': 0.6850948095831421, 'bagging_fraction': 0.7700472363773971, 'bagging_freq': 2, 'min_child_samples': 63}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,795] Trial 40 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 101, 'learning_rate': 0.12265987917011366, 'feature_fraction': 0.6278615991505664, 'bagging_fraction': 0.6061943219729066, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,831] Trial 41 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 192, 'learning_rate': 0.22440239928367492, 'feature_fraction': 0.9235750705892268, 'bagging_fraction': 0.8139841138671805, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,875] Trial 42 finished with value: 0.996078431372549 and parameters: {'num_leaves': 224, 'learning_rate': 0.16468202042196176, 'feature_fraction': 0.9752762102168617, 'bagging_fraction': 0.9218506756418707, 'bagging_freq': 3, 'min_child_samples': 21}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,908] Trial 43 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 205, 'learning_rate': 0.18476759561641976, 'feature_fraction': 0.8872572073237427, 'bagging_fraction': 0.968979597204291, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,935] Trial 44 finished with value: 0.9058823529411765 and parameters: {'num_leaves': 131, 'learning_rate': 0.1983269634496574, 'feature_fraction': 0.7680029118280796, 'bagging_fraction': 0.7998686612777284, 'bagging_freq': 3, 'min_child_samples': 43}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:11,974] Trial 45 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 172, 'learning_rate': 0.15512043347404889, 'feature_fraction': 0.869641989556782, 'bagging_fraction': 0.8567030900466408, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:12,039] Trial 46 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 216, 'learning_rate': 0.1287256042467542, 'feature_fraction': 0.8386392472090177, 'bagging_fraction': 0.7306641550038144, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 24 with value: 1.0.
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.280667
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[78]	valid_0's binary_logloss: 0.28374
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[56]	valid_0's binary_logloss: 0.297224
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[54]	valid_0's binary_logloss: 0.361198
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[60]	valid_0's binary_logloss: 0.651416
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[52]	valid_0's binary_logloss: 0.415497
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.379588
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691293
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[39]	valid_0's binary_logloss: 0.3158
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[27]	valid_0's binary_logloss: 0.143067
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.167724
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.196062
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.186143
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[47]	valid_0's binary_logloss: 0.175034
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.160059
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.223802
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.207154
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[90]	valid_0's binary_logloss: 0.18518
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.24856
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.184097
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.208255
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.421719
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[62]	valid_0's binary_logloss: 0.189718
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.211697
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.212836
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.188132
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.567754
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.286974
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.571532
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.153639
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.230692
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.464607
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.220446
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.315327
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.246827
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[86]	valid_0's binary_logloss: 0.157244
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.401646
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.186031
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[84]	valid_0's binary_logloss: 0.183469
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.147424
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[95]	valid_0's binary_logloss: 0.174301
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[94]	valid_0's binary_logloss: 0.385268
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[96]	valid_0's binary_logloss: 0.16723
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.176858
[I 2025-09-17 13:20:12,103] Trial 47 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 190, 'learning_rate': 0.10809447590128218, 'feature_fraction': 0.40029749718937924, 'bagging_fraction': 0.8306567399335281, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:12,140] Trial 48 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 168, 'learning_rate': 0.1639491000164555, 'feature_fraction': 0.9549263766813035, 'bagging_fraction': 0.904705369285893, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:12,180] Trial 49 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 143, 'learning_rate': 0.217841964956111, 'feature_fraction': 0.9030249841906308, 'bagging_fraction': 0.7587023988839604, 'bagging_freq': 3, 'min_child_samples': 26}. Best is trial 24 with value: 1.0.
[I 2025-09-17 13:20:12,490] A new study created in memory with name: no-name-5cd72f7c-5e28-4715-b9fd-d458bbbce06e
[I 2025-09-17 13:20:12,570] Trial 0 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 107, 'learning_rate': 0.08132425181189223, 'feature_fraction': 0.7278159240852404, 'bagging_fraction': 0.7443644333936487, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,631] Trial 1 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 222, 'learning_rate': 0.18567781373323514, 'feature_fraction': 0.4800659996036581, 'bagging_fraction': 0.9497626483040159, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,658] Trial 2 finished with value: 0.9568627450980393 and parameters: {'num_leaves': 162, 'learning_rate': 0.2970950310916555, 'feature_fraction': 0.7650218030432931, 'bagging_fraction': 0.7910669976798412, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,667] Trial 3 finished with value: 0.5 and parameters: {'num_leaves': 35, 'learning_rate': 0.10071122705326224, 'feature_fraction': 0.8623183693126643, 'bagging_fraction': 0.4977827296808919, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,675] Trial 4 finished with value: 0.5 and parameters: {'num_leaves': 88, 'learning_rate': 0.07884757430653193, 'feature_fraction': 0.61144843226345, 'bagging_fraction': 0.7344891660871606, 'bagging_freq': 2, 'min_child_samples': 94}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,684] Trial 5 finished with value: 0.5 and parameters: {'num_leaves': 244, 'learning_rate': 0.20193489600071937, 'feature_fraction': 0.8187875457088896, 'bagging_fraction': 0.4779597494031459, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,689] Trial 6 finished with value: 0.5 and parameters: {'num_leaves': 142, 'learning_rate': 0.18258889749544732, 'feature_fraction': 0.6563541473406964, 'bagging_fraction': 0.5257785844137873, 'bagging_freq': 1, 'min_child_samples': 69}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,694] Trial 7 finished with value: 0.5 and parameters: {'num_leaves': 82, 'learning_rate': 0.22086849958545088, 'feature_fraction': 0.5538178967650764, 'bagging_fraction': 0.9779452463999652, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,704] Trial 8 finished with value: 0.5 and parameters: {'num_leaves': 181, 'learning_rate': 0.0630955498733852, 'feature_fraction': 0.7566507311402024, 'bagging_fraction': 0.8805941595120312, 'bagging_freq': 7, 'min_child_samples': 100}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,713] Trial 9 finished with value: 0.5 and parameters: {'num_leaves': 132, 'learning_rate': 0.02988784132136721, 'feature_fraction': 0.8368260424948333, 'bagging_fraction': 0.7642991646586736, 'bagging_freq': 2, 'min_child_samples': 88}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,787] Trial 10 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 296, 'learning_rate': 0.12156720679877171, 'feature_fraction': 0.9548448510535326, 'bagging_fraction': 0.6248284015785855, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,932] Trial 11 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 220, 'learning_rate': 0.140401903673164, 'feature_fraction': 0.4951901558180959, 'bagging_fraction': 0.9988236155338287, 'bagging_freq': 6, 'min_child_samples': 8}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,962] Trial 12 finished with value: 0.8745098039215686 and parameters: {'num_leaves': 219, 'learning_rate': 0.13507587619600087, 'feature_fraction': 0.4135738763792274, 'bagging_fraction': 0.6025683186195876, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:12,997] Trial 13 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 100, 'learning_rate': 0.03383741274463306, 'feature_fraction': 0.5820727570875224, 'bagging_fraction': 0.87591301802105, 'bagging_freq': 7, 'min_child_samples': 26}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,153] Trial 14 finished with value: 0.9686274509803922 and parameters: {'num_leaves': 21, 'learning_rate': 0.149183135632734, 'feature_fraction': 0.49896184115880404, 'bagging_fraction': 0.6479412639392159, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,179] Trial 15 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 275, 'learning_rate': 0.2494896989832286, 'feature_fraction': 0.7085635088141579, 'bagging_fraction': 0.8428903954244036, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,190] Trial 16 finished with value: 0.5 and parameters: {'num_leaves': 191, 'learning_rate': 0.08709842754218985, 'feature_fraction': 0.40162885996906406, 'bagging_fraction': 0.40937154525532166, 'bagging_freq': 6, 'min_child_samples': 50}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,228] Trial 17 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 115, 'learning_rate': 0.16076535788293708, 'feature_fraction': 0.6708986859070472, 'bagging_fraction': 0.9997086193304607, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,277] Trial 18 finished with value: 0.9627450980392157 and parameters: {'num_leaves': 56, 'learning_rate': 0.0539077778240903, 'feature_fraction': 0.9753209144339552, 'bagging_fraction': 0.693968857618553, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,301] Trial 19 finished with value: 0.8313725490196079 and parameters: {'num_leaves': 244, 'learning_rate': 0.012161045967935685, 'feature_fraction': 0.5079010479945733, 'bagging_fraction': 0.9223935079061778, 'bagging_freq': 4, 'min_child_samples': 53}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,439] Trial 20 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 173, 'learning_rate': 0.11144476489013132, 'feature_fraction': 0.7324627940471498, 'bagging_fraction': 0.8325779233468705, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,613] Trial 21 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 174, 'learning_rate': 0.11133557704922892, 'feature_fraction': 0.7290882936804793, 'bagging_fraction': 0.8281002914229297, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,642] Trial 22 finished with value: 0.9372549019607843 and parameters: {'num_leaves': 202, 'learning_rate': 0.13390670091585152, 'feature_fraction': 0.6335099245777183, 'bagging_fraction': 0.6877143584901391, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 0 with value: 0.9843137254901961.
[I 2025-09-17 13:20:13,704] Trial 23 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 142, 'learning_rate': 0.10102701639996146, 'feature_fraction': 0.7782446356745227, 'bagging_fraction': 0.906734287190369, 'bagging_freq': 7, 'min_child_samples': 15}. Best is trial 23 with value: 0.9882352941176471.
[I 2025-09-17 13:20:13,761] Trial 24 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 128, 'learning_rate': 0.07351643423372163, 'feature_fraction': 0.8955851619433116, 'bagging_fraction': 0.912880880402813, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 23 with value: 0.9882352941176471.
[I 2025-09-17 13:20:13,818] Trial 25 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 134, 'learning_rate': 0.06389282111878908, 'feature_fraction': 0.9102725489167608, 'bagging_fraction': 0.9078649834355623, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 23 with value: 0.9882352941176471.
[I 2025-09-17 13:20:13,854] Trial 26 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 138, 'learning_rate': 0.053082283136752235, 'feature_fraction': 0.9151916912118435, 'bagging_fraction': 0.9159784137053201, 'bagging_freq': 7, 'min_child_samples': 32}. Best is trial 23 with value: 0.9882352941176471.
[I 2025-09-17 13:20:13,911] Trial 27 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 150, 'learning_rate': 0.06779763519677512, 'feature_fraction': 0.8959762776044538, 'bagging_fraction': 0.8906462085545495, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:13,939] Trial 28 finished with value: 0.8921568627450981 and parameters: {'num_leaves': 65, 'learning_rate': 0.09458761997277143, 'feature_fraction': 0.7913762036391928, 'bagging_fraction': 0.8034212127230184, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:13,978] Trial 29 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 113, 'learning_rate': 0.07813715032786345, 'feature_fraction': 0.8796441530457829, 'bagging_fraction': 0.9477696547508587, 'bagging_freq': 5, 'min_child_samples': 21}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,014] Trial 30 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 154, 'learning_rate': 0.028392742966903223, 'feature_fraction': 0.9346616586001761, 'bagging_fraction': 0.8708569749290125, 'bagging_freq': 3, 'min_child_samples': 29}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,074] Trial 31 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 121, 'learning_rate': 0.06946646708758936, 'feature_fraction': 0.8952498311824464, 'bagging_fraction': 0.9075502639474144, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,145] Trial 32 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 150, 'learning_rate': 0.04495669397137408, 'feature_fraction': 0.998833459120664, 'bagging_fraction': 0.9662120807978762, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,192] Trial 33 finished with value: 0.9411764705882353 and parameters: {'num_leaves': 129, 'learning_rate': 0.011803486114020843, 'feature_fraction': 0.844033540901805, 'bagging_fraction': 0.9284425020124144, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,218] Trial 34 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 163, 'learning_rate': 0.10118788013316567, 'feature_fraction': 0.8092908085290034, 'bagging_fraction': 0.8818529958404491, 'bagging_freq': 7, 'min_child_samples': 36}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,278] Trial 35 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 96, 'learning_rate': 0.07272355019947437, 'feature_fraction': 0.898673504665699, 'bagging_fraction': 0.7749551094008178, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,309] Trial 36 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 71, 'learning_rate': 0.09034999239729986, 'feature_fraction': 0.7747590172380123, 'bagging_fraction': 0.744443168484592, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,354] Trial 37 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 158, 'learning_rate': 0.04311266122614582, 'feature_fraction': 0.8631771860008294, 'bagging_fraction': 0.81107630360256, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,389] Trial 38 finished with value: 0.9529411764705883 and parameters: {'num_leaves': 108, 'learning_rate': 0.17033640912790296, 'feature_fraction': 0.9348448526164366, 'bagging_fraction': 0.951992047653743, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,411] Trial 39 finished with value: 0.7843137254901961 and parameters: {'num_leaves': 193, 'learning_rate': 0.06072879337256601, 'feature_fraction': 0.8259544781333719, 'bagging_fraction': 0.8562759969983242, 'bagging_freq': 5, 'min_child_samples': 57}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,491] Trial 40 finished with value: 0.9725490196078432 and parameters: {'num_leaves': 147, 'learning_rate': 0.1186338461371525, 'feature_fraction': 0.864643887595309, 'bagging_fraction': 0.904481143624932, 'bagging_freq': 1, 'min_child_samples': 13}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,536] Trial 41 finished with value: 0.9921568627450981 and parameters: {'num_leaves': 119, 'learning_rate': 0.07621565379086365, 'feature_fraction': 0.9075072968722753, 'bagging_fraction': 0.9498161396878936, 'bagging_freq': 7, 'min_child_samples': 22}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,575] Trial 42 finished with value: 0.9764705882352942 and parameters: {'num_leaves': 127, 'learning_rate': 0.08081266135567303, 'feature_fraction': 0.9276424614367881, 'bagging_fraction': 0.9391993197444154, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,635] Trial 43 finished with value: 0.9803921568627452 and parameters: {'num_leaves': 136, 'learning_rate': 0.10156506175810462, 'feature_fraction': 0.9572512894973654, 'bagging_fraction': 0.9764052556802327, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,718] Trial 44 finished with value: 0.9647058823529413 and parameters: {'num_leaves': 85, 'learning_rate': 0.06559815794708924, 'feature_fraction': 0.8861719491246219, 'bagging_fraction': 0.8910303323596179, 'bagging_freq': 7, 'min_child_samples': 10}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,730] Trial 45 finished with value: 0.5 and parameters: {'num_leaves': 166, 'learning_rate': 0.04591174973032377, 'feature_fraction': 0.9881848666632406, 'bagging_fraction': 0.8605213552467352, 'bagging_freq': 6, 'min_child_samples': 76}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,758] Trial 46 finished with value: 0.9607843137254902 and parameters: {'num_leaves': 99, 'learning_rate': 0.12660640293161576, 'feature_fraction': 0.8027342390933037, 'bagging_fraction': 0.9679279737289888, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,849] Trial 47 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 45, 'learning_rate': 0.029851058077964815, 'feature_fraction': 0.8454558767144104, 'bagging_fraction': 0.9287883925387422, 'bagging_freq': 6, 'min_child_samples': 10}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,890] Trial 48 finished with value: 0.9882352941176471 and parameters: {'num_leaves': 143, 'learning_rate': 0.28662044546153453, 'feature_fraction': 0.9559536529164775, 'bagging_fraction': 0.9999718550054917, 'bagging_freq': 7, 'min_child_samples': 25}. Best is trial 27 with value: 0.9921568627450981.
[I 2025-09-17 13:20:14,937] Trial 49 finished with value: 0.9843137254901961 and parameters: {'num_leaves': 182, 'learning_rate': 0.19449289777506823, 'feature_fraction': 0.7573913433311228, 'bagging_fraction': 0.8952539313066573, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 27 with value: 0.9921568627450981.
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.18203
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[89]	valid_0's binary_logloss: 0.176904
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[93]	valid_0's binary_logloss: 0.162267
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[76]	valid_0's binary_logloss: 0.229554
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.198871
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[64]	valid_0's binary_logloss: 0.28776
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[72]	valid_0's binary_logloss: 0.250078
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[57]	valid_0's binary_logloss: 0.215478
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[80]	valid_0's binary_logloss: 0.489106
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.364193
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[61]	valid_0's binary_logloss: 0.239107
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.329355
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[91]	valid_0's binary_logloss: 0.221196
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.290567
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.615981
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[38]	valid_0's binary_logloss: 0.229186
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[58]	valid_0's binary_logloss: 0.210743
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[65]	valid_0's binary_logloss: 0.317686
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[70]	valid_0's binary_logloss: 0.225063
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[83]	valid_0's binary_logloss: 0.208172
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.213945
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.344016
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[87]	valid_0's binary_logloss: 0.211191
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[77]	valid_0's binary_logloss: 0.458531
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.231286
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.386714
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.225137
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.299019
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.460032
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[97]	valid_0's binary_logloss: 0.301306
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.264417
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.317103
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.302784
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[99]	valid_0's binary_logloss: 0.288908
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[51]	valid_0's binary_logloss: 0.651274
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[98]	valid_0's binary_logloss: 0.222164
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.221258
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.240319
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[71]	valid_0's binary_logloss: 0.229563
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[85]	valid_0's binary_logloss: 0.257572
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[1]	valid_0's binary_logloss: 0.691651
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's binary_logloss: 0.310217
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[92]	valid_0's binary_logloss: 0.310264
Training until validation scores don't improve for 50 rounds
Did not meet early stopping. Best iteration is:
[82]	valid_0's binary_logloss: 0.168305
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[42]	valid_0's binary_logloss: 0.232436

3. Training models on full 216-feature dataset (no normalization)...
Training model for P024... (normalize_per_user=False)
Traceback (most recent call last):
  File "/home/iclab/minseo/Ubicomp/scripts/analysis/compare_performance.py", line 251, in <module>
    compare_datasets()
  File "/home/iclab/minseo/Ubicomp/scripts/analysis/compare_performance.py", line 162, in compare_datasets
    results_full_raw, _ = train_user_models('../../selected_users_dataset/full_216features.pkl', normalize_per_user=False)
  File "/home/iclab/minseo/Ubicomp/scripts/analysis/compare_performance.py", line 70, in train_user_models
    X_train, X_test = X_user_scaled[train_idx], X_user_scaled[test_idx]
  File "/home/iclab/miniconda/envs/navsim/lib/python3.9/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/home/iclab/miniconda/envs/navsim/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/home/iclab/miniconda/envs/navsim/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       183, 184, 185, 186, 188, 189, 190, 192, 193, 194],\n      dtype='int64', length=156)] are in the [columns]"
