{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cddd477",
   "metadata": {},
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0893640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0. Imports & Global Config ===\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from tabpfn import TabPFNClassifier  # adjust import if needed\n",
    "import torch, numpy as np, random\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b4f2d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add599e",
   "metadata": {},
   "source": [
    "`stress_binary_personal-full` pickle:\n",
    "\n",
    "- `D-2`: `/var/nfs_share/Overfitting/D-2/Intermediate/stress_binary_personal-full.pkl`\n",
    "- `D-3`: `/var/nfs_share/Overfitting/D-3/Intermediate/stress_binary_personal-full_D#3.pkl`\n",
    "- `D-4`: `/var/nfs_share/Overfitting/D-4/Intermediate/stress_binary_personal-full.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8804b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/var/nfs_share/Overfitting/'\n",
    "\n",
    "FILES = {\n",
    "    'D-2': os.path.join(data_path, 'D-2', 'Intermediate', 'stress_binary_personal-full.pkl'),\n",
    "    'D-3': os.path.join(data_path, 'D-3', 'Intermediate', 'stress_binary_personal-full_D#3.pkl'),\n",
    "    'D-4': os.path.join(data_path, 'D-4', 'Intermediate', 'stress_binary_personal-full.pkl'),\n",
    "}\n",
    "\n",
    "def load_and_attach(path, dataset_tag):\n",
    "    df, y, groups, t, datetimes = pd.read_pickle(path)\n",
    "\n",
    "    # meta (including dataset tag) but we will NOT keep label inside X\n",
    "    meta = pd.DataFrame({\n",
    "        'META#dataset': dataset_tag,\n",
    "        'PIF#participantID': groups,\n",
    "        'PIF#time_offset': t,\n",
    "        'PIF#timestamp': datetimes,\n",
    "    })\n",
    "\n",
    "    assert len(df) == len(meta), f\"Row mismatch in {dataset_tag}\"\n",
    "    out = pd.concat(\n",
    "        [meta.reset_index(drop=True), df.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # meta first, then sorted feature columns\n",
    "    meta_cols = ['META#dataset', 'PIF#participantID', 'PIF#time_offset', 'PIF#timestamp']\n",
    "\n",
    "    feature_cols = sorted(\n",
    "        c for c in out.columns\n",
    "        if c not in meta_cols)\n",
    "\n",
    "    X = out[meta_cols + feature_cols]\n",
    "    y = pd.Series(y, name='PIF#stress_label')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ---- Load datasets ----\n",
    "df_1, df_y_1 = load_and_attach(FILES['D-2'], 'D-2')\n",
    "df_2, df_y_2 = load_and_attach(FILES['D-3'], 'D-3')\n",
    "df_3, df_y_3 = load_and_attach(FILES['D-4'], 'D-4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359fd543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the overlap columns\n",
    "META_COLS = ['META#dataset', 'PIF#participantID', 'PIF#time_offset', 'PIF#timestamp']\n",
    "\n",
    "def get_common_cols(dfs):\n",
    "    feature_sets = [\n",
    "        set(df.columns) - set(META_COLS)\n",
    "        for df in dfs\n",
    "    ]\n",
    "    common = sorted(set.intersection(*feature_sets))\n",
    "    return META_COLS + common\n",
    "\n",
    "# get overlap\n",
    "COMMON_COLS = get_common_cols([df_1, df_2, df_3])\n",
    "\n",
    "# aligned datasets (same columns, same order)\n",
    "df_1_over = df_1[COMMON_COLS]\n",
    "df_2_over = df_2[COMMON_COLS]\n",
    "df_3_over = df_3[COMMON_COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2acda754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10075, 5021), (20831, 5021), (21619, 5021))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_over.shape, df_2_over.shape, df_3_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ec17a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>META#dataset</th>\n",
       "      <th>PIF#participantID</th>\n",
       "      <th>PIF#time_offset</th>\n",
       "      <th>PIF#timestamp</th>\n",
       "      <th>ACE_BCC#ASC#ImmediatePast_15</th>\n",
       "      <th>ACE_BCC#ASC#ImmediatePast_30</th>\n",
       "      <th>ACE_BCC#ASC#YesterdayAfternoon</th>\n",
       "      <th>ACE_BCC#ASC#YesterdayDawn</th>\n",
       "      <th>ACE_BCC#ASC#YesterdayEvening</th>\n",
       "      <th>ACE_BCC#ASC#YesterdayLateAfternoon</th>\n",
       "      <th>...</th>\n",
       "      <th>WLS#ETP##YesterdayMorning</th>\n",
       "      <th>WLS#ETP##YesterdayNight</th>\n",
       "      <th>WLS#ETP#_TodayAfternoon</th>\n",
       "      <th>WLS#ETP#_TodayDawn</th>\n",
       "      <th>WLS#ETP#_TodayEvening</th>\n",
       "      <th>WLS#ETP#_TodayLateAfternoon</th>\n",
       "      <th>WLS#ETP#_TodayMorning</th>\n",
       "      <th>WLS#ETP#_TodayNight</th>\n",
       "      <th>WLS#VAL=BT_OFF</th>\n",
       "      <th>WLS#VAL=BT_ON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P033</td>\n",
       "      <td>40609.415</td>\n",
       "      <td>2020-02-08 11:16:49.415000+09:00</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.949999</td>\n",
       "      <td>9.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P033</td>\n",
       "      <td>47486.022</td>\n",
       "      <td>2020-02-08 13:11:26.022000+09:00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.949999</td>\n",
       "      <td>9.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P033</td>\n",
       "      <td>50006.386</td>\n",
       "      <td>2020-02-08 13:53:26.386000+09:00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.949999</td>\n",
       "      <td>9.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P033</td>\n",
       "      <td>58937.042</td>\n",
       "      <td>2020-02-08 16:22:17.042000+09:00</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.949999</td>\n",
       "      <td>9.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P033</td>\n",
       "      <td>62263.538</td>\n",
       "      <td>2020-02-08 17:17:43.538000+09:00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.949999</td>\n",
       "      <td>9.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P138</td>\n",
       "      <td>4310332.717</td>\n",
       "      <td>2020-03-28 21:18:52.717000+09:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.879999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10071</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P138</td>\n",
       "      <td>4364048.818</td>\n",
       "      <td>2020-03-29 12:14:08.818000+09:00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.14</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.059999</td>\n",
       "      <td>4.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10072</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P138</td>\n",
       "      <td>4379381.637</td>\n",
       "      <td>2020-03-29 16:29:41.637000+09:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.059999</td>\n",
       "      <td>4.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10073</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P138</td>\n",
       "      <td>4443941.837</td>\n",
       "      <td>2020-03-30 10:25:41.837000+09:00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.740000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10074</th>\n",
       "      <td>D-2</td>\n",
       "      <td>P138</td>\n",
       "      <td>4451319.357</td>\n",
       "      <td>2020-03-30 12:28:39.357000+09:00</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.740000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10075 rows × 5021 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      META#dataset PIF#participantID  PIF#time_offset  \\\n",
       "0              D-2              P033        40609.415   \n",
       "1              D-2              P033        47486.022   \n",
       "2              D-2              P033        50006.386   \n",
       "3              D-2              P033        58937.042   \n",
       "4              D-2              P033        62263.538   \n",
       "...            ...               ...              ...   \n",
       "10070          D-2              P138      4310332.717   \n",
       "10071          D-2              P138      4364048.818   \n",
       "10072          D-2              P138      4379381.637   \n",
       "10073          D-2              P138      4443941.837   \n",
       "10074          D-2              P138      4451319.357   \n",
       "\n",
       "                         PIF#timestamp  ACE_BCC#ASC#ImmediatePast_15  \\\n",
       "0     2020-02-08 11:16:49.415000+09:00                          3.06   \n",
       "1     2020-02-08 13:11:26.022000+09:00                          0.34   \n",
       "2     2020-02-08 13:53:26.386000+09:00                          1.19   \n",
       "3     2020-02-08 16:22:17.042000+09:00                          1.35   \n",
       "4     2020-02-08 17:17:43.538000+09:00                          0.40   \n",
       "...                                ...                           ...   \n",
       "10070 2020-03-28 21:18:52.717000+09:00                          0.00   \n",
       "10071 2020-03-29 12:14:08.818000+09:00                          0.16   \n",
       "10072 2020-03-29 16:29:41.637000+09:00                          0.00   \n",
       "10073 2020-03-30 10:25:41.837000+09:00                          0.88   \n",
       "10074 2020-03-30 12:28:39.357000+09:00                          2.78   \n",
       "\n",
       "       ACE_BCC#ASC#ImmediatePast_30  ACE_BCC#ASC#YesterdayAfternoon  \\\n",
       "0                              3.86                        0.000000   \n",
       "1                              1.05                        0.000000   \n",
       "2                              2.90                        0.000000   \n",
       "3                              1.64                        0.000000   \n",
       "4                              1.44                        0.000000   \n",
       "...                             ...                             ...   \n",
       "10070                          0.28                        8.879999   \n",
       "10071                          4.14                        2.680000   \n",
       "10072                          0.00                        2.680000   \n",
       "10073                          0.88                        0.700000   \n",
       "10074                          2.78                        0.700000   \n",
       "\n",
       "       ACE_BCC#ASC#YesterdayDawn  ACE_BCC#ASC#YesterdayEvening  \\\n",
       "0                            0.0                     16.949999   \n",
       "1                            0.0                     16.949999   \n",
       "2                            0.0                     16.949999   \n",
       "3                            0.0                     16.949999   \n",
       "4                            0.0                     16.949999   \n",
       "...                          ...                           ...   \n",
       "10070                        0.0                      1.160000   \n",
       "10071                        0.0                      4.059999   \n",
       "10072                        0.0                      4.059999   \n",
       "10073                        0.0                      5.740000   \n",
       "10074                        0.0                      5.740000   \n",
       "\n",
       "       ACE_BCC#ASC#YesterdayLateAfternoon  ...  WLS#ETP##YesterdayMorning  \\\n",
       "0                                    9.26  ...                        0.0   \n",
       "1                                    9.26  ...                        0.0   \n",
       "2                                    9.26  ...                        0.0   \n",
       "3                                    9.26  ...                        0.0   \n",
       "4                                    9.26  ...                        0.0   \n",
       "...                                   ...  ...                        ...   \n",
       "10070                                0.00  ...                        0.0   \n",
       "10071                                4.22  ...                        0.0   \n",
       "10072                                4.22  ...                        0.0   \n",
       "10073                                0.02  ...                        0.0   \n",
       "10074                                0.02  ...                        0.0   \n",
       "\n",
       "       WLS#ETP##YesterdayNight  WLS#ETP#_TodayAfternoon  WLS#ETP#_TodayDawn  \\\n",
       "0                          0.0                      0.0                 0.0   \n",
       "1                          0.0                      0.0                 0.0   \n",
       "2                          0.0                      0.0                 0.0   \n",
       "3                          0.0                      0.0                 0.0   \n",
       "4                          0.0                      0.0                 0.0   \n",
       "...                        ...                      ...                 ...   \n",
       "10070                      0.0                      0.0                 0.0   \n",
       "10071                      0.0                      0.0                 0.0   \n",
       "10072                      0.0                      0.0                 0.0   \n",
       "10073                      0.0                      0.0                 0.0   \n",
       "10074                      0.0                      0.0                 0.0   \n",
       "\n",
       "       WLS#ETP#_TodayEvening  WLS#ETP#_TodayLateAfternoon  \\\n",
       "0                        0.0                          0.0   \n",
       "1                        0.0                          0.0   \n",
       "2                        0.0                          0.0   \n",
       "3                        0.0                          0.0   \n",
       "4                        0.0                          0.0   \n",
       "...                      ...                          ...   \n",
       "10070                    0.0                          0.0   \n",
       "10071                    0.0                          0.0   \n",
       "10072                    0.0                          0.0   \n",
       "10073                    0.0                          0.0   \n",
       "10074                    0.0                          0.0   \n",
       "\n",
       "       WLS#ETP#_TodayMorning  WLS#ETP#_TodayNight  WLS#VAL=BT_OFF  \\\n",
       "0                        0.0                  0.0           False   \n",
       "1                        0.0                  0.0           False   \n",
       "2                        0.0                  0.0           False   \n",
       "3                        0.0                  0.0           False   \n",
       "4                        0.0                  0.0           False   \n",
       "...                      ...                  ...             ...   \n",
       "10070                    0.0                  0.0           False   \n",
       "10071                    0.0                  0.0           False   \n",
       "10072                    0.0                  0.0           False   \n",
       "10073                    0.0                  0.0           False   \n",
       "10074                    0.0                  0.0           False   \n",
       "\n",
       "       WLS#VAL=BT_ON  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  \n",
       "...              ...  \n",
       "10070          False  \n",
       "10071          False  \n",
       "10072          False  \n",
       "10073          False  \n",
       "10074          False  \n",
       "\n",
       "[10075 rows x 5021 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee536c",
   "metadata": {},
   "source": [
    "##  Baseline models benchmarking in D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "408ab5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tabpfn import TabPFNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7281b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns that are identifiers or targets\n",
    "drop_cols = [\n",
    "    'PIF#participantID', \n",
    "    'PIF#timestamp', \n",
    "    'PIF#participationStartTimestamp', \n",
    "    'PIF#time_offset', \n",
    "    'META#dataset', \n",
    "    '__src',\n",
    "    'PIF#stress_label'\n",
    "]\n",
    "\n",
    "# Create your Feature set (X) and Target (y)\n",
    "X = df_3_over.drop(columns=drop_cols, errors='ignore') # errors='ignore' prevents crash if col is missing\n",
    "y = df_y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d51a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (14484, 5016)\n",
      "Test shape : (7135, 5016)\n"
     ]
    }
   ],
   "source": [
    "# === 1. Train–Test Split ===\n",
    "\n",
    "# If it's classification, strongly prefer stratified splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.33,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # remove if regression, but for your case it's prob. classification\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee3f764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TabPFN': TabPFNClassifier(device='cuda', ignore_pretraining_limits=True),\n",
       " 'MLP': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('mlpclassifier',\n",
       "                  MLPClassifier(batch_size=256, hidden_layer_sizes=(256, 128),\n",
       "                                random_state=42))]),\n",
       " 'XGBoost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=None, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "               n_jobs=None, num_parallel_tree=None, random_state=42, ...)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 2. Define Models ===\n",
    "def get_models():\n",
    "    models = {}\n",
    "\n",
    "    # 1) TabPFN\n",
    "    models[\"TabPFN\"] = TabPFNClassifier(\n",
    "        device=\"cuda\",\n",
    "        ignore_pretraining_limits=True,\n",
    "    )\n",
    "\n",
    "    # 2) MLP (with scaling in a pipeline)\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        batch_size=256,\n",
    "        learning_rate_init=1e-3,\n",
    "        alpha=1e-4,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "\n",
    "    models[\"MLP\"] = make_pipeline(\n",
    "        StandardScaler(),  # with_mean=False if X is sparse\n",
    "        mlp\n",
    "    )\n",
    "\n",
    "    # 3) XGBoost\n",
    "    models[\"XGBoost\"] = XGBClassifier(\n",
    "        objective=\"binary:logistic\",  # change if multi-class\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    return models\n",
    "\n",
    "models = get_models()\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec4b4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Evaluation Utilities ===\n",
    "\n",
    "def compute_metrics(y_true, y_pred, y_proba=None):\n",
    "    \"\"\"Return a dict of key metrics for classification.\"\"\"\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    metrics[\"f1_macro\"] = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    # ROC-AUC only if we have probabilities\n",
    "    if y_proba is not None:\n",
    "        n_classes = len(np.unique(y_true))\n",
    "        try:\n",
    "            if n_classes == 2:\n",
    "                # y_proba is (N,2) or (N,)\n",
    "                if y_proba.ndim == 2:\n",
    "                    y_score = y_proba[:, 1]\n",
    "                else:\n",
    "                    y_score = y_proba\n",
    "                metrics[\"roc_auc\"] = roc_auc_score(y_true, y_score)\n",
    "            else:\n",
    "                # multiclass\n",
    "                metrics[\"roc_auc_ovr\"] = roc_auc_score(\n",
    "                    y_true, y_proba, multi_class=\"ovr\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            # Don't crash experiment because of ROC-AUC issues\n",
    "            metrics[\"roc_auc_error\"] = str(e)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec50390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, verbose=False):\n",
    "    \"\"\"Fit model, predict, compute metrics, and (optionally) print a report.\"\"\"\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Predicting with {name}...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Probabilities if available\n",
    "    y_proba = None\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        # some models use decision_function instead of predict_proba\n",
    "        y_proba = model.decision_function(X_test)\n",
    "\n",
    "    metrics = compute_metrics(y_test, y_pred, y_proba=y_proba)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n{name} – classification report\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"{name} – confusion matrix\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57fef8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training TabPFN ===\n",
      "Predicting with TabPFN...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 23.64 GiB of which 1.04 GiB is free. Process 256521 has 21.71 GiB memory in use. Including non-PyTorch memory, this process has 904.00 MiB memory in use. Of the allocated memory 368.77 MiB is allocated by PyTorch, and 73.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 6\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# set False if you don’t want full report each time\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: name}\n\u001b[1;32m     14\u001b[0m     row\u001b[38;5;241m.\u001b[39mupdate(metrics)\n",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(name, model, X_train, y_train, X_test, y_test, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Probabilities if available\u001b[39;00m\n\u001b[1;32m     10\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:288\u001b[0m, in \u001b[0;36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_call_with_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_names\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:332\u001b[0m, in \u001b[0;36m_safe_call_with_telemetry\u001b[0;34m(func, args, kwargs, model_method, param_names)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# Step 2: Run the actual function\u001b[39;00m\n\u001b[1;32m    331\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 332\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m duration_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Step 3: Send telemetry event\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/classifier.py:1029\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;129m@track_model_call\u001b[39m(model_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: XType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict the class labels for the provided input samples.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m        The predicted class labels as a NumPy array.\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1029\u001b[0m     probas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(probas, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_encoder_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoder_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/classifier.py:1104\u001b[0m, in \u001b[0;36mTabPFNClassifier._predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;129m@config_context\u001b[39m(transform_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: XType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict the probabilities of the classes for the provided input samples.\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \n\u001b[1;32m   1096\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;03m        Shape (n_samples, n_classes).\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m     probas \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m   1105\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m     probas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_reweight_probas(probas\u001b[38;5;241m=\u001b[39mprobas)\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_config_\u001b[38;5;241m.\u001b[39mUSE_SKLEARN_16_DECIMAL_PRECISION:\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/classifier.py:1012\u001b[0m, in \u001b[0;36mTabPFNClassifier._raw_predict\u001b[0;34m(self, X, return_logits, return_raw_logits)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     X \u001b[38;5;241m=\u001b[39m fix_dtypes(X, cat_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minferred_categorical_indices_)\n\u001b[1;32m   1010\u001b[0m     X \u001b[38;5;241m=\u001b[39m process_text_na_dataframe(X, ord_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor_)\n\u001b[0;32m-> 1012\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_inference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_raw_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_raw_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/classifier.py:1331\u001b[0m, in \u001b[0;36mTabPFNClassifier.forward\u001b[0;34m(self, X, use_inference_mode, return_logits, return_raw_logits)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor_\u001b[38;5;241m.\u001b[39muse_torch_inference_mode(use_inference\u001b[38;5;241m=\u001b[39muse_inference_mode)\n\u001b[1;32m   1330\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output, config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor_\u001b[38;5;241m.\u001b[39miter_outputs(\n\u001b[1;32m   1332\u001b[0m     X,\n\u001b[1;32m   1333\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices_,\n\u001b[1;32m   1334\u001b[0m     autocast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_autocast_,\n\u001b[1;32m   1335\u001b[0m ):\n\u001b[1;32m   1336\u001b[0m     original_ndim \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# This block correctly handles both single configs and lists of configs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/inference.py:547\u001b[0m, in \u001b[0;36mInferenceEngineCachePreprocessing.iter_outputs\u001b[0;34m(self, X, devices, autocast, only_return_standard_out)\u001b[0m\n\u001b[1;32m    531\u001b[0m model_forward_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m     partial(\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sorted_indices\n\u001b[1;32m    544\u001b[0m )\n\u001b[1;32m    545\u001b[0m outputs \u001b[38;5;241m=\u001b[39m parallel_execute(devices, model_forward_functions)\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outputs, sorted_indices):\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _move_and_squeeze_output(output, devices[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensemble_configs[i]\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode:\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/parallel_execute.py:61\u001b[0m, in \u001b[0;36mparallel_execute\u001b[0;34m(devices, functions)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the given functions in parallel across `devices`.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03mThe function evaluations are parallelised using Python threads, so this will only\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    as `functions`.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(devices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# If we only have one device then just use the current thread to avoid overhead.\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _execute_in_current_thread(devices[\u001b[38;5;241m0\u001b[39m], functions)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _execute_with_multithreading(devices, functions)\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/parallel_execute.py:70\u001b[0m, in \u001b[0;36m_execute_in_current_thread\u001b[0;34m(device, functions)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_execute_in_current_thread\u001b[39m(\n\u001b[1;32m     67\u001b[0m     device: torch\u001b[38;5;241m.\u001b[39mdevice, functions: Iterable[ParallelFunction[R_co]]\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[R_co]:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m function \u001b[38;5;129;01min\u001b[39;00m functions:\n\u001b[0;32m---> 70\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_parallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/inference.py:592\u001b[0m, in \u001b[0;36mInferenceEngineCachePreprocessing._call_model\u001b[0;34m(self, device, is_parallel, X_train, X_test, y_train, cat_ix, autocast, only_return_standard_out, model_index, save_peak_mem)\u001b[0m\n\u001b[1;32m    586\u001b[0m batched_cat_ix \u001b[38;5;241m=\u001b[39m [cat_ix]\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[1;32m    589\u001b[0m     get_autocast_context(device, enabled\u001b[38;5;241m=\u001b[39mautocast),\n\u001b[1;32m    590\u001b[0m     torch\u001b[38;5;241m.\u001b[39minference_mode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode),\n\u001b[1;32m    591\u001b[0m ):\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_return_standard_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_return_standard_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_inds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched_cat_ix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/architectures/base/transformer.py:518\u001b[0m, in \u001b[0;36mPerFeatureTransformer.forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m    516\u001b[0m     x[k] \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(x[k], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb s f n -> s (b f) n\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    517\u001b[0m embedded_x \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_encoders_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms (b f) e -> b s f e\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m     b\u001b[38;5;241m=\u001b[39membedded_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    526\u001b[0m )  \u001b[38;5;66;03m# b s f 1 -> b s f e\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x\n\u001b[1;32m    529\u001b[0m embedded_x, embedded_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_embeddings(\n\u001b[1;32m    530\u001b[0m     embedded_x,\n\u001b[1;32m    531\u001b[0m     embedded_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m     ),\n\u001b[1;32m    541\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/architectures/base/encoders.py:353\u001b[0m, in \u001b[0;36mSequentialEncoder.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39min_keys[\u001b[38;5;241m0\u001b[39m]: \u001b[38;5;28minput\u001b[39m}\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/architectures/base/encoders.py:460\u001b[0m, in \u001b[0;36mSeqEncStep.forward\u001b[0;34m(self, state, cache_trainset_representation, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_eval_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_trainset_representation:\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_trainset_representation\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/tabpfn/architectures/base/encoders.py:525\u001b[0m, in \u001b[0;36mLinearInputEncoderStep._transform\u001b[0;34m(self, *x, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# Ensure input tensor dtype matches the layer's weight dtype\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# Since this layer gets input from the outside we verify the dtype\u001b[39;00m\n\u001b[1;32m    523\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,)\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/navsim/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 23.64 GiB of which 1.04 GiB is free. Process 256521 has 21.71 GiB memory in use. Including non-PyTorch memory, this process has 904.00 MiB memory in use. Of the allocated memory 368.77 MiB is allocated by PyTorch, and 73.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# === 4. Run Benchmark (Single Train/Test Split) ===\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    metrics = evaluate_model(\n",
    "        name,\n",
    "        model,\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        verbose=True   # set False if you don’t want full report each time\n",
    "    )\n",
    "    row = {\"model\": name}\n",
    "    row.update(metrics)\n",
    "    results.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index(\"model\")\n",
    "results_df\n",
    "\n",
    "# Optional: sort by accuracy or any metric\n",
    "results_df.sort_values(\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ddd14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01866d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1/5 =====\n",
      "\n",
      "=== Training TabPFN (fold 1) ===\n",
      "Predicting with TabPFN (fold 1)...\n",
      "\n",
      "=== Training MLP (fold 1) ===\n",
      "Predicting with MLP (fold 1)...\n",
      "\n",
      "=== Training XGBoost (fold 1) ===\n",
      "Predicting with XGBoost (fold 1)...\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "\n",
      "=== Training TabPFN (fold 2) ===\n",
      "Predicting with TabPFN (fold 2)...\n",
      "\n",
      "=== Training MLP (fold 2) ===\n",
      "Predicting with MLP (fold 2)...\n",
      "\n",
      "=== Training XGBoost (fold 2) ===\n",
      "Predicting with XGBoost (fold 2)...\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "\n",
      "=== Training TabPFN (fold 3) ===\n",
      "Predicting with TabPFN (fold 3)...\n"
     ]
    }
   ],
   "source": [
    "# === 5. Optional: K-Fold Cross-Validation Benchmark ===\n",
    "\n",
    "def crossval_benchmark(models, X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
    "        print(f\"\\n===== Fold {fold_idx}/{n_splits} =====\")\n",
    "\n",
    "        X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        for name, base_model in models.items():\n",
    "            # Important: clone models per fold to avoid state leakage\n",
    "            from sklearn.base import clone\n",
    "            model = clone(base_model)\n",
    "\n",
    "            metrics = evaluate_model(\n",
    "                f\"{name} (fold {fold_idx})\",\n",
    "                model,\n",
    "                X_tr, y_tr,\n",
    "                X_te, y_te,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            row = {\n",
    "                \"model\": name,\n",
    "                \"fold\": fold_idx,\n",
    "            }\n",
    "            row.update(metrics)\n",
    "            all_rows.append(row)\n",
    "\n",
    "    cv_df = pd.DataFrame(all_rows)\n",
    "    summary = (\n",
    "        cv_df\n",
    "        .groupby(\"model\")\n",
    "        .agg([\"mean\", \"std\"])\n",
    "        .round(4)\n",
    "    )\n",
    "\n",
    "    return cv_df, summary\n",
    "\n",
    "\n",
    "# Run CV benchmark (can be expensive, esp. TabPFN)\n",
    "cv_results, cv_summary = crossval_benchmark(models, X, y, n_splits=5)\n",
    "\n",
    "cv_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06013286",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8700dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
